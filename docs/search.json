[
  {
    "objectID": "blog/2023/12/02/index.knit.html",
    "href": "blog/2023/12/02/index.knit.html",
    "title": "Customization of Seurat plots using ggplot2",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\nlibrary(Seurat)\nlibrary(SingleR)\nlibrary(ggrepel)\nlibrary(ggthemes)\nlibrary(ggnewscale)\nlibrary(tidyverse)\nlibrary(scCustomize)\nlibrary(viridis)\nlibrary(RColorBrewer)\nlibrary(gridExtra)\nlibrary(ComplexHeatmap)\nlibrary(dittoSeq)\nlibrary(Scillus)"
  },
  {
    "objectID": "blog/2023/12/02/index.knit.html#packages",
    "href": "blog/2023/12/02/index.knit.html#packages",
    "title": "Customization of Seurat plots using ggplot2",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\nlibrary(Seurat)\nlibrary(SingleR)\nlibrary(ggrepel)\nlibrary(ggthemes)\nlibrary(ggnewscale)\nlibrary(tidyverse)\nlibrary(scCustomize)\nlibrary(viridis)\nlibrary(RColorBrewer)\nlibrary(gridExtra)\nlibrary(ComplexHeatmap)\nlibrary(dittoSeq)\nlibrary(Scillus)"
  },
  {
    "objectID": "blog/2023/12/02/index.knit.html#umap",
    "href": "blog/2023/12/02/index.knit.html#umap",
    "title": "Customization of Seurat plots using ggplot2",
    "section": "UMAP",
    "text": "UMAP\n\nLoad Seurat object\n\n### Load data\nload(here(\"projects\", \"2023_scRNA_Seurat\", \"pbmc_tutorial_singleR.RData\"))\nload(here(\"projects\", \"2023_scRNA_Seurat\", \"sce.anno.RData\"))\nload(here(\"projects\", \"2023_scRNA_Seurat\", \"all_markers.RData\"))\ntop5 &lt;- all_markers |&gt; group_by(cluster) |&gt; top_n(5, avg_log2FC)\n\n### Check data\nhead(pbmc, 2)\n##                  orig.ident nCount_RNA nFeature_RNA percent.mt percent.HB\n## AAACATACAACCAC-1     pbmc3k       2419          779   3.017776          0\n## AAACATTGAGCTAC-1     pbmc3k       4903         1352   3.793596          0\n##                  RNA_snn_res.0.5 seurat_clusters  labels\n## AAACATACAACCAC-1               0               0 T_cells\n## AAACATTGAGCTAC-1               3               3  B_cell\nhead(sce2, 2)\n##                         orig.ident nCount_RNA nFeature_RNA percent.mt\n## K16733_AAACATACTCGTTT-1     K16733       2464          965  12.662338\n## K16733_AAAGCAGAACGTTG-1     K16733       7145         1919   2.449265\n##                         percent.rp percent.HB RNA_snn_res.0.5 seurat_clusters\n## K16733_AAACATACTCGTTT-1   13.35227          0              11              11\n## K16733_AAAGCAGAACGTTG-1   36.72498          0               3               3\n##                         sampel sample group    globalC       anno\n## K16733_AAACATACTCGTTT-1    P01    P01    PT        Epi        Epi\n## K16733_AAAGCAGAACGTTG-1    P01    P01    PT Fibroblast Fibroblast\nhead(top5)\n## # A tibble: 6 × 7\n## # Groups:   cluster [2]\n##       p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene      \n##       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;chr&gt;     \n## 1 2.43e- 67       3.05 0.172 0.079 1.26e- 62 0       REG4      \n## 2 3.38e- 51       3.19 0.069 0.019 1.76e- 46 0       BPIFB1    \n## 3 5.32e- 30       3.71 0.031 0.007 2.76e- 25 0       FABP1     \n## 4 6.37e- 21       2.79 0.018 0.003 3.31e- 16 0       SLC9A4    \n## 5 1.65e- 20       2.70 0.017 0.003 8.56e- 16 0       AC073218.2\n## 6 2.51e-112       3.57 0.132 0.023 1.30e-107 1       SPRR1A\n\n\n\nDefault seurat UMAP\n\n# View the UMAP\nDimPlot(pbmc, group.by = c(\"seurat_clusters\", \"labels\"), reduction = \"umap\")\n\n\n\n\n\n\n\n\n\n\nUMAP with ggplot2\n\n# Find the UMAP data\nstr(pbmc)\n## Formal class 'Seurat' [package \"SeuratObject\"] with 13 slots\n##   ..@ assays      :List of 1\n##   .. ..$ RNA:Formal class 'Assay' [package \"SeuratObject\"] with 8 slots\n##   .. .. .. ..@ counts       :Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n##   .. .. .. .. .. ..@ i       : int [1:2238732] 29 73 80 148 163 184 186 227 229 230 ...\n##   .. .. .. .. .. ..@ p       : int [1:2639] 0 779 2131 3260 4220 4741 5522 6304 7094 7626 ...\n##   .. .. .. .. .. ..@ Dim     : int [1:2] 13714 2638\n##   .. .. .. .. .. ..@ Dimnames:List of 2\n##   .. .. .. .. .. .. ..$ : chr [1:13714] \"AL627309.1\" \"AP006222.2\" \"RP11-206L10.2\" \"RP11-206L10.9\" ...\n##   .. .. .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. .. ..@ x       : num [1:2238732] 1 1 2 1 1 1 1 41 1 1 ...\n##   .. .. .. .. .. ..@ factors : list()\n##   .. .. .. ..@ data         :Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n##   .. .. .. .. .. ..@ i       : int [1:2238732] 29 73 80 148 163 184 186 227 229 230 ...\n##   .. .. .. .. .. ..@ p       : int [1:2639] 0 779 2131 3260 4220 4741 5522 6304 7094 7626 ...\n##   .. .. .. .. .. ..@ Dim     : int [1:2] 13714 2638\n##   .. .. .. .. .. ..@ Dimnames:List of 2\n##   .. .. .. .. .. .. ..$ : chr [1:13714] \"AL627309.1\" \"AP006222.2\" \"RP11-206L10.2\" \"RP11-206L10.9\" ...\n##   .. .. .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. .. ..@ x       : num [1:2238732] 1.64 1.64 2.23 1.64 1.64 ...\n##   .. .. .. .. .. ..@ factors : list()\n##   .. .. .. ..@ scale.data   : num [1:2000, 1:2638] -0.8556 -0.2773 1.4947 -0.0463 -0.4658 ...\n##   .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. ..$ : chr [1:2000] \"ISG15\" \"CPSF3L\" \"MRPL20\" \"ATAD3C\" ...\n##   .. .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. ..@ assay.orig   : NULL\n##   .. .. .. ..@ var.features : chr [1:2000] \"PPBP\" \"LYZ\" \"S100A9\" \"IGLL5\" ...\n##   .. .. .. ..@ meta.features:'data.frame':   13714 obs. of  5 variables:\n##   .. .. .. .. ..$ vst.mean                 : num [1:13714] 0.00341 0.00114 0.0019 0.00114 0.00682 ...\n##   .. .. .. .. ..$ vst.variance             : num [1:13714] 0.0034 0.00114 0.00189 0.00114 0.00678 ...\n##   .. .. .. .. ..$ vst.variance.expected    : num [1:13714] 0.00365 0.00114 0.00197 0.00114 0.00748 ...\n##   .. .. .. .. ..$ vst.variance.standardized: num [1:13714] 0.933 0.992 0.963 0.992 0.906 ...\n##   .. .. .. .. ..$ vst.variable             : logi [1:13714] FALSE FALSE FALSE FALSE FALSE FALSE ...\n##   .. .. .. ..@ misc         : list()\n##   .. .. .. ..@ key          : chr \"rna_\"\n##   ..@ meta.data   :'data.frame': 2638 obs. of  8 variables:\n##   .. ..$ orig.ident     : Factor w/ 1 level \"pbmc3k\": 1 1 1 1 1 1 1 1 1 1 ...\n##   .. ..$ nCount_RNA     : num [1:2638] 2419 4903 3147 2639 980 ...\n##   .. ..$ nFeature_RNA   : int [1:2638] 779 1352 1129 960 521 781 782 790 532 550 ...\n##   .. ..$ percent.mt     : num [1:2638] 3.02 3.79 0.89 1.74 1.22 ...\n##   .. ..$ percent.HB     : num [1:2638] 0 0 0 0 0 0 0 0 0 0 ...\n##   .. ..$ RNA_snn_res.0.5: Factor w/ 9 levels \"0\",\"1\",\"2\",\"3\",..: 1 4 3 2 7 3 5 5 5 6 ...\n##   .. ..$ seurat_clusters: Factor w/ 9 levels \"0\",\"1\",\"2\",\"3\",..: 1 4 3 2 7 3 5 5 5 6 ...\n##   .. ..$ labels         : chr [1:2638] \"T_cells\" \"B_cell\" \"T_cells\" \"Monocyte\" ...\n##   ..@ active.assay: chr \"RNA\"\n##   ..@ active.ident: Factor w/ 9 levels \"0\",\"1\",\"2\",\"3\",..: 1 4 3 2 7 3 5 5 5 6 ...\n##   .. ..- attr(*, \"names\")= chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   ..@ graphs      :List of 2\n##   .. ..$ RNA_nn :Formal class 'Graph' [package \"SeuratObject\"] with 7 slots\n##   .. .. .. ..@ assay.used: chr \"RNA\"\n##   .. .. .. ..@ i         : int [1:52760] 0 6 102 203 213 229 292 451 547 618 ...\n##   .. .. .. ..@ p         : int [1:2639] 0 33 50 64 80 87 103 139 155 162 ...\n##   .. .. .. ..@ Dim       : int [1:2] 2638 2638\n##   .. .. .. ..@ Dimnames  :List of 2\n##   .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. ..@ x         : num [1:52760] 1 1 1 1 1 1 1 1 1 1 ...\n##   .. .. .. ..@ factors   : list()\n##   .. ..$ RNA_snn:Formal class 'Graph' [package \"SeuratObject\"] with 7 slots\n##   .. .. .. ..@ assay.used: chr \"RNA\"\n##   .. .. .. ..@ i         : int [1:194424] 0 6 102 136 187 203 229 292 421 446 ...\n##   .. .. .. ..@ p         : int [1:2639] 0 62 120 170 240 287 379 453 533 573 ...\n##   .. .. .. ..@ Dim       : int [1:2] 2638 2638\n##   .. .. .. ..@ Dimnames  :List of 2\n##   .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. ..@ x         : num [1:194424] 1 0.1111 0.1765 0.0811 0.0811 ...\n##   .. .. .. ..@ factors   : list()\n##   ..@ neighbors   : list()\n##   ..@ reductions  :List of 3\n##   .. ..$ pca :Formal class 'DimReduc' [package \"SeuratObject\"] with 9 slots\n##   .. .. .. ..@ cell.embeddings           : num [1:2638, 1:50] -5.84 -2.56 -1.64 13.29 -2.15 ...\n##   .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. .. ..$ : chr [1:50] \"PC_1\" \"PC_2\" \"PC_3\" \"PC_4\" ...\n##   .. .. .. ..@ feature.loadings          : num [1:2000, 1:50] 0.01091 0.11663 0.11569 -0.00853 -0.01632 ...\n##   .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. ..$ : chr [1:2000] \"PPBP\" \"LYZ\" \"S100A9\" \"IGLL5\" ...\n##   .. .. .. .. .. ..$ : chr [1:50] \"PC_1\" \"PC_2\" \"PC_3\" \"PC_4\" ...\n##   .. .. .. ..@ feature.loadings.projected: num[0 , 0 ] \n##   .. .. .. ..@ assay.used                : chr \"RNA\"\n##   .. .. .. ..@ global                    : logi FALSE\n##   .. .. .. ..@ stdev                     : num [1:50] 7.05 4.5 3.87 3.75 3.15 ...\n##   .. .. .. ..@ jackstraw                 :Formal class 'JackStrawData' [package \"SeuratObject\"] with 4 slots\n##   .. .. .. .. .. ..@ empirical.p.values     : num [1:2000, 1:20] 0.0005 0 0 0.0035 0 0 0.01 0 0.0135 0 ...\n##   .. .. .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. .. .. ..$ : chr [1:2000] \"PPBP\" \"LYZ\" \"S100A9\" \"IGLL5\" ...\n##   .. .. .. .. .. .. .. ..$ : chr [1:20] \"PC1\" \"PC2\" \"PC3\" \"PC4\" ...\n##   .. .. .. .. .. ..@ fake.reduction.scores  : num [1:2000, 1:20] -0.003524 0.000285 -0.000627 0.002054 0.000959 ...\n##   .. .. .. .. .. ..@ empirical.p.values.full: logi [1, 1] NA\n##   .. .. .. .. .. ..@ overall.p.values       : num [1:20, 1:2] 1 2 3 4 5 6 7 8 9 10 ...\n##   .. .. .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. .. .. ..$ : NULL\n##   .. .. .. .. .. .. .. ..$ : chr [1:2] \"PC\" \"Score\"\n##   .. .. .. ..@ misc                      :List of 1\n##   .. .. .. .. ..$ total.variance: num 1734\n##   .. .. .. ..@ key                       : chr \"PC_\"\n##   .. ..$ umap:Formal class 'DimReduc' [package \"SeuratObject\"] with 9 slots\n##   .. .. .. ..@ cell.embeddings           : num [1:2638, 1:2] -4.58 -2.81 -1.68 12.69 -9.83 ...\n##   .. .. .. .. ..- attr(*, \"scaled:center\")= num [1:2] -0.0395 -1.1523\n##   .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. .. ..$ : chr [1:2] \"UMAP_1\" \"UMAP_2\"\n##   .. .. .. ..@ feature.loadings          : num[0 , 0 ] \n##   .. .. .. ..@ feature.loadings.projected: num[0 , 0 ] \n##   .. .. .. ..@ assay.used                : chr \"RNA\"\n##   .. .. .. ..@ global                    : logi TRUE\n##   .. .. .. ..@ stdev                     : num(0) \n##   .. .. .. ..@ jackstraw                 :Formal class 'JackStrawData' [package \"SeuratObject\"] with 4 slots\n##   .. .. .. .. .. ..@ empirical.p.values     : num[0 , 0 ] \n##   .. .. .. .. .. ..@ fake.reduction.scores  : num[0 , 0 ] \n##   .. .. .. .. .. ..@ empirical.p.values.full: num[0 , 0 ] \n##   .. .. .. .. .. ..@ overall.p.values       : num[0 , 0 ] \n##   .. .. .. ..@ misc                      : list()\n##   .. .. .. ..@ key                       : chr \"UMAP_\"\n##   .. ..$ tsne:Formal class 'DimReduc' [package \"SeuratObject\"] with 9 slots\n##   .. .. .. ..@ cell.embeddings           : num [1:2638, 1:2] -11.1 -36.27 1.96 37.46 -20.88 ...\n##   .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. .. ..$ : chr [1:2] \"tSNE_1\" \"tSNE_2\"\n##   .. .. .. ..@ feature.loadings          : num[0 , 0 ] \n##   .. .. .. ..@ feature.loadings.projected: num[0 , 0 ] \n##   .. .. .. ..@ assay.used                : chr \"RNA\"\n##   .. .. .. ..@ global                    : logi TRUE\n##   .. .. .. ..@ stdev                     : num(0) \n##   .. .. .. ..@ jackstraw                 :Formal class 'JackStrawData' [package \"SeuratObject\"] with 4 slots\n##   .. .. .. .. .. ..@ empirical.p.values     : num[0 , 0 ] \n##   .. .. .. .. .. ..@ fake.reduction.scores  : num[0 , 0 ] \n##   .. .. .. .. .. ..@ empirical.p.values.full: num[0 , 0 ] \n##   .. .. .. .. .. ..@ overall.p.values       : num[0 , 0 ] \n##   .. .. .. ..@ misc                      : list()\n##   .. .. .. ..@ key                       : chr \"tSNE_\"\n##   ..@ images      : list()\n##   ..@ project.name: chr \"pbmc3k\"\n##   ..@ misc        : list()\n##   ..@ version     :Classes 'package_version', 'numeric_version'  hidden list of 1\n##   .. ..$ : int [1:3] 4 0 0\n##   ..@ commands    :List of 10\n##   .. ..$ NormalizeData.RNA       :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"NormalizeData.RNA\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:49:17\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr [1:2] \"NormalizeData(pbmc, normalization.method = \\\"LogNormalize\\\", \" \"    scale.factor = 10000)\"\n##   .. .. .. ..@ params     :List of 5\n##   .. .. .. .. ..$ assay               : chr \"RNA\"\n##   .. .. .. .. ..$ normalization.method: chr \"LogNormalize\"\n##   .. .. .. .. ..$ scale.factor        : num 10000\n##   .. .. .. .. ..$ margin              : num 1\n##   .. .. .. .. ..$ verbose             : logi TRUE\n##   .. ..$ FindVariableFeatures.RNA:Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"FindVariableFeatures.RNA\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:49:18\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"FindVariableFeatures(pbmc, selection.method = \\\"vst\\\", nfeatures = 2000)\"\n##   .. .. .. ..@ params     :List of 12\n##   .. .. .. .. ..$ assay              : chr \"RNA\"\n##   .. .. .. .. ..$ selection.method   : chr \"vst\"\n##   .. .. .. .. ..$ loess.span         : num 0.3\n##   .. .. .. .. ..$ clip.max           : chr \"auto\"\n##   .. .. .. .. ..$ mean.function      :function (mat, display_progress)  \n##   .. .. .. .. ..$ dispersion.function:function (mat, display_progress)  \n##   .. .. .. .. ..$ num.bin            : num 20\n##   .. .. .. .. ..$ binning.method     : chr \"equal_width\"\n##   .. .. .. .. ..$ nfeatures          : num 2000\n##   .. .. .. .. ..$ mean.cutoff        : num [1:2] 0.1 8\n##   .. .. .. .. ..$ dispersion.cutoff  : num [1:2] 1 Inf\n##   .. .. .. .. ..$ verbose            : logi TRUE\n##   .. ..$ ScaleData.RNA           :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"ScaleData.RNA\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:49:47\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"ScaleData(pbmc, vars.to.regress = \\\"percent.mt\\\")\"\n##   .. .. .. ..@ params     :List of 11\n##   .. .. .. .. ..$ features          : chr [1:2000] \"PPBP\" \"LYZ\" \"S100A9\" \"IGLL5\" ...\n##   .. .. .. .. ..$ assay             : chr \"RNA\"\n##   .. .. .. .. ..$ vars.to.regress   : chr \"percent.mt\"\n##   .. .. .. .. ..$ model.use         : chr \"linear\"\n##   .. .. .. .. ..$ use.umi           : logi FALSE\n##   .. .. .. .. ..$ do.scale          : logi TRUE\n##   .. .. .. .. ..$ do.center         : logi TRUE\n##   .. .. .. .. ..$ scale.max         : num 10\n##   .. .. .. .. ..$ block.size        : num 1000\n##   .. .. .. .. ..$ min.cells.to.block: num 2638\n##   .. .. .. .. ..$ verbose           : logi TRUE\n##   .. ..$ RunPCA.RNA              :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"RunPCA.RNA\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:49:54\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"RunPCA(pbmc, features = VariableFeatures(object = pbmc))\"\n##   .. .. .. ..@ params     :List of 11\n##   .. .. .. .. ..$ assay          : chr \"RNA\"\n##   .. .. .. .. ..$ features       : chr [1:2000] \"PPBP\" \"LYZ\" \"S100A9\" \"IGLL5\" ...\n##   .. .. .. .. ..$ npcs           : num 50\n##   .. .. .. .. ..$ rev.pca        : logi FALSE\n##   .. .. .. .. ..$ weight.by.var  : logi TRUE\n##   .. .. .. .. ..$ verbose        : logi TRUE\n##   .. .. .. .. ..$ ndims.print    : int [1:5] 1 2 3 4 5\n##   .. .. .. .. ..$ nfeatures.print: num 30\n##   .. .. .. .. ..$ reduction.name : chr \"pca\"\n##   .. .. .. .. ..$ reduction.key  : chr \"PC_\"\n##   .. .. .. .. ..$ seed.use       : num 42\n##   .. ..$ JackStraw.RNA.pca       :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"JackStraw.RNA.pca\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:54:13\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"JackStraw(pbmc, num.replicate = 100)\"\n##   .. .. .. ..@ params     :List of 7\n##   .. .. .. .. ..$ reduction    : chr \"pca\"\n##   .. .. .. .. ..$ assay        : chr \"RNA\"\n##   .. .. .. .. ..$ dims         : num 20\n##   .. .. .. .. ..$ num.replicate: num 100\n##   .. .. .. .. ..$ prop.freq    : num 0.01\n##   .. .. .. .. ..$ verbose      : logi TRUE\n##   .. .. .. .. ..$ maxit        : num 1000\n##   .. ..$ ScoreJackStraw          :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"ScoreJackStraw\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:54:13\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"ScoreJackStraw(pbmc, dims = 1:20)\"\n##   .. .. .. ..@ params     :List of 4\n##   .. .. .. .. ..$ reduction   : chr \"pca\"\n##   .. .. .. .. ..$ dims        : int [1:20] 1 2 3 4 5 6 7 8 9 10 ...\n##   .. .. .. .. ..$ score.thresh: num 1e-05\n##   .. .. .. .. ..$ do.plot     : logi FALSE\n##   .. ..$ FindNeighbors.RNA.pca   :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"FindNeighbors.RNA.pca\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:54:15\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"FindNeighbors(pbmc, dims = 1:10)\"\n##   .. .. .. ..@ params     :List of 17\n##   .. .. .. .. ..$ reduction      : chr \"pca\"\n##   .. .. .. .. ..$ dims           : int [1:10] 1 2 3 4 5 6 7 8 9 10\n##   .. .. .. .. ..$ assay          : chr \"RNA\"\n##   .. .. .. .. ..$ k.param        : num 20\n##   .. .. .. .. ..$ return.neighbor: logi FALSE\n##   .. .. .. .. ..$ compute.SNN    : logi TRUE\n##   .. .. .. .. ..$ prune.SNN      : num 0.0667\n##   .. .. .. .. ..$ nn.method      : chr \"annoy\"\n##   .. .. .. .. ..$ n.trees        : num 50\n##   .. .. .. .. ..$ annoy.metric   : chr \"euclidean\"\n##   .. .. .. .. ..$ nn.eps         : num 0\n##   .. .. .. .. ..$ verbose        : logi TRUE\n##   .. .. .. .. ..$ force.recalc   : logi FALSE\n##   .. .. .. .. ..$ do.plot        : logi FALSE\n##   .. .. .. .. ..$ graph.name     : chr [1:2] \"RNA_nn\" \"RNA_snn\"\n##   .. .. .. .. ..$ l2.norm        : logi FALSE\n##   .. .. .. .. ..$ cache.index    : logi FALSE\n##   .. ..$ FindClusters            :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"FindClusters\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:54:15\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"FindClusters(pbmc, resolution = 0.5)\"\n##   .. .. .. ..@ params     :List of 10\n##   .. .. .. .. ..$ graph.name      : chr \"RNA_snn\"\n##   .. .. .. .. ..$ modularity.fxn  : num 1\n##   .. .. .. .. ..$ resolution      : num 0.5\n##   .. .. .. .. ..$ method          : chr \"matrix\"\n##   .. .. .. .. ..$ algorithm       : num 1\n##   .. .. .. .. ..$ n.start         : num 10\n##   .. .. .. .. ..$ n.iter          : num 10\n##   .. .. .. .. ..$ random.seed     : num 0\n##   .. .. .. .. ..$ group.singletons: logi TRUE\n##   .. .. .. .. ..$ verbose         : logi TRUE\n##   .. ..$ RunUMAP.RNA.pca         :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"RunUMAP.RNA.pca\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:54:28\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"RunUMAP(pbmc, dims = 1:10)\"\n##   .. .. .. ..@ params     :List of 22\n##   .. .. .. .. ..$ dims                : int [1:10] 1 2 3 4 5 6 7 8 9 10\n##   .. .. .. .. ..$ reduction           : chr \"pca\"\n##   .. .. .. .. ..$ assay               : chr \"RNA\"\n##   .. .. .. .. ..$ slot                : chr \"data\"\n##   .. .. .. .. ..$ umap.method         : chr \"uwot\"\n##   .. .. .. .. ..$ return.model        : logi FALSE\n##   .. .. .. .. ..$ n.neighbors         : int 30\n##   .. .. .. .. ..$ n.components        : int 2\n##   .. .. .. .. ..$ metric              : chr \"cosine\"\n##   .. .. .. .. ..$ learning.rate       : num 1\n##   .. .. .. .. ..$ min.dist            : num 0.3\n##   .. .. .. .. ..$ spread              : num 1\n##   .. .. .. .. ..$ set.op.mix.ratio    : num 1\n##   .. .. .. .. ..$ local.connectivity  : int 1\n##   .. .. .. .. ..$ repulsion.strength  : num 1\n##   .. .. .. .. ..$ negative.sample.rate: int 5\n##   .. .. .. .. ..$ uwot.sgd            : logi FALSE\n##   .. .. .. .. ..$ seed.use            : int 42\n##   .. .. .. .. ..$ angular.rp.forest   : logi FALSE\n##   .. .. .. .. ..$ verbose             : logi TRUE\n##   .. .. .. .. ..$ reduction.name      : chr \"umap\"\n##   .. .. .. .. ..$ reduction.key       : chr \"UMAP_\"\n##   .. ..$ RunTSNE                 :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"RunTSNE\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:54:36\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"RunTSNE(pbmc, dims = 1:10)\"\n##   .. .. .. ..@ params     :List of 8\n##   .. .. .. .. ..$ reduction     : chr \"pca\"\n##   .. .. .. .. ..$ cells         : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. ..$ dims          : int [1:10] 1 2 3 4 5 6 7 8 9 10\n##   .. .. .. .. ..$ seed.use      : num 1\n##   .. .. .. .. ..$ tsne.method   : chr \"Rtsne\"\n##   .. .. .. .. ..$ dim.embed     : num 2\n##   .. .. .. .. ..$ reduction.name: chr \"tsne\"\n##   .. .. .. .. ..$ reduction.key : chr \"tSNE_\"\n##   ..@ tools       :List of 2\n##   .. ..$ BuildClusterTree           :List of 4\n##   .. .. ..$ edge       : int [1:16, 1:2] 10 10 11 12 12 11 13 14 14 16 ...\n##   .. .. ..$ edge.length: num [1:16] 463 158 174 131 131 ...\n##   .. .. ..$ tip.label  : chr [1:9] \"0\" \"1\" \"2\" \"3\" ...\n##   .. .. ..$ Nnode      : int 8\n##   .. .. ..- attr(*, \"class\")= chr \"phylo\"\n##   .. .. ..- attr(*, \"order\")= chr \"cladewise\"\n##   .. ..$ CalculateBarcodeInflections:List of 4\n##   .. .. ..$ barcode_distribution:'data.frame':   2638 obs. of  4 variables:\n##   .. .. .. ..$ orig.ident: Factor w/ 1 level \"pbmc3k\": 1 1 1 1 1 1 1 1 1 1 ...\n##   .. .. .. ..$ nCount_RNA: num [1:2638] 8875 8415 8011 7928 7167 ...\n##   .. .. .. ..$ rank      : num [1:2638] 1 2 3 4 5 6 7 8 9 10 ...\n##   .. .. .. ..$ rawdiff   : num [1:2638] 0 -0.02311 -0.02136 -0.00452 -0.04382 ...\n##   .. .. ..$ inflection_points   :'data.frame':   1 obs. of  3 variables:\n##   .. .. .. ..$ orig.ident: Factor w/ 1 level \"pbmc3k\": 1\n##   .. .. .. ..$ nCount_RNA: num 7167\n##   .. .. .. ..$ rank      : num 5\n##   .. .. ..$ threshold_values    :'data.frame':   2 obs. of  2 variables:\n##   .. .. .. ..$ threshold: chr [1:2] \"threshold.low\" \"threshold.high\"\n##   .. .. .. ..$ rank     : num [1:2] 1 2638\n##   .. .. ..$ cells_pass          : chr [1:2635] \"GGGCCAACCTTGGA-1\" \"CAGGTTGAGGATCT-1\" \"ACGAGGGACAGGAG-1\" \"AAGCCATGAACTGC-1\" ...\n# Retrieve UMAP data\n# Retrieve the coordinates of each cell, and cluster, celltype information\numap &lt;- pbmc@reductions$umap@cell.embeddings |&gt; \n  as.data.frame() |&gt; \n  cbind(cell_type = pbmc@meta.data$labels)\n\nhead(umap)\n##                     UMAP_1     UMAP_2 cell_type\n## AAACATACAACCAC-1 -4.577857   1.650203   T_cells\n## AAACATTGAGCTAC-1 -2.813911 -11.897462    B_cell\n## AAACATTGATCAGC-1 -1.684490   3.302480   T_cells\n## AAACCGTGCTTCCG-1 12.694498   2.098798  Monocyte\n## AAACCGTGTATGCG-1 -9.829201   3.982013   NK_cell\n## AAACGCACTGGTAC-1 -2.908319   1.249230   T_cells\n\n\n# Define the colors\nallcolour &lt;- c(\n    \"#DC143C\",\"#0000FF\",\"#20B2AA\",\"#FFA500\",\"#9370DB\",\"#98FB98\",\"#F08080\",\n    \"#1E90FF\",\"#7CFC00\",\"#FFFF00\", \"#808000\",\"#FF00FF\",\"#FA8072\",\"#7B68EE\",\n    \"#9400D3\",\"#800080\",\"#A0522D\",\"#D2B48C\",\"#D2691E\",\"#87CEEB\",\"#40E0D0\",\n    \"#5F9EA0\",\"#FF1493\",\"#0000CD\",\"#008B8B\",\"#FFE4B5\",\"#8A2BE2\",\"#228B22\",\n    \"#E9967A\",\"#4682B4\",\"#32CD32\",\"#F0E68C\",\"#FFFFE0\",\"#EE82EE\",\"#FF6347\",\n    \"#6A5ACD\",\"#9932CC\",\"#8B008B\",\"#8B4513\",\"#DEB887\"\n)\n# ggplot2\np &lt;- ggplot(umap, aes(x = UMAP_1, y = UMAP_2, color = cell_type)) +\n    geom_point(size = 1, alpha = 1) +\n    ### MAP cluster with color\n    scale_color_manual(values = allcolour) +\n    ### Axis annotation\n    geom_segment(\n        aes(\n            x = min(umap$UMAP_1) , y = min(umap$UMAP_2) ,\n            xend = min(umap$UMAP_1) +3, yend = min(umap$UMAP_2)\n        ), colour = \"black\", linewidth = 1,arrow = arrow(length = unit(0.3,\"cm\"))\n    ) + \n    geom_segment(\n        aes(\n            x = min(umap$UMAP_1)  , y = min(umap$UMAP_2)  ,\n            xend = min(umap$UMAP_1) , yend = min(umap$UMAP_2) + 3),\n            colour = \"black\", linewidth = 1,arrow = arrow(length = unit(0.3,\"cm\"))\n    ) +\n    annotate(\n        \"text\", x = min(umap$UMAP_1) +1.5, y = min(umap$UMAP_2) -1, \n        label = \"UMAP_1\", color=\"black\",size = 3, fontface=\"bold\"\n    ) + \n    annotate(\n        \"text\", x = min(umap$UMAP_1) -1, y = min(umap$UMAP_2) + 1.5, \n        label = \"UMAP_2\", color=\"black\",size = 3, fontface=\"bold\" ,angle=90\n    ) + \n    theme(\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.border = element_blank(),\n        axis.title = element_blank(),\n        axis.text = element_blank(),\n        axis.ticks = element_blank(),\n        panel.background = element_rect(fill = \"white\"),\n        plot.background = element_rect(fill = \"white\"),\n        legend.title = element_blank(), \n        legend.key=element_rect(fill= \"white\"),\n        legend.text = element_text(size = 20),\n        legend.key.size=unit(1, \"cm\")\n    ) +\n    ### legend label size\n    guides(color = guide_legend(override.aes = list(size=5)))\n### View it\np\n\n\n\n\n\n\n\n\n\n\nAnnotate cell type on UMAP\n\n# Calcualte the median coordinates of each cluster\ncell_type_med &lt;- umap |&gt;\n  group_by(cell_type) |&gt;\n  summarise(UMAP_1 = median(UMAP_1),\n    UMAP_2 = median(UMAP_2)\n  )\n# Annotation\np + geom_label_repel(\n    aes(label = cell_type, size = 20), fontface = \"bold\", data = cell_type_med,\n    point.padding = unit(0.5, \"lines\")\n)"
  },
  {
    "objectID": "blog/2023/12/02/index.knit.html#featureplot",
    "href": "blog/2023/12/02/index.knit.html#featureplot",
    "title": "Customization of Seurat plots using ggplot2",
    "section": "FeaturePlot",
    "text": "FeaturePlot\n\nDefault Seurat FeaturePlot\n\nDimPlot(pbmc, label = TRUE)|FeaturePlot(pbmc, features = \"CD79A\")\n\n\n\n\n\n\n\nFeaturePlot(pbmc, features = c(\"CD79A\", \"CD8A\"), blend=TRUE)\n\n\n\n\n\n\n\nFeaturePlot(pbmc, features = c(\"CD79A\",\"CD79B\"), blend=TRUE)\n\n\n\n\n\n\n\nFeaturePlot(pbmc, features = c(\"CD79A\",\"CD79B\", \"CD68\", \"CD163\"))\n\n\n\n\n\n\n\n\n\n\nFeature with ggplot2\n\nmydata  &lt;- FetchData(\n    pbmc,\n    vars = c(\"rna_CD79A\", \"rna_CD8A\", \"rna_CCR7\", \"UMAP_1\", \"UMAP_2\")\n)\nhead(mydata)\n##                  rna_CD79A rna_CD8A rna_CCR7    UMAP_1     UMAP_2\n## AAACATACAACCAC-1  0.000000 1.635873 1.635873 -4.577857   1.650203\n## AAACATTGAGCTAC-1  1.962726 0.000000 0.000000 -2.813911 -11.897462\n## AAACATTGATCAGC-1  0.000000 0.000000 0.000000 -1.684490   3.302480\n## AAACCGTGCTTCCG-1  0.000000 0.000000 0.000000 12.694498   2.098798\n## AAACCGTGTATGCG-1  0.000000 0.000000 0.000000 -9.829201   3.982013\n## AAACGCACTGGTAC-1  0.000000 0.000000 0.000000 -2.908319   1.249230\n\n### Single gene\nmydata |&gt;\n    ggplot(aes(x = UMAP_1, y = UMAP_2)) +\n    geom_point(\n        data = mydata, aes(x = UMAP_1, y = UMAP_2,\n        color = rna_CD79A), size = 1\n    ) +\n    ### Increase the transprancy of gray dots\n    scale_color_gradient(\n        \"rna_CD79A\", low = alpha(\"grey\", 0.1), \n        high = alpha(\"red\", 1)\n    ) +\n    ### Density\n    stat_density2d(aes(colour=rna_CD79A))\n\n\n\n\n\n\n\n\n\n### Multiple genes in feature plot\n# ggplot(mydata, aes(x = UMAP_1, y = UMAP_2)) +\n#     geom_point(\n#         data = mydata, aes(x = UMAP_1, y = UMAP_2, color = rna_CD79A), \n#         size = 1\n#     ) +\n#     scale_color_gradient(\n#         \"CD79A\", low = alpha(\"grey\", 0.1), high = alpha(\"purple\", 1)\n#     ) +\n#     new_scale(\"color\") +\n#     geom_point(\n#         data = mydata, aes(x = UMAP_1, y = UMAP_2, color = rna_CD8A), \n#         size = 1\n#     ) +\n#     scale_color_gradient(\n#         \"CD8A\", low = alpha(\"grey\", 0.1), high = alpha(\"red\", 1)\n#     ) +\n#     new_scale(\"color\") +\n#     geom_point(\n#         data = mydata, aes(x = UMAP_1, y = UMAP_2,color = rna_CCR7), \n#         size = 1\n#     ) +\n#     scale_color_gradient(\n#         \"CCR7\", low = alpha(\"grey\", 0.1), high = alpha(\"green\", 1)\n#     ) +\n#     theme_bw()"
  },
  {
    "objectID": "blog/2023/12/02/index.knit.html#dotplot",
    "href": "blog/2023/12/02/index.knit.html#dotplot",
    "title": "Customization of Seurat plots using ggplot2",
    "section": "Dotplot",
    "text": "Dotplot\n\nDeafult Dotplot within Seurat\n\n# Find marker genes\n# all_markers &lt;- FindAllMarkers(object = sce2)\n# save(all_markers,file = here(\"learn\", \"2023_scRNA\", \"all_markers.RData\"))\n\nDotPlot(sce2,features = unique(top5$gene) ,assay='RNA')\n\n\n\n\n\n\n\n\n\n# Optimize colors, size, and direction\np1 &lt;- DotPlot(sce2, features = unique(top5$gene), assay = \"RNA\") + \n  coord_flip() + \n  labs(x = NULL,y = NULL) + \n  guides(size = guide_legend(\"Percent Expression\"))+\n  scale_color_gradientn(colours = c(\"#330066\", \"#336699\", \"#66CC66\", \"#FFCC33\")) +\n  theme(\n    panel.grid = element_blank(), \n    axis.text.x = element_text(angle = 45, hjust = 0.5,vjust = 0.5)\n  )\n## Scale for colour is already present.\n## Adding another scale for colour, which will replace the existing scale.\np1\n\n\n\n\n\n\n\n\n\n\nDotplot with Complexheatmap\nWe can refer to details from here for detailed parameters customization.\n\n# Retrieve data\ndf &lt;- p1$data\nhead(df)\n##               avg.exp   pct.exp features.plot id avg.exp.scaled\n## REG4       7.70481043 17.174382          REG4  0       2.500000\n## BPIFB1     0.30669602  6.860158        BPIFB1  0       2.500000\n## FABP1      0.29179596  3.118254         FABP1  0       2.500000\n## SLC9A4     0.01901309  1.751019        SLC9A4  0       2.500000\n## AC073218.2 0.03103152  1.655073    AC073218.2  0       1.137072\n## SPRR1A     0.07460096  3.837851        SPRR1A  0       0.208155\n\n# The matrix for the scaled expression \nexp_mat &lt;-df |&gt; \n  select(-pct.exp, -avg.exp) |&gt;  \n  pivot_wider(names_from = id, values_from = avg.exp.scaled) |&gt; \n  as.data.frame()\nrow.names(exp_mat) &lt;- exp_mat$features.plot\nexp_mat &lt;- exp_mat[, -1] |&gt; as.matrix()\nhead(exp_mat, 2)\n##          0          1          2          3          4        5          6\n## REG4   2.5  1.0681259 -0.6492553 -0.6766277  0.4956595 1.826576 -0.4005466\n## BPIFB1 2.5 -0.1015123 -0.4099583 -0.5370206 -0.3309614 1.039651 -0.6032213\n##                 7          8          9         10        11         12\n## REG4   -0.3648312 -0.6411552  0.3682808 -0.4876358 0.3408992 -0.6358072\n## BPIFB1  0.4017002 -0.5414065 -0.2597756 -0.5685453 1.6007798 -0.6318396\n##                13         14        15         16         17         18\n## REG4   -0.7044399 -0.7832735 0.5617191 -0.7888883 -0.5395693 -0.7888883\n## BPIFB1 -0.6318396 -0.6318396 1.1110916 -0.6318396 -0.6318396 -0.6318396\n\n## The matrix for the percentage of cells express a gene\npercent_mat &lt;- df |&gt; \n  select(-avg.exp, -avg.exp.scaled) |&gt;  \n  pivot_wider(names_from = id, values_from = pct.exp) |&gt; \n  as.data.frame()\n \nrow.names(percent_mat) &lt;- percent_mat$features.plot  \npercent_mat &lt;- percent_mat[, -1] |&gt; as.matrix()\nhead(percent_mat, 2)\n##                0         1        2         3        4         5         6\n## REG4   17.174382 11.642157 5.015480 3.2281731 7.209302 16.111851 7.9301075\n## BPIFB1  6.860158  2.389706 1.114551 0.7336757 2.015504  3.062583 0.2688172\n##                7         8         9        10        11       12       13 14\n## REG4   11.367673 2.5782689 12.406948 7.1090047 12.244898 5.797101 2.380952  1\n## BPIFB1  6.571936 0.3683241  1.736973 0.4739336  8.843537 0.000000 0.000000  0\n##              15 16       17 18\n## REG4   9.278351  0 8.571429  0\n## BPIFB1 7.216495  0 0.000000  0\n\n\n# Complexheatmap\n## any value that is greater than 2 will be mapped to yellow\ncol_fun &lt;-  circlize::colorRamp2(c(-1, 0, 2), viridis(20)[c(1,10, 20)])\ncell_fun &lt;- function(j, i, x, y, w, h, fill) {\n    grid.rect(x = x, y = y, width = w, height = h,\n        gp = gpar(col = NA, fill = NA))\n    grid.circle(x = x, y = y, r = percent_mat[i, j] / 100 * min(unit.c(w, h)),\n        gp = gpar(fill = col_fun(exp_mat[i, j]), col = NA))\n}\n\n# also do a kmeans clustering for the genes with k = 4\nHeatmap(\n    exp_mat,\n    heatmap_legend_param = list(title = \"Average Expression\"),\n    column_title = \"clustered dotplot\",\n    col = col_fun,\n    rect_gp = gpar(type = \"none\"),\n    cell_fun = cell_fun,\n    row_names_gp = gpar(fontsize = 3),\n    # row_km = 4,\n    border = \"black\"\n)\n\n\n# Annotate celltype\ncolnames(exp_mat)\ncluster_anno &lt;- c(\"Epi\", \"Myeloid\", \"Fibroblast\", \"T\", \"Endo\", \"un\")\n\ncolumn_ha &lt;- HeatmapAnnotation(\n    cluster_anno = cluster_anno,\n    col = list(cluster_anno = setNames(brewer.pal(6, \"Paired\"), unique(cluster_anno))\n    ),\n    na_col = \"grey\"\n)\n\nHeatmap(\n    exp_mat,\n    heatmap_legend_param = list(title = \"Average Expression\"),\n    column_title = \"clustered dotplot\",\n    col = col_fun,\n    rect_gp = gpar(type = \"none\"),\n    cell_fun = cell_fun,\n    row_names_gp = gpar(fontsize = 5),\n    # row_km = 4,\n    border = \"black\",\n    top_annotation = column_ha\n)\n\n\n# Add legend\nlayer_fun &lt;- function(j, i, x, y, w, h, fill) {\n    grid.rect(\n        x = x, y = y, width = w, height = h, gp = gpar(col = NA, fill = NA)\n    )\n    grid.circle(\n        x = x, y = y, r = pindex(percent_mat, i, j) / 100 * unit(2, \"mm\"),\n        gp = gpar(fill = col_fun(pindex(exp_mat, i, j)), col = NA)\n    )\n}\n\nlgd_list = list(\n    Legend(\n        labels = c(0, 0.25, 0.5, 0.75, 1), title = \"Percent Expressed\",\n        graphics = list(\n            function(x, y, w, h) grid.circle(x = x, y = y, r = 0 * unit(2, \"mm\"),\n                gp = gpar(fill = \"black\")),\n            function(x, y, w, h) grid.circle(x = x, y = y, r = 0.25 * unit(2, \"mm\"),\n                gp = gpar(fill = \"black\")),\n            function(x, y, w, h) grid.circle(x = x, y = y, r = 0.5 * unit(2, \"mm\"),\n                gp = gpar(fill = \"black\")),\n            function(x, y, w, h) grid.circle(x = x, y = y, r = 0.75 * unit(2, \"mm\"),\n                gp = gpar(fill = \"black\")),\n            function(x, y, w, h) grid.circle(x = x, y = y, r = 1 * unit(2, \"mm\"),\n                gp = gpar(fill = \"black\"))\n        )\n    )\n)\n\nhp &lt;- Heatmap(\n    exp_mat,\n    heatmap_legend_param = list(title = \"expression\"),\n    column_title = \"clustered dotplot\",\n    col = col_fun,\n    rect_gp = gpar(type = \"none\"),\n    layer_fun = layer_fun,\n    row_names_gp = gpar(fontsize = 5),\n    # row_km = 4,\n    border = \"black\",\n    top_annotation = column_ha\n)\n\ndraw(hp, annotation_legend_list = lgd_list)\n\n\n\nDotplot with scCustomize"
  },
  {
    "objectID": "blog/2022/12/23/index.html",
    "href": "blog/2022/12/23/index.html",
    "title": "VSCode Keyboard Shortcut Cheat Sheet",
    "section": "",
    "text": "The most useful VSCode shotcuts that can boost my productivity!\n\n\n\n\n\n\n\n\nDescription\nMac\nWindows\n\n\n\n\nGeneral\n\n\n\n\nCommand Palette\nCmd + Shift + P\nCtrl + Shift + P\n\n\nOpen settings\nCmd + ,\nCtrl + ,\n\n\nKeyboard shoutcuts\nCmd + K Cmd + S\nCtrl + K Ctrl + S\n\n\nToggle sidebar\nCmd + B\nCtrl + B\n\n\nOpen new window\nCmd + Shift + N\nCtrl + Shift + N\n\n\nClose window\nCmd + Shift + W\nCtrl + Shift + W\n\n\nClose tab\nCmd + W\nCtrl + W\n\n\nOpen the terminal\nCmd + J\nCtrl + J\n\n\nEditor\n\n\n\n\nSplit view\nCmd + \\\nCtrl + \\\n\n\nNavigate tabs\nCmd + Shift + Tab\nCtrl + Shift + Tab\n\n\nNavigate tab groups\nCmd + 1 / 2 / 3\nCtrl + 1 / 2 / 3\n\n\nMultiple cursor\nCmd + Opt + ↑ / ↓\nCmd + Opt + ↑ / ↓\n\n\nSelect text\nCmd + Shift + ↑ / ↓\nCtrl + Shift + ↑ / ↓\n\n\nDelete previous word\nCmd + Backspace\nCtrl + Backspace\n\n\nMove the line Up / Down\nOpt + ↑ / ↓\nAlt + ↑ / ↓\n\n\nCopy line Up / Down\nShift + Opt + ↑ / ↓\nShift + Alt + ↑ / ↓\n\n\nSelect word\nCmd + D\nCtrl + D\n\n\nSelect current line\nCmd + L\nCtrl + L\n\n\nSelect similar occurrences\nCmd + Shift + L\nCtrl + Shift + L\n\n\nDelete current line\nCmd + Shift + K\nCtrl + Shift + K\n\n\nComment lines\nCmd + /\nCtrl + /\n\n\nNavigate to line\nCmd + G\nCtrl + G\n\n\nCode folding\nCmd + Opt + [ / ]\nCtrl + Shift + [ / ]\n\n\nIndent / outdent lines\nCmd + [ / ]\nCtrl + [ / ]\n\n\nFormat selected code\nCmd + K Cmd + F\nCtrl + K Ctrl + F\n\n\nFormat document\nShift + Opt + F\nShift + Alt + F\n\n\nGo to the start / end of the word\nOpt + ← / →\nAlt + ← / →\n\n\nGo to the start / end of the line\nCmd + ← / →\nCtrl + ← / →\n\n\nGo to beginning or end of file\nCmd + ↑ / ↓\nCtrl + ↑ / ↓\n\n\nSearch and Replace\n\n\n\n\nSearch files\nCmd + Shift + F\nCtrl + Shift + F\n\n\nFind text\nCmd + F\nCtrl + F\n\n\nReplace text\nCmd + Opt + F\nCtrl + H"
  },
  {
    "objectID": "blog/2022/12/19/index.html",
    "href": "blog/2022/12/19/index.html",
    "title": "Learn Linux basic for computing",
    "section": "",
    "text": "After working at Bioinformatics Institute for 3 years, I gradullly relizaed that it’s essential to learn Linux as:\nSo I start to learn Linux for computional biology from：\nThe following content are credited from the GEN242"
  },
  {
    "objectID": "blog/2022/12/19/index.html#unix-shortcuts",
    "href": "blog/2022/12/19/index.html#unix-shortcuts",
    "title": "Learn Linux basic for computing",
    "section": "Unix Shortcuts",
    "text": "Unix Shortcuts\n\nCtrl + A # cursor to beginning of command line\nCtrl + E # cursor to end of command line\nCtrl + L # clear the screen\nCtrl + U # clear the line before the cursor position\nCtrl + K # clear the line after the cursor\nCtrl + C # kill the command that is currently running\nCtrl + D # exit the current shell\nCtrl + W # cut last word\nCtrl + Y # Paste (“yank”) content that was cut earlier (by Ctrl-w or Ctrl-k)\nAlt + F # move the cursor forward one word\nAlt + B # move the cursor backward one word"
  },
  {
    "objectID": "blog/2022/12/19/index.html#copy-and-paste",
    "href": "blog/2022/12/19/index.html#copy-and-paste",
    "title": "Learn Linux basic for computing",
    "section": "Copy and paste",
    "text": "Copy and paste\n\n\n\n\n\n\n\n\nLinux (xterm)\nWindows\nMac (Terminal)\n\n\n\n\n# Copy CTRL+SHIFT+C# Paste CTRL+SHIFT+V\n# Copy by highlighting with mouse # Paste SHIFT+INSERT\n# Copy COMMAND+c # Paste COMMAND+v"
  },
  {
    "objectID": "blog/2022/12/19/index.html#navigation",
    "href": "blog/2022/12/19/index.html#navigation",
    "title": "Learn Linux basic for computing",
    "section": "Navigation",
    "text": "Navigation\npwd               # \"Print working directory\"; show your current path\nls                # \"List\" contents of current directory\nls -l             # Similar to ls, but provides additional info on files and directories\nls -a             # List all files, including hidden files (.name) as well\nls -R             # Lists subdirectories recursively\nls -t             # Lists files in chronological order\ncd &lt;dir_name&gt;     # \"Change directory\" to specified path\ncd                # Brings you to your home directory\ncd ~              # Also bring you to your home directory\ncd ..             # Moves one directory up\ncd ../../         # Moves two directories up (and so on)\ncd -              # Go back to you were previously (before the last directory change)\n↑                 # Up arrow key scrolls backwards through command history\n↓                 # Down arrow key scrolls forwards through command history\nhistory           # Shows all commands you have used recently\n\nThe tab (⇥) key auto completes commands or file names if there is only one option.\nHitting the tab (⇥) key twice will list multiple options."
  },
  {
    "objectID": "blog/2022/12/19/index.html#viewing-text-files",
    "href": "blog/2022/12/19/index.html#viewing-text-files",
    "title": "Learn Linux basic for computing",
    "section": "Viewing Text files",
    "text": "Viewing Text files\n\nless              # Progressively print a file to the screen.\ncat               # Concatenate and print files.\nwc                # Line, word, and byte (character) count of a file. \nsort              # Sort the lines of a file and print the result to the screen.\nuniq              # Show only the unique lines of a file.\nfile              # Determine the type of a file.\nhead              # Print the head (i.e., first few lines) of a file.\ntail              # Print the tail (i.e., last few lines) of a file.\ndiff              # Show the differences between two files.\ncut               # Selecting columns\ntr                # Substituting characters\ngrep              # finds all the lines of a file that match a given pattern."
  },
  {
    "objectID": "blog/2022/12/19/index.html#informative",
    "href": "blog/2022/12/19/index.html#informative",
    "title": "Learn Linux basic for computing",
    "section": "Informative",
    "text": "Informative\nfile &lt;file-name&gt;  # Show type of file (text, binary, compressed, etc...)\nid                # Shows your user name and associated groups\nhostname          # Shows the name of the machine your shell is currently on\n\n### Other useful unix commands\ndf -h /scratch                # Show local disk space for /scratch, do not use for /rhome or /bigdata\nfree -h                       # Show memory of current machine\nbc                            # Command-line calculator (to exit type 'quit')\nwget &lt;URL&gt;                    # Download a file or directory from the web\nln -s &lt;FILENAME1&gt; &lt;FILENAME2&gt; # Creates symbolic link (shortcut, or alias) for file or directory\ndu -sh .                      # Shows size of current directory\ndu -sh &lt;FILENAME&gt;             # Shows size of individual file\ndu -s * | sort -nr            # Shows size of each file within current directory, sorted by size\ndf                            # Check size of storage pool\ndu                            # Check size of file or directory\ncheck_quota                   # Check quota for home and bigdata"
  },
  {
    "objectID": "blog/2022/12/19/index.html#files-and-directories",
    "href": "blog/2022/12/19/index.html#files-and-directories",
    "title": "Learn Linux basic for computing",
    "section": "Files and Directories",
    "text": "Files and Directories\nmkdir &lt;dir_name&gt;   # Creates specified directory\nrmdir &lt;dir_name&gt;   # Removes empty directory\ntouch              # Update teh date of last access to file\nrm &lt;file_name&gt;     # Removes file_name\nrm -r &lt;dir_name&gt;   # Removes directory including its contents, but asks for confirmation\nrm -rf &lt;dir_name&gt;  # Same as above, but turns confirmation off. Use with caution\ncp &lt;name&gt; &lt;path&gt;   # Copy file/directory as specified in path (-r to include content in directories)\nmv &lt;name1&gt; &lt;name2&gt; # Renames directories or files\nmv &lt;name&gt; &lt;path&gt;   # Moves file/directory as specified in path"
  },
  {
    "objectID": "blog/2022/12/19/index.html#permissions-and-ownship",
    "href": "blog/2022/12/19/index.html#permissions-and-ownship",
    "title": "Learn Linux basic for computing",
    "section": "Permissions and Ownship",
    "text": "Permissions and Ownship\n\n\n\nuser (u) - User ownership of a file/directory. This user has the special right to change the permission bits and group ownership.\ngroup (g) - Group ownership of a file/directory. Members of this group may be assigned greater access rights than non-members.\nother (o) - Everyone else that isn’t the owning user or from the owning group.\n\n\n\n\n\n\n\n\n\n\n\n\nLetter\nNumber\nFile\nDirectory\n\n\n\n\nRead\nr\n4\nView the contents\nView the listings\n\n\nWrite\nw\n2\nModify the contents\nCreate a new file, or rename or delete existing files\n\n\nExecute\nx\n1\nExecute a program/script\nTraversal rights\n\n\n\n### Checking permissions\nls -la\n[zhonggr@nucleus ~]$ ls -la\ntotal 688\ndrwx------  14 zhonggr users   4096 Dec 17 12:04 .\ndrwxr-xr-x. 28 root    root    4096 Aug  9 21:57 ..\n-rw-------   1 zhonggr users  11428 Dec 19 14:30 .bash_history\n-rw-r--r--   1 zhonggr users     18 Sep  9  2019 .bash_logout\n-rw-r--r--   1 zhonggr users    141 Sep  9  2019 .bash_profile\n-rw-r--r--   1 zhonggr users    376 Dec 17 12:04 .bashrc\ndrwxr-xr-x   3 zhonggr users   4096 Dec 17 10:54 biosoft\ndrwx------   6 zhonggr users   4096 Nov 16 13:19 .cache\n-rw-rw-r--   1 zhonggr users    101 Mar 18  2022 .cellXpress2\ndrwx------   4 zhonggr users   4096 Mar 15  2022 .config\n-rw-r--r--   1 zhonggr users   3287 Sep  9  2019 .conkyrc\n-rw-r--r--   1 zhonggr mail     302 Dec 13 12:39 dead.letter\ndrwxr-xr-x   2 zhonggr users   4096 Sep  9  2019 Desktop\n-rw-r--r--   1 zhonggr users     29 Nov 16 13:08 .gitconfig\n-rw-------   1 zhonggr users     20 Dec 17 10:30 .lesshst\ndrwx------   4 zhonggr users   4096 Nov 16 21:15 .local\ndrwxr-xr-x   4 zhonggr users   4096 Sep  9  2019 .mozilla\ndrwx------   3 zhonggr users   4096 Jul 14 12:58 .nv\ndrwxr-xr-x   3 zhonggr users   4096 Nov 16 11:12 R\n-rw-r--r--   1 zhonggr users 585671 Dec 18 20:54 .radian_history\ndrwx------   2 zhonggr users   4096 Nov 16 10:58 .ssh\nd---------   2 zhonggr users   4096 Dec 17 10:25 test\n-rw-------   1 zhonggr users   2350 Dec 17 12:04 .viminfo\ndrwxr-xr-x   2 zhonggr users   4096 Nov 16 17:01 .vscode-R\ndrwxr-xr-x   5 zhonggr users   4096 Dec 18 20:45 .vscode-server\n-rw-r--r--   1 zhonggr users    223 Dec 17 10:57 .wget-hsts\n-rw-r--r--   1 zhonggr users     38 Sep  9  2019 .xsession\nAssign write and execute permissions to user and group\nchmod ug+rx test\n[zhonggr@nucleus ~]$ ls -la\ntotal 688\ndrwx------  14 zhonggr users   4096 Dec 17 12:04 .\ndrwxr-xr-x. 28 root    root    4096 Aug  9 21:57 ..\n-rw-------   1 zhonggr users  11428 Dec 19 14:30 .bash_history\n-rw-r--r--   1 zhonggr users     18 Sep  9  2019 .bash_logout\n-rw-r--r--   1 zhonggr users    141 Sep  9  2019 .bash_profile\n-rw-r--r--   1 zhonggr users    376 Dec 17 12:04 .bashrc\ndrwxr-xr-x   3 zhonggr users   4096 Dec 17 10:54 biosoft\ndrwx------   6 zhonggr users   4096 Nov 16 13:19 .cache\n-rw-rw-r--   1 zhonggr users    101 Mar 18  2022 .cellXpress2\ndrwx------   4 zhonggr users   4096 Mar 15  2022 .config\n-rw-r--r--   1 zhonggr users   3287 Sep  9  2019 .conkyrc\n-rw-r--r--   1 zhonggr mail     302 Dec 13 12:39 dead.letter\ndrwxr-xr-x   2 zhonggr users   4096 Sep  9  2019 Desktop\n-rw-r--r--   1 zhonggr users     29 Nov 16 13:08 .gitconfig\n-rw-------   1 zhonggr users     20 Dec 17 10:30 .lesshst\ndrwx------   4 zhonggr users   4096 Nov 16 21:15 .local\ndrwxr-xr-x   4 zhonggr users   4096 Sep  9  2019 .mozilla\ndrwx------   3 zhonggr users   4096 Jul 14 12:58 .nv\ndrwxr-xr-x   3 zhonggr users   4096 Nov 16 11:12 R\n-rw-r--r--   1 zhonggr users 585671 Dec 18 20:54 .radian_history\ndrwx------   2 zhonggr users   4096 Nov 16 10:58 .ssh\ndr-xr-x---   2 zhonggr users   4096 Dec 17 10:25 test\n-rw-------   1 zhonggr users   2350 Dec 17 12:04 .viminfo\ndrwxr-xr-x   2 zhonggr users   4096 Nov 16 17:01 .vscode-R\ndrwxr-xr-x   5 zhonggr users   4096 Dec 18 20:45 .vscode-server\n-rw-r--r--   1 zhonggr users    223 Dec 17 10:57 .wget-hsts\n-rw-r--r--   1 zhonggr users     38 Sep  9  2019 .xsession\n## Change ownership\nchown &lt;user&gt; &lt;file or dir&gt;         # changes user ownership\nchgrp &lt;group&gt; &lt;file or dir&gt;        # changes group ownership\nchown &lt;user&gt;:&lt;group&gt; &lt;file or dir&gt; # changes user & group ownership"
  },
  {
    "objectID": "blog/2022/12/19/index.html#finding-things",
    "href": "blog/2022/12/19/index.html#finding-things",
    "title": "Learn Linux basic for computing",
    "section": "Finding things",
    "text": "Finding things\nUseful find arguments:\n\n-user &lt;userName&gt;\n-group &lt;groupName&gt;\n-ctime &lt;number of days ago changed&gt;\n-exec &lt;command to run on each file&gt; {} \\;\n\n### Find text\n\ngrep \"pattern\" &lt;FILENAME&gt;                              # Provides lines in a file where \"pattern\" appears\ngrep -H \"pattern\"                                      # -H prints out file name in front of pattern\nfind ~ -name \"*.txt\" -exec grep -H \"pattern\" {} \\;     # Search lines where \"pattern\" appears in files with names that end with \".txt\"\n### Find application\nwhich &lt;APPLICATION_NAME&gt;                # Location of application\nwhereis &lt;APPLICATION_NAME&gt;              # Searches for executables in set of directories\nrpm -qa | grep \"pattern\"                # List all RPM packages and filter based on \"pattern\""
  },
  {
    "objectID": "blog/2022/12/19/index.html#help",
    "href": "blog/2022/12/19/index.html#help",
    "title": "Learn Linux basic for computing",
    "section": "Help",
    "text": "Help\nhelp &lt;COMMAND&gt;    # Show help for a Bash command\nman &lt;COMMAND&gt;     # Show the manual page for a program (press the 'q' key to exit)\n&lt;COMMAND&gt; --help  # Show help documentation for command\n&lt;COMMAND&gt; -h      # Show help documentation for command"
  },
  {
    "objectID": "blog/2022/12/19/index.html#variables",
    "href": "blog/2022/12/19/index.html#variables",
    "title": "Learn Linux basic for computing",
    "section": "Variables",
    "text": "Variables\nSome softwares utilize this feature and require that specific environment variables be set. For example, every time you login, the following variables are set by default:\n### Default Variables\necho $HOME               #Contains your home path\necho $USER               #Contains your username\necho $PATH               #Contains paths of executables\necho $LD_LIBRARY_PATH    #Contains paths of library dependencies\nTo see a list of all variables currently set in your shell, use the env command. You can also grep through this list to find variables, like so:\nenv | grep -i home\nOr if you are in a Slurm job, you can find all related Slurm variables:\nenv | grep -i slurm\nTry to choose unique names when setting variables. It is best to not overwrite a variable that is already set, unless on purpose.\nTo set a variable in your current shell, you can do so like this:\n### Setting variables\nMYVAR='Something Important'\n\nNotice that there is no spaces around the = sign.\n\nIf you would like to set a variable that is carried over to all other commands or sub-shells, then it must be exported:\nexport MYVAR='Something Important'"
  },
  {
    "objectID": "blog/2022/12/19/index.html#process-management",
    "href": "blog/2022/12/19/index.html#process-management",
    "title": "Learn Linux basic for computing",
    "section": "Process management",
    "text": "Process management\n### User\ntop               # view top consumers of memory and CPU (press 1 to see per-CPU statistics)\nhtop\nwho               # Shows who is logged into system\nw                 # Shows which users are logged into system and what they are doing\n### Process\nps                         # Shows processes running by user\nps -e                      # Shows all processes on system; try also '-a' and '-x' arguments\nps ux -u &lt;USERNAME&gt;        # Shows all processes owned by user\nps axjf                    # Shows the child-parent hierarchy of all processes\nps -o %t -p &lt;PID&gt;          # Shows how long a particular process was running.\n                           # (E.g. 6-04:30:50 means 6 days 4 hours ...)\nHere are two common utilities for displaying processes, sorting, and even killing them:\ntop            # Basic text based interface for exploring and managing processes\nhtop           # Text based interface for exploring and managing processes\n#### Background Resume Cancel\nCTRL+z ENTER         # Suspend a process in the background\nfg                   # Resume a suspended process and brings it into foreground\nbg                   # Resume a suspended process but keeps it running in the background\n\nCTRL+c               # Cancel the process that is currently running in the foreground\n#### PID\necho $!              # Get PID of last executed command\n#### Killing\nkill -l              # List all of the signals that can be sent to a process\nkill &lt;PID&gt;           # Kill a specific process with process ID using SIGTERM\nkill -9 &lt;PID&gt;        # Violently kill process with process ID using SIGKILL, may corrupt files\nMore on Terminating Processes DigitalOcean - How To Use ps, kill, and nice to Manage Processes in Linux"
  },
  {
    "objectID": "blog/2022/12/19/index.html#screen-session",
    "href": "blog/2022/12/19/index.html#screen-session",
    "title": "Learn Linux basic for computing",
    "section": "Screen session",
    "text": "Screen session\nscreen                   # start a screen session\nscreen -S session_name   # start a named session\nscreen -r                # reattach to a linux screen\nscreen -ls               # list the current running screen session\nCommon commands for managing Linux Screen Windows:\n\nCtrl + A + C # create a new window (with shell).\nCtrl + A + ” # list all windows.\nCtrl + A + 0 # switch to window 0 (by number).\nCtrl + A + A # rename the current window.\nCtrl + A + S # split current region horizontally into two regions.\nCtrl + A + | # split current region vertically into two regions.\nCtrl + A + Tab # switch the input focus to the next region.\nCtrl + A + Ctrl + A # toggle between the current and previous windows\nCtrl + A + Q # close all regions but the current one.\nCtrl + A + X # close the current region.\nCtrl + A + D # detach from linux screen session\n\nscreen -ls\n## Output\nThere are screens on:\n    10835.pts-0.linuxize-desktop   (Detached)\n    10366.pts-0.linuxize-desktop   (Detached)\n2 Sockets in /run/screens/S-linuxize.\nIf want to restore screen 10835.pts-0, then\nscreen -r 10835"
  },
  {
    "objectID": "blog/2022/12/19/index.html#vim-basics",
    "href": "blog/2022/12/19/index.html#vim-basics",
    "title": "Learn Linux basic for computing",
    "section": "Vim Basics",
    "text": "Vim Basics\nvim &lt;my_file_name&gt; # open/create file with vim\n\nOnce you are in Vim the most important commands are i , : and ESC.\ni key brings you into the insert mode for typing.\nESC brings you out of there.\n: key starts the command mode at the bottom of the screen.\n\nIn the following text, all commands starting with : need to be typed in the command mode. All other commands are typed in the normal mode after hitting the ESC key.\n\nModifiers\ni                   # INSERT MODE\nESC                 # NORMAL (NON-EDITING) MODE\n:                   # Commands start with ':'\n:w                  # Save command; if you are in editing mode you have to hit ESC first!!\n:q                  # Quit file, don't save\n:q!                 # Exits WITHOUT saving any changes you have made\n:wq                 # Save and quit\nR                   # Replace MODE\nr                   # Replace only one character under cursor\nq:                  # History of commands (from NORMAL MODE!), to reexecute one of them, select and hit enter!\n:w new_filename     # Saves into new file\n:#,#w new_filename  # Saves specific lines (#,#) to new file\n:#                  # Go to specified line number\n\n\nMoving Around\n$               # Moves cursor to end of line\nA               # Same as $, but switches to insert mode\n0               # Zero moves cursor to beginning of line\nCTRL-g          # Shows file name and current line you are on\nSHIFT-G         # Brings you to bottom of file\n\n\nLines\n:set wrap       # Wrap lines around the screen if too long\n:set nowrap     # No line wrapping\n:set number     # Shows line numbers\n:set nonumber   # No line numbers\n\n\nMultiple Files\nvim -o *.txt    # Opens many files at once and displays them with horizontal\n                # Split, '-O' does vertical split\nvim *.txt       # Opens many files at once; ':n' switches between files\n:wall or :qall    # Write or quit all open files\n:args *.txt       # Places all the relevant files in the argument list\n:all              # Splits all files in the argument list (buffer) horizontally\nCTRL-w            # Switch between windows\n:split            # Shows same file in two windows\n:split &lt;file-to-open&gt; # Opens second file in new window\n:vsplit           # Splits windows vertically, very useful for tables, \":set scrollbind\" let's you scroll all open windows simultaneously\n:close            # Closes current window\n:only             # Closes all windows except current one\n\n\nSpell Checking\n:set spell           # Turns on spell checking\n:set nospell         # Turns spell checking off\n:! dict &lt;word&gt;       # Meaning of word\n:! wn 'word' -over   # Synonyms of word\n\n\nSyntax Highlighting\n:set filetype=perl   # Turns on syntax coloring for a chosen programming language.\n:syn on              # Turns syntax highlighting on\n:syn off             # Turns syntax highlighting off\n\n\nUndo and Redo\nu          # Undo last command\nU          # Undo all changes on current line\nCTRL-R     # Redo one change which was undone\n\n\nDeleting\nx       # Deletes what is under cursor\ndw      # Deletes from curser to end of word including the space\nde      # Deletes from curser to end of word NOT including the space\ncw      # Deletes rest of word and lets you then insert, hit ESC to continue with NORMAL mode\nc$      # Deletes rest of line and lets you then insert, hit ESC to continue with with NORMAL mode\nd$      # Deletes from cursor to the end of the line\ndd      # Deletes entire line\n2dd     # Deletes next two lines, continues: 3dd, 4dd and so on.\n\n\nCopy and Paste\nyy    # Copies line, for copying several lines do 2yy, 3yy and so on\np     # Pastes clipboard behind cursor\n\n\nSearch\n/my_pattern    # Searches for my_pattern downwards, type n for next match\n?my_pattern    # Searches for my_pattern upwards, type n for next match\n:set ic        # Switches to ignore case search (case insensitive)\n:set hls       # Switches to highlight search (highlights search hits)\n\n\nReplacements\nGreat intro: A Tao of Regular Expressions\nQuick reference to some replacement techniques:\n:s/old_pat/new_pat/                      # Replaces first occurrence in a line\n:s/old_pat/new_pat/g                     # Replaces all occurrence in a line\n:s/old_pat/new_pat/gc                    # Add 'c' to ask for confirmation\n:#,#s/old_pat/new_pat/g                  # Replaces all occurrence between line numbers: #,#\n:%s/old_pat/new_pat/g                    # Replaces all occurrence in file\n:%s/\\(pattern1\\)\\(pattern2\\)/\\1test\\2/g  # Regular expression to insert, you need here '\\' in front of parentheses (&lt;# Perl)\n:%s/\\(pattern.*\\)/\\1 my_tag/g            # Appends something to line containing pattern (&lt;# .+ from Perl is .* in VIM)\n:%s/\\(pattern\\)\\(.*\\)/\\1/g               # Removes everything in lines after pattern\n:%s/\\(At\\dg\\d\\d\\d\\d\\d\\.\\d\\)\\(.*\\)/\\1\\t\\2/g  # Inserts tabs between At1g12345.1 and Description\n:%s/\\n/new_pattern/g                     # Replaces return signs\n:%s/pattern/\\r/g                         # Replace pattern with return signs!!\n:%s/\\(\\n\\)/\\1\\1/g                        # Insert additional return signs\n:%s/\\(^At\\dg\\d\\d\\d\\d\\d.\\d\\t.\\{-}\\t.\\{-}\\t.\\{-}\\t.\\{-}\\t\\).\\{-}\\t/\\1/g  # Replaces content between 5th and 6th tab (5th column), '{-}' turns off 'greedy' behavior\n:#,#s/\\( \\{-} \\|\\.\\|\\n\\)/\\1/g            # Performs simple word count in specified range of text\n:%s/\\(E\\{6,\\}\\)/&lt;font color=\"green\"&gt;\\1&lt;\\/font&gt;/g  # Highlight pattern in html colors, here highlighting of &gt;= 6 occurences of Es\n:%s/\\([A-Z]\\)/\\l\\1/g                     # Change uppercase to lowercase, '%s/\\([A-Z]\\)/\\u\\1/g' does the opposite\nUses ‘global’ command to apply replace function only on those lines that match a certain pattern. The ‘copy $’ command after the pipe ‘|’ prints all matching lines at the end of the file.\n:g/my_pattern/ s/\\([A-Z]\\)/\\l\\1/g | copy $\nCommand ‘args’ places all relevant files in the argument list (buffer); ‘all’ displays each file in separate split window; command ‘argdo’ applies replacement to all files in argument list (buffer); flag ‘e’ is necessary to avoid stop at error messages for files with no matches; command ‘update’ saves all changes to files that were updated.\n:args *.txt | all | argdo %s/\\old_pat/new_pat/ge | update\n\n\nUtilities\n\nMatching Parentheses\n\nPlace cursor on (, [ or { and type % # cursor moves to matching parentheses\n\nPrinting and Inserting Files\n\n:ha # Prints entire file\n:#,#ha # Prints specified lines: #,#\n:r &lt;filename&gt; # Inserts content of specified file after cursor\n\nConvert Text File to HTML Format\n\n:runtime! syntax/2html.vim # Run this command with open file in Vim\n\nShell Commands in Vim\n\n:!&lt;SHELL_COMMAND&gt; &lt;ENTER&gt; # Executes any shell command, hit &lt;enter&gt; to return\n:sh # Switches window to shell, 'exit' switches back to vim\n\nUsing Vim as Table Editor\n\nv starts visual mode for selecting characters\nV starts visual mode for selecting lines`\nCTRL-V starts visual mode for selecting blocks (use CTRL-q in gVim under Windows). This allows column-wise selections and operations like inserting and deleting columns. To restrict substitute commands to a column, one can select it and switch to the command-line by typing :. After this the substitution syntax for a selected block looks like this: '&lt;,'&gt;s///.\n:set scrollbind starts simultaneous scrolling of ‘vsplitted’ files. To set to horizontal binding of files, use command :set scrollopt=hor (after first one). Run all these commands before the :split command.\n:AlignCtrl I= \\t then :%Align This allows to align tables by column separators (here ’) when the Align utility from Charles Campbell’s is installed. To sort table rows by selected lines or block, perform the visual select and then hit F3 key. The rest is interactive. To enable this function, one has to include in the .vimrc file the Vim sort script from Gerald Lai.\n\n\n\n\nSettings\nThe default settings in Vim are controlled by the .vimrc file in your home directory.\n\nsee last chapter of vimtutor (start from shell)\nuseful .vimrc sample\nwhen vim starts to respond very slowly then one may need to delete the .viminf* files in home directory\n\n\n\nHelp\n\nOnline Help\n\nFind help on the web. Google will find answers to most questions on vi and vim (try searching for both terms).\nPurdue University Vi Tutorial\nAnimated Vim Tutorial: https://linuxconfig.org/vim-tutorial\nUseful list of vim commands:\n\nVim Commands Cheat Sheet\nVimCard\n\n\n\nYou can run a tutor from the command Line:\nvimtutor      # Open vim tutorial from shell, \":q\" to quit\nYou can also get help from within Vim:\n:help                # opens help within vim, hit :q to get back to your file\n:help &lt;topic&gt;        # opens help on specified topic\n:help_topic| CTRL-]  # when you are in help this command opens help topic specified between |...|,\n                     # CTRL-t brings you back to last topic\n:help &lt;topic&gt; CTRL-D # gives list of help topics that contain key word\n: &lt;up-down keys&gt;     # like in shell you get recent commands!!!!"
  },
  {
    "objectID": "blog/2022/12/19/index.html#reference",
    "href": "blog/2022/12/19/index.html#reference",
    "title": "Learn Linux basic for computing",
    "section": "Reference",
    "text": "Reference\n\nBash basics"
  },
  {
    "objectID": "blog/2022/10/01/index.html",
    "href": "blog/2022/10/01/index.html",
    "title": "Nomenclature for the description of mutations and variations",
    "section": "",
    "text": "DNA:\n\nc. → coding DNA\ng. → genomic DNA\nm. → mitochondrial DNA\n\nRNA:\n\nr. → RNA\n\nProtein:\n\np. → protein"
  },
  {
    "objectID": "blog/2022/10/01/index.html#indicate-the-reference-sequence",
    "href": "blog/2022/10/01/index.html#indicate-the-reference-sequence",
    "title": "Nomenclature for the description of mutations and variations",
    "section": "",
    "text": "DNA:\n\nc. → coding DNA\ng. → genomic DNA\nm. → mitochondrial DNA\n\nRNA:\n\nr. → RNA\n\nProtein:\n\np. → protein"
  },
  {
    "objectID": "blog/2022/10/01/index.html#code",
    "href": "blog/2022/10/01/index.html#code",
    "title": "Nomenclature for the description of mutations and variations",
    "section": "Code",
    "text": "Code\n\n\n\nSubstitution (for bases)\n&gt;\n\n\n\n\nrange\n-\n\n\nmore change in one allele\n;\n\n\nmore transcripts / mosaicism\n,\n\n\nuncertain\n()\n\n\nallele\n[ ]\n\n\ndeletion\ndel\n\n\nduplication\ndup\n\n\ninsertion\nins\n\n\ninversion\ninv\n\n\nconversion\ncon\n\n\nextension\next\n\n\nstop codon\nX\n\n\nframe shift\nfsX\n\n\nopposite strand\no\n\n\ntranslocation\nt"
  },
  {
    "objectID": "blog/2022/10/01/index.html#mutation",
    "href": "blog/2022/10/01/index.html#mutation",
    "title": "Nomenclature for the description of mutations and variations",
    "section": "Mutation",
    "text": "Mutation\nA mutation is a change in the DNA sequence of an organism. Mutations can result from errors in DNA replication during cell division, exposure to mutagens or a viral infection.\nGermline mutations (that occur in eggs and sperm) can be passed on to offspring, while somatic mutations (that occur in body cells) are not passed on.\n\nThe translation of disrupted sequence can be checked via Expasy\n\nSubstitution\nSubstitution, as related to genomics, is a type of mutation in which one nucleotide is replaced by a different nucleotide. The term can also refer to the replacement of one amino acid in a protein with a different amino acid.\n\nc.123A&gt;G: on cDNA, A in 123 is replaced by G\np.P252R: on protein, proline (P) replaced by arginine (R)\n\n\n\n\nPoint mutation\nA point mutation occurs in a genome when a single base pair is added, deleted or changed. While most point mutations are benign, they can also have various functional consequences, including changes in gene expression or alterations in encoded proteins.\nA point mutation is when a single base pair is altered. Point mutations can have one of three effects.\n\nFirst, the base substitution can be a silent mutation where the altered codon corresponds to the same amino acid.\nSecond, the base substitution can be a missense mutation where the altered codon corresponds to a different amino acid.\nOr third, the base substitution can be a nonsense mutation where the altered codon corresponds to a stop signal.\n\n\nA missense mutation is a DNA change that results in different amino acids being encoded at a particular position in the resulting protein. Some missense mutations alter the function of the resulting protein.\n\nA nonsense mutation occurs in DNA when a sequence change gives rise to a stop codon rather than a codon specifying an amino acid. The presence of the new stop codon results in the production of a shortened protein that is likely non-functional.\n\n\n\nDeletion\nDeletion, as related to genomics, is a type of mutation that involves the loss of one or more nucleotides from a segment of DNA. A deletion can involve the loss of any number of nucleotides, from a single nucleotide to an entire piece of a chromosome.\n\nc.546delT, deletion of T in 546\nc.586_591del, for six bases deleted\np.F508del, deletion of phenylalanine (F) in 508\n\n\n\n\nDuplication\nDuplication, as related to genomics, refers to a type of mutation in which one or more copies of a DNA segment (which can be as small as a few bases or as large as a major chromosomal region) is produced. Duplications occur in all organisms. For example, they are especially prominent in plants, although they can also cause genetic diseases in humans. Duplications have been an important mechanism in the evolution of the genomes of humans and other organisms.\n\nc.546dupT, duplication of T in 546\nc.586_591dup, duplication of the segment 586 to 591\np.G4_Q6dup, duplication of the segment from glycine (G) in 4 to glutamine (Q) in 6\n\n\n\n\nInsertion\nAn insertion, as related to genomics, is a type of mutation that involves the addition of one or more nucleotides into a segment of DNA. An insertion can involve the addition of any number of nucleotides, from a single nucleotide to an entire piece of a chromosome.\n\nc.546_547insT, insertion of T between 546 and 547\nc.1086_1087insGCGTGA, insertion of GCGTGA\np.K2_L3insQS, insertion of glutamine serine between lysine (K) in 2 and leucine (L) in 3\n\n\n\n\nInversion\nAn inversion in a chromosome occurs when a segment breaks off and reattaches within the same chromosome, but in reverse orientation. DNA may or may not be lost in the process.\n\nc.546_2031inv, segment 546 to 2031 inverted\n\n\n\n\nFrameshift\nA frameshift mutation in a gene refers to the insertion or deletion of nucleotide bases in numbers that are not multiples of three. This is important because a cell reads a gene’s code in groups of three bases when making a protein. Each of these “triplet codons” corresponds to one of 20 different amino acids used to build a protein. If a mutation disrupts this normal reading frame, then the entire gene sequence following the mutation will be incorrectly read. This can result in the addition of the wrong amino acids to the protein and/or the creation of a codon that stops the protein from growing longer.\n\np.R83SfsX15, arginine (R) is the first amino acid changed, it is in position 83, it makes serine (S) instead, the length of the shift frame is 15, including the stop codon (X)"
  },
  {
    "objectID": "blog/2022/10/01/index.html#example",
    "href": "blog/2022/10/01/index.html#example",
    "title": "Nomenclature for the description of mutations and variations",
    "section": "Example",
    "text": "Example\n\n\nReference\n\nhttps://atlasgeneticsoncology.org/teaching/30067/nomenclature-for-the-description-of-mutations-and-other-sequence-variations\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC1867422/\nhttps://www.genome.gov/genetics-glossary/Mutation"
  },
  {
    "objectID": "blog/2021/03/16/index.html",
    "href": "blog/2021/03/16/index.html",
    "title": "Crop image and add scale bar with ImageJ/Fiji",
    "section": "",
    "text": "Edit -&gt; Selection -&gt; Specify\nimage -&gt; Crop"
  },
  {
    "objectID": "blog/2021/03/16/index.html#crop-images-to-a-given-physical-size",
    "href": "blog/2021/03/16/index.html#crop-images-to-a-given-physical-size",
    "title": "Crop image and add scale bar with ImageJ/Fiji",
    "section": "",
    "text": "Edit -&gt; Selection -&gt; Specify\nimage -&gt; Crop"
  },
  {
    "objectID": "blog/2021/03/16/index.html#crop-same-area-from-different-images",
    "href": "blog/2021/03/16/index.html#crop-same-area-from-different-images",
    "title": "Crop image and add scale bar with ImageJ/Fiji",
    "section": "Crop same area from different images",
    "text": "Crop same area from different images\n\nSelect the area on the first image\nAnalyze -&gt; Tools -&gt; ROI manager -&gt; Add [t]\nClick the second image, select and click the parameters on the ROI manager"
  },
  {
    "objectID": "blog/2021/03/16/index.html#set-scale-and-add-scale-bar",
    "href": "blog/2021/03/16/index.html#set-scale-and-add-scale-bar",
    "title": "Crop image and add scale bar with ImageJ/Fiji",
    "section": "Set scale and add scale bar",
    "text": "Set scale and add scale bar\n\nAnalyze -&gt; Set Scale\n\n\nNikon (20x object):\n\n3.2 pixel/um, 5 um/16 pixel\n5uM = 16 pixels (cellxpress exported as 100%)\n5uM = 32 pixels (cellxpress exported as 200%)\n5uM = 64 pixels (cellxpress exported as 400%)\n12.8 pixel/um (when exported with 400% zoom in using cellXpress)\n\nNikon (40x object):\n\n6.25 pixel/um, 0.16 um/pixel\n1um = 6.25 pixel (cellxpress exported as 100%)\n1um = 12.5 pixel (cellxpress exported as 200%)\n1um = 25 pixel (cellxpress exported as 400%)\n5uM = 125 pixels (cellxpress exported as 400%)\n\nTC microscope:\n\nphysical length of a pixel: 3.4375 um\n10x: 0.34375 um/pixel = 2.91 pixel/um\n20x: 0.171875 um/pixel = 5.82 pixel/um\n\n\n\nAnalyze -&gt; Tools -&gt; Scale bar\nFile save as png format."
  },
  {
    "objectID": "blog/2021/01/02/index.html",
    "href": "blog/2021/01/02/index.html",
    "title": "Markdown input greek letters",
    "section": "",
    "text": "inline-equation: \\(xyz\\)\ninsert an equation to a new line and settled in the middle: \\[xyz\\]"
  },
  {
    "objectID": "tools/index.html",
    "href": "tools/index.html",
    "title": "Tools",
    "section": "",
    "text": "Zotero"
  },
  {
    "objectID": "stat/index.html",
    "href": "stat/index.html",
    "title": "Statistics",
    "section": "",
    "text": "type &lt;- factor(c(rep(\"control\", times = 4), rep(\"mutant\", times = 4)))\nweight &lt;- c(2.4, 3.5, 4.4, 4.9, 1.7, 2.8, 3.2, 3.9)\nsize &lt;- c(1.9, 3, 2.9, 3.7, 2.8, 3.3, 3.9, 4.8)\nmodel.matrix(~type + weight)\n\n  (Intercept) typemutant weight\n1           1          0    2.4\n2           1          0    3.5\n3           1          0    4.4\n4           1          0    4.9\n5           1          1    1.7\n6           1          1    2.8\n7           1          1    3.2\n8           1          1    3.9\nattr(,\"assign\")\n[1] 0 1 2\nattr(,\"contrasts\")\nattr(,\"contrasts\")$type\n[1] \"contr.treatment\"\n\nmodel &lt;- lm(size ~ type + weight)\nsummary(model)\n\n\nCall:\nlm(formula = size ~ type + weight)\n\nResiduals:\n       1        2        3        4        5        6        7        8 \n 0.05455  0.34562 -0.41623  0.01607 -0.01753 -0.32646 -0.02062  0.36461 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  0.08052    0.52744   0.153  0.88463   \ntypemutant   1.48685    0.26023   5.714  0.00230 **\nweight       0.73539    0.13194   5.574  0.00256 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3275 on 5 degrees of freedom\nMultiple R-squared:  0.8975,    Adjusted R-squared:  0.8564 \nF-statistic: 21.88 on 2 and 5 DF,  p-value: 0.003367\n\n\n\nlab &lt;- factor(\n    c(rep(\"a\", times = 6), rep(\"b\", times = 6))\n)\n\ntype &lt;- factor(\n    c(\n        rep(\"control\", times = 3), \n        rep(\"mutant\", times = 3),\n        rep(\"control\", times = 3), \n        rep(\"mutant\", times = 3)\n    )\n)\n\nexpression &lt;- c(\n    1.7, 2, 2.2,\n    3.1, 3.6, 3.9,\n    0.9, 1.2, 1.9,\n    1.8, 2.2, 2.9\n)\nmodel.matrix(~lab + type)\n\n   (Intercept) labb typemutant\n1            1    0          0\n2            1    0          0\n3            1    0          0\n4            1    0          1\n5            1    0          1\n6            1    0          1\n7            1    1          0\n8            1    1          0\n9            1    1          0\n10           1    1          1\n11           1    1          1\n12           1    1          1\nattr(,\"assign\")\n[1] 0 1 2\nattr(,\"contrasts\")\nattr(,\"contrasts\")$lab\n[1] \"contr.treatment\"\n\nattr(,\"contrasts\")$type\n[1] \"contr.treatment\"\n\n### linear model\nbatch_lm &lt;- lm(expression ~ lab + type)\nsummary(batch_lm)\n\n\nCall:\nlm(formula = expression ~ lab + type)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.6500 -0.2833 -0.0500  0.2750  0.7167 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.1167     0.2279   9.287  6.6e-06 ***\nlabb         -0.9333     0.2632  -3.546 0.006250 ** \ntypemutant    1.2667     0.2632   4.813 0.000956 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4558 on 9 degrees of freedom\nMultiple R-squared:  0.7989,    Adjusted R-squared:  0.7542 \nF-statistic: 17.87 on 2 and 9 DF,  p-value: 0.0007342"
  },
  {
    "objectID": "stat/index.html#linear-models",
    "href": "stat/index.html#linear-models",
    "title": "Statistics",
    "section": "",
    "text": "type &lt;- factor(c(rep(\"control\", times = 4), rep(\"mutant\", times = 4)))\nweight &lt;- c(2.4, 3.5, 4.4, 4.9, 1.7, 2.8, 3.2, 3.9)\nsize &lt;- c(1.9, 3, 2.9, 3.7, 2.8, 3.3, 3.9, 4.8)\nmodel.matrix(~type + weight)\n\n  (Intercept) typemutant weight\n1           1          0    2.4\n2           1          0    3.5\n3           1          0    4.4\n4           1          0    4.9\n5           1          1    1.7\n6           1          1    2.8\n7           1          1    3.2\n8           1          1    3.9\nattr(,\"assign\")\n[1] 0 1 2\nattr(,\"contrasts\")\nattr(,\"contrasts\")$type\n[1] \"contr.treatment\"\n\nmodel &lt;- lm(size ~ type + weight)\nsummary(model)\n\n\nCall:\nlm(formula = size ~ type + weight)\n\nResiduals:\n       1        2        3        4        5        6        7        8 \n 0.05455  0.34562 -0.41623  0.01607 -0.01753 -0.32646 -0.02062  0.36461 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  0.08052    0.52744   0.153  0.88463   \ntypemutant   1.48685    0.26023   5.714  0.00230 **\nweight       0.73539    0.13194   5.574  0.00256 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3275 on 5 degrees of freedom\nMultiple R-squared:  0.8975,    Adjusted R-squared:  0.8564 \nF-statistic: 21.88 on 2 and 5 DF,  p-value: 0.003367\n\n\n\nlab &lt;- factor(\n    c(rep(\"a\", times = 6), rep(\"b\", times = 6))\n)\n\ntype &lt;- factor(\n    c(\n        rep(\"control\", times = 3), \n        rep(\"mutant\", times = 3),\n        rep(\"control\", times = 3), \n        rep(\"mutant\", times = 3)\n    )\n)\n\nexpression &lt;- c(\n    1.7, 2, 2.2,\n    3.1, 3.6, 3.9,\n    0.9, 1.2, 1.9,\n    1.8, 2.2, 2.9\n)\nmodel.matrix(~lab + type)\n\n   (Intercept) labb typemutant\n1            1    0          0\n2            1    0          0\n3            1    0          0\n4            1    0          1\n5            1    0          1\n6            1    0          1\n7            1    1          0\n8            1    1          0\n9            1    1          0\n10           1    1          1\n11           1    1          1\n12           1    1          1\nattr(,\"assign\")\n[1] 0 1 2\nattr(,\"contrasts\")\nattr(,\"contrasts\")$lab\n[1] \"contr.treatment\"\n\nattr(,\"contrasts\")$type\n[1] \"contr.treatment\"\n\n### linear model\nbatch_lm &lt;- lm(expression ~ lab + type)\nsummary(batch_lm)\n\n\nCall:\nlm(formula = expression ~ lab + type)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.6500 -0.2833 -0.0500  0.2750  0.7167 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.1167     0.2279   9.287  6.6e-06 ***\nlabb         -0.9333     0.2632  -3.546 0.006250 ** \ntypemutant    1.2667     0.2632   4.813 0.000956 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4558 on 9 degrees of freedom\nMultiple R-squared:  0.7989,    Adjusted R-squared:  0.7542 \nF-statistic: 17.87 on 2 and 9 DF,  p-value: 0.0007342"
  },
  {
    "objectID": "python/index.html",
    "href": "python/index.html",
    "title": "Python Programming",
    "section": "",
    "text": "Number\nString\nTuple\nList: Mutable, container\nDictionary: Mutable, container\nSet: Mutable, container\nNone: empty value\n\ntuple = (1, 2, 3)\nlist = [1, 2, 3]\ndict = {\"ele1\":1, \"ele2\":2, \"ele3\":3}\n\n\n\nNumerical Operators: - &lt; : less than - &gt; : greater than - &lt;= : less than or equal to - &gt;= : greater than or equal to - == : equal to - != : not equal to\nString Operators: - == : equal to - != : not equal to\nLogical Operators: - and - or - not\n\n\n\nConditional execution in Python is achieved using the if/else construct (if and else are reserved words).\n# Conidtional execution\nx = 10\nif x &gt; 10:\n    print(\"I am a big number\")\nelse:\n    print(\"I am a small number\")\n\n# Multi-way if/else\nx = 10\nif x &gt; 10:\n    print(\"I am a big number\")\nelif x &gt; 5:\n    print(\"I am kind of small\")\nelse:\n    print(\"I am really number\")\n\n\n\nTwo looping constructs in Python\n\nFor : used when the number of possible iterations (repetitions) are known in advance\nWhile: used when the number of possible iterations (repetitions) can not be defined in advance. Can lead to infinite loops, if conditions are not handled properly\n\nfor customer in [“John”, “Mary”, “Jane”]:\n    print(“Hello ”, customer)\n    print(“Please pay”)\n    collectCash()\n    giveGoods()\n\nhour_of_day = 9\nwhile hour_of_day &lt; 17:\n    moveToWarehouse()\n    locateGoods()\n    moveGoodsToShip()\n    hour_of_day = getCurrentTime()\nWhat happens if you need to stop early? We use the break keyword to do this.\nIt stops the iteration immediately and moves on to the statement that follows the looping\nwhile hour_of_day &lt; 17:\n    if shipIsFull() == True:\n        break\n    moveToWarehouse()\n    locateGoods()\n    moveGoodsToShip()\n    hour_of_day = getCurrentTime()\ncollectPay()\nWhat happens when you want to just skip the rest of the steps? We can use the continue keyword for this.\nIt skips the rest of the steps but moves on to the next iteration.\nfor customer in [\"John\", \"Mary\", \"Jane\"]:\n    print(“Hello ”, customer)\n    print(“Please pay”)\n    paid = collectCash()\n    if paid == false:\n        continue\n    giveGoods()\n\n\n\n\nExceptions are errors that are found during execution of the Python program.\nThey typically cause the program to fail.\nHowever we can handle them using the ‘try/except’ construct.\n\nnum = input(\"Please enter a number: \")\ntry:\n    num = int(num)\n    print(\"number squared is \" + str(num**2))\nexcept:\n    print(\"You did not enter a valid number\")\n\n\n\nhelp()\ntype()\nlen() \nrange()\nlist()      \ntuple()\ndict()"
  },
  {
    "objectID": "python/index.html#basic-concepts",
    "href": "python/index.html#basic-concepts",
    "title": "Python Programming",
    "section": "",
    "text": "Number\nString\nTuple\nList: Mutable, container\nDictionary: Mutable, container\nSet: Mutable, container\nNone: empty value\n\ntuple = (1, 2, 3)\nlist = [1, 2, 3]\ndict = {\"ele1\":1, \"ele2\":2, \"ele3\":3}\n\n\n\nNumerical Operators: - &lt; : less than - &gt; : greater than - &lt;= : less than or equal to - &gt;= : greater than or equal to - == : equal to - != : not equal to\nString Operators: - == : equal to - != : not equal to\nLogical Operators: - and - or - not\n\n\n\nConditional execution in Python is achieved using the if/else construct (if and else are reserved words).\n# Conidtional execution\nx = 10\nif x &gt; 10:\n    print(\"I am a big number\")\nelse:\n    print(\"I am a small number\")\n\n# Multi-way if/else\nx = 10\nif x &gt; 10:\n    print(\"I am a big number\")\nelif x &gt; 5:\n    print(\"I am kind of small\")\nelse:\n    print(\"I am really number\")\n\n\n\nTwo looping constructs in Python\n\nFor : used when the number of possible iterations (repetitions) are known in advance\nWhile: used when the number of possible iterations (repetitions) can not be defined in advance. Can lead to infinite loops, if conditions are not handled properly\n\nfor customer in [“John”, “Mary”, “Jane”]:\n    print(“Hello ”, customer)\n    print(“Please pay”)\n    collectCash()\n    giveGoods()\n\nhour_of_day = 9\nwhile hour_of_day &lt; 17:\n    moveToWarehouse()\n    locateGoods()\n    moveGoodsToShip()\n    hour_of_day = getCurrentTime()\nWhat happens if you need to stop early? We use the break keyword to do this.\nIt stops the iteration immediately and moves on to the statement that follows the looping\nwhile hour_of_day &lt; 17:\n    if shipIsFull() == True:\n        break\n    moveToWarehouse()\n    locateGoods()\n    moveGoodsToShip()\n    hour_of_day = getCurrentTime()\ncollectPay()\nWhat happens when you want to just skip the rest of the steps? We can use the continue keyword for this.\nIt skips the rest of the steps but moves on to the next iteration.\nfor customer in [\"John\", \"Mary\", \"Jane\"]:\n    print(“Hello ”, customer)\n    print(“Please pay”)\n    paid = collectCash()\n    if paid == false:\n        continue\n    giveGoods()\n\n\n\n\nExceptions are errors that are found during execution of the Python program.\nThey typically cause the program to fail.\nHowever we can handle them using the ‘try/except’ construct.\n\nnum = input(\"Please enter a number: \")\ntry:\n    num = int(num)\n    print(\"number squared is \" + str(num**2))\nexcept:\n    print(\"You did not enter a valid number\")\n\n\n\nhelp()\ntype()\nlen() \nrange()\nlist()      \ntuple()\ndict()"
  },
  {
    "objectID": "python/index.html#reference",
    "href": "python/index.html#reference",
    "title": "Python Programming",
    "section": "Reference",
    "text": "Reference\n\nhttps://www.py4e.com/\nhttps://omgenomics.com/\nhttps://www.coursera.org/learn/bioinformatics\nhttp://do1.dr-chuck.com/pythonlearn/EN_us/pythonlearn.pdf\nhttps://www.py4e.com/html3\nhttp://do1.dr-chuck.com/pythonlearn/EN_us/pythonlearn.epub\nPrimer on Python for R Users"
  },
  {
    "objectID": "keyboard/index.html",
    "href": "keyboard/index.html",
    "title": "Commonly used Keyboard Shortcuts",
    "section": "",
    "text": "VSCode\n\n\n\n\n\n\n\n\nActin\nMac\nWindows\n\n\n\n\nGeneral Commands\n\n\n\n\nCommand Palette\nCmd + Shift + P\nCtrl + Shift + P\n\n\nOpen Settings\nCmd + ,\nCtrl + ,\n\n\nKeyboard Shortcuts\nCmd + K Cmd + S\nCtrl + K Ctrl + S\n\n\nToggle Sidebar\nCmd + B\nCtrl + B\n\n\nFull Screen\nCmd + Ctrl + F\nF11\n\n\nOpen File\nCmd + P\nCtrl + P\n\n\nNew Window\nCmd + Shift + N\nCtrl + Shift + N\n\n\nClose Window\nCmd + Shift + W\nCtrl + Shift + W\n\n\nTerminal Management\n\n\n\n\nToggle Terminal\nCmd + `\nCtrl + `\n\n\nCreate New Terminal\nCmd + Shift + `\nCtrl + Shift + `\n\n\nNavigate Between Terminals\nCmd + Shift + [ / ]\nCtrl + PgUp / PgDn\n\n\nSplit Terminal\nCmd + \\\nCtrl + \\\n\n\nNavigate Between Terminal Panes\nCmd + Option + ← / →\nCtrl + Left / Right Arrow\n\n\nEditor Management\n\n\n\n\nClose Tab\nCmd + W\nCtrl + W\n\n\nSplit Editor\nCmd + \\\nCtrl + \\\n\n\nNavigate Tabs\nCmd + Shift + Tab\nCtrl + Shift + Tab\n\n\nNavigate Tab Groups\nCmd + 1 / 2 / 3\nCtrl + 1 / 2 / 3\n\n\nText Manipulation\n\n\n\n\nAdd Multiple Cursors\nCmd + Option + ↑ / ↓\nCtrl + Alt + ↑ / ↓\n\n\nSelect Text\nCmd + Shift + ↑ / ↓\nCtrl + Shift + ↑ / ↓\n\n\nMove Line Up/Down\nOption + ↑ / ↓\nAlt + ↑ / ↓\n\n\nCopy Line Up/Down\nShift + Option + ↑ / ↓\nShift + Alt + ↑ / ↓\n\n\nSelect Word\nCmd + D\nCtrl + D\n\n\nSelect Current Line\nCmd + L\nCtrl + L\n\n\nSelect All Occurrences\nCmd + Shift + L\nCtrl + Shift + L\n\n\nDelete Current Line\nCmd + Shift + K\nCtrl + Shift + K\n\n\nDelete Word Backward\nOption + Backspace\nCtrl + Backspace\n\n\nComment/Uncomment Lines\nCmd + /\nCtrl + /\n\n\nGo to Line\nCmd + G\nCtrl + G\n\n\nGo to last cursor position\nCtl + -\nAlt + ←\n\n\nGo to next cursor position\nCtl + Shift -\nAlt + →\n\n\nCode Folding\nCmd + Option + [ / ]\nCtrl + Shift + [ / ]\n\n\nIndent/Outdent Lines\nCmd + [ / ]\nCtrl + [ / ]\n\n\nFormat Selected Code\nCmd + K Cmd + F\nCtrl + K Ctrl + F\n\n\nFormat Document\nShift + Option + F\nShift + Alt + F\n\n\nGo to Word Start/End\nOption + ← / →\nCtrl + ← / →\n\n\nGo to Line Start/End\nCmd + ← / →\nHome / End\n\n\nGo to File Start/End\nCmd + ↑ / ↓\nCtrl + Home / End\n\n\nSearch Files\nCmd + Shift + F\nCtrl + Shift + F\n\n\nFind Text\nCmd + F\nCtrl + F\n\n\nReplace Text\nCmd + Option + F\nCtrl + H\n\n\n\n\n\nZsh/Bash\n\n\n\nActin\nShortcut\n\n\n\n\nCursor Movement\n\n\n\nMove to the beginning of line\nCtrl + A\n\n\nMove to the end of line\nCtrl + E\n\n\nMove one word backward\nOpt + ←\n\n\nMove one word forward\nOpt + →\n\n\nMove one character backward\n←\n\n\nMove one character forward\n→\n\n\nJump to the start of buffer\nAlt + &lt;\n\n\nJump to the end of buffer\nAlt + &gt;\n\n\nDeleting Text\n\n\n\nDelete the current line\nCtrl + U\n\n\nDelete to end of the line\nCtrl + K\n\n\nClear the screen\nCtrl + L\n\n\nDelete one word backward\nCtrl + W\n\n\nDelete one character forward\nCtrl + D\n\n\nDelete one character forward\nFn + Backspace\n\n\nDelete one character backward\nBackspace\n\n\nDelete from cursor to start\nAlt + Backspace\n\n\nDelete from cursor to word end\nAlt + D\n\n\nProcess Management\n\n\n\nTerminate a process\nCtrl + C\n\n\nSuspend a process\nCtrl + Z\n\n\nExit the shell\nCtrl + D\n\n\nSend process to background\nCtrl + Z then bg\n\n\nBring background process to fg\nfg\n\n\nUndo and History Navigation\n\n\n\nUndo the last change\nCtrl + _\n\n\nRecall previous command\n↑\n\n\nRecall next command\n↓\n\n\nSearch command history\nCtrl + R\n\n\nExit history search\nCtrl + G\n\n\nShow history\nhistory\n\n\nRe-Execute Commands\n\n\n\nRun the last command\n!!\n\n\nRun last pw command\n!pw\n\n\nRun command # from history\n!&lt;number&gt;\n\n\nAuto-Completion\n\n\n\nAuto-complete command\nTAB\n\n\nList matching commands\nTAB TAB\n\n\nCycle through matches\nTAB TAB TAB...\n\n\nMiscellaneous\n\n\n\nOpen last edited command\nCtrl + X Ctrl + E\n\n\nTranspose two characters\nCtrl + T\n\n\nCapitalize word at cursor\nAlt + C\n\n\nConvert word to lowercase\nAlt + L\n\n\nConvert word to uppercase\nAlt + U\n\n\nSwap position with prev word\nCtrl + W Alt + T\n\n\n\n\n\nVim\n\n\n\nAction\nShortcut\n\n\n\n\nModes\ni\n\n\nInsert mode\ni\n\n\nCommand mode (normal)\nesc\n\n\nVisual mode (select text)\nv\n\n\nVisual line mode\nV\n\n\nVisual block mode\nCtrl + v\n\n\nSaving and Quitting\n\n\n\nSave\n:w\n\n\nQuit\n:q\n\n\nSave and quit\n:wq\n\n\nQuit without saving\n:q!\n\n\nSave and quit (shortcut)\nZZ\n\n\nQuit without saving (shortcut)\nZQ\n\n\nUsing Arrow Keys\n\n\n\nMove left\nh\n\n\nMove down\nj\n\n\nMove up\nk\n\n\nMove right\nl\n\n\nMoving the Cursor\n\n\n\nNext word\nw\n\n\nPrevious word\nb\n\n\nBeginning of line\n0\n\n\nFirst non-blank of line\n^\n\n\nEnd of line\n$\n\n\nFirst line\ngg\n\n\nLast line\nG\n\n\nGo to line 33\n33G\n\n\nUp half a page\nCtrl + u\n\n\nDown half a page\nCtrl + d\n\n\nSearching\n\n\n\nSearch text\n/text\n\n\nNext match\nn\n\n\nPrevious match\nN\n\n\nSearch backward\n?text\n\n\nSearch current word\n/\n\n\nEditing\n\n\n\nDelete char\nx\n\n\nDelete line\ndd\n\n\nDelete word\ndw\n\n\nDelete to end of line\nd$\n\n\nDelete to start of line\nd0\n\n\nCopy line\nyy\n\n\nCopy word\nyw\n\n\nPaste after cursor\np\n\n\nPaste before cursor\nP\n\n\nUndo\nu\n\n\nRedo\nCtrl + r\n\n\nChange text\nc\n\n\nReplace char\nr\n\n\nJoin line with next\nJ\n\n\nOther Useful Commands\n\n\n\nSplit window horizontally\n:split\n\n\nSplit window vertically\n:vsplit\n\n\nMove left split\nCtrl + w, h\n\n\nMove down split\nCtrl + w, j\n\n\nMove up split\nCtrl + w, k\n\n\nMove right split\nCtrl + w, l\n\n\nIncrease window size\n:resize +N\n\n\nDecrease window size\n:resize -N\n\n\nOpen new tab\n:tabnew\n\n\nNext tab\n:tabnext\n\n\nPrevious tab\n:tabprev\n\n\n\n\n\nTmux\n### Shortcut in terminal\nalias t=\"tmux\"\nalias ta=\"t a -t\"\nalias tls=\"t ls\"\nalias tn=\"t new -s\"\nalias tk=\"t kill-session -t\"\nalias tks=\"t kill-server\"\n\n### Change defautl prefix in .tmux.conf\nset-option -g prefix C-a\nbind-key C-a send-prefix\n\n### To enter copy mode, drag mouse to select text first, then paste with \nCtrl + A + ]\n\n### Sessions\ntmux list-sessions\ntmux attach-session -t target-session\nCtrl + A + s     # Switch between seesion\nCtrl + A + l     # Switch to the lastest session, regardless of whether it was detached or attached\nCtrl + A + d     # Detach from linux screen session\n\n### Windows\nCtrl + A + w     # List all windows (the current window is marked with \"*\").\nCtrl + A + ,     # Rename current window\nCtrl + A + →     # Switch to the next window.                                \nCtrl + A + ←     # Switch to the previous window.                            \nCtrl + A + c     # create a new window.                         \nCtrl + A + q     # kill the current window.                                  \n\n### Panes\nShift + ↑     # Switch to the pane above the current one\nShift + ↓     # Switch to the pane below the current one\nShift + ←     # Switch to the pane left of the current one\nShift + →     # Switch to the pane right of the current one\nCtrl + A + x     # kill the current pane.                                  \n\n\nScreen\n### Shortcut in terminal\nalias s=\"screen\"   # start a screen session\nalias ss=\"s -S\"    # start a named screen session\nalias sr=\"s -r\"    # reattach to a screen session\nalias sls=\"s -ls\"  # list the current running screen session\n\n### General commands\nscreen                   # start a screen session\nscreen -S session_name   # start a named session\nscreen -r                # reattach to a linux screen\nscreen -ls               # list the current running screen session\n\n### Shortcuts\nCtrl + A + C            # create a new window (with shell).\nCtrl + A + K            # kill the current window.\nCtrl + A + W            # list all windows (the current window is marked with \"*\") .\nCtrl + A + 0-9          # go to a window numbered 0-9 .\nCtrl + A + N            # go to the next window.\nCtrl + A  Ctrl + A      # toggle between the current and previous window.\nCtrl + A + A            # rename the current window.\nCtrl + A + S            # split current region horizontally into two regions.\nCtrl + A + |            # split current region vertically into two regions.\nCtrl + A + Tab          # switch the input focus to the next region.\nCtrl + A + Ctrl + A     # toggle between the current and previous windows\nCtrl + A + Q            # close all regions but the current one.\nCtrl + A + X            # close the current region.\nCtrl + A + D            # detach from linux screen session\nCtrl + A + [            # start copy mode\nCtrl + A + ]            # paste copied text\nCtrl + A + ?            # help, display  a list commands\nCtrl + A + Ctrl + \\     # quit screen"
  },
  {
    "objectID": "immune/index.html",
    "href": "immune/index.html",
    "title": "Learning Immunology!",
    "section": "",
    "text": "Lymphatic system"
  },
  {
    "objectID": "crispr/index.html",
    "href": "crispr/index.html",
    "title": "CRISPR-Cas Tools",
    "section": "",
    "text": "Guide Design Resources\nNew CRISPR Method Allows Scientists to Understand Impact of Subtle Mutations\nCRISPR Transfection Protocols Guide: How To Select The Best Method\nHow To Use CRISPR: Your Guide to Successful Genome Engineering\nThe Ultimate Guide To CRISPR: Mechanism, Applications, Methods & More\nIrregular Protein Expression After CRISPR Edits: Troubleshooting Tips\nCRISPR Editing in Primary Cells"
  },
  {
    "objectID": "crispr/index.html#design",
    "href": "crispr/index.html#design",
    "title": "CRISPR-Cas Tools",
    "section": "",
    "text": "Guide Design Resources\nNew CRISPR Method Allows Scientists to Understand Impact of Subtle Mutations\nCRISPR Transfection Protocols Guide: How To Select The Best Method\nHow To Use CRISPR: Your Guide to Successful Genome Engineering\nThe Ultimate Guide To CRISPR: Mechanism, Applications, Methods & More\nIrregular Protein Expression After CRISPR Edits: Troubleshooting Tips\nCRISPR Editing in Primary Cells"
  },
  {
    "objectID": "crispr/index.html#protocol",
    "href": "crispr/index.html#protocol",
    "title": "CRISPR-Cas Tools",
    "section": "Protocol",
    "text": "Protocol\n\nCrispR screen analysis using R and Bioconductor"
  },
  {
    "objectID": "blog/2024/07/01/index.html",
    "href": "blog/2024/07/01/index.html",
    "title": "Simple SVM classification example in R",
    "section": "",
    "text": "library(parallel)\nlibrary(lme4)\n\nLoading required package: Matrix\n### Check the number of cores\ndetectCores()\n\n[1] 8"
  },
  {
    "objectID": "blog/2024/07/01/index.html#reference",
    "href": "blog/2024/07/01/index.html#reference",
    "title": "Simple SVM classification example in R",
    "section": "Reference",
    "text": "Reference"
  },
  {
    "objectID": "blog/2024/05/13/index.html",
    "href": "blog/2024/05/13/index.html",
    "title": "Plot scatter plot with 2D density",
    "section": "",
    "text": "library(ggpubr)\n## Loading required package: ggplot2\nlibrary(MASS)\nlibrary(viridis)\n## Loading required package: viridisLite\nlibrary(patchwork)\n## \n## Attaching package: 'patchwork'\n## The following object is masked from 'package:MASS':\n## \n##     area\nlibrary(tidyverse)\n## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n## ✔ dplyr     1.1.4     ✔ readr     2.1.5\n## ✔ forcats   1.0.0     ✔ stringr   1.5.1\n## ✔ lubridate 1.9.3     ✔ tibble    3.2.1\n## ✔ purrr     1.0.2     ✔ tidyr     1.3.1\n## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n## ✖ dplyr::filter() masks stats::filter()\n## ✖ dplyr::lag()    masks stats::lag()\n## ✖ dplyr::select() masks MASS::select()\n## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n### Add 2d density estimation\nplot_data &lt;- iris |&gt; mutate(Species = factor(Species)) |&gt; as_tibble()\n\nsp &lt;- ggplot(plot_data, aes(x = Sepal.Length, y = Sepal.Width))+\n    geom_point()+\n    theme_bw()\n\n### Show the countour only\nsp + geom_density_2d()\n\n\n\n\n\n\n\n### Show the area only, with gradient color\nsp + stat_density_2d(aes(fill = ..level..), geom = \"polygon\")\n## Warning: The dot-dot notation (`..level..`) was deprecated in ggplot2 3.4.0.\n## ℹ Please use `after_stat(level)` instead.\n\n\n\n\n\n\n\n### Change gradient color: custom\nsp + stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n    gradient_fill(c(\"white\", \"steelblue\"))\n\n\n\n\n\n\n\n### Change gradient color: custom\nsp + stat_density_2d(\n    aes(\n        fill = after_stat(nlevel)), geom = \"polygon\", \n        n = 200, bins = 10, contour = TRUE\n) +\n    scale_fill_viridis_c(option = \"A\")\n\n\n\n\n\n\n    # gradient_fill(c(\"white\", \"steelblue\"))\n\n### Category data\nsp + stat_density_2d(aes(alpha = ..level.., fill = Species), geom = \"polygon\") +\n    scale_fill_manual(values = c(\"red\", \"steelblue\", \"green\"))\n\n\n\n\n\n\n\nsp + stat_density_2d(\n    aes(alpha = ..level.., fill = Species), geom = \"polygon\",\n     n = 200, bins = 10, contour = TRUE\n) +\n    scale_fill_manual(values = c(\"red\", \"steelblue\", \"green\")) +\n    facet_wrap(~Species)\n\n\n\n\n\n\n\nsp + stat_density_2d(\n    aes(alpha = after_stat(nlevel), fill = Species), geom = \"polygon\",\n     n = 200, bins = 10, contour = TRUE\n) +\n    scale_fill_manual(values = c(\"red\", \"steelblue\", \"green\")) +\n    facet_wrap(~Species)\n\n\n\n\n\n\n\n### By adding to stat_density_2d the argument bins to avoid overplotting, \n### control and draw the attention to a number of density areas in a very economical fashion.\nsp + \nstat_density_2d(\n    aes(alpha = ..level.., fill = Species), geom = \"polygon\", bins = 4\n) +\n    scale_fill_manual(values = c(\"red\", \"steelblue\", \"green\"))\n\n\n\n\n\n\n\n### Assigning manually the colours, NA for those levels we do not want to plot. Main disadvantage, we should know the number of levels and colours needed in advance (or compute them)\nsp +\nstat_density_2d(geom = \"polygon\", aes(fill = as.factor(..level..))) +\n  scale_fill_manual(\n    values = c(NA, NA, NA, NA, NA,\"#BDD7E7\", \"#6BAED6\", \"#3182BD\", \"#08519C\")\n)\n\n\n\n\n\n\n\n###\nsp + geom_density_2d_filled() +\n  scale_fill_brewer()\n## Warning in RColorBrewer::brewer.pal(n, pal): n too large, allowed maximum for palette Blues is 9\n## Returning the palette you asked for with that many colors\n\n\n\n\n\n\n\n### Change the gradient color: RColorBrewer palette\nsp + stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n    gradient_fill(\"YlOrRd\")\n\n\n\n\n\n\n\n### Area + contour\nsp + stat_density_2d(aes(fill = ..level..), geom = \"polygon\", colour = \"white\") +\n    gradient_fill(\"YlOrRd\")\n\n\n\n\n\n\n\n### Using raster\nsp +\n    stat_density_2d(aes(fill = ..density..), geom = \"raster\", contour = FALSE) +\n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0)) +\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n### Call the palette with a number\nsp +\n    stat_density_2d(aes(fill = ..density..), geom = \"raster\", contour = FALSE) +\n    scale_fill_distiller(palette = 4, direction = -1) +\n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0)) +\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n### The direction argument allows to reverse the palette\nsp +\n    stat_density_2d(aes(fill = ..density..), geom = \"raster\", contour = FALSE) +\n    scale_fill_distiller(palette = 4, direction = 1) +\n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0)) +\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n### Call the palette using a name.\nsp +\n    stat_density_2d(aes(fill = ..density..), geom = \"raster\", contour = FALSE) +\n    scale_fill_distiller(palette = \"Spectral\", direction = 1) +\n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0)) +\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nplot_data &lt;-\n  data.frame(X = c(rnorm(300, 3, 2.5), rnorm(150, 7, 2)),\n             Y = c(rnorm(300, 6, 2.5), rnorm(150, 2, 2)),\n             Label = c(rep('A', 300), rep('B', 150)))\n\n\nlibrary(ggplot2)\nlibrary(MASS)\nlibrary(tidyr)\n#Calculate the range\nxlim &lt;- range(plot_data$X)\nylim &lt;-range(plot_data$Y)\n\n\n#Genrate the kernel density for each group\nnewplot_data &lt;- plot_data %&gt;% group_by(Label) %&gt;% do(Dens=kde2d(.$X, .$Y, n=100, lims=c(xlim,ylim)))\n\n#Transform the density in  data.frame\nnewplot_data  %&lt;&gt;%  do(Label=.$Label, V=expand.grid(.$Dens$x,.$Dens$y), Value=c(.$Dens$z)) %&gt;% do(data.frame(Label=.$Label,x=.$V$Var1, y=.$V$Var2, Value=.$Value))\n\n#Untidy data and chose the value for each point.\n#In this case chose the value of the label with highest value  \n   newplot_data  %&lt;&gt;%   spread( Label,value=Value) %&gt;%\n        mutate(Level = if_else(A&gt;B, A, B), Label = if_else(A&gt;B,\"A\", \"B\"))\n# Contour plot\nggplot(newplot_data, aes(x,y, z=Level, fill=Label, alpha=..level..))  + stat_contour(geom=\"polygon\")\n\n\n\n\n\n\n\n\n### Define the functio using kde2d\n# Get density of points in 2 dimensions.\n# @param x A numeric vector.\n# @param y A numeric vector.\n# @param n Create a square n by n grid to compute density.\n# @return The density within each square.\nget_density &lt;- function(x, y, ...) {\n  dens &lt;- MASS::kde2d(x, y, ...)\n  ix &lt;- findInterval(x, dens$x)\n  iy &lt;- findInterval(y, dens$y)\n  ii &lt;- cbind(ix, iy)\n  return(dens$z[ii])\n}\n\n### Example data\nset.seed(1)\ndat &lt;- data.frame(\n  x = c(\n    rnorm(1e4, mean = 0, sd = 0.1),\n    rnorm(1e3, mean = 0, sd = 0.1)\n  ),\n  y = c(\n    rnorm(1e4, mean = 0, sd = 0.1),\n    rnorm(1e3, mean = 0.1, sd = 0.2)\n  )\n)\n\n### Split the plot into a 100 by 100 grid of squares and then color the points \n### by the estimated density in each square\ndat$density &lt;- get_density(dat$x, dat$y, n = 100)\n\n### Points are overplotted, so you can’t see the peak density:\nggplot(dat) + geom_point(aes(x, y))\n\n\n\n\n\n\n\nggplot(dat) + geom_point(aes(x, y, color = density)) + \n    scale_color_viridis()\n\n\n\n\n\n\n\n### set n = 15 (the squares in the grid are too big)\ndat$density &lt;- get_density(dat$x, dat$y, n = 15)\nggplot(dat) + geom_point(aes(x, y, color = density)) + \n    scale_color_viridis()\n\n\n\n\n\n\n\n### And what if you modify the bandwidth of the normal kernel with h = c(1, 1)?\ndat$density &lt;- get_density(dat$x, dat$y, h = c(1, 1), n = 100)\nggplot(dat) + geom_point(aes(x, y, color = density)) + scale_color_viridis()\n\n\n\n\n\n\n\n\n# Generate example data\nset.seed(123)\ndf &lt;- data.frame(matrix(rnorm(1000), ncol=10))\ndf$type &lt;- sample(c(\"WT\", \"MUT/HET\"), nrow(df), replace = TRUE)\n\n# Perform UMAP\numap_result &lt;- umap(df %&gt;% select(-type))\n\n# Prepare data for plotting\numap_df &lt;- as.data.frame(umap_result$layout)\ncolnames(umap_df) &lt;- c(\"UMAP1\", \"UMAP2\")\numap_df$type &lt;- df$type\n\n# Function to create density plots with customized legend\nplot_density &lt;- function(data, title, color_low, color_high) {\n  ggplot(data, aes(x = UMAP1, y = UMAP2)) +\n    geom_density_2d_filled(aes(fill = after_stat(level)), bins = 30) +  # Ensure enough bins for continuous fill\n    scale_fill_gradient(low = color_low, high = color_high, name = \"Density\", \n                        labels = c(\"Low\", \"High\")) +\n    theme_minimal() +\n    labs(title = title) +\n    theme(\n      legend.position = \"top\",\n      legend.title = element_text(size = 10),\n      legend.text = element_text(size = 8),\n      plot.title = element_text(hjust = 0.5)\n    ) +\n    guides(fill = guide_colorbar(barwidth = 7, barheight = 1,\n                                 title.position = \"top\", title.hjust = 0.5,\n                                 label.position = \"bottom\"))\n}\n\n# WT Density Plot\nwt_density_plot &lt;- plot_density(umap_df %&gt;% filter(type == \"WT\"), \"WT density\", \"white\", \"blue\")\n\n# Display the plot\nprint(wt_density_plot)"
  },
  {
    "objectID": "blog/2024/04/18/index.html",
    "href": "blog/2024/04/18/index.html",
    "title": "Multiplex image-based phenotypic data analysis",
    "section": "",
    "text": "### Required libraries\n# if (!require(\"BiocManager\", quietly = TRUE))\n#     install.packages(\"BiocManager\")\n# BiocManager::install(\n#     c(\n#         \"rmarkdown\", \"bookdown\", \"pheatmap\", \"viridis\", \"zoo\",\n#         \"devtools\", \"testthat\", \"tiff\", \"distill\", \"ggrepel\",\n#         \"patchwork\", \"mclust\", \"RColorBrewer\", \"uwot\", \"Rtsne\",\n#         \"harmony\", \"Seurat\", \"SeuratObject\", \"cowplot\", \"kohonen\",\n#         \"caret\", \"randomForest\", \"ggridges\", \"cowplot\",\n#         \"gridGraphics\", \"scales\", \"tiff\", \"harmony\", \"Matrix\",\n#         \"CATALYST\", \"scuttle\", \"scater\", \"dittoSeq\",\n#         \"tidyverse\", \"BiocStyle\", \"batchelor\", \"bluster\", \"scran\",\n#         \"lisaClust\", \"spicyR\", \"iSEE\", \"imcRtools\", \"cytomapper\",\n#         \"imcdatasets\", \"cytoviewer\"\n#     ),\n#     force = TRUE\n# )\n\nlibrary(here)\nlibrary(fs)\nlibrary(qs)\nlibrary(tidyverse)\nlibrary(ggrepel)\nlibrary(ggridges)\nlibrary(patchwork)\nlibrary(cowplot)\nlibrary(RColorBrewer)\nlibrary(viridis)\nlibrary(imcRtools)\nlibrary(cytomapper)\nlibrary(dittoSeq)\nlibrary(CATALYST)\nlibrary(pheatmap)\nlibrary(BiocParallel)\nlibrary(tiff)\nlibrary(EBImage)\nlibrary(mclust)\nlibrary(batchelor)\nlibrary(scater)\nlibrary(viridis)\nlibrary(harmony)\nlibrary(BiocSingular)\nlibrary(Seurat)\nlibrary(SeuratObject)\nlibrary(Rphenograph)\nlibrary(igraph)\nlibrary(bluster)\nlibrary(scran)\nlibrary(caret)\nlibrary(lisaClust)\nlibrary(scuttle)\nlibrary(ComplexHeatmap)\nlibrary(circlize)\n\n### Project directory\ndir &lt;- here(\"projects/2024_IMC_Profile\")\nset.seed(20240419)"
  },
  {
    "objectID": "blog/2024/04/18/index.html#initial-general-setup",
    "href": "blog/2024/04/18/index.html#initial-general-setup",
    "title": "Multiplex image-based phenotypic data analysis",
    "section": "",
    "text": "### Required libraries\n# if (!require(\"BiocManager\", quietly = TRUE))\n#     install.packages(\"BiocManager\")\n# BiocManager::install(\n#     c(\n#         \"rmarkdown\", \"bookdown\", \"pheatmap\", \"viridis\", \"zoo\",\n#         \"devtools\", \"testthat\", \"tiff\", \"distill\", \"ggrepel\",\n#         \"patchwork\", \"mclust\", \"RColorBrewer\", \"uwot\", \"Rtsne\",\n#         \"harmony\", \"Seurat\", \"SeuratObject\", \"cowplot\", \"kohonen\",\n#         \"caret\", \"randomForest\", \"ggridges\", \"cowplot\",\n#         \"gridGraphics\", \"scales\", \"tiff\", \"harmony\", \"Matrix\",\n#         \"CATALYST\", \"scuttle\", \"scater\", \"dittoSeq\",\n#         \"tidyverse\", \"BiocStyle\", \"batchelor\", \"bluster\", \"scran\",\n#         \"lisaClust\", \"spicyR\", \"iSEE\", \"imcRtools\", \"cytomapper\",\n#         \"imcdatasets\", \"cytoviewer\"\n#     ),\n#     force = TRUE\n# )\n\nlibrary(here)\nlibrary(fs)\nlibrary(qs)\nlibrary(tidyverse)\nlibrary(ggrepel)\nlibrary(ggridges)\nlibrary(patchwork)\nlibrary(cowplot)\nlibrary(RColorBrewer)\nlibrary(viridis)\nlibrary(imcRtools)\nlibrary(cytomapper)\nlibrary(dittoSeq)\nlibrary(CATALYST)\nlibrary(pheatmap)\nlibrary(BiocParallel)\nlibrary(tiff)\nlibrary(EBImage)\nlibrary(mclust)\nlibrary(batchelor)\nlibrary(scater)\nlibrary(viridis)\nlibrary(harmony)\nlibrary(BiocSingular)\nlibrary(Seurat)\nlibrary(SeuratObject)\nlibrary(Rphenograph)\nlibrary(igraph)\nlibrary(bluster)\nlibrary(scran)\nlibrary(caret)\nlibrary(lisaClust)\nlibrary(scuttle)\nlibrary(ComplexHeatmap)\nlibrary(circlize)\n\n### Project directory\ndir &lt;- here(\"projects/2024_IMC_Profile\")\nset.seed(20240419)"
  },
  {
    "objectID": "blog/2024/04/18/index.html#data-preparation",
    "href": "blog/2024/04/18/index.html#data-preparation",
    "title": "Multiplex image-based phenotypic data analysis",
    "section": "Data preparation",
    "text": "Data preparation\nIMC example data is from here\nDownload example data\n\n### Create directory for data \nfs::dir_create(dir, \"data/steinbock\")\n\n### Download sample/patient metadata information\ndownload.file(\n    \"https://zenodo.org/record/7575859/files/sample_metadata.csv\",\n    destfile = here(dir, \"data/sample_metadata.csv\")\n)\n\n### Download intensities\nurl &lt;- \"https://zenodo.org/record/7624451/files/intensities.zip\"\ndestfile &lt;- here(dir, \"data/steinbock/intensities.zip\")\ndownload.file(url, destfile)\nunzip(destfile, exdir = here(dir, \"data/steinbock\"), overwrite = TRUE)\nunlink(destfile)\n\n### Download regionprops\nurl &lt;- \"https://zenodo.org/record/7624451/files/regionprops.zip\"\ndestfile &lt;- here(dir, \"data/steinbock/regionprops.zip\")\ndownload.file(url, destfile)\nunzip(destfile, exdir = here(dir, \"data/steinbock\"), overwrite = TRUE)\nunlink(destfile)\n\n### Download neighbors\nurl &lt;- \"https://zenodo.org/record/7624451/files/neighbors.zip\"\ndestfile &lt;- here(dir, \"data/steinbock/neighbors.zip\")\ndownload.file(url, destfile)\nunzip(destfile, exdir = here(dir, \"data/steinbock\"), overwrite = TRUE)\nunlink(destfile)\n\n### Download images\nurl &lt;- \"https://zenodo.org/record/7624451/files/img.zip\"\ndestfile &lt;- here(dir, \"data/steinbock/img.zip\")\ndownload.file(url, destfile)\nunzip(destfile, exdir = here(dir, \"data/steinbock\"), overwrite = TRUE)\nunlink(destfile)\n\n### Download masks\nurl &lt;- \"https://zenodo.org/record/7624451/files/masks_deepcell.zip\"\ndestfile &lt;- here(dir, \"data/steinbock/masks_deepcell.zip\")\ndownload.file(url, destfile)\nunzip(destfile, exdir = here(dir, \"data/steinbock\"), overwrite = TRUE)\nunlink(destfile)\n\n### Download individual files\ndownload.file(\n    \"https://zenodo.org/record/7624451/files/panel.csv\",\n    here(dir, \"data/steinbock/panel.csv\")\n)\ndownload.file(\n    \"https://zenodo.org/record/7624451/files/images.csv\",\n    here(dir, \"data/steinbock/images.csv\")\n)\ndownload.file(\n    \"https://zenodo.org/record/7624451/files/steinbock.sh\",\n    here(dir, \"data/steinbock/steinbock.sh\")\n)\n\n### Files for spillover matrix estimation\ndownload.file(\n    \"https://zenodo.org/record/7575859/files/compensation.zip\",\n    here(dir, \"data/compensation.zip\")\n)\nunzip(\n    here(dir, \"data/compensation.zip\"),\n    exdir = here(dir, \"data\"), overwrite = TRUE\n)\nunlink(here(dir, \"data/compensation.zip\"))\n\n### Gated cells\ndownload.file(\n    \"https://zenodo.org/record/8095133/files/gated_cells.zip\",\n    here(dir, \"data/gated_cells.zip\")\n)\nunzip(\n    here(dir, \"data/gated_cells.zip\"),\n    exdir = here(dir, \"data\"), overwrite = TRUE\n)\nunlink(here(dir, \"data/gated_cells.zip\"))\n\nPreprocess data\n\n### Read steinbock generated data into a SpatialExperiment object\nspe &lt;- imcRtools::read_steinbock(here(dir, \"data/steinbock/\"))\nspe\n\nclass: SpatialExperiment \ndim: 40 47859 \nmetadata(0):\nassays(1): counts\nrownames(40): MPO HistoneH3 ... DNA1 DNA2\nrowData names(12): channel name ... Final.Concentration...Dilution\n  uL.to.add\ncolnames: NULL\ncolData names(8): sample_id ObjectNumber ... width_px height_px\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nspatialCoords names(2) : Pos_X Pos_Y\nimgData names(1): sample_id\n\n### Summarized pixel intensities\ncounts(spe)[1:5, 1:5]\n\n               [,1]       [,2]      [,3]      [,4]      [,5]\nMPO       0.5751064  0.4166667 0.4975494  0.890154 0.1818182\nHistoneH3 3.1273082 11.3597883 2.3841440  7.712961 1.4512715\nSMA       0.2600939  1.6720383 0.1535190  1.193948 0.2986703\nCD16      2.0347747  2.5880536 2.2943074 15.629083 0.6084220\nCD38      0.2530137  0.6826669 1.1902979  2.126060 0.2917793\n\n### Metadata\nhead(colData(spe))\n\nDataFrame with 6 rows and 8 columns\n     sample_id ObjectNumber      area axis_major_length axis_minor_length\n   &lt;character&gt;    &lt;numeric&gt; &lt;numeric&gt;         &lt;numeric&gt;         &lt;numeric&gt;\n1 Patient1_001            1        12           7.40623           1.89529\n2 Patient1_001            2        24          16.48004           1.96284\n3 Patient1_001            3        17           9.85085           1.98582\n4 Patient1_001            4        24           8.08290           3.91578\n5 Patient1_001            5        22           8.79367           3.11653\n6 Patient1_001            6        25           9.17436           3.46929\n  eccentricity  width_px height_px\n     &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt;\n1     0.966702       600       600\n2     0.992882       600       600\n3     0.979470       600       600\n4     0.874818       600       600\n5     0.935091       600       600\n6     0.925744       600       600\n\n### SpatialExperiment container stores locations of all cells in the\n### spatialCoords slot\nhead(spatialCoords(spe))\n\n        Pos_X     Pos_Y\n[1,] 468.5833 0.4166667\n[2,] 515.8333 0.4166667\n[3,] 587.2353 0.4705882\n[4,] 192.2500 1.2500000\n[5,] 231.7727 0.9090909\n[6,] 270.1600 1.0400000\n\ncolPair(spe, \"neighborhood\")\n\nSelfHits object with 257116 hits and 0 metadata columns:\n                from        to\n           &lt;integer&gt; &lt;integer&gt;\n       [1]         1        27\n       [2]         1        55\n       [3]         2        10\n       [4]         2        44\n       [5]         2        81\n       ...       ...       ...\n  [257112]     47858     47836\n  [257113]     47859     47792\n  [257114]     47859     47819\n  [257115]     47859     47828\n  [257116]     47859     47854\n  -------\n  nnode: 47859\n\nhead(rowData(spe))\n\nDataFrame with 6 rows and 12 columns\n              channel        name      keep   ilastik  deepcell  cellpose\n          &lt;character&gt; &lt;character&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;logical&gt;\nMPO               Y89         MPO         1        NA        NA        NA\nHistoneH3       In113   HistoneH3         1         1         1        NA\nSMA             In115         SMA         1        NA        NA        NA\nCD16            Pr141        CD16         1        NA        NA        NA\nCD38            Nd142        CD38         1        NA        NA        NA\nHLADR           Nd143       HLADR         1        NA        NA        NA\n          Tube.Number              Target Antibody.Clone Stock.Concentration\n            &lt;numeric&gt;         &lt;character&gt;    &lt;character&gt;           &lt;numeric&gt;\nMPO              2101 Myeloperoxidase MPO Polyclonal MPO                 500\nHistoneH3        2113          Histone H3           D1H2                 500\nSMA              1914                 SMA            1A4                 500\nCD16             2079                CD16       EPR16784                 500\nCD38             2095                CD38        EPR4106                 500\nHLADR            2087              HLA-DR        TAL 1B5                 500\n          Final.Concentration...Dilution   uL.to.add\n                             &lt;character&gt; &lt;character&gt;\nMPO                              4 ug/mL         0.8\nHistoneH3                        1 ug/mL         0.2\nSMA                           0.25 ug/mL        0.05\nCD16                             5 ug/mL           1\nCD38                           2.5 ug/mL         0.5\nHLADR                            1 ug/mL         0.2\n\n### Add additional metadata: generate unique identifiers per cell\ncolnames(spe) &lt;- paste0(spe$sample_id, \"_\", spe$ObjectNumber)\n\n### Read patient metadata\nmeta &lt;- read_csv(here(dir, \"data/sample_metadata.csv\"), show_col_types = FALSE)\n\n### Extract patient id and ROI id from sample name\nspe$patient_id &lt;- str_extract(spe$sample_id, \"Patient[1-4]\")\nspe$ROI &lt;- str_extract(spe$sample_id, \"00[1-8]\")\n\n### Store cancer type in SPE object\nspe$indication &lt;- meta$Indication[match(spe$patient_id, meta$`Sample ID`)]\nunique(spe$patient_id)\n\n[1] \"Patient1\" \"Patient2\" \"Patient3\" \"Patient4\"\n\nunique(spe$ROI)\n\n[1] \"001\" \"002\" \"003\" \"004\" \"005\" \"006\" \"007\" \"008\"\n\nunique(spe$indication)\n\n[1] \"SCCHN\" \"BCC\"   \"NSCLC\" \"CRC\"  \n\n### Transform counts\np1 &lt;- dittoRidgePlot(\n    spe, var = \"CD3\", group.by = \"patient_id\", assay = \"counts\"\n) +\n    ggtitle(\"CD3 - before transformation\")\n\n### Perform counts transformation using an inverse hyperbolic sine function\nassay(spe, \"exprs\") &lt;- asinh(counts(spe) / 1)\n\np2 &lt;- dittoRidgePlot(\n    spe, var = \"CD3\", group.by = \"patient_id\", assay = \"exprs\"\n) +\n    ggtitle(\"CD3 - after transformation\")\n\nwrap_plots(p1, p2, ncol = 2) +\n    plot_layout(guides = \"collect\") & theme(legend.position = \"bottom\")\n\nPicking joint bandwidth of 0.22\n\n\nPicking joint bandwidth of 0.0984\n\n\n\n\n\n\n\n\n\n### Add Feature meta for easy specifies the markers of interest.\nrowData(spe)$use_channel &lt;- !grepl(\"DNA|Histone\", rownames(spe))\n\n### Define color schemes for different metadata entries of the data\ncolor_vectors &lt;- list()\n\nROI &lt;- setNames(\n    brewer.pal(length(unique(spe$ROI)), name = \"BrBG\"),\n    unique(spe$ROI)\n)\n\npatient_id &lt;- setNames(\n    brewer.pal(length(unique(spe$patient_id)), name = \"Set1\"),\n    unique(spe$patient_id)\n)\n\nsample_id &lt;- setNames(\n    c(\n        brewer.pal(6, \"YlOrRd\")[3:5],\n        brewer.pal(6, \"PuBu\")[3:6],\n        brewer.pal(6, \"YlGn\")[3:5],\n        brewer.pal(6, \"BuPu\")[3:6]\n    ),\n    unique(spe$sample_id)\n)\n\nindication &lt;- setNames(\n    brewer.pal(length(unique(spe$indication)), name = \"Set2\"),\n    unique(spe$indication)\n)\n\ncolor_vectors$ROI &lt;- ROI\ncolor_vectors$patient_id &lt;- patient_id\ncolor_vectors$sample_id &lt;- sample_id\ncolor_vectors$indication &lt;- indication\n\nmetadata(spe)$color_vectors &lt;- color_vectors\n\nRead in images\n\nimages &lt;- loadImages(here(dir, \"data/steinbock/img/\"))\n\nAll files in the provided location will be read in.\n\nmasks &lt;- loadImages(here(dir, \"data/steinbock/masks_deepcell/\"), as.is = TRUE)\n\nAll files in the provided location will be read in.\n\n### Make sure that the channel order is identical between the single-cell data and the images\nchannelNames(images) &lt;- rownames(spe)\nimages\n\nCytoImageList containing 14 image(s)\nnames(14): Patient1_001 Patient1_002 Patient1_003 Patient2_001 Patient2_002 Patient2_003 Patient2_004 Patient3_001 Patient3_002 Patient3_003 Patient4_005 Patient4_006 Patient4_007 Patient4_008 \nEach image contains 40 channel(s)\nchannelNames(40): MPO HistoneH3 SMA CD16 CD38 HLADR CD27 CD15 CD45RA CD163 B2M CD20 CD68 Ido1 CD3 LAG3 / LAG33 CD11c PD1 PDGFRb CD7 GrzB PDL1 TCF7 CD45RO FOXP3 ICOS CD8a CarbonicAnhydrase CD33 Ki67 VISTA CD40 CD4 CD14 Ecad CD303 CD206 cleavedPARP DNA1 DNA2 \n\n### Order of the images\nall.equal(names(images), names(masks))\n\n[1] TRUE\n\n### Extract patient id from image name\npatient_id &lt;- str_extract(names(images), \"Patient[1-4]\")\n\n### Retrieve cancer type per patient from metadata file\nindication &lt;- meta$Indication[match(patient_id, meta$`Sample ID`)]\n\n### Store patient and image level information in elementMetadata\nmcols(images) &lt;- mcols(masks) &lt;- DataFrame(\n    sample_id = names(images),\n    patient_id = patient_id,\n    indication = indication\n)\n\nSave data\n\nqsave(spe, here(dir, \"data/spe.qs\"))\nqsave(images, here(dir, \"data/images.qs\"))\nqsave(masks, here(dir, \"data/masks.qs\"))"
  },
  {
    "objectID": "blog/2024/04/18/index.html#spillover-correction",
    "href": "blog/2024/04/18/index.html#spillover-correction",
    "title": "Multiplex image-based phenotypic data analysis",
    "section": "Spillover correction",
    "text": "Spillover correction\nGenerate the spillover matrix\n\n### Create SingleCellExperiment from TXT files\nsce &lt;- readSCEfromTXT(here(dir, \"data/compensation/\"))\n\nSpotted channels:  Y89, In113, In115, Pr141, Nd142, Nd143, Nd144, Nd145, Nd146, Sm147, Nd148, Sm149, Nd150, Eu151, Sm152, Eu153, Sm154, Gd155, Gd156, Gd158, Tb159, Gd160, Dy161, Dy162, Dy163, Dy164, Ho165, Er166, Er167, Er168, Tm169, Er170, Yb171, Yb172, Yb173, Yb174, Lu175, Yb176\nAcquired channels:  Ar80, Y89, In113, In115, Xe131, Xe134, Ba136, La138, Pr141, Nd142, Nd143, Nd144, Nd145, Nd146, Sm147, Nd148, Sm149, Nd150, Eu151, Sm152, Eu153, Sm154, Gd155, Gd156, Gd158, Tb159, Gd160, Dy161, Dy162, Dy163, Dy164, Ho165, Er166, Er167, Er168, Tm169, Er170, Yb171, Yb172, Yb173, Yb174, Lu175, Yb176, Ir191, Ir193, Pt196, Pb206\nChannels spotted but not acquired:  \nChannels acquired but not spotted:  Ar80, Xe131, Xe134, Ba136, La138, Ir191, Ir193, Pt196, Pb206\n\nassay(sce, \"exprs\") &lt;- asinh(counts(sce)/5)\n\n\n### Quality control\n### Log10 median pixel counts per spot and channel\nplotSpotHeatmap(sce)\n\n\n\n\n\n\n### Thresholded on 200 pixel counts\nplotSpotHeatmap(sce, log = FALSE, threshold = 200)\n\n\n\n\n\n\n\n\n### Optional pixel binning\n### Define grouping\nbin_size = 10\nsce2 &lt;- binAcrossPixels(sce, bin_size = bin_size)\n\n### Log10 median pixel counts per spot and channel\nplotSpotHeatmap(sce2)\n\n\n\n\n\n\n### Thresholded on 200 pixel counts\nplotSpotHeatmap(sce2, log = FALSE, threshold = 200)\n\n\n\n\n\n\n### Filtering incorrectly assigned pixels\nbc_key &lt;- as.numeric(unique(sce$sample_mass))\nbc_key &lt;- bc_key[order(bc_key)]\nsce &lt;- assignPrelim(sce, bc_key = bc_key)\n\nDebarcoding data...\n\n\n o ordering\n\n\n o classifying events\n\n\nNormalizing...\n\n\nComputing deltas...\n\nsce &lt;- estCutoffs(sce)\nsce &lt;- applyCutoffs(sce)\n\n### Visualize the correctly and incorrectly assigned pixels\ncur_table &lt;- table(sce$bc_id, sce$sample_mass)\npheatmap(\n    log10(cur_table + 1),\n    cluster_rows = FALSE,\n    cluster_cols = FALSE\n)\n\n\n\n\n\n\n### Compute the fraction of unassigned pixels per spot\ncur_table[\"0\", ] / colSums(cur_table)\n\n   113    115    141    142    143    144    145    146    147    148    149 \n0.1985 0.1060 0.2575 0.3195 0.3190 0.3825 0.3545 0.4280 0.3570 0.4770 0.4200 \n   150    151    152    153    154    155    156    158    159    160    161 \n0.4120 0.4025 0.4050 0.4630 0.4190 0.4610 0.3525 0.4020 0.4655 0.4250 0.5595 \n   162    163    164    165    166    167    168    169    170    171    172 \n0.4340 0.4230 0.4390 0.4055 0.5210 0.3900 0.3285 0.3680 0.5015 0.4900 0.5650 \n   173    174    175    176     89 \n0.3125 0.4605 0.4710 0.2845 0.3015 \n\nsce &lt;- filterPixels(sce, minevents = 40, correct_pixels = TRUE)\n\n### Compute spillover matrix\nsce &lt;- computeSpillmat(sce)\nisotope_list &lt;- CATALYST::isotope_list\nisotope_list$Ar &lt;- 80\nplotSpillmat(sce, isotope_list = isotope_list)\n\nWarning: The `guide` argument in `scale_*()` cannot be `FALSE`. This was deprecated in\nggplot2 3.3.4.\nℹ Please use \"none\" instead.\nℹ The deprecated feature was likely used in the CATALYST package.\n  Please report the issue at &lt;https://github.com/HelenaLC/CATALYST/issues&gt;.\n\n\n\n\n\n\n\n### Save spillover matrix in variable\nsm &lt;- metadata(sce)$spillover_matrix\nwrite.csv(sm, here(dir, \"data/sm.csv\"))\n\nSingle-cell data compensation\n\nspe &lt;- qread(here(dir, \"data/spe.qs\"))\n\nrowData(spe)$channel_name &lt;- paste0(rowData(spe)$channel, \"Di\")\nspe &lt;- compCytof(\n    spe, sm,\n    transform = TRUE, cofactor = 1,\n    isotope_list = isotope_list,\n    overwrite = FALSE\n)\n\n### Check the effect of channel spillover compensation\nbefore &lt;- dittoScatterPlot(\n    spe, x.var = \"Ecad\", y.var = \"CD303\",\n    assay.x = \"exprs\", assay.y = \"exprs\"\n) +\n    ggtitle(\"Before compensation\")\n\nafter &lt;- dittoScatterPlot(\n    spe, x.var = \"Ecad\", y.var = \"CD303\",\n    assay.x = \"compexprs\", assay.y = \"compexprs\"\n) +\n    ggtitle(\"After compensation\")\n\nwrap_plots(before, after)\n\n\n\n\n\n\nassay(spe, \"counts\") &lt;- assay(spe, \"compcounts\") \nassay(spe, \"exprs\") &lt;- assay(spe, \"compexprs\") \nassay(spe, \"compcounts\") &lt;- assay(spe, \"compexprs\") &lt;- NULL\n\nImage compensation\n\nimages &lt;- qread(here(dir, \"data/images.qs\"))\n\nchannelNames(images) &lt;- rowData(spe)$channel_name\n\nadapted_sm &lt;- adaptSpillmat(\n    sm, channelNames(images),\n    isotope_list = isotope_list\n)\n\nimages_comp &lt;- compImage(\n    images, adapted_sm,\n    BPPARAM = MulticoreParam()\n)\n\n### Visualize the image before and after compensation\n# Before compensation\nplotPixels(\n    images[5], colour_by = \"Yb173Di\",\n    image_title = list(text = \"Yb173 (Ecad) - before\", position = \"topleft\"),\n    legend = NULL, bcg = list(Yb173Di = c(0, 4, 1))\n)\nplotPixels(\n    images[5], colour_by = \"Yb174Di\",\n    image_title = list(text = \"Yb174 (CD303) - before\", position = \"topleft\"),\n    legend = NULL, bcg = list(Yb174Di = c(0, 4, 1))\n)\n\n# After compensation\nplotPixels(\n    images_comp[5], colour_by = \"Yb173Di\",\n    image_title = list(text = \"Yb173 (Ecad) - after\", position = \"topleft\"),\n    legend = NULL, bcg = list(Yb173Di = c(0, 4, 1))\n)\nplotPixels(\n    images_comp[5], colour_by = \"Yb174Di\",\n    image_title = list(text = \"Yb174 (CD303) - after\", position = \"topleft\"),\n    legend = NULL, bcg = list(Yb174Di = c(0, 4, 1))\n)\n\n### Re-set the channelNames to their biological targtes\nchannelNames(images_comp) &lt;- rownames(spe)\n\nWrite out compensated images\n\nfs::dir_create(here(dir, \"data/comp_img\"))\nlapply(\n    names(images_comp), function(x) {\n        writeImage(as.array(images_comp[[x]]) / (2^16 - 1),\n            paste0(dir, \"/data/comp_img/\", x, \".tiff\"),\n            bits.per.sample = 16)\n    }\n)\n\n\n### Save the compensated SpatialExperiment and CytoImageList objects\nqsave(spe, here(dir, \"data/spe.qs\"))\nqsave(images_comp, here(dir,\"data/images.qs\"))"
  },
  {
    "objectID": "blog/2024/04/18/index.html#image-and-cell-quality-control",
    "href": "blog/2024/04/18/index.html#image-and-cell-quality-control",
    "title": "Multiplex image-based phenotypic data analysis",
    "section": "Image and cell quality control",
    "text": "Image and cell quality control\nSegmentation quality control\n\n### Load data: 63.01 MB\nimages &lt;- qread(here(dir, \"data/images.qs\"))\nmasks &lt;- qread(here(dir, \"data/masks.qs\"))\nspe &lt;- qread(here(dir, \"data/spe.qs\"))\nlobstr::obj_size(spe, image, masks)\n\n\n### Select 3 random images\nset.seed(20220118)\nimg_ids &lt;- sample(seq_along(images), 3)\n\n### Image- and channel-wise min-max normalization and scaled to a range of 0-1\ncur_images &lt;- images[img_ids]\ncur_images &lt;- cytomapper::normalize(cur_images, separateImages = TRUE)\n\n### Clipping the maximum intensity to 0.2\ncur_images &lt;- cytomapper::normalize(cur_images, inputRange = c(0, 0.2))\n\n### Segmentation approach here appears to correctly segment cells\ncytomapper::plotPixels(\n    cur_images,\n    mask = masks[img_ids],\n    img_id = \"sample_id\",\n    missing_colour = \"white\",\n    colour_by = c(\"CD163\", \"CD20\", \"CD3\", \"Ecad\", \"DNA1\"),\n    colour = list(\n        CD163 = c(\"black\", \"yellow\"),\n        CD20 = c(\"black\", \"red\"),\n        CD3 = c(\"black\", \"green\"),\n        Ecad = c(\"black\", \"cyan\"),\n        DNA1 = c(\"black\", \"blue\")\n    ),\n    image_title = NULL,\n    legend = list(\n        colour_by.title.cex = 0.7,\n        colour_by.labels.cex = 0.7\n    )\n)\n\n\n\n\n\n\n### Heatmap to observe cell segmentation quality and\n### potentially also antibody specificity issues\n\n### Sub-sample the dataset to 2000 cells\ncur_cells &lt;- sample(seq_len(ncol(spe)), 2000)\n\n### Epithelial cells (Ecad+) and immune cells (CD45RO+) can be differentiate\n### Some of the markers are detected in specific cells (e.g., Ki67, CD20, Ecad) ### while others are more broadly expressed across cells (e.g., HLADR, B2M, CD4).\ndittoHeatmap(\n    spe[, cur_cells],\n    genes = rownames(spe)[rowData(spe)$use_channel],\n    assay = \"exprs\",\n    cluster_cols = TRUE,\n    scale = \"none\",\n    heatmap.colors = viridis(100),\n    annot.by = \"indication\",\n    annotation_colors = list(\n        indication = metadata(spe)$color_vectors$indication\n    )\n)\n\n\n\n\n\n\n\nImage_level quality control\n\n### Average SNR versus the average signal intensity across all images\ncur_snr &lt;- lapply(names(images), function(x){\n    img &lt;- images[[x]]\n    mat &lt;- apply(img, 3, function(ch){\n        # Otsu threshold\n        thres &lt;- otsu(ch, range = c(min(ch), max(ch)), levels = 65536)\n        # Signal-to-noise ratio\n        snr &lt;- mean(ch[ch &gt; thres]) / mean(ch[ch &lt;= thres])\n        # Signal intensity\n        ps &lt;- mean(ch[ch &gt; thres])\n        \n        return(c(snr = snr, ps = ps))\n    })\n    t(mat) |&gt;  as.data.frame() |&gt;  \n        mutate(image = x,\n               marker = colnames(mat)) |&gt;  \n        pivot_longer(cols = c(snr, ps))\n})\n\ncur_snr &lt;- do.call(rbind, cur_snr)\n\ncur_snr |&gt;  \n    group_by(marker, name) |&gt; \n    summarize(log_mean = log2(mean(value))) |&gt; \n    pivot_wider(names_from = name, values_from = log_mean) |&gt; \n    ggplot() +\n    geom_point(aes(ps, snr)) +\n    geom_label_repel(aes(ps, snr, label = marker)) +\n    theme_minimal(base_size = 15) + ylab(\"Signal-to-noise ratio [log2]\") +\n    xlab(\"Signal intensity [log2]\")\n\n`summarise()` has grouped output by 'marker'. You can override using the\n`.groups` argument.\n\n\nWarning: ggrepel: 9 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n### Remove markers that have a positive signal of below 2 per image\ncur_snr &lt;- cur_snr |&gt;  \n    pivot_wider(names_from = name, values_from = value) |&gt; \n    filter(ps &gt; 2) |&gt; \n    pivot_longer(cols = c(snr, ps))\n\ncur_snr |&gt;  \n    group_by(marker, name) |&gt; \n    summarize(log_mean = log2(mean(value))) |&gt; \n    pivot_wider(names_from = name, values_from = log_mean) |&gt; \n    ggplot() +\n    geom_point(aes(ps, snr)) +\n    geom_label_repel(aes(ps, snr, label = marker)) +\n    theme_minimal(base_size = 15) + ylab(\"Signal-to-noise ratio [log2]\") +\n    xlab(\"Signal intensity [log2]\")\n\n`summarise()` has grouped output by 'marker'. You can override using the\n`.groups` argument.\n\n\nWarning: ggrepel: 7 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n### Compute the percentage of covered image area\ncell_density &lt;- colData(spe) |&gt; \n    as.data.frame() |&gt; \n    group_by(sample_id) |&gt; \n    # Compute the number of pixels covered by cells and \n    # the total number of pixels\n    summarize(cell_area = sum(area),\n              no_pixels = mean(width_px) * mean(height_px)) |&gt; \n    # Divide the total number of pixels \n    # by the number of pixels covered by cells\n    mutate(covered_area = cell_area / no_pixels)\n\n### Visualize the image area covered by cells per image\nggplot(cell_density) +\n        geom_point(aes(reorder(sample_id,covered_area), covered_area)) + \n        theme_minimal(base_size = 15) +\n        theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 15)) +\n        ylim(c(0, 1)) +\n        ylab(\"% covered area\") + xlab(\"\")\n\n\n\n\n\n\n### Normalize and clip images\ncur_images &lt;- images[c(\"Patient4_005\", \"Patient4_007\")]\ncur_images &lt;- cytomapper::normalize(cur_images, separateImages = TRUE)\ncur_images &lt;- cytomapper::normalize(cur_images, inputRange = c(0, 0.2))\n\nplotPixels(cur_images,\n           mask = masks[c(\"Patient4_005\", \"Patient4_007\")],\n           img_id = \"sample_id\",\n           missing_colour = \"white\",\n           colour_by = c(\"CD163\", \"CD20\", \"CD3\", \"Ecad\", \"DNA1\"),\n           colour = list(CD163 = c(\"black\", \"yellow\"),\n                         CD20 = c(\"black\", \"red\"),\n                         CD3 = c(\"black\", \"green\"),\n                         Ecad = c(\"black\", \"cyan\"),\n                         DNA1 = c(\"black\", \"blue\")),\n           legend = list(colour_by.title.cex = 0.7,\n                         colour_by.labels.cex = 0.7))\n\n\n\n\n\n\n###  Visualize the mean marker expression per image to identify images with outlying marker expression\nimage_mean &lt;- scuttle::aggregateAcrossCells(\n    spe, \n    ids = spe$sample_id, \n    statistics=\"mean\",\n    use.assay.type = \"counts\"\n)\n\nassay(image_mean, \"exprs\") &lt;- asinh(counts(image_mean))\n\ndittoHeatmap(\n    image_mean, \n    genes = rownames(spe)[rowData(spe)$use_channel],\n    assay = \"exprs\", cluster_cols = TRUE, scale = \"none\",\n    heatmap.colors = viridis(100), \n    annot.by = c(\"indication\", \"patient_id\", \"ROI\"),\n    annotation_colors = list(\n        indication = metadata(spe)$color_vectors$indication,\n                                      patient_id = metadata(spe)$color_vectors$patient_id,\n                                      ROI = metadata(spe)$color_vectors$ROI\n        ),\n    show_colnames = TRUE\n)                        \n\n\n\n\n\n\n\nCell_level quality control\n\nset.seed(220224)\nmat &lt;- sapply(seq_len(nrow(spe)), function(x){\n    cur_exprs &lt;- assay(spe, \"exprs\")[x,]\n    cur_counts &lt;- assay(spe, \"counts\")[x,]\n    \n    cur_model &lt;- Mclust(cur_exprs, G = 2)\n    mean1 &lt;- mean(cur_counts[cur_model$classification == 1])\n    mean2 &lt;- mean(cur_counts[cur_model$classification == 2])\n    \n    signal &lt;- ifelse(mean1 &gt; mean2, mean1, mean2)\n    noise &lt;- ifelse(mean1 &gt; mean2, mean2, mean1)\n    \n    return(c(snr = signal/noise, ps = signal))\n})\n    \ncur_snr &lt;- t(mat) |&gt;  as.data.frame() |&gt;  \n        mutate(marker = rownames(spe))\n\ncur_snr |&gt;  ggplot() +\n    geom_point(aes(log2(ps), log2(snr))) +\n    geom_label_repel(aes(log2(ps), log2(snr), label = marker)) +\n    theme_minimal(base_size = 15) + ylab(\"Signal-to-noise ratio [log2]\") +\n    xlab(\"Signal intensity [log2]\")\n\nWarning: ggrepel: 2 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n### Observe the distributions of cell size across the individual images\ndittoPlot(spe, var = \"area\", \n          group.by = \"sample_id\", \n          plots = \"boxplot\") +\n        ylab(\"Cell area\") + xlab(\"\")\n\n\n\n\n\n\nsummary(spe$area)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   5.00   47.00   70.00   76.48   98.00  466.00 \n\nsum(spe$area &lt; 5)\n\n[1] 0\n\nspe &lt;- spe[,spe$area &gt;= 5]\n\n### Absolute measure of cell density\ncell_density &lt;- colData(spe) |&gt; \n    as.data.frame() |&gt; \n    group_by(sample_id) |&gt; \n    summarize(cell_count = n(),\n           no_pixels = mean(width_px) * mean(height_px)) |&gt; \n    mutate(cells_per_mm2 = cell_count/(no_pixels/1000000))\n\nggplot(cell_density) +\n    geom_point(aes(reorder(sample_id,cells_per_mm2), cells_per_mm2)) + \n    theme_minimal(base_size = 15) + \n    theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8)) +\n    ylab(\"Cells per mm2\") + xlab(\"\")\n\n\n\n\n\n\n ### Observing staining differences between samples or batches of samples\nmulti_dittoPlot(\n    spe, \n    vars = rownames(spe)[rowData(spe)$use_channel],\n    group.by = \"patient_id\", plots = \"ridgeplot\", \n    assay = \"exprs\", \n    color.panel = metadata(spe)$color_vectors$patient_id\n)\n\nPicking joint bandwidth of 0.0118\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0247\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0809\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0408\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.163\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0766\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.083\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0675\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.105\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0795\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0444\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.107\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0599\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0992\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0211\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.11\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0364\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0901\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.119\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0582\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0542\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0804\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.106\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0306\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0469\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0825\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0485\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0845\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.111\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.081\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0939\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0973\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.15\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.173\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0642\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0987\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\nPicking joint bandwidth of 0.0117\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's colour values.\n\n\n\n\n\n\n\nset.seed(220225)\nspe &lt;- scater::runUMAP(\n    spe, subset_row = rowData(spe)$use_channel, exprs_values = \"exprs\"\n)\n\nFound more than one class \"dist\" in cache; using the first, from namespace 'BiocGenerics'\n\n\nAlso defined by 'spam'\n\n\nFound more than one class \"dist\" in cache; using the first, from namespace 'BiocGenerics'\n\n\nAlso defined by 'spam'\n\nspe &lt;- scater::runTSNE(\n    spe, subset_row = rowData(spe)$use_channel, exprs_values = \"exprs\"\n)\n\nreducedDims(spe)\n\nList of length 9\nnames(9): UMAP TSNE fastMNN ... UMAP_harmony seurat UMAP_seurat\n\nhead(reducedDim(spe, \"UMAP\"))\n\n                   UMAP1     UMAP2\nPatient1_001_1 -4.965459 -2.914412\nPatient1_001_2 -4.336567 -2.855069\nPatient1_001_3 -4.357023 -2.846398\nPatient1_001_4 -3.930147 -2.693578\nPatient1_001_5 -6.713229 -1.826328\nPatient1_001_6 -6.416659 -2.157444\n\n\n\n### visualize patient id \np1 &lt;- dittoDimPlot(\n    spe, var = \"patient_id\", reduction.use = \"UMAP\", size = 0.2\n    ) + \n    scale_color_manual(values = metadata(spe)$color_vectors$patient_id) +\n    ggtitle(\"Patient ID on UMAP\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\np2 &lt;- dittoDimPlot(\n    spe, var = \"patient_id\", reduction.use = \"TSNE\", size = 0.2\n    ) + \n    scale_color_manual(values = metadata(spe)$color_vectors$patient_id) +\n    ggtitle(\"Patient ID on TSNE\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n### visualize region of interest id\np3 &lt;- dittoDimPlot(\n    spe, var = \"ROI\", reduction.use = \"UMAP\", size = 0.2\n    ) + \n    scale_color_manual(values = metadata(spe)$color_vectors$ROI) +\n    ggtitle(\"ROI ID on UMAP\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\np4 &lt;- dittoDimPlot(\n    spe, var = \"ROI\", reduction.use = \"TSNE\", size = 0.2\n    ) + \n    scale_color_manual(values = metadata(spe)$color_vectors$ROI) +\n    ggtitle(\"ROI ID on TSNE\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n### visualize indication\np5 &lt;- dittoDimPlot(\n    spe, var = \"indication\", reduction.use = \"UMAP\", size = 0.2\n    ) + \n    scale_color_manual(values = metadata(spe)$color_vectors$indication) +\n    ggtitle(\"Indication on UMAP\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\np6 &lt;- dittoDimPlot(\n    spe, var = \"indication\", reduction.use = \"TSNE\", size = 0.2\n    ) + \n    scale_color_manual(values = metadata(spe)$color_vectors$indication) +\n    ggtitle(\"Indication on TSNE\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n(p1 + p2) / (p3 + p4) / (p5 + p6)\n\n\n\n\n\n\n\n\n### visualize marker expression\np1 &lt;- dittoDimPlot(\n        spe, var = \"Ecad\", reduction.use = \"UMAP\", \n        assay = \"exprs\", size = 0.2\n    ) +\n    scale_color_viridis(name = \"Ecad\") +\n    ggtitle(\"E-Cadherin expression on UMAP\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\np2 &lt;- dittoDimPlot(\n    spe, var = \"CD45RO\", reduction.use = \"UMAP\", \n    assay = \"exprs\", size = 0.2\n    ) +\n    scale_color_viridis(name = \"CD45RO\") +\n    ggtitle(\"CD45RO expression on UMAP\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\np3 &lt;- dittoDimPlot(\n    spe, var = \"Ecad\", reduction.use = \"TSNE\", \n    assay = \"exprs\", size = 0.2\n    ) +\n    scale_color_viridis(name = \"Ecad\") +\n    ggtitle(\"Ecad expression on TSNE\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\np4 &lt;- dittoDimPlot(\n    spe, var = \"CD45RO\", reduction.use = \"TSNE\", \n    assay = \"exprs\", size = 0.2\n    ) +\n    scale_color_viridis(name = \"CD45RO\") +\n    ggtitle(\"CD45RO expression on TSNE\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n(p1 + p2) / (p3 + p4)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe observe a strong separation of tumor cells (Ecad+ cells) between the patients. Here, each patient was diagnosed with a different tumor type. The separation of tumor cells could be of biological origin since tumor cells tend to display differences in expression between patients and cancer types and/or of technical origin: the panel only contains a single tumor marker (E-Cadherin) and therefore slight technical differences in staining causes visible separation between cells of different patients. Nevertheless, the immune compartment (CD45RO+ cells) mix between patients and we can rule out systematic staining differences between patients.\n\n\n\n### Save objects for further downstream analysis\nqsave(spe, here(dir, \"data/spe.qs\"))"
  },
  {
    "objectID": "blog/2024/04/18/index.html#batch-effect-correction",
    "href": "blog/2024/04/18/index.html#batch-effect-correction",
    "title": "Multiplex image-based phenotypic data analysis",
    "section": "Batch effect correction",
    "text": "Batch effect correction\nfastMNN correction\n\nspe &lt;- qread(here(dir, \"data/spe.qs\"))\n\n\n### Perform sample correction\nset.seed(220228)\nout &lt;- batchelor::fastMNN(\n    spe, \n    batch = spe$patient_id,\n    auto.merge = TRUE,\n    subset.row = rowData(spe)$use_channel,\n    assay.type = \"exprs\"\n)\n\nWarning in check_numbers(k = k, nu = nu, nv = nv, limit = min(dim(x)) - : more\nsingular values/vectors requested than available\n\n\nWarning in (function (A, nv = 5, nu = nv, maxit = 1000, work = nv + 7, reorth =\nTRUE, : You're computing too large a percentage of total singular values, use a\nstandard svd instead.\n\n### Check that order of cells is the same\nstopifnot(all.equal(colnames(spe), colnames(out)))\n\n### Transfer the correction results to the main spe object\nreducedDim(spe, \"fastMNN\") &lt;- reducedDim(out, \"corrected\")\n\n### Quality control of correction results\nmerge_info &lt;- metadata(out)$merge.info \n\n### 1. We observe that Patient4 and Patient2 are most similar with a low batch effect. \n### 2. Merging cells of Patient3 into the combined batch of Patient1, Patient2 \n### and Patient4 resulted in the highest percentage of lost variance and the \n### detection of the largest batch effect. \nmerge_info[, c(\"left\", \"right\", \"batch.size\")]\n\nDataFrame with 3 rows and 3 columns\n                        left    right batch.size\n                      &lt;List&gt;   &lt;List&gt;  &lt;numeric&gt;\n1                   Patient4 Patient2   0.366641\n2          Patient4,Patient2 Patient1   0.541466\n3 Patient4,Patient2,Patient1 Patient3   0.749047\n\nmerge_info$lost.var\n\n        Patient1    Patient2   Patient3    Patient4\n[1,] 0.000000000 0.030385015 0.00000000 0.048613071\n[2,] 0.042567359 0.007911340 0.00000000 0.011963319\n[3,] 0.007594552 0.003602307 0.07579009 0.006601185\n\n\n\n### Recompute the UMAP embedding using the corrected low-dimensional \n### coordinates for each cell.\nset.seed(220228)\nspe &lt;- scater::runUMAP(spe, dimred= \"fastMNN\", name = \"UMAP_mnnCorrected\")\n\nFound more than one class \"dist\" in cache; using the first, from namespace 'BiocGenerics'\n\n\nAlso defined by 'spam'\n\n\nFound more than one class \"dist\" in cache; using the first, from namespace 'BiocGenerics'\n\n\nAlso defined by 'spam'\n\n### Visualize patient id \np1 &lt;- dittoDimPlot(\n    spe, var = \"patient_id\", reduction.use = \"UMAP\", size = 0.2\n    ) + \n    scale_color_manual(values = metadata(spe)$color_vectors$patient_id) +\n    ggtitle(\"Patient ID on UMAP before correction\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\np2 &lt;- dittoDimPlot(\n    spe, var = \"patient_id\", reduction.use = \"UMAP_mnnCorrected\", size = 0.2\n    ) + \n    scale_color_manual(values = metadata(spe)$color_vectors$patient_id) +\n    ggtitle(\"Patient ID on UMAP after correction\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n### We observe an imperfect merging of Patient3 into all other samples. \n### This was already seen when displaying the merging information above. \ncowplot::plot_grid(p1, p2)\n\n\n\n\n\n\n\n\n### Visualize the expression of selected markers across all cells before and \n### after batch correction\nmarkers &lt;- c(\n    \"Ecad\", \"CD45RO\", \"CD20\", \"CD3\", \"FOXP3\", \"CD206\", \"MPO\", \"SMA\", \"Ki67\"\n)\n\n### Before correction\nplot_list &lt;- multi_dittoDimPlot(\n    spe, var = markers, reduction.use = \"UMAP\", \n    assay = \"exprs\", size = 0.2, list.out = TRUE\n    )\n\nplot_list &lt;- lapply(plot_list, function(x) x + scale_color_viridis())\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\ncowplot::plot_grid(plotlist = plot_list)\n\n\n\n\n\n\n### After correction\nplot_list &lt;- multi_dittoDimPlot(\n    spe, var = markers, reduction.use = \"UMAP_mnnCorrected\", \n    assay = \"exprs\", size = 0.2, list.out = TRUE\n    ) \nplot_list &lt;- lapply(plot_list, function(x) x + scale_color_viridis())\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n### We observe that immune cells across patients are merged after batch \n### correction using fastMNN. However, the tumor cells of different patients \n### still cluster separately.\ncowplot::plot_grid(plotlist = plot_list) \n\n\n\n\n\n\n\nharmony correction\n\n### harmony returns the corrected low-dimensional coordinates for each cell\nspe &lt;- runPCA(\n    spe, \n    subset_row = rowData(spe)$use_channel, \n    exprs_values = \"exprs\", \n    ncomponents = 30,\n    BSPARAM = ExactParam()\n)\n\nset.seed(230616)\nout &lt;- RunHarmony(spe, group.by.vars = \"patient_id\")\n\nTransposing data matrix\n\n\nInitializing state using k-means centroids initialization\n\n\nHarmony 1/10\n\n\nHarmony 2/10\n\n\nHarmony 3/10\n\n\nHarmony 4/10\n\n\nHarmony 5/10\n\n\nHarmony converged after 5 iterations\n\n### Check that order of cells is the same\nstopifnot(all.equal(colnames(spe), colnames(out)))\n\nreducedDim(spe, \"harmony\") &lt;- reducedDim(out, \"HARMONY\")\n\n\nset.seed(220228)\nspe &lt;- runUMAP(spe, dimred = \"harmony\", name = \"UMAP_harmony\")\n\nFound more than one class \"dist\" in cache; using the first, from namespace 'BiocGenerics'\n\n\nAlso defined by 'spam'\n\n\nFound more than one class \"dist\" in cache; using the first, from namespace 'BiocGenerics'\n\n\nAlso defined by 'spam'\n\n### visualize patient id\np1 &lt;- dittoDimPlot(\n    spe, var = \"patient_id\", reduction.use = \"UMAP\", size = 0.2\n) +\n    scale_color_manual(values = metadata(spe)$color_vectors$patient_id) +\n    ggtitle(\"Patient ID on UMAP before correction\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\np2 &lt;- dittoDimPlot(\n    spe, var = \"patient_id\", reduction.use = \"UMAP_harmony\", size = 0.2\n) +\n    scale_color_manual(values = metadata(spe)$color_vectors$patient_id) +\n    ggtitle(\"Patient ID on UMAP after correction\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\nplot_grid(p1, p2)\n\n\n\n\n\n\n### Visualize selected marker expression\n### Before correction\nplot_list &lt;- multi_dittoDimPlot(\n    spe, var = markers, reduction.use = \"UMAP\",\n    assay = \"exprs\", size = 0.2, list.out = TRUE\n)\n\nplot_list &lt;- lapply(plot_list, function(x) x + scale_color_viridis())\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\nplot_grid(plotlist = plot_list)\n\n\n\n\n\n\n### After correction\nplot_list &lt;- multi_dittoDimPlot(\n    spe, var = markers, reduction.use = \"UMAP_harmony\",\n    assay = \"exprs\", size = 0.2, list.out = TRUE\n)\nplot_list &lt;- lapply(plot_list, function(x) x + scale_color_viridis())\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n### We observe a more aggressive merging of cells from different patients \n### compared to the results after fastMNN correction. Importantly, immune cell \n### and epithelial markers are expressed in distinct regions of the UMAP.\nplot_grid(plotlist = plot_list) \n\n\n\n\n\n\n\nSeurat correction\n\nseurat_obj &lt;- as.Seurat(spe, counts = \"counts\", data = \"exprs\")\n\nWarning: Keys should be one or more alphanumeric characters followed by an\nunderscore, setting key from UMAP to UMAP_\n\n\nWarning: Keys should be one or more alphanumeric characters followed by an\nunderscore, setting key from TSNE to TSNE_\n\n\nWarning: Keys should be one or more alphanumeric characters followed by an\nunderscore, setting key from UMAP to UMAP_\n\n\nWarning: Key 'UMAP_' taken, using 'umapmnncorrected_' instead\n\n\nWarning: Keys should be one or more alphanumeric characters followed by an\nunderscore, setting key from PC to PC_\n\n\nWarning: Keys should be one or more alphanumeric characters followed by an\nunderscore, setting key from UMAP to UMAP_\n\n\nWarning: Key 'UMAP_' taken, using 'umapharmony_' instead\n\n\nWarning: Key 'PC_' taken, using 'seurat_' instead\n\n\nWarning: Keys should be one or more alphanumeric characters followed by an\nunderscore, setting key from UMAP to UMAP_\n\n\nWarning: Key 'UMAP_' taken, using 'umapseurat_' instead\n\nseurat_obj &lt;- AddMetaData(seurat_obj, as.data.frame(colData(spe)))\nseurat_list &lt;- SplitObject(seurat_obj, split.by = \"patient_id\")\n\n### Define the features used for integration and perform PCA on cells of each\n### patient individually\nfeatures &lt;- rownames(spe)[rowData(spe)$use_channel]\n\nseurat_list &lt;- lapply(\n    X = seurat_list,\n    FUN = function(x) {\n        x &lt;- ScaleData(x, features = features, verbose = FALSE)\n        x &lt;- RunPCA(x, features = features, verbose = FALSE, approx = FALSE)\n        return(x)\n    }\n)\n\nWarning: Key 'PC_' taken, using 'pca_' instead\n\n\nWarning: Key 'PC_' taken, using 'pca_' instead\nKey 'PC_' taken, using 'pca_' instead\nKey 'PC_' taken, using 'pca_' instead\n\nanchors &lt;- FindIntegrationAnchors(\n    object.list = seurat_list,\n    anchor.features = features,\n    reduction = \"rpca\",\n    k.anchor = 20\n)\n\nScaling features for provided objects\n\n\nComputing within dataset neighborhoods\n\n\nFinding all pairwise anchors\n\n\nProjecting new data onto SVD\nProjecting new data onto SVD\n\n\nFinding neighborhoods\n\n\nFinding anchors\n\n\n    Found 53333 anchors\n\n\nProjecting new data onto SVD\nProjecting new data onto SVD\n\n\nFinding neighborhoods\n\n\nFinding anchors\n\n\n    Found 47418 anchors\n\n\nProjecting new data onto SVD\nProjecting new data onto SVD\n\n\nFinding neighborhoods\n\n\nFinding anchors\n\n\n    Found 46957 anchors\n\n\nProjecting new data onto SVD\nProjecting new data onto SVD\n\n\nFinding neighborhoods\n\n\nFinding anchors\n\n\n    Found 55977 anchors\n\n\nProjecting new data onto SVD\nProjecting new data onto SVD\n\n\nFinding neighborhoods\n\n\nFinding anchors\n\n\n    Found 67563 anchors\n\n\nProjecting new data onto SVD\nProjecting new data onto SVD\n\n\nFinding neighborhoods\n\n\nFinding anchors\n\n\n    Found 52131 anchors\n\ncombined &lt;- IntegrateData(anchorset = anchors)\n\nMerging dataset 2 into 4\n\n\nExtracting anchors for merged samples\n\n\nFinding integration vectors\n\n\nWarning in irlba(A = t(x = object), nv = npcs, ...): You're computing too large\na percentage of total singular values, use a standard svd instead.\n\n\nFinding integration vector weights\n\n\nIntegrating data\n\n\nMerging dataset 1 into 4 2\n\n\nExtracting anchors for merged samples\n\n\nFinding integration vectors\n\n\nWarning in irlba(A = t(x = object), nv = npcs, ...): You're computing too large\na percentage of total singular values, use a standard svd instead.\n\n\nFinding integration vector weights\n\n\nIntegrating data\n\n\nMerging dataset 3 into 4 2 1\n\n\nExtracting anchors for merged samples\n\n\nFinding integration vectors\n\n\nWarning in irlba(A = t(x = object), nv = npcs, ...): You're computing too large\na percentage of total singular values, use a standard svd instead.\n\n\nFinding integration vector weights\n\n\nIntegrating data\n\nDefaultAssay(combined) &lt;- \"integrated\"\n\ncombined &lt;- ScaleData(combined, verbose = FALSE)\ncombined &lt;- RunPCA(combined, npcs = 30, verbose = FALSE, approx = FALSE)\n\n### Check that order of cells is the same\nstopifnot(all.equal(colnames(spe), colnames(combined)))\n\nreducedDim(spe, \"seurat\") &lt;- Embeddings(combined, reduction = \"pca\")\n\n\nset.seed(220228)\nspe &lt;- runUMAP(spe, dimred = \"seurat\", name = \"UMAP_seurat\") \n\nFound more than one class \"dist\" in cache; using the first, from namespace 'BiocGenerics'\n\n\nAlso defined by 'spam'\n\n\nFound more than one class \"dist\" in cache; using the first, from namespace 'BiocGenerics'\n\n\nAlso defined by 'spam'\n\n### Visualize patient id \np1 &lt;- dittoDimPlot(\n        spe, var = \"patient_id\", \n        reduction.use = \"UMAP\", size = 0.2\n    ) + \n    scale_color_manual(values = metadata(spe)$color_vectors$patient_id) +\n    ggtitle(\"Patient ID on UMAP before correction\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\np2 &lt;- dittoDimPlot(\n        spe, var = \"patient_id\", \n        reduction.use = \"UMAP_seurat\", size = 0.2\n    ) + \n    scale_color_manual(values = metadata(spe)$color_vectors$patient_id) +\n    ggtitle(\"Patient ID on UMAP after correction\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\nplot_grid(p1, p2)\n\n\n\n\n\n\n### Before correction\nplot_list &lt;- multi_dittoDimPlot(\n    spe, var = markers, reduction.use = \"UMAP\", \n    assay = \"exprs\", size = 0.2, list.out = TRUE\n    ) \nplot_list &lt;- lapply(plot_list, function(x) x + scale_color_viridis())\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\nplot_grid(plotlist = plot_list)\n\n\n\n\n\n\n### After correction\nplot_list &lt;- multi_dittoDimPlot(\n    spe, var = markers, reduction.use = \"UMAP_seurat\", \n    assay = \"exprs\", size = 0.2, list.out = TRUE\n    ) \n\nplot_list &lt;- lapply(plot_list, function(x) x + scale_color_viridis())\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n### Similar to the methods presented above, Seurat integrates immune cells \n### correctly. When visualizing the patient IDs, slight patient-to-patient \n### differences within tumor cells can be detected.\nplot_grid(plotlist = plot_list) \n\n\n\n\n\n\n\n\n### Save modified object\nqsave(spe, here(dir, \"data/spe.qs\"))"
  },
  {
    "objectID": "blog/2024/04/18/index.html#cell-phenotyping",
    "href": "blog/2024/04/18/index.html#cell-phenotyping",
    "title": "Multiplex image-based phenotypic data analysis",
    "section": "Cell phenotyping",
    "text": "Cell phenotyping\nA common step during single-cell data analysis is the annotation of cells based on their phenotype. Defining cell phenotypes is often subjective and relies on previous biological knowledge.\nIn highly-multiplexed imaging, target proteins or molecules are manually selected based on the biological question at hand. It narrows down the feature space and facilitates the manual annotation of clusters to derive cell phenotypes.\n\nspe &lt;- qread(here(dir, \"data/spe.qs\"))\n\n###  Sample 2000 cells to visualize cluster membership.\nset.seed(220619)\ncur_cells &lt;- sample(seq_len(ncol(spe)), 2000)\n\nRphenograph\n\nmat &lt;- t(assay(spe, \"exprs\")[rowData(spe)$use_channel, ])\n\nset.seed(230619)\nout &lt;- Rphenograph(mat, k = 45)\n\nRun Rphenograph starts:\n  -Input data of 47794 rows and 37 columns\n  -k is set to 45\n\n\n  Finding nearest neighbors...DONE ~ 57.221 s\n  Compute jaccard coefficient between nearest-neighbor sets...DONE ~ 20.057 s\n  Build undirected graph from the weighted links...DONE ~ 2.609 s\n  Run louvain clustering on the graph ...DONE ~ 5.252 s\n\n\nRun Rphenograph DONE, totally takes 85.139s.\n\n\n  Return a community class\n  -Modularity value: 0.8620567 \n  -Number of clusters: 24\n\nclusters &lt;- factor(membership(out[[2]]))\n\nspe$pg_clusters &lt;- clusters\n\ndittoDimPlot(\n    spe, var = \"pg_clusters\",\n    reduction.use = \"UMAP\", size = 0.2,\n    do.label = TRUE\n) +\n    ggtitle(\"Phenograph clusters on UMAP\")\n\n\n\n\n\n\n### We can observe that some of the clusters only contain cells of a single \n### patient. This can often be observed in the tumor compartment.\ndittoHeatmap(\n    spe[, cur_cells],\n    genes = rownames(spe)[rowData(spe)$use_channel],\n    assay = \"exprs\", scale = \"none\",\n    heatmap.colors = viridis(100),\n    annot.by = c(\"pg_clusters\", \"patient_id\"),\n    annot.colors = c(\n        dittoColors(1)[1:length(unique(spe$pg_clusters))],\n        metadata(spe)$color_vectors$patient_id\n    )\n)\n\n\n\n\n\n\n\n\n### Use the integrated cells in low dimensional embedding for clustering\nmat &lt;- reducedDim(spe, \"fastMNN\")\n\nset.seed(230619)\nout &lt;- Rphenograph(mat, k = 45)\n\nRun Rphenograph starts:\n  -Input data of 47794 rows and 36 columns\n  -k is set to 45\n\n\n  Finding nearest neighbors...DONE ~ 51.466 s\n  Compute jaccard coefficient between nearest-neighbor sets...DONE ~ 20.096 s\n  Build undirected graph from the weighted links...DONE ~ 2.728 s\n  Run louvain clustering on the graph ...DONE ~ 7.708 s\n\n\nRun Rphenograph DONE, totally takes 81.998s.\n\n\n  Return a community class\n  -Modularity value: 0.8453626 \n  -Number of clusters: 25\n\nclusters &lt;- factor(membership(out[[2]]))\n\nspe$pg_clusters_corrected &lt;- clusters\n\ndittoDimPlot(\n    spe, var = \"pg_clusters_corrected\",\n    reduction.use = \"UMAP_mnnCorrected\", size = 0.2,\n    do.label = TRUE\n) +\n    ggtitle(\"Phenograph clusters on UMAP, integrated cells\")\n\n\n\n\n\n\n### Clustering using the integrated embedding leads to clusters that contain \n### cells of different patients. \ndittoHeatmap(\n    spe[, cur_cells],\n    genes = rownames(spe)[rowData(spe)$use_channel],\n    assay = \"exprs\", scale = \"none\",\n    heatmap.colors = viridis(100),\n    annot.by = c(\"pg_clusters_corrected\", \"patient_id\"),\n    annot.colors = c(dittoColors(1)[1:length(unique(spe$pg_clusters_corrected))],\n        metadata(spe)$color_vectors$patient_id)\n)\n\n\n\n\n\n\n\nShared nearest neighbour graph\n\nmat &lt;- t(assay(spe, \"exprs\")[rowData(spe)$use_channel, ])\n\ncombinations &lt;- clusterSweep(\n    mat,\n    BLUSPARAM = SNNGraphParam(),\n    k = c(10L, 20L),\n    type = c(\"rank\", \"jaccard\"),\n    cluster.fun = \"louvain\",\n    BPPARAM = MulticoreParam(RNGseed = 220427)\n)\n\nsil &lt;- vapply(\n    as.list(combinations$clusters),\n    function(x) mean(approxSilhouette(mat, x)$width),\n    0\n)\n\nggplot(\n    data.frame(method = names(sil),\n    sil = sil)\n    ) +\n    geom_point(aes(method, sil)) +\n    theme_classic(base_size = 15) +\n    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n    xlab(\"Cluster parameter combination\") +\n    ylab(\"Average silhouette width\")\n\n\n\n\n\n\npur &lt;- vapply(\n    as.list(combinations$clusters), \n    function(x) mean(neighborPurity(mat, x)$purity), \n    0\n)\n\nggplot(\n    data.frame(method = names(pur), pur = pur)\n    ) +\n    geom_point(aes(method, pur)) +\n    theme_classic(base_size = 15) +\n    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n    xlab(\"Cluster parameter combination\") +\n    ylab(\"Average neighborhood purity\")\n\n\n\n\n\n\n\n\nset.seed(220620)\nclusters &lt;- clusterCells(\n    spe[rowData(spe)$use_channel,], \n    assay.type = \"exprs\", \n    BLUSPARAM = SNNGraphParam(k=20, \n    cluster.fun = \"louvain\",\n    type = \"rank\")\n)\n\nspe$nn_clusters &lt;- clusters\n\ndittoDimPlot(\n    spe, var = \"nn_clusters\", \n    reduction.use = \"UMAP\", size = 0.2,\n    do.label = TRUE\n    ) +\n    ggtitle(\"SNN clusters on UMAP\")\n\n\n\n\n\n\ndittoHeatmap(\n    spe[,cur_cells], \n             genes = rownames(spe)[rowData(spe)$use_channel],\n             assay = \"exprs\", scale = \"none\",\n             heatmap.colors = viridis(100), \n             annot.by = c(\"nn_clusters\", \"patient_id\"),\n             annot.colors = c(dittoColors(1)[1:length(unique(spe$nn_clusters))],\n                              metadata(spe)$color_vectors$patient_id)\n)\n\n\n\n\n\n\n\n\nset.seed(220621)\nclusters &lt;- clusterCells(\n    spe, \n    use.dimred = \"fastMNN\", \n    BLUSPARAM = SNNGraphParam(k = 20, \n    cluster.fun = \"louvain\",\n    type = \"rank\")\n)\n\nspe$nn_clusters_corrected &lt;- clusters\n\ndittoDimPlot(\n    spe, var = \"nn_clusters_corrected\", \n    reduction.use = \"UMAP_mnnCorrected\", size = 0.2,\n    do.label = TRUE\n) +\n    ggtitle(\"SNN clusters on UMAP, integrated cells\")\n\n\n\n\n\n\ndittoHeatmap(\n    spe[,cur_cells], \n    genes = rownames(spe)[rowData(spe)$use_channel],\n    assay = \"exprs\", scale = \"none\",\n    heatmap.colors = viridis(100), \n    annot.by = c(\"nn_clusters_corrected\",\"patient_id\"),\n    annot.colors = c(dittoColors(1)[1:length(unique(spe$nn_clusters_corrected))],\n                    metadata(spe)$color_vectors$patient_id)\n)\n\n\n\n\n\n\n\nSelf organizing maps\n\n# Run FlowSOM and ConsensusClusterPlus clustering\nset.seed(220410)\nspe &lt;- CATALYST::cluster(spe, \n               features = rownames(spe)[rowData(spe)$use_channel],\n               maxK = 30)\n\no running FlowSOM clustering...\n\n\no running ConsensusClusterPlus metaclustering...\n\n# Assess cluster stability\ndelta_area(spe)\n\n\n\n\n\n\nspe$som_clusters &lt;- cluster_ids(spe, \"meta13\")\n\ndittoDimPlot(\n    spe, var = \"som_clusters\", \n    reduction.use = \"UMAP\", size = 0.2,\n    do.label = TRUE\n    ) +\n    ggtitle(\"SOM clusters on UMAP\")\n\n\n\n\n\n\ndittoHeatmap(\n    spe[,cur_cells], \n    genes = rownames(spe)[rowData(spe)$use_channel],\n    assay = \"exprs\", scale = \"none\",\n    heatmap.colors = viridis(100), \n    annot.by = c(\"som_clusters\", \"patient_id\"),\n    annot.colors = c(dittoColors(1)[1:length(unique(spe$som_clusters))],\n    metadata(spe)$color_vectors$patient_id)\n)\n\n\n\n\n\n\n\n\nlibrary(kohonen)\n\n\nAttaching package: 'kohonen'\n\n\nThe following object is masked from 'package:mclust':\n\n    map\n\n\nThe following object is masked from 'package:purrr':\n\n    map\n\nlibrary(ConsensusClusterPlus)\n\n### Select integrated cells\nmat &lt;- reducedDim(spe, \"fastMNN\")\n\n### Perform SOM clustering\nset.seed(220410)\nsom.out &lt;- clusterRows(mat, SomParam(100), full = TRUE)\n\n### Cluster the 100 SOM codes into larger clusters\nccp &lt;- ConsensusClusterPlus(\n    t(som.out$objects$som$codes[[1]]),\n    maxK = 30,\n    reps = 100, \n    distance = \"euclidean\", \n    seed = 220410, \n    plot = NULL\n)\n\nend fraction\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\nclustered\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n### Visualize delta area plot\nCATALYST:::.plot_delta_area(ccp)\n\n\n\n\n\n\n### Link ConsensusClusterPlus clusters with SOM codes and save in object\nsom.cluster &lt;- ccp[[16]][[\"consensusClass\"]][som.out$clusters]\nspe$som_clusters_corrected &lt;- as.factor(som.cluster)\n\ndittoDimPlot(\n    spe, var = \"som_clusters_corrected\", \n    reduction.use = \"UMAP_mnnCorrected\", size = 0.2,\n    do.label = TRUE\n    ) +\n    ggtitle(\"SOM clusters on UMAP, integrated cells\")\n\n\n\n\n\n\ndittoHeatmap(\n    spe[,cur_cells], \n    genes = rownames(spe)[rowData(spe)$use_channel],\n    assay = \"exprs\", scale = \"none\",\n    heatmap.colors = viridis(100), \n    annot.by = c(\"som_clusters_corrected\",\"patient_id\"),\n    annot.colors = c(dittoColors(1)[1:length(unique(spe$som_clusters_corrected))],\n                              metadata(spe)$color_vectors$patient_id)\n)\n\n\n\n\n\n\n\nCompare between clustering approaches\n\nlibrary(patchwork)\nlibrary(pheatmap)\nlibrary(gridExtra)\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:EBImage':\n\n    combine\n\n\nThe following object is masked from 'package:Biobase':\n\n    combine\n\n\nThe following object is masked from 'package:BiocGenerics':\n\n    combine\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\ntab1 &lt;- table(\n    paste(\"Rphenograph\", spe$pg_clusters), \n    paste(\"SNN\", spe$nn_clusters)\n)\n\ntab2 &lt;- table(\n    paste(\"Rphenograph\", spe$pg_clusters), \n    paste(\"SOM\", spe$som_clusters)\n)\n\ntab3 &lt;- table(\n    paste(\"SNN\", spe$nn_clusters), \n    paste(\"SOM\", spe$som_clusters)\n)\n\npheatmap(log10(tab1 + 10), color = viridis(100))\n\n\n\n\n\n\npheatmap(log10(tab2 + 10), color = viridis(100))\n\n\n\n\n\n\npheatmap(log10(tab3 + 10), color = viridis(100))\n\n\n\n\n\n\n\nFurther clustering notes\n\nlibrary(dplyr)\ncluster_celltype &lt;- recode(spe$nn_clusters_corrected,\n                            \"1\" = \"Tumor_proliferating\",\n                            \"2\" = \"Myeloid\",\n                            \"3\" = \"Tumor\",\n                            \"4\" = \"Tumor\",\n                            \"5\" = \"Stroma\",\n                            \"6\" = \"Proliferating\",\n                            \"7\" = \"Myeloid\",\n                            \"8\" = \"Plasma_cell\",\n                            \"9\" = \"CD8\",\n                            \"10\" = \"CD4\",\n                            \"11\" = \"Neutrophil\",\n                            \"12\" = \"Bcell\",\n                            \"13\" = \"Stroma\")\n\nspe$cluster_celltype &lt;- cluster_celltype\n\n\nqsave(spe, here(dir, \"data/spe.qs\"))\n\nClassfication approach\n\n### Manual labeling of cells\n# if (interactive()) {\n\n#     images &lt;- qread(here(dir, \"data/images.qs\"))\n#     masks &lt;- qread(here(dir, \"data/masks.qs\"))\n\n#     cytomapperShiny(object = spe, mask = masks, image = images,\n#                     cell_id = \"ObjectNumber\", img_id = \"sample_id\")\n# }\nspe &lt;- qread(here(dir, \"data/spe.qs\"))\n### Define color vectors\ncelltype &lt;- setNames(\n    c(\"#3F1B03\", \"#F4AD31\", \"#894F36\", \"#1C750C\", \"#EF8ECC\",\n        \"#6471E2\", \"#4DB23B\", \"grey\", \"#F4800C\", \"#BF0A3D\", \"#066970\"\n    ),\n    c(\"Tumor\", \"Stroma\", \"Myeloid\", \"CD8\", \"Plasma_cell\",\n        \"Treg\", \"CD4\", \"undefined\", \"BnTcell\", \"Bcell\", \"Neutrophil\")\n)\n\nmetadata(spe)$color_vectors$celltype &lt;- celltype\n\n\n### Read in and consolidate labeled data\nlabel_files &lt;- list.files(\n    here(dir, \"data/gated_cells\"), \n    full.names = TRUE, pattern = \".rds$\"\n)\n\n### Read in SPE objects\nspes &lt;- lapply(label_files, readRDS)\n\n### Merge SPE objects\nconcat_spe &lt;- do.call(\"cbind\", spes)\n\n'sample_id's are duplicated across 'SpatialExperiment' objects to cbind; appending sample indices.\n\n\n\nfilter_labels &lt;- function(object, \n                          label = \"cytomapper_CellLabel\") {\n    cur_tab &lt;- unclass(table(colnames(object), object[[label]]))\n    \n    cur_labels &lt;- colnames(cur_tab)[apply(cur_tab, 1, which.max)]\n    names(cur_labels) &lt;- rownames(cur_tab)\n    \n    cur_labels &lt;- cur_labels[rowSums(cur_tab) == 1]\n    \n    return(cur_labels)\n}\n\nlabels &lt;- filter_labels(concat_spe)\n\ncur_spe &lt;- concat_spe[,concat_spe$cytomapper_CellLabel != \"Tumor\"]\n\nnon_tumor_labels &lt;- filter_labels(cur_spe)\n\nadditional_cells &lt;- setdiff(names(non_tumor_labels), names(labels))\n\nfinal_labels &lt;- c(labels, non_tumor_labels[additional_cells])\n\n### Transfer labels to SPE object\nspe_labels &lt;- rep(\"unlabeled\", ncol(spe))\nnames(spe_labels) &lt;- colnames(spe)\nspe_labels[names(final_labels)] &lt;- final_labels\nspe$cell_labels &lt;- spe_labels\n\n### Number of cells labeled per patient\ntable(spe$cell_labels, spe$patient_id)\n\n             \n              Patient1 Patient2 Patient3 Patient4\n  Bcell            152      131      234      263\n  BnTcell          396       37      240     1029\n  CD4               45      342      167      134\n  CD8               60      497      137      128\n  Myeloid          183      378      672      517\n  Neutrophil        97        4       17       16\n  Plasma_cell       34      536       87       59\n  Stroma            84       37       85      236\n  Treg             139      149       49       24\n  Tumor           2342      906     1618     1133\n  unlabeled       7214     9780     7826     9580\n\n\n\n### Split between labeled and unlabeled cells\nlab_spe &lt;- spe[,spe$cell_labels != \"unlabeled\"]\nunlab_spe &lt;- spe[,spe$cell_labels == \"unlabeled\"]\n\n### Randomly split into train and test data\nset.seed(221029)\ntrainIndex &lt;- createDataPartition(factor(lab_spe$cell_labels), p = 0.75)\n\ntrain_spe &lt;- lab_spe[,trainIndex$Resample1]\ntest_spe &lt;- lab_spe[,-trainIndex$Resample1]\n\n### Define fit parameters for 5-fold cross validation\nfitControl &lt;- trainControl(method = \"cv\",number = 5)\n\n### Select the arsinh-transformed counts for training\ncur_mat &lt;- t(assay(train_spe, \"exprs\")[rowData(train_spe)$use_channel,])\n\n### Train a random forest classifier\nrffit &lt;- train(\n    x = cur_mat, \n    y = factor(train_spe$cell_labels),\n    method = \"rf\", ntree = 1000,\n    tuneLength = 5,\n    trControl = fitControl\n)\n\nrffit\n\nRandom Forest \n\n10049 samples\n   37 predictor\n   10 classes: 'Bcell', 'BnTcell', 'CD4', 'CD8', 'Myeloid', 'Neutrophil', 'Plasma_cell', 'Stroma', 'Treg', 'Tumor' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 8040, 8039, 8038, 8038, 8041 \nResampling results across tuning parameters:\n\n  mtry  Accuracy   Kappa    \n   2    0.9643721  0.9523612\n  10    0.9754201  0.9672910\n  19    0.9757188  0.9676911\n  28    0.9751223  0.9668928\n  37    0.9735309  0.9647805\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was mtry = 19.\n\n\n\n### Classifier performance\nggplot(rffit) + \n  geom_errorbar(data = rffit$results,\n                aes(ymin = Accuracy - AccuracySD,\n                    ymax = Accuracy + AccuracySD),\n                width = 0.4) +\n    theme_classic(base_size = 15)\n\n\n\n\n\n\n### Visualize the variable importance of the classifier.\nplot(varImp(rffit))\n\n\n\n\n\n\n\n\n### Select the arsinh-transformed counts of the test data\ncur_mat &lt;- t(assay(test_spe, \"exprs\")[rowData(test_spe)$use_channel,])\n\n### Predict the cell phenotype labels of the test data\nset.seed(231019)\ncur_pred &lt;- predict(rffit, newdata = cur_mat)\n\n\ncm &lt;- confusionMatrix(\n    data = cur_pred, \n    reference = factor(test_spe$cell_labels), \n    mode = \"everything\"\n)\n\ncm\n\nConfusion Matrix and Statistics\n\n             Reference\nPrediction    Bcell BnTcell  CD4  CD8 Myeloid Neutrophil Plasma_cell Stroma\n  Bcell         185       4    0    0       0          0           5      0\n  BnTcell         3     421    2    1       0          0           1      0\n  CD4             0       0  161    0       0          2           4      2\n  CD8             0       0    0  197       0          0           7      0\n  Myeloid         0       0    2    3     437          0           0      0\n  Neutrophil      0       0    0    0       0         30           0      0\n  Plasma_cell     0       0    4    1       0          0         158      0\n  Stroma          0       0    2    0       0          0           0    108\n  Treg            0       0    0    0       0          0           3      0\n  Tumor           7       0    1    3       0          1           1      0\n             Reference\nPrediction    Treg Tumor\n  Bcell          0     0\n  BnTcell        0     0\n  CD4            0     4\n  CD8            1     5\n  Myeloid        0     0\n  Neutrophil     0     0\n  Plasma_cell    0     0\n  Stroma         0     0\n  Treg          89     2\n  Tumor          0  1488\n\nOverall Statistics\n                                          \n               Accuracy : 0.9788          \n                 95% CI : (0.9733, 0.9834)\n    No Information Rate : 0.4481          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.9717          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: Bcell Class: BnTcell Class: CD4 Class: CD8\nSensitivity               0.94872         0.9906    0.93605    0.96098\nSpecificity               0.99714         0.9976    0.99622    0.99586\nPos Pred Value            0.95361         0.9836    0.93064    0.93810\nNeg Pred Value            0.99683         0.9986    0.99653    0.99745\nPrecision                 0.95361         0.9836    0.93064    0.93810\nRecall                    0.94872         0.9906    0.93605    0.96098\nF1                        0.95116         0.9871    0.93333    0.94940\nPrevalence                0.05830         0.1271    0.05142    0.06129\nDetection Rate            0.05531         0.1259    0.04813    0.05889\nDetection Prevalence      0.05800         0.1280    0.05172    0.06278\nBalanced Accuracy         0.97293         0.9941    0.96613    0.97842\n                     Class: Myeloid Class: Neutrophil Class: Plasma_cell\nSensitivity                  1.0000          0.909091            0.88268\nSpecificity                  0.9983          1.000000            0.99842\nPos Pred Value               0.9887          1.000000            0.96933\nNeg Pred Value               1.0000          0.999095            0.99340\nPrecision                    0.9887          1.000000            0.96933\nRecall                       1.0000          0.909091            0.88268\nF1                           0.9943          0.952381            0.92398\nPrevalence                   0.1306          0.009865            0.05351\nDetection Rate               0.1306          0.008969            0.04723\nDetection Prevalence         0.1321          0.008969            0.04873\nBalanced Accuracy            0.9991          0.954545            0.94055\n                     Class: Stroma Class: Treg Class: Tumor\nSensitivity                0.98182     0.98889       0.9927\nSpecificity                0.99938     0.99846       0.9930\nPos Pred Value             0.98182     0.94681       0.9913\nNeg Pred Value             0.99938     0.99969       0.9940\nPrecision                  0.98182     0.94681       0.9913\nRecall                     0.98182     0.98889       0.9927\nF1                         0.98182     0.96739       0.9920\nPrevalence                 0.03288     0.02691       0.4481\nDetection Rate             0.03229     0.02661       0.4448\nDetection Prevalence       0.03288     0.02810       0.4487\nBalanced Accuracy          0.99060     0.99368       0.9928\n\n\n\ndata.frame(cm$byClass) |&gt;\n  mutate(class = sub(\"Class: \", \"\", rownames(cm$byClass))) |&gt;\n  ggplot() + \n  geom_point(aes(1 - Specificity, Sensitivity, \n                 size = Detection.Rate,\n                 fill = class),\n             shape = 21) + \n  scale_fill_manual(values = metadata(spe)$color_vectors$celltype) +\n  theme_classic(base_size = 15) + \n  ylab(\"Sensitivity (TPR)\") +\n  xlab(\"1 - Specificity (FPR)\")\n\n\n\n\n\n\n\n\nset.seed(231019)\ncur_pred &lt;- predict(rffit, \n                    newdata = cur_mat, \n                    type = \"prob\")\ncur_pred$truth &lt;- factor(test_spe$cell_labels)\n\ncur_pred |&gt;\n  pivot_longer(cols = Bcell:Tumor) |&gt;\n  ggplot() +\n  geom_boxplot(aes(x = name, y = value, fill = name), outlier.size = 0.5) +\n  facet_wrap(. ~ truth, ncol = 1) + \n  scale_fill_manual(values = metadata(spe)$color_vectors$celltype)  +\n  theme(\n    panel.background = element_blank(), \n    axis.text.x = element_text(angle = 45, hjust = 1)\n    )\n\n\n\n\n\n\n\n\n### Classification of new data\n### Select the arsinh-transformed counts of the unlabeled data for prediction\ncur_mat &lt;- t(assay(unlab_spe, \"exprs\")[rowData(unlab_spe)$use_channel,])\n\n### Predict the cell phenotype labels of the unlabeled data\nset.seed(231014)\ncell_class &lt;- as.character(predict(\n    rffit, \n    newdata = cur_mat, \n    type = \"raw\")\n)\nnames(cell_class) &lt;- rownames(cur_mat)\n\ntable(cell_class)\n\ncell_class\n      Bcell     BnTcell         CD4         CD8     Myeloid  Neutrophil \n        799        1047        3664        2728        5726         453 \nPlasma_cell      Stroma        Treg       Tumor \n       3369        4669        1057       10888 \n\n### Extract prediction probabilities for each cell\nset.seed(231014)\ncell_prob &lt;- predict(rffit, newdata = cur_mat, type = \"prob\")\n\n### Distribution of maximum probabilities\ntibble(max_prob = rowMax(as.matrix(cell_prob)),\n       type = cell_class) |&gt;\n    ggplot() +\n        geom_density_ridges(aes(x = max_prob, y = cell_class, fill = cell_class)) +\n        scale_fill_manual(values = metadata(spe)$color_vectors$celltype) +\n        theme_classic(base_size = 15) +\n        xlab(\"Maximum probability\") +\n        ylab(\"Cell type\") + \n        xlim(c(0,1.2))\n\nPicking joint bandwidth of 0.0281\n\n\n\n\n\n\n\n### Label undefined cells\ncell_class[rowMax(as.matrix(cell_prob)) &lt; 0.4] &lt;- \"undefined\"\n\n### Store labels in SpatialExperiment onject\ncell_labels &lt;- spe$cell_labels\ncell_labels[colnames(unlab_spe)] &lt;- cell_class\nspe$celltype &lt;- cell_labels \n\ntable(spe$celltype, spe$patient_id)\n\n             \n              Patient1 Patient2 Patient3 Patient4\n  Bcell            179      517      422      460\n  BnTcell          422      601      604     1110\n  CD4              407     1383      700     1394\n  CD8              510     1370      478     1156\n  Myeloid         1210     1876     1599     2685\n  Neutrophil       284        6       92      164\n  Plasma_cell      809     2428      425      338\n  Stroma           582      603      662     3169\n  Treg             524      379      244      258\n  Tumor           5593     3360     5793     2117\n  undefined        226      274      113      268\n\n\n\ntab1 &lt;- table(spe$celltype, \n              paste(\"Rphenograph\", spe$pg_clusters))\ntab2 &lt;- table(spe$celltype, \n              paste(\"SNN\", spe$nn_clusters))\ntab3 &lt;- table(spe$celltype, \n              paste(\"SOM\", spe$som_clusters))\n\npheatmap(log10(tab1 + 10), color = viridis(100))\n\n\n\n\n\n\npheatmap(log10(tab2 + 10), color = viridis(100))\n\n\n\n\n\n\npheatmap(log10(tab3 + 10), color = viridis(100))\n\n\n\n\n\n\n\n\ntab1 &lt;- table(spe$celltype, \n              paste(\"Rphenograph\", spe$pg_clusters_corrected))\ntab2 &lt;- table(spe$celltype, \n              paste(\"SNN\", spe$nn_clusters_corrected))\ntab3 &lt;- table(spe$celltype, \n              paste(\"SOM\", spe$som_clusters_corrected))\n\npheatmap(log10(tab1 + 10), color = viridis(100))\n\n\n\n\n\n\npheatmap(log10(tab2 + 10), color = viridis(100))\n\n\n\n\n\n\npheatmap(log10(tab3 + 10), color = viridis(100))\n\n\n\n\n\n\n\n\nqsave(spe, here(dir, \"data/spe.qs\"))"
  },
  {
    "objectID": "blog/2024/04/18/index.html#single-cell-visualization",
    "href": "blog/2024/04/18/index.html#single-cell-visualization",
    "title": "Multiplex image-based phenotypic data analysis",
    "section": "Single cell visualization",
    "text": "Single cell visualization\nInital setup\n\nspe &lt;- qread(here(dir, \"data/spe.qs\"))\nreducedDims(spe)\n\nList of length 9\nnames(9): UMAP TSNE fastMNN ... UMAP_harmony seurat UMAP_seurat\n\ncolnames(colData(spe))\n\n [1] \"sample_id\"              \"ObjectNumber\"           \"area\"                  \n [4] \"axis_major_length\"      \"axis_minor_length\"      \"eccentricity\"          \n [7] \"width_px\"               \"height_px\"              \"patient_id\"            \n[10] \"ROI\"                    \"indication\"             \"pg_clusters\"           \n[13] \"pg_clusters_corrected\"  \"nn_clusters\"            \"cluster_id\"            \n[16] \"som_clusters\"           \"som_clusters_corrected\" \"nn_clusters_corrected\" \n[19] \"cluster_celltype\"       \"cell_labels\"            \"celltype\"              \n\n### Define cell phenotype markers\ntype_markers &lt;- c(\n    \"Ecad\", \"CD45RO\", \"CD20\", \"CD3\", \"FOXP3\", \"CD206\", \"MPO\",\n    \"SMA\", \"CD8a\", \"CD4\", \"HLADR\", \"CD15\", \"CD38\", \"PDGFRb\"\n)\n\n### Define cell state markers\nstate_markers &lt;- c(\n    \"CarbonicAnhydrase\", \"Ki67\", \"PD1\", \"GrzB\", \"PDL1\",\n    \"ICOS\", \"TCF7\", \"VISTA\"\n)\n\n### Add to spe\nrowData(spe)$marker_class &lt;- ifelse(\n    rownames(spe) %in% type_markers, \"type\",\n    ifelse(rownames(spe) %in% state_markers, \"state\",\n        \"other\")\n)\n\nCell-type level\n\n### Dimensionality reduction visualization\n### Interpreting these UMAP, tSNE plots is not trivial, but local neighborhoods \n### in the plot can suggest similarity in expression for given cells.\n### tSNE/UMAP aim to preserve the distances between each cell and its neighbors in the high-dimensional space.\n\n### UMAP colored by cell type and expression - dittoDimPlot\np1 &lt;- dittoDimPlot(\n    spe, \n    var = \"celltype\", \n    reduction.use = \"UMAP_mnnCorrected\", \n    size = 0.2,\n    do.label = TRUE\n) +\n  scale_color_manual(values = metadata(spe)$color_vectors$celltype) +\n  theme(legend.title = element_blank()) +\n  ggtitle(\"Cell types on UMAP, integrated cells\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\np2 &lt;- dittoDimPlot(\n    spe, \n    var = \"Ecad\", \n    assay = \"exprs\",\n    reduction.use = \"UMAP_mnnCorrected\", \n    size = 0.2, \n    colors = viridis(100), \n    do.label = TRUE\n) +\n    scale_color_viridis()\n\ndo.label was/were ignored for non-discrete data.\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n    # coord_fixed()\n  \np1 + p2\n\n\n\n\n\n\n\n\n# UMAP colored by expression for all markers - plotReducedDim\nplot_list &lt;- lapply(\n    rownames(spe)[rowData(spe)$marker_class == \"type\"],\n    function(x) {\n        p &lt;- scater::plotReducedDim(\n            spe,\n            dimred = \"UMAP_mnnCorrected\",\n            colour_by = x,\n            by_exprs_values = \"exprs\",\n            point_size = 0.2\n        )\n        return(p)\n    }\n)\n\nplot_grid(plotlist = plot_list)\n\n\n\n\n\n\n\n\n### Heatmap visualization, it is often useful to visualize single-cell \n### expression per cell type in form of a heatmap\nset.seed(220818)\ncur_cells &lt;- sample(seq_len(ncol(spe)), 4000)\n\n### Heatmap visualization\ndittoHeatmap(\n    spe[,cur_cells], \n    genes = rownames(spe)[rowData(spe)$marker_class == \"type\"],\n    assay = \"exprs\", \n    cluster_cols = FALSE, \n    scale = \"none\",\n    heatmap.colors = viridis(100), \n    annot.by = c(\"celltype\", \"indication\", \"patient_id\"),\n    annotation_colors = list(\n        indication = metadata(spe)$color_vectors$indication,\n        patient_id = metadata(spe)$color_vectors$patient_id,\n        celltype = metadata(spe)$color_vectors$celltype\n    )\n)\n\n\n\n\n\n\n\n\n### Visualize the mean marker expression per cell type for all cells\n### aggregate by cell type\ncelltype_mean &lt;- scuttle::aggregateAcrossCells(\n    as(spe, \"SingleCellExperiment\"),  \n    ids = spe$celltype, \n    statistics = \"mean\",\n    use.assay.type = \"exprs\", \n    subset.row = rownames(spe)[rowData(spe)$marker_class == \"type\"]\n)\n\n### No scaling\ndittoHeatmap(\n    celltype_mean,\n    assay = \"exprs\", \n    cluster_cols = TRUE, \n    scale = \"none\",\n    heatmap.colors = viridis(100),\n    annot.by = c(\"celltype\", \"ncells\"),\n    annotation_colors = list(\n        celltype = metadata(spe)$color_vectors$celltype,\n        ncells = plasma(100)\n    )\n)\n\n\n\n\n\n\n### Scaled to max\ndittoHeatmap(\n    celltype_mean,\n    assay = \"exprs\", \n    cluster_cols = TRUE, \n    scaled.to.max = TRUE,\n    heatmap.colors.max.scaled = inferno(100),\n    annot.by = c(\"celltype\", \"ncells\"),\n    annotation_colors = list(\n        celltype = metadata(spe)$color_vectors$celltype,\n        ncells = plasma(100)\n    )\n)\n\n\n\n\n\n\n### # Z score scaled\ndittoHeatmap(\n    celltype_mean,\n    assay = \"exprs\", \n    cluster_cols = TRUE, \n    annot.by = c(\"celltype\", \"ncells\"),\n    annotation_colors = list(\n        celltype = metadata(spe)$color_vectors$celltype,\n        ncells = plasma(100)\n    )\n)\n\n\n\n\n\n\n\n\n### Violin plot visualization - plotExpression\nplotExpression(\n    spe[,cur_cells], \n    features = rownames(spe)[rowData(spe)$marker_class == \"type\"],\n    x = \"celltype\", \n    exprs_values = \"exprs\", \n    colour_by = \"celltype\"\n) +\n    theme(axis.text.x =  element_text(angle = 90))+\n    scale_color_manual(values = metadata(spe)$color_vectors$celltype)\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\n### Scatter plot visualization\ndittoScatterPlot(\n    spe,\n    x.var = \"CD3\",\n    y.var = \"CD20\",\n    assay.x = \"exprs\",\n    assay.y = \"exprs\",\n    color.var = \"celltype\"\n) +\n    scale_color_manual(values = metadata(spe)$color_vectors$celltype) +\n    ggtitle(\"Scatterplot for CD3/CD20 labelled by celltype\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\n### by sample_id - percentage\ndittoBarPlot(spe, var = \"celltype\", group.by = \"sample_id\") +\n    scale_fill_manual(values = metadata(spe)$color_vectors$celltype)\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\n\n\n\n\n\n### by patient_id - percentage\ndittoBarPlot(spe, var = \"celltype\", group.by = \"patient_id\") +\n    scale_fill_manual(values = metadata(spe)$color_vectors$celltype)\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\n\n\n\n\n\n### by patient_id - count\ndittoBarPlot(spe, scale = \"count\",var = \"celltype\", group.by = \"patient_id\") +\n    scale_fill_manual(values = metadata(spe)$color_vectors$celltype)\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\n\n\n\n\n\n### We can see that cell type frequencies change between samples/patients and that the highest proportion/counts of plasma cells and stromal cells can be observed for Patient 2 and Patient 4, respectively.\n\n\n### CATALYST-based visualization\n### Save SPE in CATALYST-compatible object with renamed colData entries and\n### new metadata information\nspe_cat &lt;- spe\nspe_cat$sample_id &lt;- factor(spe$sample_id)\nspe_cat$condition &lt;- factor(spe$indication)\nspe_cat$cluster_id &lt;- factor(spe$celltype)\n\n### Add celltype information to metadata\nmetadata(spe_cat)$cluster_codes &lt;- data.frame(\n    celltype = factor(spe_cat$celltype)\n)\n\n### Pseudobulk-level MDS plot\n### MDS pseudobulk by cell type to highlight expression similarities between \n### cell types and subsequently for each celltype-sample-combination.\nCATALYST::pbMDS(\n    spe_cat,\n    by = \"cluster_id\",\n    features = rownames(spe_cat)[rowData(spe_cat)$marker_class == \"type\"],\n    label_by = \"cluster_id\",\n    k = \"celltype\"\n) +\n    scale_color_manual(values = metadata(spe_cat)$color_vectors$celltype)\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\n\n\n\n\n\n### MDS pseudobulk by cell type and sample_id\n### We can see that the pseudobulk-expression profile of neutrophils seems \n### markedly distinct from the other cell types, while comparable cell types \n### such as the T cell subtypes group together. Furthermore, pseudobulk \n## cell-type profiles from SCCHN appear different from the other indications.\nCATALYST::pbMDS(\n    spe_cat, \n    by = \"both\", \n    features = rownames(spe_cat)[rowData(spe_cat)$marker_class == \"type\"], \n    k = \"celltype\", \n    shape_by = \"condition\", \n    size_by = TRUE\n) +\n  scale_color_manual(values = metadata(spe_cat)$color_vectors$celltype)\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\n\n\n\n\n\n### Reduced dimension plot on CLR of proportions\n### The output plots aim to illustrate the degree of similarity between \n### cell types based on sample proportions.\n### CLR on cluster proportions across samples\n### We can again observe that neutrophils have a divergent profile also in terms of their sample proportions.\nCATALYST::clrDR(\n    spe_cat, \n    dr = \"PCA\", \n    by = \"cluster_id\", \n    k = \"celltype\", \n    label_by = \"cluster_id\", \n    arrow_col = \"sample_id\", \n    point_pal = metadata(spe_cat)$color_vectors$celltype\n)\n\n\n\n\n\n\n### Pseudobulk expression boxplot\n### Notably, CD15 levels are elevated in SCCHN in comparison to all other \n### indications for most cell types.\nCATALYST::plotPbExprs(\n    spe_cat, \n    k = \"celltype\", \n    facet_by = \"cluster_id\", \n    ncol = 2, \n    features = rownames(spe_cat)[rowData(spe_cat)$marker_class == \"type\"]\n) +\n    scale_color_manual(values = metadata(spe_cat)$color_vectors$indication)\n\n\n\n\n\n\n\nSample level\n\n### Dimensionality reduction visualization\n## UMAP colored by cell type and expression - dittoDimPlot\np1 &lt;- dittoDimPlot(\n    spe,\n    var = \"sample_id\",\n    reduction.use = \"UMAP\",\n    size = 0.2,\n    colors = viridis(100),\n    do.label = FALSE\n) +\n    scale_color_manual(values = metadata(spe)$color_vectors$sample_id) +\n    theme(legend.title = element_blank()) +\n    ggtitle(\"Sample ID\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\np2 &lt;- dittoDimPlot(\n    spe,\n    var = \"sample_id\",\n    reduction.use = \"UMAP_mnnCorrected\",\n    size = 0.2,\n    colors = viridis(100),\n    do.label = FALSE\n) +\n    scale_color_manual(values = metadata(spe)$color_vectors$sample_id) +\n    theme(legend.title = element_blank()) +\n    ggtitle(\"Sample ID\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\np3 &lt;- dittoDimPlot(\n    spe,\n    var = \"patient_id\",\n    reduction.use = \"UMAP\",\n    size = 0.2,\n    do.label = FALSE\n) +\n    scale_color_manual(values = metadata(spe)$color_vectors$patient_id) +\n    theme(legend.title = element_blank()) +\n    ggtitle(\"Patient ID\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\np4 &lt;- dittoDimPlot(\n    spe,\n    var = \"patient_id\",\n    reduction.use = \"UMAP_mnnCorrected\",\n    size = 0.2,\n    do.label = FALSE\n) +\n    scale_color_manual(values = metadata(spe)$color_vectors$patient_id) +\n    theme(legend.title = element_blank()) +\n    ggtitle(\"Patient ID\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n### fastMNN approach (right side of the plot) leads to mixing of cells across \n### samples/patients and thus batch effect correction.\n(p1 + p2) / (p3 + p4)\n\n\n\n\n\n\n\n\n### Heatmap visualization to highlight biological differences across samples/patients.\ndittoHeatmap(\n    spe[,cur_cells], \n    genes = rownames(spe)[rowData(spe)$marker_class == \"type\"],\n    assay = \"exprs\", \n    order.by = c(\"patient_id\",\"sample_id\"),\n    cluster_cols = FALSE, \n    scale = \"none\",\n    heatmap.colors = viridis(100), \n    annot.by = c(\"celltype\", \"indication\", \"patient_id\", \"sample_id\"),\n    annotation_colors = list(\n        celltype = metadata(spe)$color_vectors$celltype,\n        indication = metadata(spe)$color_vectors$indication,\n        patient_id = metadata(spe)$color_vectors$patient_id,\n        sample_id = metadata(spe)$color_vectors$sample_id)\n)\n\n\n\n\n\n\n### mean expression by patient_id\npatient_mean &lt;- aggregateAcrossCells(\n    as(spe, \"SingleCellExperiment\"),  \n    ids = spe$patient_id, \n    statistics = \"mean\",\n    use.assay.type = \"exprs\", \n    subset.row = rownames(spe)[rowData(spe)$marker_class == \"type\"]\n)\n\n### No scaling\ndittoHeatmap(\n    patient_mean,\n    assay = \"exprs\", \n    cluster_cols = TRUE, \n    scale = \"none\",\n    heatmap.colors = viridis(100),\n    annot.by = c(\"patient_id\",\"indication\",\"ncells\"),\n    annotation_colors = list(\n        patient_id = metadata(spe)$color_vectors$patient_id,\n        indication = metadata(spe)$color_vectors$indication,\n        ncells = plasma(100)\n    )\n)\n\n\n\n\n\n\n### Max expression scaling\ndittoHeatmap(\n    patient_mean,\n    assay = \"exprs\", \n    cluster_cols = TRUE, \n    scaled.to.max =  TRUE,\n    heatmap.colors.max.scaled = inferno(100),\n    annot.by = c(\"patient_id\",\"indication\",\"ncells\"),\n    annotation_colors = list(\n        patient_id = metadata(spe)$color_vectors$patient_id,\n        indication = metadata(spe)$color_vectors$indication,\n        ncells = plasma(100)\n    )\n)\n\n\n\n\n\n\n\n\n### Barplot visualization\ndittoBarPlot(\n    spe, \n    var = \"patient_id\", \n    group.by = \"celltype\"\n) +\n    scale_fill_manual(values = metadata(spe)$color_vectors$patient_id)\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\n\n\n\n\n\n### \ndittoBarPlot(\n    spe, \n    var = \"sample_id\", \n    group.by = \"celltype\"\n) +\n    scale_fill_manual(values = metadata(spe)$color_vectors$sample_id)\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\n\n\n\n\n\n\nComplexHeatmap\n\nset.seed(22)\n\n### 1. Heatmap bodies ###\n### Heatmap body color\ncol_exprs &lt;- colorRamp2(\n    c(0, 1, 2, 3, 4),\n    c(\"#440154FF\", \"#3B518BFF\", \"#20938CFF\", \"#6ACD5AFF\", \"#FDE725FF\")\n)\n\n### Create Heatmap objects\n### By cell type markers\ncelltype_mean &lt;- aggregateAcrossCells(\n    as(spe, \"SingleCellExperiment\"),\n    ids = spe$celltype,\n    statistics = \"mean\",\n    use.assay.type = \"exprs\",\n    subset.row = rownames(spe)[rowData(spe)$marker_class == \"type\"]\n)\n\nh_type &lt;- Heatmap(\n    t(assay(celltype_mean, \"exprs\")),\n    column_title = \"type_markers\",\n    col = col_exprs,\n    name = \"mean exprs\",\n    show_row_names = TRUE,\n    show_column_names = TRUE\n)\n\n# By cell state markers\ncellstate_mean &lt;- aggregateAcrossCells(\n    as(spe, \"SingleCellExperiment\"),\n    ids = spe$celltype,\n    statistics = \"mean\",\n    use.assay.type = \"exprs\",\n    subset.row = rownames(spe)[rowData(spe)$marker_class == \"state\"]\n)\n\nh_state &lt;- Heatmap(\n    t(assay(cellstate_mean, \"exprs\")),\n    column_title = \"state_markers\",\n    col = col_exprs,\n    name = \"mean exprs\",\n    show_row_names = TRUE,\n    show_column_names = TRUE\n)\n\n\n### 2. Heatmap annotation ###\n### 2.1  Metadata features\nanno &lt;- colData(celltype_mean) |&gt; \n    as.data.frame() |&gt; \n    select(celltype, ncells)\n\n### Proportion of indication per celltype\nindication &lt;- unclass(prop.table(table(spe$celltype, spe$indication), margin = 1))\n\n### Number of contributing patients per celltype\ncluster_PID &lt;- colData(spe) |&gt;\n    as.data.frame() |&gt;\n    select(celltype, patient_id) |&gt;\n    group_by(celltype) |&gt; table() |&gt;\n    as.data.frame()\n\nn_PID &lt;- cluster_PID |&gt;\n    filter(Freq &gt; 0) |&gt;\n    group_by(celltype) |&gt;\n    dplyr::count(name = \"n_PID\") |&gt;\n    column_to_rownames(\"celltype\")\n\n### Create HeatmapAnnotation objects\nha_anno &lt;- HeatmapAnnotation(\n    celltype = anno$celltype,\n    border = TRUE,\n    gap = unit(1, \"mm\"),\n    col = list(celltype = metadata(spe)$color_vectors$celltype),\n    which = \"row\"\n)\n\nha_meta &lt;- HeatmapAnnotation(\n    n_cells = anno_barplot(anno$ncells, width = unit(10, \"mm\")),\n    n_PID = anno_barplot(n_PID, width = unit(10, \"mm\")),\n    indication = anno_barplot(indication, width = unit(10, \"mm\"),\n    gp = gpar(fill = metadata(spe)$color_vectors$indication)),\n    border = TRUE,\n    annotation_name_rot = 90,\n    gap = unit(1, \"mm\"),\n    which = \"row\"\n)\n\n### 2.2 Spatial features\n### Add number of neighbors to spe object (saved in colPair)\nspe$n_neighbors &lt;- countLnodeHits(colPair(spe, \"neighborhood\"))\n\n### Select spatial features and average over celltypes\nspatial &lt;- colData(spe) |&gt;\n    as.data.frame() |&gt;\n    select(area, celltype, n_neighbors)\n\nspatial &lt;- spatial |&gt;\n    select(-celltype) |&gt;\n    aggregate(by = list(celltype = spatial$celltype), FUN = mean) |&gt;\n    column_to_rownames(\"celltype\")\n\n### Create HeatmapAnnotation object\nha_spatial &lt;- HeatmapAnnotation(\n    area = spatial$area,\n    n_neighbors = spatial$n_neighbors,\n    border = TRUE,\n    gap = unit(1, \"mm\"),\n    which = \"row\"\n)\n\n### 3. Plot rich heatmap ###\n\n### Create HeatmapList object\nh_list &lt;- h_type +\n    h_state +\n    ha_anno +\n    ha_spatial +\n    ha_meta\n\nWarning: Heatmap/annotation names are duplicated: mean exprs\n\nWarning: Heatmap/annotation names are duplicated: mean exprs\n\nWarning: Heatmap/annotation names are duplicated: mean exprs\n\nWarning: Heatmap/annotation names are duplicated: mean exprs\n\n### Add customized legend for anno_barplot()\nlgd &lt;- Legend(\n    title = \"indication\",\n    at = colnames(indication),\n    legend_gp = gpar(fill = metadata(spe)$color_vectors$indication)\n)\n\n### Plot\ndraw(h_list, annotation_legend_list = list(lgd))"
  },
  {
    "objectID": "blog/2024/04/18/index.html#reference",
    "href": "blog/2024/04/18/index.html#reference",
    "title": "Multiplex image-based phenotypic data analysis",
    "section": "Reference",
    "text": "Reference\n\nAnalysis workflow for IMC data\nWorking with CellProfiler data in R"
  },
  {
    "objectID": "blog/2024/04/18/index.html#sessioninfo",
    "href": "blog/2024/04/18/index.html#sessioninfo",
    "title": "Multiplex image-based phenotypic data analysis",
    "section": "Sessioninfo",
    "text": "Sessioninfo\n\nsessionInfo()\n\nR version 4.3.2 (2023-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.4.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Singapore\ntzcode source: internal\n\nattached base packages:\n[1] grid      stats4    stats     graphics  grDevices utils     datasets \n[8] methods   base     \n\nother attached packages:\n [1] gridExtra_2.3               ConsensusClusterPlus_1.66.0\n [3] kohonen_3.0.12              circlize_0.4.16            \n [5] ComplexHeatmap_2.18.0       lisaClust_1.10.1           \n [7] caret_6.0-94                lattice_0.22-6             \n [9] scran_1.30.2                bluster_1.12.0             \n[11] Rphenograph_0.99.1          igraph_2.0.3               \n[13] Seurat_5.0.3                SeuratObject_5.0.1         \n[15] sp_2.1-3                    BiocSingular_1.18.0        \n[17] harmony_1.2.0               Rcpp_1.0.12                \n[19] scater_1.30.1               scuttle_1.12.0             \n[21] batchelor_1.18.1            mclust_6.1                 \n[23] tiff_0.1-12                 BiocParallel_1.36.0        \n[25] pheatmap_1.0.12             CATALYST_1.26.1            \n[27] dittoSeq_1.14.3             cytomapper_1.14.0          \n[29] EBImage_4.44.0              imcRtools_1.8.0            \n[31] SpatialExperiment_1.12.0    SingleCellExperiment_1.24.0\n[33] SummarizedExperiment_1.32.0 Biobase_2.62.0             \n[35] GenomicRanges_1.54.1        GenomeInfoDb_1.38.8        \n[37] IRanges_2.36.0              S4Vectors_0.40.2           \n[39] BiocGenerics_0.48.1         MatrixGenerics_1.14.0      \n[41] matrixStats_1.3.0           viridis_0.6.5              \n[43] viridisLite_0.4.2           RColorBrewer_1.1-3         \n[45] cowplot_1.1.3               patchwork_1.2.0            \n[47] ggridges_0.5.6              ggrepel_0.9.5              \n[49] lubridate_1.9.3             forcats_1.0.0              \n[51] stringr_1.5.1               dplyr_1.1.4                \n[53] purrr_1.0.2                 readr_2.1.5                \n[55] tidyr_1.3.1                 tibble_3.2.1               \n[57] ggplot2_3.5.1               tidyverse_2.0.0            \n[59] qs_0.26.1                   fs_1.6.4                   \n[61] here_1.0.1                 \n\nloaded via a namespace (and not attached):\n  [1] vroom_1.6.5                 nnet_7.3-19                \n  [3] goftest_1.2-3               DT_0.33                    \n  [5] HDF5Array_1.30.1            TH.data_1.1-2              \n  [7] vctrs_0.6.5                 spatstat.random_3.2-3      \n  [9] RApiSerialize_0.1.2         digest_0.6.35              \n [11] png_0.1-8                   shape_1.4.6.1              \n [13] proxy_0.4-27                spicyR_1.14.3              \n [15] deldir_2.0-4                parallelly_1.37.1          \n [17] magick_2.8.3                MASS_7.3-60.0.1            \n [19] reshape2_1.4.4              httpuv_1.6.15              \n [21] foreach_1.5.2               withr_3.0.0                \n [23] xfun_0.43                   ggpubr_0.6.0               \n [25] survival_3.5-8              memoise_2.0.1              \n [27] RTriangle_1.6-0.13          ggbeeswarm_0.7.2           \n [29] RProtoBufLib_2.14.1         drc_3.0-1                  \n [31] systemfonts_1.0.6           zoo_1.8-12                 \n [33] GlobalOptions_0.1.2         gtools_3.9.5               \n [35] pbapply_1.7-2               promises_1.3.0             \n [37] httr_1.4.7                  rstatix_0.7.2              \n [39] globals_0.16.3              fitdistrplus_1.1-11        \n [41] rhdf5filters_1.14.1         stringfish_0.16.0          \n [43] rhdf5_2.46.1                archive_1.1.7              \n [45] units_0.8-5                 miniUI_0.1.1.1             \n [47] generics_0.1.3              concaveman_1.1.0           \n [49] zlibbioc_1.48.2             ScaledMatrix_1.10.0        \n [51] ggraph_2.2.1                randomForest_4.7-1.1       \n [53] polyclip_1.10-6             GenomeInfoDbData_1.2.11    \n [55] SparseArray_1.2.4           fftwtools_0.9-11           \n [57] xtable_1.8-4                doParallel_1.0.17          \n [59] evaluate_0.23               S4Arrays_1.2.1             \n [61] hms_1.1.3                   irlba_2.3.5.1              \n [63] colorspace_2.1-0            ROCR_1.0-11                \n [65] reticulate_1.36.0           spatstat.data_3.0-4        \n [67] magrittr_2.0.3              lmtest_0.9-40              \n [69] later_1.3.2                 spatstat.geom_3.2-9        \n [71] future.apply_1.11.2         scattermore_1.2            \n [73] XML_3.99-0.16.1             RcppAnnoy_0.0.22           \n [75] class_7.3-22                svgPanZoom_0.3.4           \n [77] pillar_1.9.0                nlme_3.1-164               \n [79] iterators_1.0.14            compiler_4.3.2             \n [81] beachmat_2.18.1             RSpectra_0.16-1            \n [83] stringi_1.8.4               gower_1.0.1                \n [85] sf_1.0-16                   minqa_1.2.6                \n [87] ClassifyR_3.6.5             tensor_1.5                 \n [89] plyr_1.8.9                  crayon_1.5.2               \n [91] abind_1.4-5                 locfit_1.5-9.9             \n [93] graphlayouts_1.1.1          bit_4.0.5                  \n [95] terra_1.7-71                sandwich_3.1-0             \n [97] codetools_0.2-20            multcomp_1.4-25            \n [99] recipes_1.0.10              e1071_1.7-14               \n[101] GetoptLong_1.0.5            plotly_4.10.4              \n[103] MultiAssayExperiment_1.28.0 mime_0.12                  \n[105] splines_4.3.2               fastDummies_1.7.3          \n[107] sparseMatrixStats_1.14.0    knitr_1.45                 \n[109] utf8_1.2.4                  clue_0.3-65                \n[111] lme4_1.1-35.3               listenv_0.9.1              \n[113] nnls_1.5                    DelayedMatrixStats_1.24.0  \n[115] ggsignif_0.6.4              scam_1.2-16                \n[117] Matrix_1.6-5                statmod_1.5.0              \n[119] tzdb_0.4.0                  svglite_2.1.3              \n[121] tweenr_2.0.3                pkgconfig_2.0.3            \n[123] tools_4.3.2                 cachem_1.0.8               \n[125] RhpcBLASctl_0.23-42         numDeriv_2016.8-1.1        \n[127] DBI_1.2.2                   fastmap_1.1.1              \n[129] rmarkdown_2.26              scales_1.3.0               \n[131] ica_1.0-3                   shinydashboard_0.7.2       \n[133] broom_1.0.5                 dotCall64_1.1-1            \n[135] carData_3.0-5               rpart_4.1.23               \n[137] RANN_2.6.1                  farver_2.1.1               \n[139] mgcv_1.9-1                  tidygraph_1.3.1            \n[141] yaml_2.3.8                  cli_3.6.2                  \n[143] leiden_0.4.3.1              lifecycle_1.0.4            \n[145] uwot_0.1.16                 mvtnorm_1.2-4              \n[147] lava_1.8.0                  backports_1.4.1            \n[149] cytolib_2.14.1              timechange_0.3.0           \n[151] gtable_0.3.5                rjson_0.2.21               \n[153] progressr_0.14.0            pROC_1.18.5                \n[155] limma_3.58.1                parallel_4.3.2             \n[157] edgeR_4.0.16                jsonlite_1.8.8             \n[159] RcppHNSW_0.6.0              bitops_1.0-7               \n[161] bit64_4.0.5                 Rtsne_0.17                 \n[163] FlowSOM_2.10.0              spatstat.utils_3.0-4       \n[165] BiocNeighbors_1.20.2        RcppParallel_5.1.7         \n[167] flowCore_2.14.2             metapod_1.10.1             \n[169] dqrng_0.3.2                 timeDate_4032.109          \n[171] lazyeval_0.2.2              shiny_1.8.1.1              \n[173] htmltools_0.5.8.1           sctransform_0.4.1          \n[175] distances_0.1.10            glue_1.7.0                 \n[177] spam_2.10-0                 ResidualMatrix_1.12.0      \n[179] XVector_0.42.0              RCurl_1.98-1.14            \n[181] rprojroot_2.0.4             classInt_0.4-10            \n[183] jpeg_0.1-10                 boot_1.3-30                \n[185] R6_2.5.1                    labeling_0.4.3             \n[187] cluster_2.1.6               Rhdf5lib_1.24.2            \n[189] ipred_0.9-14                nloptr_2.0.3               \n[191] DelayedArray_0.28.0         tidyselect_1.2.1           \n[193] vipor_0.4.7                 plotrix_3.8-4              \n[195] ggforce_0.4.2               raster_3.6-26              \n[197] car_3.1-2                   future_1.33.2              \n[199] ModelMetrics_1.2.2.2        rsvd_1.0.5                 \n[201] munsell_0.5.1               KernSmooth_2.23-22         \n[203] data.table_1.15.4           htmlwidgets_1.6.4          \n[205] rlang_1.1.3                 spatstat.sparse_3.0-3      \n[207] spatstat.explore_3.2-7      lmerTest_3.1-3             \n[209] colorRamps_2.3.4            Cairo_1.6-2                \n[211] ggnewscale_0.4.10           fansi_1.0.6                \n[213] hardhat_1.3.1               prodlim_2023.08.28         \n[215] beeswarm_0.4.0"
  },
  {
    "objectID": "blog/2024/03/13/index.html",
    "href": "blog/2024/03/13/index.html",
    "title": "SingleCellExperiment | Practise Single-cell RNA-seq data analysis",
    "section": "",
    "text": "Note\n\n\n\nAll the contents are credited or adapted from Orchestrating Single-Cell Analysis with Bioconductor for leaning purpose."
  },
  {
    "objectID": "blog/2024/03/13/index.html#overall-workflow",
    "href": "blog/2024/03/13/index.html#overall-workflow",
    "title": "SingleCellExperiment | Practise Single-cell RNA-seq data analysis",
    "section": "Overall Workflow",
    "text": "Overall Workflow"
  },
  {
    "objectID": "blog/2024/03/13/index.html#install-and-load-packages",
    "href": "blog/2024/03/13/index.html#install-and-load-packages",
    "title": "SingleCellExperiment | Practise Single-cell RNA-seq data analysis",
    "section": "Install and Load packages",
    "text": "Install and Load packages\n\n# BiocManager::install(\"OSCA.intro\")\n# BiocManager::install(\"SingleCellExperiment\", force = TRUE)\n# BiocManager::install(c(\"scuttle\", \"scran\", \"scater\", \"uwot\", \"rtracklayer\"))\n\nlibrary(scRNAseq)\nlibrary(scuttle)\nlibrary(scater)\nlibrary(robustbase)\nlibrary(org.Mm.eg.db)"
  },
  {
    "objectID": "blog/2024/03/13/index.html#read-counts-into-r",
    "href": "blog/2024/03/13/index.html#read-counts-into-r",
    "title": "SingleCellExperiment | Practise Single-cell RNA-seq data analysis",
    "section": "Read counts into R",
    "text": "Read counts into R\n\nFrom tabular formats\n\n\nFrom Cellranger output\n\n\nFrom HDF5-based formats"
  },
  {
    "objectID": "blog/2024/03/13/index.html#singlecellexperiment-class",
    "href": "blog/2024/03/13/index.html#singlecellexperiment-class",
    "title": "SingleCellExperiment | Practise Single-cell RNA-seq data analysis",
    "section": "SingleCellExperiment class",
    "text": "SingleCellExperiment class"
  },
  {
    "objectID": "blog/2024/03/13/index.html#quality-control",
    "href": "blog/2024/03/13/index.html#quality-control",
    "title": "SingleCellExperiment | Practise Single-cell RNA-seq data analysis",
    "section": "Quality Control",
    "text": "Quality Control\n\nQC metrics\nCommon QC metrics to identify low-quality cells based on their expression profiles.\n\nlibrary size\nnumber of expressed features\n\n\n#--- loading ---#\nsce.416b &lt;- LunSpikeInData(which=\"416b\")\nsce.416b$block &lt;- factor(sce.416b$block)\n\n# 46604 features x  192 cells\nsce.416b\n\n\n# Identifying the mitochondrial transcripts in our SingleCellExperiment.\nlocation &lt;- rowRanges(sce.416b)\nis.mito &lt;- any(seqnames(location) == \"MT\")\n\ndf &lt;- scater::perCellQCMetrics(sce.416b, subsets = list(Mito = is.mito))\n# Total count for each cell\nsummary(df$sum)\n\n# The number of detected genes\nsummary(df$detected)\n\n# The percentage of reads mapped to mitochondrial transcripts\nsummary(df$subsets_Mito_percent)\n\n# The percentage of reads mapped to ERCC transcripts\nsummary(df$altexps_ERCC_percent)\n\n# Computes and appends the per-cell QC statistics to the colData\nsce.416b &lt;- addPerCellQCMetrics(sce.416b, subsets=list(Mito=is.mito))\ncolnames(colData(sce.416b))\n\nA key assumption here is that the QC metrics are independent of the biological state of each cell. Poor values (e.g., low library sizes, high mitochondrial proportions) are presumed to be driven by technical factors rather than biological processes, meaning that the subsequent removal of cells will not misrepresent the biology in downstream analyses.\nMajor violations of this assumption would potentially result in the loss of cell types that have, say, systematically low RNA content or high numbers of mitochondria.\n\n\nIdentifying low-quality cells\n\nWith fixed thresholds\nThe simplest approach to identifying low-quality cells involves applying fixed thresholds to the QC metrics.\nFor example, we might consider cells to be low quality if they:\n\nhave library sizes below 100,000 reads;\nexpress fewer than 5,000 genes;\nhave spike-in proportions above 10%;\nor have mitochondrial proportions above 10%.\n\n\n# With fixed thresholds\nqc.lib &lt;- df$sum &lt; 1e5\nqc.nexprs &lt;- df$detected &lt; 5e3\nqc.spike &lt;- df$altexps_ERCC_percent &gt; 10\nqc.mito &lt;- df$subsets_Mito_percent &gt; 10\ndiscard &lt;- qc.lib | qc.nexprs | qc.spike | qc.mito\n\n# Summarize the number of cells removed for each reason.\nDataFrame(\n    LibSize = sum(qc.lib), NExprs = sum(qc.nexprs),\n    SpikeProp = sum(qc.spike), MitoProp = sum(qc.mito), Total = sum(discard)\n)\n\n\n\n\n\n\n\nNote\n\n\n\nWhile simple, this strategy requires considerable experience to determine appropriate thresholds for each experimental protocol and biological system. - Thresholds for read count-based data are not applicable for UMI-based data, and vice versa. - Differences in mitochondrial activity or total RNA content require constant adjustment of the mitochondrial and spike-in thresholds, respectively, for different biological systems. - Indeed, even with the same protocol and system, the appropriate threshold can vary from run to run due to the vagaries of cDNA capture efficiency and sequencing depth per cell.\n\n\n\n\nWith adaptive thresholds\nWe then identify cells that are outliers for the various QC metrics, based on the median absolute deviation (MAD) from the median value of each metric across all cells.\nBy default, we consider a value to be an outlier if it is more than 3 MADs from the median in the “problematic” direction. This is loosely motivated by the fact that such a filter will retain 99% of non-outlier values that follow a normal distribution.\n\n# Identify cells with log-transformed library sizes that are more than 3 MADs below the median\nreasons &lt;- perCellQCFilters(\n    df,\n    sub.fields = c(\"subsets_Mito_percent\", \"altexps_ERCC_percent\")\n)\ncolSums(as.matrix(reasons))\n\n# A cell that is an outlier for any of these metrics is considered to be of low quality and discarded\nsummary(reasons$discard)\n\n# Exact filter thresholds from the attributes of each of the logical vectors\nattr(reasons$low_lib_size, \"thresholds\")\nattr(reasons$low_n_features, \"thresholds\")\n\n\n\nOther approaches\n\nstats &lt;- cbind(\n    log10(df$sum), log10(df$detected),\n    df$subsets_Mito_percent, df$altexps_ERCC_percent\n)\n\noutlying &lt;- adjOutlyingness(stats, only.outlyingness = TRUE)\nmulti.outlier &lt;- isOutlier(outlying, type = \"higher\")\nsummary(multi.outlier)\n\nOutliers can also be identified from the gene expression profiles, rather than QC metrics.\nWe consider this to be a risky strategy as it can remove high-quality cells in rare populations.\n\n\nDiagnostic plots\n\ncolData(sce.416b) &lt;- cbind(colData(sce.416b), df)\nsce.416b$block &lt;- factor(sce.416b$block)\nsce.416b$phenotype &lt;- ifelse(\n    grepl(\"induced\", sce.416b$phenotype),\n    \"induced\", \"wild type\"\n)\nsce.416b$discard &lt;- reasons$discard\n\ngridExtra::grid.arrange(\n    plotColData(\n        sce.416b, x = \"block\", y = \"sum\", colour_by = \"discard\",\n        other_fields = \"phenotype\"\n    ) +\n        facet_wrap(~phenotype) +\n        scale_y_log10() + ggtitle(\"Total count\"),\n\n    plotColData(\n        sce.416b, x = \"block\", y = \"detected\", colour_by = \"discard\",\n        other_fields = \"phenotype\"\n    ) +\n        facet_wrap(~phenotype) +\n        scale_y_log10() + ggtitle(\"Detected features\"),\n\n    plotColData(\n        sce.416b, x = \"block\", y = \"subsets_Mito_percent\",\n        colour_by = \"discard\", other_fields = \"phenotype\"\n    ) +\n        facet_wrap(~phenotype) +\n        ggtitle(\"Mito percent\"),\n\n    plotColData(\n        sce.416b, x = \"block\", y = \"altexps_ERCC_percent\",\n        colour_by = \"discard\", other_fields = \"phenotype\"\n    ) +\n        facet_wrap(~phenotype) +\n        ggtitle(\"ERCC percent\"),\n    ncol = 1\n)\n\nAnother useful diagnostic involves plotting the proportion of mitochondrial counts against some of the other QC metrics.\nThe aim is to confirm that there are no cells with both large total counts and large mitochondrial counts, to ensure that we are not inadvertently removing high-quality cells that happen to be highly metabolically active (e.g., hepatocytes).\n\n#--- loading ---#\nsce.zeisel &lt;- ZeiselBrainData()\nsce.zeisel\n\nsce.zeisel &lt;- aggregateAcrossFeatures(\n    sce.zeisel,\n    id = sub(\"_loc[0-9]+$\", \"\", rownames(sce.zeisel))\n)\n\n#--- gene-annotation ---#\nrowData(sce.zeisel)$Ensembl &lt;- mapIds(\n    org.Mm.eg.db,\n    keys = rownames(sce.zeisel),\n    keytype = \"SYMBOL\",\n    column = \"ENSEMBL\"\n)\n\nsce.zeisel &lt;- addPerCellQC(\n    sce.zeisel,\n    subsets = list(Mt = rowData(sce.zeisel)$featureType == \"mito\")\n)\n\nqc &lt;- quickPerCellQC(\n    colData(sce.zeisel),\n    sub.fields = c(\"altexps_ERCC_percent\", \"subsets_Mt_percent\")\n)\n\nsce.zeisel$discard &lt;- qc$discard\n\nplotColData(\n    sce.zeisel, x = \"sum\", y = \"subsets_Mt_percent\", colour_by = \"discard\"\n)\n\nLow-quality cells with small mitochondrial percentages, large spike-in percentages and small library sizes are likely to be stripped nuclei, i.e., they have been so extensively damaged that they have lost all cytoplasmic content.\nOn the other hand, cells with high mitochondrial percentages and low ERCC percentages may represent undamaged cells that are metabolically active.\nThis interpretation also applies for single-nuclei studies but with a switch of focus: the stripped nuclei become the libraries of interest while the undamaged cells are considered to be low quality.\n\nplotColData(\n    sce.zeisel, x=\"altexps_ERCC_percent\", y=\"subsets_Mt_percent\",\n    colour_by=\"discard\"\n)\n\nThese metrics exhibit weak correlations to each other, presumably a manifestation of a common underlying effect of cell damage.\nThe weakness of the correlations motivates the use of several metrics to capture different aspects of technical quality.\nOf course, the flipside is that these metrics may also represent different aspects of biology, increasing the risk of inadvertently discarding entire cell types.\n\n\n\nRemove low quality cells\n\n# Keeping the columns we DON'T want to discard.\nfiltered &lt;- sce.416b[, !reasons$discard]\n\n# Mark the low-quality cells as such and retain them in the downstream analysis\nmarked &lt;- sce.416b\nmarked$discard &lt;- reasons$discard"
  },
  {
    "objectID": "blog/2024/03/13/index.html#normalization",
    "href": "blog/2024/03/13/index.html#normalization",
    "title": "SingleCellExperiment | Practise Single-cell RNA-seq data analysis",
    "section": "Normalization",
    "text": "Normalization\n\nLibrary size normalization\n\nlib.sf.zeisel &lt;- scater::librarySizeFactors(sce.zeisel)\nsummary(lib.sf.zeisel)\nhist(log10(lib.sf.zeisel), xlab = \"Log10[Size factor]\", col = \"grey80\")"
  },
  {
    "objectID": "blog/2024/03/13/index.html#session-info",
    "href": "blog/2024/03/13/index.html#session-info",
    "title": "SingleCellExperiment | Practise Single-cell RNA-seq data analysis",
    "section": "Session Info",
    "text": "Session Info\n\n\nCode\nsessionInfo()"
  },
  {
    "objectID": "blog/2023/12/08/index.html",
    "href": "blog/2023/12/08/index.html",
    "title": "Pseudobulk differential expression analysis",
    "section": "",
    "text": "## Load packages\nlibrary(ExperimentHub)\nlibrary(Seurat)\nlibrary(DESeq2)\nlibrary(data.table)\nlibrary(tidyverse)\nlibrary(RColorBrewer)\n\n## retrieve data\neh &lt;- ExperimentHub()\nquery(eh, \"Kang\")\n\nsce_obj &lt;- eh[[\"EH2259\"]]\nseu_obj &lt;- as.Seurat(sce_obj, data = NULL)\nas_tibble(seu_obj@meta.data)\n\n## add mito percent\nseu_obj$mitoPercent &lt;- PercentageFeatureSet(seu_obj, pattern = '^MT-')\nas_tibble(seu_obj@meta.data)\n\n## general qc and filter\nseu_obj &lt;- subset(\n    seu_obj,\n    subset = nFeature_originalexp &gt; 200 & nFeature_originalexp &lt; 2500 &\n        nCount_originalexp &gt; 800 &\n        mitoPercent &lt; 5 &\n        multiplets == 'singlet'\n)\nmessage(ncol(sce_obj) - ncol(seu_obj), \" cells are removed ...\")\n\n## run Seurat's standard workflow steps\nseu_obj &lt;- NormalizeData(seu_obj)\nseu_obj &lt;- FindVariableFeatures(seu_obj)\nseu_obj &lt;- ScaleData(seu_obj)\nseu_obj &lt;- RunPCA(seu_obj)\nElbowPlot(seu_obj)\nseu_obj &lt;- RunUMAP(seu_obj, dims = 1:20)\n\n## visualize\ncell_plot &lt;- DimPlot(\n    seu_obj, reduction = \"umap\", group.by = \"cell\", label = TRUE\n)\ncond_plot &lt;- DimPlot(seu_obj, reduction = \"umap\", group.by = \"stim\")\n\ncell_plot | cond_plot\n\n## aggregate counts to sample level with condition"
  },
  {
    "objectID": "blog/2023/12/08/index.html#prepare-single-cell-rna-seq-data",
    "href": "blog/2023/12/08/index.html#prepare-single-cell-rna-seq-data",
    "title": "Pseudobulk differential expression analysis",
    "section": "",
    "text": "## Load packages\nlibrary(ExperimentHub)\nlibrary(Seurat)\nlibrary(DESeq2)\nlibrary(data.table)\nlibrary(tidyverse)\nlibrary(RColorBrewer)\n\n## retrieve data\neh &lt;- ExperimentHub()\nquery(eh, \"Kang\")\n\nsce_obj &lt;- eh[[\"EH2259\"]]\nseu_obj &lt;- as.Seurat(sce_obj, data = NULL)\nas_tibble(seu_obj@meta.data)\n\n## add mito percent\nseu_obj$mitoPercent &lt;- PercentageFeatureSet(seu_obj, pattern = '^MT-')\nas_tibble(seu_obj@meta.data)\n\n## general qc and filter\nseu_obj &lt;- subset(\n    seu_obj,\n    subset = nFeature_originalexp &gt; 200 & nFeature_originalexp &lt; 2500 &\n        nCount_originalexp &gt; 800 &\n        mitoPercent &lt; 5 &\n        multiplets == 'singlet'\n)\nmessage(ncol(sce_obj) - ncol(seu_obj), \" cells are removed ...\")\n\n## run Seurat's standard workflow steps\nseu_obj &lt;- NormalizeData(seu_obj)\nseu_obj &lt;- FindVariableFeatures(seu_obj)\nseu_obj &lt;- ScaleData(seu_obj)\nseu_obj &lt;- RunPCA(seu_obj)\nElbowPlot(seu_obj)\nseu_obj &lt;- RunUMAP(seu_obj, dims = 1:20)\n\n## visualize\ncell_plot &lt;- DimPlot(\n    seu_obj, reduction = \"umap\", group.by = \"cell\", label = TRUE\n)\ncond_plot &lt;- DimPlot(seu_obj, reduction = \"umap\", group.by = \"stim\")\n\ncell_plot | cond_plot\n\n## aggregate counts to sample level with condition"
  },
  {
    "objectID": "blog/2023/12/08/index.html#pseudobulk-workflow",
    "href": "blog/2023/12/08/index.html#pseudobulk-workflow",
    "title": "Pseudobulk differential expression analysis",
    "section": "Pseudobulk workflow",
    "text": "Pseudobulk workflow\n\n## counts aggregate to sample level\nas_tibble(seu_obj@meta.data)\nseu_obj$samples &lt;- paste0(seu_obj$stim, seu_obj$ind)\nDefaultAssay(seu_obj)\n\ncounts &lt;- AggregateExpression(\n    seu_obj,\n    group.by = c(\"cell\", \"samples\"),\n    assays = \"originalexp\",\n    # slot = \"counts\",\n    return.seurat = FALSE\n)\n\ncounts &lt;- t(counts$originalexp) |&gt; as.data.frame()\ncounts[1:5, 1:5]\n\n## get values where to split\nsplit_rows &lt;- gsub('_.*', '', rownames(counts))\n\n## split data.frame\ncounts_list &lt;- split.data.frame(counts, f = factor(split_rows))\ncounts_list$`B cells`[1:5, 1:5]\n\n## fix colnames and transpose\ncounts_list &lt;- lapply(\n    counts_list, function(x) {\n        rownames(x) &lt;- gsub('.*_(.*)', '\\\\1', rownames(x))\n        t(x)\n    }\n)"
  },
  {
    "objectID": "blog/2023/12/08/index.html#de-testing-with-deseq2",
    "href": "blog/2023/12/08/index.html#de-testing-with-deseq2",
    "title": "Pseudobulk differential expression analysis",
    "section": "DE testing with DESeq2",
    "text": "DE testing with DESeq2\n\n## get counts matrix\ncounts_bcell &lt;- counts_list[[\"B cells\"]]\n\n## generate sample level metadata\ncol_data &lt;- data.frame(samples = colnames(counts_bcell)) |&gt;\n    mutate(condition = if_else(\n        grepl(\"stim\", samples), \"Stimulated\", \"Control\")\n    ) |&gt;\n    column_to_rownames(var = \"samples\")\n\n## create DESeq2 object\ndds &lt;- DESeqDataSetFromMatrix(\n    countData = counts_bcell,\n    colData = col_data,\n    design = ~condition\n)\n\n## filter\nkeep &lt;- rowSums(counts(dds)) &gt;= 10\ndds &lt;- dds[keep, ]\n\n## plot PCA\nDESeq2::plotPCA(rld, ntop = 500, intgroup = \"condition\")\nrld &lt;- rlog(dds, blind = TRUE) ## transform counts for data visualization\n\n## hierarchical clustering\nrld_mat &lt;- assay(rld)\nrld_cor &lt;- cor(rld_mat)\npheatmap::pheatmap(\n    rld_cor, annotation = col_data[, c(\"condition\"), drop = FALSE]\n)\n\n## run DESeq2\ndds &lt;- DESeq(dds)\nplotDispEsts(dds) # Plot dispersion estimates\nresultsNames(dds) # Check the coefficients for the comparison\n\n## Generate results object\nres &lt;- results(dds, name = \"condition_Stimulated_vs_Control\", alpha = 0.05)\nres\n\n## Shrink the log2 fold changes to be more appropriate using the apeglm method\nres &lt;- lfcShrink(\n    dds,\n    coef = \"group_id_stim_vs_ctrl\",\n    res = res,\n    type = \"apeglm\"\n)\n\n## results tibble\nres_tbl &lt;- res |&gt;\n    data.frame() |&gt;\n    rownames_to_column(var = \"gene\") |&gt;\n    as_tibble() |&gt;\n    arrange(padj)\n\npadj_cutoff &lt;- 0.05\nlog2fc_cutoff &lt;- 0.58\n\n### significant genes\nsig_res &lt;- res_tbl |&gt;\n    dplyr::filter(padj &lt; padj_cutoff) %&gt;%\n    dplyr::arrange(padj)\n\nn_sig_up &lt;- sig_res |&gt;\n    dplyr::filter(log2FoldChange &gt;= log2fc_cutoff) %&gt;%\n    nrow()\nn_sig_dn &lt;- sig_res |&gt;\n    dplyr::filter(log2FoldChange &lt;= -log2fc_cutoff) %&gt;%\n    nrow()"
  },
  {
    "objectID": "blog/2023/12/08/index.html#de-testing-with-seurat",
    "href": "blog/2023/12/08/index.html#de-testing-with-seurat",
    "title": "Pseudobulk differential expression analysis",
    "section": "DE testing with Seurat",
    "text": "DE testing with Seurat"
  },
  {
    "objectID": "blog/2023/12/08/index.html#visualize-the-signifcant-genes",
    "href": "blog/2023/12/08/index.html#visualize-the-signifcant-genes",
    "title": "Pseudobulk differential expression analysis",
    "section": "Visualize the signifcant genes",
    "text": "Visualize the signifcant genes\n\n## Extract normalized counts from dds object\nnormalized_counts &lt;- counts(dds, normalized = TRUE)\n\n## Extract top 20 DEG from resLFC (make sure to order by padj)\ntop20_sig_genes &lt;- sig_res %&gt;%\n    dplyr::arrange(padj) %&gt;%\n    dplyr::pull(gene) %&gt;%\n    head(n = 20)\n\n## Extract matching normalized count values from matrix\ntop_sig_counts &lt;- normalized_counts[\n    rownames(normalized_counts) %in% top20_sig_genes, ]\n\n## Convert wide matrix to long data frame for ggplot2\ntop_sig_tbl &lt;- top_sig_counts |&gt;\n    as_tibble(rownames = \"gene\") |&gt;\n    pivot_longer(-gene, names_to = \"samples\") |&gt;\n    left_join(as_tibble(colData(dds), rownames = \"samples\"))\n\n## Generate scatter plot\nggplot(top_sig_tbl, aes(y = value, x = condition, color = condition)) +\n    geom_jitter(height = 0, width = 0.15) +\n    scale_y_continuous(trans = \"log10\") +\n    ylab(\"log10 of normalized expression level\") +\n    xlab(\"condition\") +\n    ggtitle(\"Top 20 Significant DE Genes\") +\n    theme(plot.title = element_text(hjust = 0.5)) +\n    facet_wrap(~gene)\n\n## Extract normalized counts for significant genes only\nsig_counts &lt;- normalized_counts[rownames(normalized_counts) %in% sig_res$gene, ]\ndim(sig_counts)\n## Set a color-blind friendly palette\nheat_colors &lt;- rev(brewer.pal(11, \"PuOr\"))\ncol_data$condition\nrownames(col_data)\ncolnames(sig_counts)\n## Run pheatmap using the metadata data frame for the annotation\npheatmap::pheatmap(\n    sig_counts,\n    color = heat_colors,\n    cluster_rows = TRUE,\n    show_rownames = FALSE,\n    annotation = col_data[, c(\"condition\"), drop = FALSE],\n    border_color = NA,\n    fontsize = 10,\n    scale = \"row\",\n    fontsize_row = 10,\n    height = 20\n)"
  },
  {
    "objectID": "blog/2023/12/08/index.html#reference",
    "href": "blog/2023/12/08/index.html#reference",
    "title": "Pseudobulk differential expression analysis",
    "section": "Reference",
    "text": "Reference\n\nhttps://rpubs.com/Sri_Upasna/1066070\nhttps://hbctraining.github.io/scRNA-seq_online/lessons/pseudobulk_DESeq2_scrnaseq.html"
  },
  {
    "objectID": "blog/2023/12/02/index.html",
    "href": "blog/2023/12/02/index.html",
    "title": "Customization of Seurat plots using ggplot2",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\nlibrary(Seurat)\nlibrary(SingleR)\nlibrary(ggrepel)\nlibrary(ggthemes)\nlibrary(ggnewscale)\nlibrary(tidyverse)\nlibrary(scCustomize)\nlibrary(viridis)\nlibrary(RColorBrewer)\nlibrary(gridExtra)\nlibrary(ComplexHeatmap)\nlibrary(dittoSeq)\nlibrary(Scillus)"
  },
  {
    "objectID": "blog/2023/12/02/index.html#packages",
    "href": "blog/2023/12/02/index.html#packages",
    "title": "Customization of Seurat plots using ggplot2",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\nlibrary(Seurat)\nlibrary(SingleR)\nlibrary(ggrepel)\nlibrary(ggthemes)\nlibrary(ggnewscale)\nlibrary(tidyverse)\nlibrary(scCustomize)\nlibrary(viridis)\nlibrary(RColorBrewer)\nlibrary(gridExtra)\nlibrary(ComplexHeatmap)\nlibrary(dittoSeq)\nlibrary(Scillus)"
  },
  {
    "objectID": "blog/2023/12/02/index.html#umap",
    "href": "blog/2023/12/02/index.html#umap",
    "title": "Customization of Seurat plots using ggplot2",
    "section": "UMAP",
    "text": "UMAP\nLoad Seurat object\n\n### Load data\nload(here(\"learn\", \"2023_scRNA_Seurat\", \"pbmc_tutorial_singleR.RData\"))\nload(here(\"learn\", \"2023_scRNA_Seurat\", \"sce.anno.RData\"))\nload(here(\"learn\", \"2023_scRNA_Seurat\", \"all_markers.RData\"))\ntop5 &lt;- all_markers |&gt; group_by(cluster) |&gt; top_n(5, avg_log2FC)\n\n### Check data\nhead(pbmc, 2)\n##                  orig.ident nCount_RNA nFeature_RNA percent.mt percent.HB\n## AAACATACAACCAC-1     pbmc3k       2419          779   3.017776          0\n## AAACATTGAGCTAC-1     pbmc3k       4903         1352   3.793596          0\n##                  RNA_snn_res.0.5 seurat_clusters  labels\n## AAACATACAACCAC-1               0               0 T_cells\n## AAACATTGAGCTAC-1               3               3  B_cell\nhead(sce2, 2)\n##                         orig.ident nCount_RNA nFeature_RNA percent.mt\n## K16733_AAACATACTCGTTT-1     K16733       2464          965  12.662338\n## K16733_AAAGCAGAACGTTG-1     K16733       7145         1919   2.449265\n##                         percent.rp percent.HB RNA_snn_res.0.5 seurat_clusters\n## K16733_AAACATACTCGTTT-1   13.35227          0              11              11\n## K16733_AAAGCAGAACGTTG-1   36.72498          0               3               3\n##                         sampel sample group    globalC       anno\n## K16733_AAACATACTCGTTT-1    P01    P01    PT        Epi        Epi\n## K16733_AAAGCAGAACGTTG-1    P01    P01    PT Fibroblast Fibroblast\nhead(top5)\n## # A tibble: 6 × 7\n## # Groups:   cluster [2]\n##       p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene      \n##       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;chr&gt;     \n## 1 2.43e- 67       3.05 0.172 0.079 1.26e- 62 0       REG4      \n## 2 3.38e- 51       3.19 0.069 0.019 1.76e- 46 0       BPIFB1    \n## 3 5.32e- 30       3.71 0.031 0.007 2.76e- 25 0       FABP1     \n## 4 6.37e- 21       2.79 0.018 0.003 3.31e- 16 0       SLC9A4    \n## 5 1.65e- 20       2.70 0.017 0.003 8.56e- 16 0       AC073218.2\n## 6 2.51e-112       3.57 0.132 0.023 1.30e-107 1       SPRR1A\n\nDefault seurat UMAP\n\n# View the UMAP\nDimPlot(pbmc, group.by = c(\"seurat_clusters\", \"labels\"), reduction = \"umap\")\n\n\n\n\n\n\n\nUMAP with ggplot2\n\n# Find the UMAP data\nstr(pbmc)\n## Formal class 'Seurat' [package \"SeuratObject\"] with 13 slots\n##   ..@ assays      :List of 1\n##   .. ..$ RNA:Formal class 'Assay' [package \"SeuratObject\"] with 8 slots\n##   .. .. .. ..@ counts       :Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n##   .. .. .. .. .. ..@ i       : int [1:2238732] 29 73 80 148 163 184 186 227 229 230 ...\n##   .. .. .. .. .. ..@ p       : int [1:2639] 0 779 2131 3260 4220 4741 5522 6304 7094 7626 ...\n##   .. .. .. .. .. ..@ Dim     : int [1:2] 13714 2638\n##   .. .. .. .. .. ..@ Dimnames:List of 2\n##   .. .. .. .. .. .. ..$ : chr [1:13714] \"AL627309.1\" \"AP006222.2\" \"RP11-206L10.2\" \"RP11-206L10.9\" ...\n##   .. .. .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. .. ..@ x       : num [1:2238732] 1 1 2 1 1 1 1 41 1 1 ...\n##   .. .. .. .. .. ..@ factors : list()\n##   .. .. .. ..@ data         :Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n##   .. .. .. .. .. ..@ i       : int [1:2238732] 29 73 80 148 163 184 186 227 229 230 ...\n##   .. .. .. .. .. ..@ p       : int [1:2639] 0 779 2131 3260 4220 4741 5522 6304 7094 7626 ...\n##   .. .. .. .. .. ..@ Dim     : int [1:2] 13714 2638\n##   .. .. .. .. .. ..@ Dimnames:List of 2\n##   .. .. .. .. .. .. ..$ : chr [1:13714] \"AL627309.1\" \"AP006222.2\" \"RP11-206L10.2\" \"RP11-206L10.9\" ...\n##   .. .. .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. .. ..@ x       : num [1:2238732] 1.64 1.64 2.23 1.64 1.64 ...\n##   .. .. .. .. .. ..@ factors : list()\n##   .. .. .. ..@ scale.data   : num [1:2000, 1:2638] -0.8556 -0.2773 1.4947 -0.0463 -0.4658 ...\n##   .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. ..$ : chr [1:2000] \"ISG15\" \"CPSF3L\" \"MRPL20\" \"ATAD3C\" ...\n##   .. .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. ..@ assay.orig   : NULL\n##   .. .. .. ..@ var.features : chr [1:2000] \"PPBP\" \"LYZ\" \"S100A9\" \"IGLL5\" ...\n##   .. .. .. ..@ meta.features:'data.frame':   13714 obs. of  5 variables:\n##   .. .. .. .. ..$ vst.mean                 : num [1:13714] 0.00341 0.00114 0.0019 0.00114 0.00682 ...\n##   .. .. .. .. ..$ vst.variance             : num [1:13714] 0.0034 0.00114 0.00189 0.00114 0.00678 ...\n##   .. .. .. .. ..$ vst.variance.expected    : num [1:13714] 0.00365 0.00114 0.00197 0.00114 0.00748 ...\n##   .. .. .. .. ..$ vst.variance.standardized: num [1:13714] 0.933 0.992 0.963 0.992 0.906 ...\n##   .. .. .. .. ..$ vst.variable             : logi [1:13714] FALSE FALSE FALSE FALSE FALSE FALSE ...\n##   .. .. .. ..@ misc         : list()\n##   .. .. .. ..@ key          : chr \"rna_\"\n##   ..@ meta.data   :'data.frame': 2638 obs. of  8 variables:\n##   .. ..$ orig.ident     : Factor w/ 1 level \"pbmc3k\": 1 1 1 1 1 1 1 1 1 1 ...\n##   .. ..$ nCount_RNA     : num [1:2638] 2419 4903 3147 2639 980 ...\n##   .. ..$ nFeature_RNA   : int [1:2638] 779 1352 1129 960 521 781 782 790 532 550 ...\n##   .. ..$ percent.mt     : num [1:2638] 3.02 3.79 0.89 1.74 1.22 ...\n##   .. ..$ percent.HB     : num [1:2638] 0 0 0 0 0 0 0 0 0 0 ...\n##   .. ..$ RNA_snn_res.0.5: Factor w/ 9 levels \"0\",\"1\",\"2\",\"3\",..: 1 4 3 2 7 3 5 5 5 6 ...\n##   .. ..$ seurat_clusters: Factor w/ 9 levels \"0\",\"1\",\"2\",\"3\",..: 1 4 3 2 7 3 5 5 5 6 ...\n##   .. ..$ labels         : chr [1:2638] \"T_cells\" \"B_cell\" \"T_cells\" \"Monocyte\" ...\n##   ..@ active.assay: chr \"RNA\"\n##   ..@ active.ident: Factor w/ 9 levels \"0\",\"1\",\"2\",\"3\",..: 1 4 3 2 7 3 5 5 5 6 ...\n##   .. ..- attr(*, \"names\")= chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   ..@ graphs      :List of 2\n##   .. ..$ RNA_nn :Formal class 'Graph' [package \"SeuratObject\"] with 7 slots\n##   .. .. .. ..@ assay.used: chr \"RNA\"\n##   .. .. .. ..@ i         : int [1:52760] 0 6 102 203 213 229 292 451 547 618 ...\n##   .. .. .. ..@ p         : int [1:2639] 0 33 50 64 80 87 103 139 155 162 ...\n##   .. .. .. ..@ Dim       : int [1:2] 2638 2638\n##   .. .. .. ..@ Dimnames  :List of 2\n##   .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. ..@ x         : num [1:52760] 1 1 1 1 1 1 1 1 1 1 ...\n##   .. .. .. ..@ factors   : list()\n##   .. ..$ RNA_snn:Formal class 'Graph' [package \"SeuratObject\"] with 7 slots\n##   .. .. .. ..@ assay.used: chr \"RNA\"\n##   .. .. .. ..@ i         : int [1:194424] 0 6 102 136 187 203 229 292 421 446 ...\n##   .. .. .. ..@ p         : int [1:2639] 0 62 120 170 240 287 379 453 533 573 ...\n##   .. .. .. ..@ Dim       : int [1:2] 2638 2638\n##   .. .. .. ..@ Dimnames  :List of 2\n##   .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. ..@ x         : num [1:194424] 1 0.1111 0.1765 0.0811 0.0811 ...\n##   .. .. .. ..@ factors   : list()\n##   ..@ neighbors   : list()\n##   ..@ reductions  :List of 3\n##   .. ..$ pca :Formal class 'DimReduc' [package \"SeuratObject\"] with 9 slots\n##   .. .. .. ..@ cell.embeddings           : num [1:2638, 1:50] -5.84 -2.56 -1.64 13.29 -2.15 ...\n##   .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. .. ..$ : chr [1:50] \"PC_1\" \"PC_2\" \"PC_3\" \"PC_4\" ...\n##   .. .. .. ..@ feature.loadings          : num [1:2000, 1:50] 0.01091 0.11663 0.11569 -0.00853 -0.01632 ...\n##   .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. ..$ : chr [1:2000] \"PPBP\" \"LYZ\" \"S100A9\" \"IGLL5\" ...\n##   .. .. .. .. .. ..$ : chr [1:50] \"PC_1\" \"PC_2\" \"PC_3\" \"PC_4\" ...\n##   .. .. .. ..@ feature.loadings.projected: num[0 , 0 ] \n##   .. .. .. ..@ assay.used                : chr \"RNA\"\n##   .. .. .. ..@ global                    : logi FALSE\n##   .. .. .. ..@ stdev                     : num [1:50] 7.05 4.5 3.87 3.75 3.15 ...\n##   .. .. .. ..@ jackstraw                 :Formal class 'JackStrawData' [package \"SeuratObject\"] with 4 slots\n##   .. .. .. .. .. ..@ empirical.p.values     : num [1:2000, 1:20] 0.0005 0 0 0.0035 0 0 0.01 0 0.0135 0 ...\n##   .. .. .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. .. .. ..$ : chr [1:2000] \"PPBP\" \"LYZ\" \"S100A9\" \"IGLL5\" ...\n##   .. .. .. .. .. .. .. ..$ : chr [1:20] \"PC1\" \"PC2\" \"PC3\" \"PC4\" ...\n##   .. .. .. .. .. ..@ fake.reduction.scores  : num [1:2000, 1:20] -0.003524 0.000285 -0.000627 0.002054 0.000959 ...\n##   .. .. .. .. .. ..@ empirical.p.values.full: logi [1, 1] NA\n##   .. .. .. .. .. ..@ overall.p.values       : num [1:20, 1:2] 1 2 3 4 5 6 7 8 9 10 ...\n##   .. .. .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. .. .. ..$ : NULL\n##   .. .. .. .. .. .. .. ..$ : chr [1:2] \"PC\" \"Score\"\n##   .. .. .. ..@ misc                      :List of 1\n##   .. .. .. .. ..$ total.variance: num 1734\n##   .. .. .. ..@ key                       : chr \"PC_\"\n##   .. ..$ umap:Formal class 'DimReduc' [package \"SeuratObject\"] with 9 slots\n##   .. .. .. ..@ cell.embeddings           : num [1:2638, 1:2] -4.58 -2.81 -1.68 12.69 -9.83 ...\n##   .. .. .. .. ..- attr(*, \"scaled:center\")= num [1:2] -0.0395 -1.1523\n##   .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. .. ..$ : chr [1:2] \"UMAP_1\" \"UMAP_2\"\n##   .. .. .. ..@ feature.loadings          : num[0 , 0 ] \n##   .. .. .. ..@ feature.loadings.projected: num[0 , 0 ] \n##   .. .. .. ..@ assay.used                : chr \"RNA\"\n##   .. .. .. ..@ global                    : logi TRUE\n##   .. .. .. ..@ stdev                     : num(0) \n##   .. .. .. ..@ jackstraw                 :Formal class 'JackStrawData' [package \"SeuratObject\"] with 4 slots\n##   .. .. .. .. .. ..@ empirical.p.values     : num[0 , 0 ] \n##   .. .. .. .. .. ..@ fake.reduction.scores  : num[0 , 0 ] \n##   .. .. .. .. .. ..@ empirical.p.values.full: num[0 , 0 ] \n##   .. .. .. .. .. ..@ overall.p.values       : num[0 , 0 ] \n##   .. .. .. ..@ misc                      : list()\n##   .. .. .. ..@ key                       : chr \"UMAP_\"\n##   .. ..$ tsne:Formal class 'DimReduc' [package \"SeuratObject\"] with 9 slots\n##   .. .. .. ..@ cell.embeddings           : num [1:2638, 1:2] -11.1 -36.27 1.96 37.46 -20.88 ...\n##   .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. .. ..$ : chr [1:2] \"tSNE_1\" \"tSNE_2\"\n##   .. .. .. ..@ feature.loadings          : num[0 , 0 ] \n##   .. .. .. ..@ feature.loadings.projected: num[0 , 0 ] \n##   .. .. .. ..@ assay.used                : chr \"RNA\"\n##   .. .. .. ..@ global                    : logi TRUE\n##   .. .. .. ..@ stdev                     : num(0) \n##   .. .. .. ..@ jackstraw                 :Formal class 'JackStrawData' [package \"SeuratObject\"] with 4 slots\n##   .. .. .. .. .. ..@ empirical.p.values     : num[0 , 0 ] \n##   .. .. .. .. .. ..@ fake.reduction.scores  : num[0 , 0 ] \n##   .. .. .. .. .. ..@ empirical.p.values.full: num[0 , 0 ] \n##   .. .. .. .. .. ..@ overall.p.values       : num[0 , 0 ] \n##   .. .. .. ..@ misc                      : list()\n##   .. .. .. ..@ key                       : chr \"tSNE_\"\n##   ..@ images      : list()\n##   ..@ project.name: chr \"pbmc3k\"\n##   ..@ misc        : list()\n##   ..@ version     :Classes 'package_version', 'numeric_version'  hidden list of 1\n##   .. ..$ : int [1:3] 4 0 0\n##   ..@ commands    :List of 10\n##   .. ..$ NormalizeData.RNA       :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"NormalizeData.RNA\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:49:17\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr [1:2] \"NormalizeData(pbmc, normalization.method = \\\"LogNormalize\\\", \" \"    scale.factor = 10000)\"\n##   .. .. .. ..@ params     :List of 5\n##   .. .. .. .. ..$ assay               : chr \"RNA\"\n##   .. .. .. .. ..$ normalization.method: chr \"LogNormalize\"\n##   .. .. .. .. ..$ scale.factor        : num 10000\n##   .. .. .. .. ..$ margin              : num 1\n##   .. .. .. .. ..$ verbose             : logi TRUE\n##   .. ..$ FindVariableFeatures.RNA:Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"FindVariableFeatures.RNA\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:49:18\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"FindVariableFeatures(pbmc, selection.method = \\\"vst\\\", nfeatures = 2000)\"\n##   .. .. .. ..@ params     :List of 12\n##   .. .. .. .. ..$ assay              : chr \"RNA\"\n##   .. .. .. .. ..$ selection.method   : chr \"vst\"\n##   .. .. .. .. ..$ loess.span         : num 0.3\n##   .. .. .. .. ..$ clip.max           : chr \"auto\"\n##   .. .. .. .. ..$ mean.function      :function (mat, display_progress)  \n##   .. .. .. .. ..$ dispersion.function:function (mat, display_progress)  \n##   .. .. .. .. ..$ num.bin            : num 20\n##   .. .. .. .. ..$ binning.method     : chr \"equal_width\"\n##   .. .. .. .. ..$ nfeatures          : num 2000\n##   .. .. .. .. ..$ mean.cutoff        : num [1:2] 0.1 8\n##   .. .. .. .. ..$ dispersion.cutoff  : num [1:2] 1 Inf\n##   .. .. .. .. ..$ verbose            : logi TRUE\n##   .. ..$ ScaleData.RNA           :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"ScaleData.RNA\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:49:47\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"ScaleData(pbmc, vars.to.regress = \\\"percent.mt\\\")\"\n##   .. .. .. ..@ params     :List of 11\n##   .. .. .. .. ..$ features          : chr [1:2000] \"PPBP\" \"LYZ\" \"S100A9\" \"IGLL5\" ...\n##   .. .. .. .. ..$ assay             : chr \"RNA\"\n##   .. .. .. .. ..$ vars.to.regress   : chr \"percent.mt\"\n##   .. .. .. .. ..$ model.use         : chr \"linear\"\n##   .. .. .. .. ..$ use.umi           : logi FALSE\n##   .. .. .. .. ..$ do.scale          : logi TRUE\n##   .. .. .. .. ..$ do.center         : logi TRUE\n##   .. .. .. .. ..$ scale.max         : num 10\n##   .. .. .. .. ..$ block.size        : num 1000\n##   .. .. .. .. ..$ min.cells.to.block: num 2638\n##   .. .. .. .. ..$ verbose           : logi TRUE\n##   .. ..$ RunPCA.RNA              :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"RunPCA.RNA\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:49:54\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"RunPCA(pbmc, features = VariableFeatures(object = pbmc))\"\n##   .. .. .. ..@ params     :List of 11\n##   .. .. .. .. ..$ assay          : chr \"RNA\"\n##   .. .. .. .. ..$ features       : chr [1:2000] \"PPBP\" \"LYZ\" \"S100A9\" \"IGLL5\" ...\n##   .. .. .. .. ..$ npcs           : num 50\n##   .. .. .. .. ..$ rev.pca        : logi FALSE\n##   .. .. .. .. ..$ weight.by.var  : logi TRUE\n##   .. .. .. .. ..$ verbose        : logi TRUE\n##   .. .. .. .. ..$ ndims.print    : int [1:5] 1 2 3 4 5\n##   .. .. .. .. ..$ nfeatures.print: num 30\n##   .. .. .. .. ..$ reduction.name : chr \"pca\"\n##   .. .. .. .. ..$ reduction.key  : chr \"PC_\"\n##   .. .. .. .. ..$ seed.use       : num 42\n##   .. ..$ JackStraw.RNA.pca       :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"JackStraw.RNA.pca\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:54:13\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"JackStraw(pbmc, num.replicate = 100)\"\n##   .. .. .. ..@ params     :List of 7\n##   .. .. .. .. ..$ reduction    : chr \"pca\"\n##   .. .. .. .. ..$ assay        : chr \"RNA\"\n##   .. .. .. .. ..$ dims         : num 20\n##   .. .. .. .. ..$ num.replicate: num 100\n##   .. .. .. .. ..$ prop.freq    : num 0.01\n##   .. .. .. .. ..$ verbose      : logi TRUE\n##   .. .. .. .. ..$ maxit        : num 1000\n##   .. ..$ ScoreJackStraw          :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"ScoreJackStraw\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:54:13\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"ScoreJackStraw(pbmc, dims = 1:20)\"\n##   .. .. .. ..@ params     :List of 4\n##   .. .. .. .. ..$ reduction   : chr \"pca\"\n##   .. .. .. .. ..$ dims        : int [1:20] 1 2 3 4 5 6 7 8 9 10 ...\n##   .. .. .. .. ..$ score.thresh: num 1e-05\n##   .. .. .. .. ..$ do.plot     : logi FALSE\n##   .. ..$ FindNeighbors.RNA.pca   :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"FindNeighbors.RNA.pca\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:54:15\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"FindNeighbors(pbmc, dims = 1:10)\"\n##   .. .. .. ..@ params     :List of 17\n##   .. .. .. .. ..$ reduction      : chr \"pca\"\n##   .. .. .. .. ..$ dims           : int [1:10] 1 2 3 4 5 6 7 8 9 10\n##   .. .. .. .. ..$ assay          : chr \"RNA\"\n##   .. .. .. .. ..$ k.param        : num 20\n##   .. .. .. .. ..$ return.neighbor: logi FALSE\n##   .. .. .. .. ..$ compute.SNN    : logi TRUE\n##   .. .. .. .. ..$ prune.SNN      : num 0.0667\n##   .. .. .. .. ..$ nn.method      : chr \"annoy\"\n##   .. .. .. .. ..$ n.trees        : num 50\n##   .. .. .. .. ..$ annoy.metric   : chr \"euclidean\"\n##   .. .. .. .. ..$ nn.eps         : num 0\n##   .. .. .. .. ..$ verbose        : logi TRUE\n##   .. .. .. .. ..$ force.recalc   : logi FALSE\n##   .. .. .. .. ..$ do.plot        : logi FALSE\n##   .. .. .. .. ..$ graph.name     : chr [1:2] \"RNA_nn\" \"RNA_snn\"\n##   .. .. .. .. ..$ l2.norm        : logi FALSE\n##   .. .. .. .. ..$ cache.index    : logi FALSE\n##   .. ..$ FindClusters            :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"FindClusters\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:54:15\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"FindClusters(pbmc, resolution = 0.5)\"\n##   .. .. .. ..@ params     :List of 10\n##   .. .. .. .. ..$ graph.name      : chr \"RNA_snn\"\n##   .. .. .. .. ..$ modularity.fxn  : num 1\n##   .. .. .. .. ..$ resolution      : num 0.5\n##   .. .. .. .. ..$ method          : chr \"matrix\"\n##   .. .. .. .. ..$ algorithm       : num 1\n##   .. .. .. .. ..$ n.start         : num 10\n##   .. .. .. .. ..$ n.iter          : num 10\n##   .. .. .. .. ..$ random.seed     : num 0\n##   .. .. .. .. ..$ group.singletons: logi TRUE\n##   .. .. .. .. ..$ verbose         : logi TRUE\n##   .. ..$ RunUMAP.RNA.pca         :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"RunUMAP.RNA.pca\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:54:28\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"RunUMAP(pbmc, dims = 1:10)\"\n##   .. .. .. ..@ params     :List of 22\n##   .. .. .. .. ..$ dims                : int [1:10] 1 2 3 4 5 6 7 8 9 10\n##   .. .. .. .. ..$ reduction           : chr \"pca\"\n##   .. .. .. .. ..$ assay               : chr \"RNA\"\n##   .. .. .. .. ..$ slot                : chr \"data\"\n##   .. .. .. .. ..$ umap.method         : chr \"uwot\"\n##   .. .. .. .. ..$ return.model        : logi FALSE\n##   .. .. .. .. ..$ n.neighbors         : int 30\n##   .. .. .. .. ..$ n.components        : int 2\n##   .. .. .. .. ..$ metric              : chr \"cosine\"\n##   .. .. .. .. ..$ learning.rate       : num 1\n##   .. .. .. .. ..$ min.dist            : num 0.3\n##   .. .. .. .. ..$ spread              : num 1\n##   .. .. .. .. ..$ set.op.mix.ratio    : num 1\n##   .. .. .. .. ..$ local.connectivity  : int 1\n##   .. .. .. .. ..$ repulsion.strength  : num 1\n##   .. .. .. .. ..$ negative.sample.rate: int 5\n##   .. .. .. .. ..$ uwot.sgd            : logi FALSE\n##   .. .. .. .. ..$ seed.use            : int 42\n##   .. .. .. .. ..$ angular.rp.forest   : logi FALSE\n##   .. .. .. .. ..$ verbose             : logi TRUE\n##   .. .. .. .. ..$ reduction.name      : chr \"umap\"\n##   .. .. .. .. ..$ reduction.key       : chr \"UMAP_\"\n##   .. ..$ RunTSNE                 :Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"RunTSNE\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2021-07-08 11:54:36\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr \"RunTSNE(pbmc, dims = 1:10)\"\n##   .. .. .. ..@ params     :List of 8\n##   .. .. .. .. ..$ reduction     : chr \"pca\"\n##   .. .. .. .. ..$ cells         : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. ..$ dims          : int [1:10] 1 2 3 4 5 6 7 8 9 10\n##   .. .. .. .. ..$ seed.use      : num 1\n##   .. .. .. .. ..$ tsne.method   : chr \"Rtsne\"\n##   .. .. .. .. ..$ dim.embed     : num 2\n##   .. .. .. .. ..$ reduction.name: chr \"tsne\"\n##   .. .. .. .. ..$ reduction.key : chr \"tSNE_\"\n##   ..@ tools       :List of 2\n##   .. ..$ BuildClusterTree           :List of 4\n##   .. .. ..$ edge       : int [1:16, 1:2] 10 10 11 12 12 11 13 14 14 16 ...\n##   .. .. ..$ edge.length: num [1:16] 463 158 174 131 131 ...\n##   .. .. ..$ tip.label  : chr [1:9] \"0\" \"1\" \"2\" \"3\" ...\n##   .. .. ..$ Nnode      : int 8\n##   .. .. ..- attr(*, \"class\")= chr \"phylo\"\n##   .. .. ..- attr(*, \"order\")= chr \"cladewise\"\n##   .. ..$ CalculateBarcodeInflections:List of 4\n##   .. .. ..$ barcode_distribution:'data.frame':   2638 obs. of  4 variables:\n##   .. .. .. ..$ orig.ident: Factor w/ 1 level \"pbmc3k\": 1 1 1 1 1 1 1 1 1 1 ...\n##   .. .. .. ..$ nCount_RNA: num [1:2638] 8875 8415 8011 7928 7167 ...\n##   .. .. .. ..$ rank      : num [1:2638] 1 2 3 4 5 6 7 8 9 10 ...\n##   .. .. .. ..$ rawdiff   : num [1:2638] 0 -0.02311 -0.02136 -0.00452 -0.04382 ...\n##   .. .. ..$ inflection_points   :'data.frame':   1 obs. of  3 variables:\n##   .. .. .. ..$ orig.ident: Factor w/ 1 level \"pbmc3k\": 1\n##   .. .. .. ..$ nCount_RNA: num 7167\n##   .. .. .. ..$ rank      : num 5\n##   .. .. ..$ threshold_values    :'data.frame':   2 obs. of  2 variables:\n##   .. .. .. ..$ threshold: chr [1:2] \"threshold.low\" \"threshold.high\"\n##   .. .. .. ..$ rank     : num [1:2] 1 2638\n##   .. .. ..$ cells_pass          : chr [1:2635] \"GGGCCAACCTTGGA-1\" \"CAGGTTGAGGATCT-1\" \"ACGAGGGACAGGAG-1\" \"AAGCCATGAACTGC-1\" ...\n# Retrieve UMAP data\n# Retrieve the coordinates of each cell, and cluster, celltype information\numap &lt;- pbmc@reductions$umap@cell.embeddings |&gt; \n  as.data.frame() |&gt; \n  cbind(cell_type = pbmc@meta.data$labels)\n\nhead(umap)\n##                     UMAP_1     UMAP_2 cell_type\n## AAACATACAACCAC-1 -4.577857   1.650203   T_cells\n## AAACATTGAGCTAC-1 -2.813911 -11.897462    B_cell\n## AAACATTGATCAGC-1 -1.684490   3.302480   T_cells\n## AAACCGTGCTTCCG-1 12.694498   2.098798  Monocyte\n## AAACCGTGTATGCG-1 -9.829201   3.982013   NK_cell\n## AAACGCACTGGTAC-1 -2.908319   1.249230   T_cells\n\n\n# Define the colors\nallcolour &lt;- c(\n    \"#DC143C\",\"#0000FF\",\"#20B2AA\",\"#FFA500\",\"#9370DB\",\"#98FB98\",\"#F08080\",\n    \"#1E90FF\",\"#7CFC00\",\"#FFFF00\", \"#808000\",\"#FF00FF\",\"#FA8072\",\"#7B68EE\",\n    \"#9400D3\",\"#800080\",\"#A0522D\",\"#D2B48C\",\"#D2691E\",\"#87CEEB\",\"#40E0D0\",\n    \"#5F9EA0\",\"#FF1493\",\"#0000CD\",\"#008B8B\",\"#FFE4B5\",\"#8A2BE2\",\"#228B22\",\n    \"#E9967A\",\"#4682B4\",\"#32CD32\",\"#F0E68C\",\"#FFFFE0\",\"#EE82EE\",\"#FF6347\",\n    \"#6A5ACD\",\"#9932CC\",\"#8B008B\",\"#8B4513\",\"#DEB887\"\n)\n# ggplot2\np &lt;- ggplot(umap, aes(x = UMAP_1, y = UMAP_2, color = cell_type)) +\n    geom_point(size = 1, alpha = 1) +\n    ### MAP cluster with color\n    scale_color_manual(values = allcolour) +\n    ### Axis annotation\n    geom_segment(\n        aes(\n            x = min(umap$UMAP_1) , y = min(umap$UMAP_2) ,\n            xend = min(umap$UMAP_1) +3, yend = min(umap$UMAP_2)\n        ), colour = \"black\", linewidth = 1,arrow = arrow(length = unit(0.3,\"cm\"))\n    ) + \n    geom_segment(\n        aes(\n            x = min(umap$UMAP_1)  , y = min(umap$UMAP_2)  ,\n            xend = min(umap$UMAP_1) , yend = min(umap$UMAP_2) + 3),\n            colour = \"black\", linewidth = 1,arrow = arrow(length = unit(0.3,\"cm\"))\n    ) +\n    annotate(\n        \"text\", x = min(umap$UMAP_1) +1.5, y = min(umap$UMAP_2) -1, \n        label = \"UMAP_1\", color=\"black\",size = 3, fontface=\"bold\"\n    ) + \n    annotate(\n        \"text\", x = min(umap$UMAP_1) -1, y = min(umap$UMAP_2) + 1.5, \n        label = \"UMAP_2\", color=\"black\",size = 3, fontface=\"bold\" ,angle=90\n    ) + \n    theme(\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.border = element_blank(),\n        axis.title = element_blank(),\n        axis.text = element_blank(),\n        axis.ticks = element_blank(),\n        panel.background = element_rect(fill = \"white\"),\n        plot.background = element_rect(fill = \"white\"),\n        legend.title = element_blank(), \n        legend.key=element_rect(fill= \"white\"),\n        legend.text = element_text(size = 20),\n        legend.key.size=unit(1, \"cm\")\n    ) +\n    ### legend label size\n    guides(color = guide_legend(override.aes = list(size=5)))\n### View it\np\n\n\n\n\n\n\n\nAnnotate cell type on UMAP\n\n# Calcualte the median coordinates of each cluster\ncell_type_med &lt;- umap |&gt;\n  group_by(cell_type) |&gt;\n  summarise(UMAP_1 = median(UMAP_1),\n    UMAP_2 = median(UMAP_2)\n  )\n# Annotation\np + geom_label_repel(\n    aes(label = cell_type, size = 20), fontface = \"bold\", data = cell_type_med,\n    point.padding = unit(0.5, \"lines\")\n)"
  },
  {
    "objectID": "blog/2023/12/02/index.html#featureplot",
    "href": "blog/2023/12/02/index.html#featureplot",
    "title": "Customization of Seurat plots using ggplot2",
    "section": "FeaturePlot",
    "text": "FeaturePlot\nDefault Seurat FeaturePlot\n\nDimPlot(pbmc, label = TRUE)|FeaturePlot(pbmc, features = \"CD79A\")\n\n\n\n\n\n\nFeaturePlot(pbmc, features = c(\"CD79A\", \"CD8A\"), blend=TRUE)\n\n\n\n\n\n\nFeaturePlot(pbmc, features = c(\"CD79A\",\"CD79B\"), blend=TRUE)\n\n\n\n\n\n\nFeaturePlot(pbmc, features = c(\"CD79A\",\"CD79B\", \"CD68\", \"CD163\"))\n\n\n\n\n\n\n\nFeature with ggplot2\n\nmydata  &lt;- FetchData(\n    pbmc,\n    vars = c(\"rna_CD79A\", \"rna_CD8A\", \"rna_CCR7\", \"UMAP_1\", \"UMAP_2\")\n)\nhead(mydata)\n##                  rna_CD79A rna_CD8A rna_CCR7    UMAP_1     UMAP_2\n## AAACATACAACCAC-1  0.000000 1.635873 1.635873 -4.577857   1.650203\n## AAACATTGAGCTAC-1  1.962726 0.000000 0.000000 -2.813911 -11.897462\n## AAACATTGATCAGC-1  0.000000 0.000000 0.000000 -1.684490   3.302480\n## AAACCGTGCTTCCG-1  0.000000 0.000000 0.000000 12.694498   2.098798\n## AAACCGTGTATGCG-1  0.000000 0.000000 0.000000 -9.829201   3.982013\n## AAACGCACTGGTAC-1  0.000000 0.000000 0.000000 -2.908319   1.249230\n\n### Single gene\nmydata |&gt;\n    ggplot(aes(x = UMAP_1, y = UMAP_2)) +\n    geom_point(\n        data = mydata, aes(x = UMAP_1, y = UMAP_2,\n        color = rna_CD79A), size = 1\n    ) +\n    ### Increase the transprancy of gray dots\n    scale_color_gradient(\n        \"rna_CD79A\", low = alpha(\"grey\", 0.1), \n        high = alpha(\"red\", 1)\n    ) +\n    ### Density\n    stat_density2d(aes(colour=rna_CD79A))\n\n\n\n\n\n\n\n\n### Multiple genes in feature plot\nggplot(mydata, aes(x = UMAP_1, y = UMAP_2)) +\n    geom_point(\n        data = mydata, aes(x = UMAP_1, y = UMAP_2, color = rna_CD79A), \n        size = 1\n    ) +\n    scale_color_gradient(\n        \"CD79A\", low = alpha(\"grey\", 0.1), high = alpha(\"purple\", 1)\n    ) +\n    new_scale(\"color\") +\n    geom_point(\n        data = mydata, aes(x = UMAP_1, y = UMAP_2, color = rna_CD8A), \n        size = 1\n    ) +\n    scale_color_gradient(\n        \"CD8A\", low = alpha(\"grey\", 0.1), high = alpha(\"red\", 1)\n    ) +\n    new_scale(\"color\") +\n    geom_point(\n        data = mydata, aes(x = UMAP_1, y = UMAP_2,color = rna_CCR7), \n        size = 1\n    ) +\n    scale_color_gradient(\n        \"CCR7\", low = alpha(\"grey\", 0.1), high = alpha(\"green\", 1)\n    ) +\n    theme_bw()"
  },
  {
    "objectID": "blog/2023/12/02/index.html#dotplot",
    "href": "blog/2023/12/02/index.html#dotplot",
    "title": "Customization of Seurat plots using ggplot2",
    "section": "Dotplot",
    "text": "Dotplot\nDeafult Dotplot within Seurat\n\n# Find marker genes\n# all_markers &lt;- FindAllMarkers(object = sce2)\n# save(all_markers,file = here(\"learn\", \"2023_scRNA\", \"all_markers.RData\"))\n\nDotPlot(sce2,features = unique(top5$gene) ,assay='RNA')\n\n\n\n\n\n\n\n\n# Optimize colors, size, and direction\np1 &lt;- DotPlot(sce2, features = unique(top5$gene), assay = \"RNA\") + \n  coord_flip() + \n  labs(x = NULL,y = NULL) + \n  guides(size = guide_legend(\"Percent Expression\"))+\n  scale_color_gradientn(colours = c(\"#330066\", \"#336699\", \"#66CC66\", \"#FFCC33\")) +\n  theme(\n    panel.grid = element_blank(), \n    axis.text.x = element_text(angle = 45, hjust = 0.5,vjust = 0.5)\n  )\n## Scale for colour is already present.\n## Adding another scale for colour, which will replace the existing scale.\np1\n\n\n\n\n\n\n\nDotplot with Complexheatmap\nWe can refer to details from here for detailed parameters customization.\n\n# Retrieve data\ndf &lt;- p1$data\nhead(df)\n##               avg.exp   pct.exp features.plot id avg.exp.scaled\n## REG4       7.70481043 17.174382          REG4  0       2.500000\n## BPIFB1     0.30669602  6.860158        BPIFB1  0       2.500000\n## FABP1      0.29179596  3.118254         FABP1  0       2.500000\n## SLC9A4     0.01901309  1.751019        SLC9A4  0       2.500000\n## AC073218.2 0.03103152  1.655073    AC073218.2  0       1.137072\n## SPRR1A     0.07460096  3.837851        SPRR1A  0       0.208155\n\n# The matrix for the scaled expression \nexp_mat &lt;-df |&gt; \n  select(-pct.exp, -avg.exp) |&gt;  \n  pivot_wider(names_from = id, values_from = avg.exp.scaled) |&gt; \n  as.data.frame()\nrow.names(exp_mat) &lt;- exp_mat$features.plot\nexp_mat &lt;- exp_mat[, -1] |&gt; as.matrix()\nhead(exp_mat, 2)\n##          0          1          2          3          4        5          6\n## REG4   2.5  1.0681259 -0.6492553 -0.6766277  0.4956595 1.826576 -0.4005466\n## BPIFB1 2.5 -0.1015123 -0.4099583 -0.5370206 -0.3309614 1.039651 -0.6032213\n##                 7          8          9         10        11         12\n## REG4   -0.3648312 -0.6411552  0.3682808 -0.4876358 0.3408992 -0.6358072\n## BPIFB1  0.4017002 -0.5414065 -0.2597756 -0.5685453 1.6007798 -0.6318396\n##                13         14        15         16         17         18\n## REG4   -0.7044399 -0.7832735 0.5617191 -0.7888883 -0.5395693 -0.7888883\n## BPIFB1 -0.6318396 -0.6318396 1.1110916 -0.6318396 -0.6318396 -0.6318396\n\n## The matrix for the percentage of cells express a gene\npercent_mat &lt;- df |&gt; \n  select(-avg.exp, -avg.exp.scaled) |&gt;  \n  pivot_wider(names_from = id, values_from = pct.exp) |&gt; \n  as.data.frame()\n \nrow.names(percent_mat) &lt;- percent_mat$features.plot  \npercent_mat &lt;- percent_mat[, -1] |&gt; as.matrix()\nhead(percent_mat, 2)\n##                0         1        2         3        4         5         6\n## REG4   17.174382 11.642157 5.015480 3.2281731 7.209302 16.111851 7.9301075\n## BPIFB1  6.860158  2.389706 1.114551 0.7336757 2.015504  3.062583 0.2688172\n##                7         8         9        10        11       12       13 14\n## REG4   11.367673 2.5782689 12.406948 7.1090047 12.244898 5.797101 2.380952  1\n## BPIFB1  6.571936 0.3683241  1.736973 0.4739336  8.843537 0.000000 0.000000  0\n##              15 16       17 18\n## REG4   9.278351  0 8.571429  0\n## BPIFB1 7.216495  0 0.000000  0\n\n\n# Complexheatmap\n## any value that is greater than 2 will be mapped to yellow\ncol_fun &lt;-  circlize::colorRamp2(c(-1, 0, 2), viridis(20)[c(1,10, 20)])\ncell_fun &lt;- function(j, i, x, y, w, h, fill) {\n    grid.rect(x = x, y = y, width = w, height = h,\n        gp = gpar(col = NA, fill = NA))\n    grid.circle(x = x, y = y, r = percent_mat[i, j] / 100 * min(unit.c(w, h)),\n        gp = gpar(fill = col_fun(exp_mat[i, j]), col = NA))\n}\n\n# also do a kmeans clustering for the genes with k = 4\nHeatmap(\n    exp_mat,\n    heatmap_legend_param = list(title = \"Average Expression\"),\n    column_title = \"clustered dotplot\",\n    col = col_fun,\n    rect_gp = gpar(type = \"none\"),\n    cell_fun = cell_fun,\n    row_names_gp = gpar(fontsize = 3),\n    # row_km = 4,\n    border = \"black\"\n)\n\n\n# Annotate celltype\ncolnames(exp_mat)\ncluster_anno &lt;- c(\"Epi\", \"Myeloid\", \"Fibroblast\", \"T\", \"Endo\", \"un\")\n\ncolumn_ha &lt;- HeatmapAnnotation(\n    cluster_anno = cluster_anno,\n    col = list(cluster_anno = setNames(brewer.pal(6, \"Paired\"), unique(cluster_anno))\n    ),\n    na_col = \"grey\"\n)\n\nHeatmap(\n    exp_mat,\n    heatmap_legend_param = list(title = \"Average Expression\"),\n    column_title = \"clustered dotplot\",\n    col = col_fun,\n    rect_gp = gpar(type = \"none\"),\n    cell_fun = cell_fun,\n    row_names_gp = gpar(fontsize = 5),\n    # row_km = 4,\n    border = \"black\",\n    top_annotation = column_ha\n)\n\n\n# Add legend\nlayer_fun &lt;- function(j, i, x, y, w, h, fill) {\n    grid.rect(\n        x = x, y = y, width = w, height = h, gp = gpar(col = NA, fill = NA)\n    )\n    grid.circle(\n        x = x, y = y, r = pindex(percent_mat, i, j) / 100 * unit(2, \"mm\"),\n        gp = gpar(fill = col_fun(pindex(exp_mat, i, j)), col = NA)\n    )\n}\n\nlgd_list = list(\n    Legend(\n        labels = c(0, 0.25, 0.5, 0.75, 1), title = \"Percent Expressed\",\n        graphics = list(\n            function(x, y, w, h) grid.circle(x = x, y = y, r = 0 * unit(2, \"mm\"),\n                gp = gpar(fill = \"black\")),\n            function(x, y, w, h) grid.circle(x = x, y = y, r = 0.25 * unit(2, \"mm\"),\n                gp = gpar(fill = \"black\")),\n            function(x, y, w, h) grid.circle(x = x, y = y, r = 0.5 * unit(2, \"mm\"),\n                gp = gpar(fill = \"black\")),\n            function(x, y, w, h) grid.circle(x = x, y = y, r = 0.75 * unit(2, \"mm\"),\n                gp = gpar(fill = \"black\")),\n            function(x, y, w, h) grid.circle(x = x, y = y, r = 1 * unit(2, \"mm\"),\n                gp = gpar(fill = \"black\"))\n        )\n    )\n)\n\nhp &lt;- Heatmap(\n    exp_mat,\n    heatmap_legend_param = list(title = \"expression\"),\n    column_title = \"clustered dotplot\",\n    col = col_fun,\n    rect_gp = gpar(type = \"none\"),\n    layer_fun = layer_fun,\n    row_names_gp = gpar(fontsize = 5),\n    # row_km = 4,\n    border = \"black\",\n    top_annotation = column_ha\n)\n\ndraw(hp, annotation_legend_list = lgd_list)\n\nDotplot with scCustomize\n\nClustered_DotPlot(seurat_object = sce2, features = unique(top5$gene))\n\n\n\n\n\n\n## [[1]]\n\n\n\n\n\n\n## \n## [[2]]\n\n\n\n\n\n\n\nmy36colors &lt;- c(\n    '#E5D2DD', '#53A85F', '#F1BB72', '#F3B1A0', '#D6E7A3', '#57C3F3', '#476D87',\n    '#E95C59', '#E59CC4', '#AB3282', '#23452F', '#BD956A', '#8C549C', '#585658',\n    '#9FA3A8', '#E0D4CA', '#5F3D69', '#C5DEBA', '#58A4C3', '#E4C755', '#F7F398',\n    '#AA9A59', '#E63863', '#E39A35', '#C1E6F3', '#6778AE', '#91D0BE', '#B53E2B',\n    '#712820', '#DCC1DD', '#CCE0F5', '#CCC9E6', '#625D9E', '#68A180', '#3A6963',\n    '#968175'\n)\n\nClustered_DotPlot(\n    seurat_object = sce2,\n    colors_use_exp = c('#330066', '#336699', '#66CC66', '#FFCC33'),\n    colors_use_idents = my36colors,\n    features = unique(top5$gene)\n)\n\n\n\n\n\n\n## [[1]]\n\n\n\n\n\n\n## \n## [[2]]"
  },
  {
    "objectID": "blog/2023/12/02/index.html#doheatmap",
    "href": "blog/2023/12/02/index.html#doheatmap",
    "title": "Customization of Seurat plots using ggplot2",
    "section": "DoHeatmap",
    "text": "DoHeatmap\nDeafult DoHeatmap with Seurat\n\nDoHeatmap(sce2, top5$gene)\n\n\n\n\n\n\n\n\n# Customize label and color\nDoHeatmap(\n    sce2,\n    label = F, # remove label\n    features = as.character(unique(top5$gene)),\n    group.by = \"celltype\",\n    assay = \"RNA\",\n    group.colors = c(\n        \"#C77CFF\", \"#7CAE00\", \"#00BFC4\", \"#F8766D\", \"#AB82FF\", \"#90EE90\",\n        \"#00CD00\", \"#008B8B\", \"#FFA500\"\n    ) # Group color\n) +\n    scale_fill_gradientn(\n        colors = c(\"navy\", \"white\", \"firebrick3\")\n    ) # heatmap color\n\nComplexheatmap or pheatmap\n\n# Retrieve matix\n# mat &lt;- GetAssayData(pbmc,slot = \"scale.data\")\n\ndittoSeq\n\n# BiocManager::install(\"dittoSeq\")\n\ndittoHeatmap(sce2, top5$gene,\n             annot.by = c(\"celltype\", \"sample\",\"AUCell\"))\n\nscillus\n\n# devtools::install_github(\"xmc811/Scillus\", ref = \"development\")\n# Use same colors of umap  \nmy36colors &lt;-c(\n  '#E5D2DD', '#53A85F', '#F1BB72', '#F3B1A0', '#D6E7A3', '#57C3F3', '#476D87',\n  '#E95C59', '#E59CC4', '#AB3282', '#23452F', '#BD956A', '#8C549C', '#585658',\n  '#9FA3A8', '#E0D4CA', '#5F3D69', '#C5DEBA', '#58A4C3', '#E4C755', '#F7F398',\n  '#AA9A59', '#E63863', '#E39A35', '#C1E6F3', '#6778AE', '#91D0BE', '#B53E2B',\n  '#712820', '#DCC1DD', '#CCE0F5',  '#CCC9E6', '#625D9E', '#68A180', '#3A6963',\n  '#968175'\n)\n\nplot_heatmap(dataset = sce2, \n             markers = top5$gene,\n             sort_var = c(\"celltype\",\"sample\"),\n             anno_var = c(\"celltype\",\"sample\",\"percent.mt\",\"AUCell\"),\n             anno_colors = list(\n                \"Set2\",  # RColorBrewer palette\n                my36colors,  # color vecto\n                \"Reds\",\n                \"Greens\")\n)"
  },
  {
    "objectID": "blog/2023/12/02/index.html#vlnplot",
    "href": "blog/2023/12/02/index.html#vlnplot",
    "title": "Customization of Seurat plots using ggplot2",
    "section": "VlnPlot",
    "text": "VlnPlot\nDefault Seurat VlnPlot\n\n# Few marker\nVlnPlot(sce2, features = c(\"CD3D\",\"SPP1\"))\n\n\n\n\n\n\n\n# All marker genes\n# VlnPlot(sce2, features = top5$gene)\n\nStacked Vlnplot\n\na &lt;- VlnPlot(sce2, features = top5$gene, stack = TRUE, sort = TRUE) +\n  theme(legend.position = \"none\") + ggtitle(\"Identity on y-axis\")\n\n# Flip\nb &lt;- VlnPlot(sce2, features = top5$gene, stack = TRUE, sort = TRUE, flip = TRUE) +\n  theme(legend.position = \"none\") + ggtitle(\"Identity on x-axis\")\n\na + b\n\n\n\n\n\n\n\n\n# Optimize colors, size and direction\nmy36colors &lt;- c(\n    '#E5D2DD', '#53A85F', '#F1BB72', '#F3B1A0', '#D6E7A3', '#57C3F3', '#476D87',\n    '#E95C59', '#E59CC4', '#AB3282', '#23452F', '#BD956A', '#8C549C', '#585658',\n    '#9FA3A8', '#E0D4CA', '#5F3D69', '#C5DEBA', '#58A4C3', '#E4C755', '#F7F398',\n    '#AA9A59', '#E63863', '#E39A35', '#C1E6F3', '#6778AE', '#91D0BE', '#B53E2B',\n    '#712820', '#DCC1DD', '#CCE0F5', '#CCC9E6', '#625D9E', '#68A180', '#3A6963',\n    '#968175'\n)\n\nVlnPlot(\n    sce2, \n    features = top_marker$gene,\n    stack = TRUE,\n    sort = TRUE,\n    cols = my36colors,\n    split.by = \"celltype\", # color for each cluster\n    flip = TRUE\n  ) +\n    theme(legend.position = \"none\") +\n    ggtitle(\"Identity on x-axis\")\n\nVlnPlot with ggplot2\n\nvln.dat  &lt;- FetchData(sce2, c(top_marker$gene,\"celltype\",\"seurat_clusters\"))\n\nvln.dat$Cell &lt;- rownames(vln.dat)\nvln.dat.melt &lt;- reshape2::melt(vln.dat, id.vars = c(\"Cell\",\"seurat_clusters\"), \n                               measure.vars = top_marker$gene,\n                               variable.name = \"gene\", \n                               value.name = \"Expr\") |&gt;\n  group_by(seurat_clusters,gene) |&gt; \n  mutate(fillcolor=mean(Expr))\n\n# Plot \nggplot(vln.dat.melt, aes(factor(seurat_clusters), Expr, fill = gene)) +\n  geom_violin(scale = \"width\", adjust = 1, trim = TRUE) +\n  facet_grid(rows = vars(gene), scales = \"free\", switch = \"y\") \n\n\n# Customize\np1 &lt;- ggplot(vln.dat.melt, aes(gene, Expr, fill = gene)) +\n  geom_violin(scale = \"width\", adjust = 1, trim = TRUE) +\n  scale_y_continuous(expand = c(0, 0), position=\"right\", labels = function(x)\n    c(rep(x = \"\", times = length(x)-2), x[length(x) - 1], \"\")) +\n  facet_grid(rows = vars(seurat_clusters), scales = \"free\", switch = \"y\") +\n  scale_fill_manual(values = my36colors) + \n  theme_cowplot(font_size = 12) +\n  theme(legend.position = \"none\", panel.spacing = unit(0, \"lines\"),\n        plot.title = element_text(hjust = 0.5),\n        panel.background = element_rect(fill = NA, color = \"black\"),\n        plot.margin = margin(7, 7, 0, 7, \"pt\"),\n        strip.background = element_blank(),\n        strip.text = element_text(face = \"bold\"),\n        strip.text.y.left = element_text(angle = 0),\n        axis.title.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, color = \"black\")\n        ) +\n  ggtitle(\"Feature on x-axis with annotation\") + ylab(\"Expression Level\")\np1\n\n\np2 &lt;- ggplot(vln.dat.melt, aes(gene, Expr, fill = gene)) +\n  geom_violin(scale = \"width\", adjust = 1, trim = TRUE) +\n  scale_y_continuous(expand = c(0, 0), position=\"right\", labels = function(x)\n    c(rep(x = \"\", times = length(x)-2), x[length(x) - 1], \"\")) +\n  facet_grid(rows = vars(seurat_clusters), scales = \"free\", switch = \"y\") +\n  scale_fill_manual(values = my36colors) + \n  theme_cowplot(font_size = 12) +\n  theme(legend.position = \"none\", panel.spacing = unit(0, \"lines\"),\n        plot.title = element_text(hjust = 0.5),\n        panel.background = element_rect(fill = NA, color = \"black\"),\n        plot.margin = margin(7, 7, 0, 7, \"pt\"),\n        strip.background = element_blank(),\n        strip.text = element_text(face = \"bold\"),\n        strip.text.y.left = element_text(angle = 0),\n        axis.title.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.text.x = element_blank()\n  ) +\n  ggtitle(\"Feature on x-axis with annotation\") + ylab(\"Expression Level\")\np2\n\n\n# Create grouping info\ndf &lt;- data.frame(x = levels(vln.dat.melt$gene), \n                 group = c(\"A\",\"A\",\"B\",\"B\",\"B\",\"B\",\"B\",\"C\",\"C\",\"C\",\"D\",\"D\",\"D\",\n                           \"D\",\"D\",\"D\",\"D\",\"D\"), \n                 stringsAsFactors = FALSE)\ndf$x &lt;- factor(df$x, levels = levels(vln.dat.melt$gene))\ndf$group &lt;- factor(df$group)\n\nlevels(df$group) = c(\"ECM-receptor interaction\", \"PI3K-Akt signaling pathway\", \n                     \"MAPK signaling pathway\", \"Cell adhesion molecules\")\n\ncolor &lt;- c(\"cyan\", \"pink\", \"green\", \"darkorange\")\n\np3 &lt;- ggplot(df, aes(x = x, y = 1, fill = group)) + geom_tile() + theme_bw(base_size = 12) +\n  scale_fill_manual(values = my36colors) + scale_y_continuous(expand = c(0, 0)) +\n  guides(fill = guide_legend(direction = \"vertical\", label.position = \"right\",\n                             title.theme = element_blank(), keyheight = 0.5, nrow = 2)) +\n  theme(legend.position = \"bottom\",\n        legend.justification = \"left\",\n        legend.margin = margin(0,0,0,0),\n        legend.box.margin = margin(-10,5,0,0),\n        panel.spacing = unit(0, \"lines\"),\n        panel.background = element_blank(),\n        panel.border = element_blank(),\n        plot.background = element_blank(),\n        plot.margin = margin(0, 7, 7, 7, \"pt\"),\n        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, color = \"black\"),\n        axis.title.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.y = element_blank()) + xlab(\"Feature\")\np3\n\n\n# Use plot_grid to join plots\nplot_grid(p2, p3, ncol = 1, rel_heights = c(0.78, 0.22), align = \"v\", axis = \"lr\")"
  },
  {
    "objectID": "blog/2023/12/02/index.html#reference",
    "href": "blog/2023/12/02/index.html#reference",
    "title": "Customization of Seurat plots using ggplot2",
    "section": "Reference",
    "text": "Reference\n\nhttps://github.com/ycl6/StackedVlnPlot\nhttps://scillus.netlify.app/vignettes/plotting.html\nhttps://bioconductor.org/packages/devel/bioc/vignettes/dittoSeq/inst/doc/dittoSeq.html"
  },
  {
    "objectID": "blog/2023/11/29/index.html",
    "href": "blog/2023/11/29/index.html",
    "title": "Visual the usage of CPU and memory with htop",
    "section": "",
    "text": "The content is credited from here\nLet’s start with the upper section.\n\nHere’s the lower section of htop."
  },
  {
    "objectID": "blog/2023/11/26/index.html",
    "href": "blog/2023/11/26/index.html",
    "title": "Learning Harmony to integrate single cell RNA-seq data for batch borrection and meta analysis",
    "section": "",
    "text": "data(cell_lines)\nscaled_pcs &lt;- cell_lines$scaled_pcs\nmeta_data &lt;- cell_lines$meta_data\n### cells cluster by dataset initially\np1 &lt;- do_scatter(scaled_pcs, meta_data, \"dataset\") +\n    labs(title = \"Colored by dataset\")\np2 &lt;- do_scatter(scaled_pcs, meta_data, \"cell_type\") +\n    labs(title = \"Colored by cell type\")\n### combine plot\ncowplot::plot_grid(p1, p2)\n\n\n\n\n\n\n\nRun harmonoy to remove the influence of dataset-of origin from ceel embeddings. After Harmony, the datasets are now mixed and the cell types are still separate.\n\nharmony_embeddings &lt;- harmony::RunHarmony(\n    scaled_pcs, meta_data, \"dataset\", verbose = FALSE\n)\np1 &lt;- do_scatter(harmony_embeddings, meta_data, \"dataset\") +\nlabs(title = \"Colored by dataset\")\np2 &lt;- do_scatter(harmony_embeddings, meta_data, \"cell_type\") +\n    labs(title = \"Colored by cell type\")\n### combine plot\ncowplot::plot_grid(p1, p2, nrow = 1)"
  },
  {
    "objectID": "blog/2023/11/26/index.html#harmony-to-integrating-cell-line-datasets-from-10x",
    "href": "blog/2023/11/26/index.html#harmony-to-integrating-cell-line-datasets-from-10x",
    "title": "Learning Harmony to integrate single cell RNA-seq data for batch borrection and meta analysis",
    "section": "",
    "text": "data(cell_lines)\nscaled_pcs &lt;- cell_lines$scaled_pcs\nmeta_data &lt;- cell_lines$meta_data\n### cells cluster by dataset initially\np1 &lt;- do_scatter(scaled_pcs, meta_data, \"dataset\") +\n    labs(title = \"Colored by dataset\")\np2 &lt;- do_scatter(scaled_pcs, meta_data, \"cell_type\") +\n    labs(title = \"Colored by cell type\")\n### combine plot\ncowplot::plot_grid(p1, p2)\n\n\n\n\n\n\n\nRun harmonoy to remove the influence of dataset-of origin from ceel embeddings. After Harmony, the datasets are now mixed and the cell types are still separate.\n\nharmony_embeddings &lt;- harmony::RunHarmony(\n    scaled_pcs, meta_data, \"dataset\", verbose = FALSE\n)\np1 &lt;- do_scatter(harmony_embeddings, meta_data, \"dataset\") +\nlabs(title = \"Colored by dataset\")\np2 &lt;- do_scatter(harmony_embeddings, meta_data, \"cell_type\") +\n    labs(title = \"Colored by cell type\")\n### combine plot\ncowplot::plot_grid(p1, p2, nrow = 1)"
  },
  {
    "objectID": "blog/2023/11/26/index.html#mudan",
    "href": "blog/2023/11/26/index.html#mudan",
    "title": "Learning Harmony to integrate single cell RNA-seq data for batch borrection and meta analysis",
    "section": "MUDAN",
    "text": "MUDAN\n\n### get data\ndata(\"pbmcA\")\ndata(\"pbmcB\")\ndim(pbmcA)\ndim(pbmcB)\n\n### downsize the number of cells in each PBMC dataset\npbmcA &lt;- pbmcA[, 500] # take 500 cells\npbmcB &lt;- pbmcB[, 2000] # take 500 cells\n\nCombine the two datasets into one cell by gene counts matrix and use a meta vector to keep track of which cell belongs to which sample\n\n### combine into one coutns matrix\ngenes_int &lt;- intersect(rownames(pbmcA), rownames(pbmcB))\ncd &lt;- cbind(pbmcA[genes_int, ], pbmcB[genes_int, ])\n\n### meta data\nmeta &lt;- c(rep(\"pbmcA\", ncol(pbmcA)), rep(\"pbmcB\", ncol(pbmcB)))\nnames(meta) &lt;- c(colnames(pbmcA), colnames(pbmcB))\nmeta &lt;- factor(meta)\n\ncd[1:5, 1:2]\nmeta[1:5]\n\nGiven this counts matrix, we can normalize our data, derive principal components, and perform dimensionality reduction using tSNE. However, we see prominent separation by sample due to batch effects.\n\n### CPM normalization\nmat &lt;- MUDAN::normalizeCounts(cd, verbose = FALSE)\n\n### variance normalize, identify overdispersed genes\nmatnorm_info &lt;- MUDAN::normalizeVariance(mat, details = TRUE, verbose = FALSE)\n\n### log transform\nmatnorm &lt;- log10(matnorm_info$mat + 1)\n\n### 30 PCs on over dispersed genes\npcs &lt;- MUDAN::getPcs(\n    matnorm[matnorm_info$ods, ],\n    nGenes = length(matnorm_info$ods),\n    nPcs = 30, \n    verbose = FALSE\n)\n### TSNE embedding with regular PCS\nemb &lt;- Rtsne::Rtsne(\n    pcs,\n    is_distance = FALSE,\n    perplexity = 30, \n    num_threads = 1,\n    verbose = FALSE\n)$Y\nrownames(emb) &lt;- rownames(pcs)\n### plot\npar(mfrow = c(1, 1), mar = rep(2, 4))\nMUDAN::plotEmbedding(\n    emb, groups = meta, show.legend = TRUE,\n    xlab = NA, ylab = NA,\n    main = \"Regular tSNE Embedding\",\n    verbose = FALSE\n)\n\nIndeed, when we inspect certain cell-type specific marker genes (MS4A1/CD20 for B-cells, CD3E for T-cells, FCGR3A/CD16 for NK cells, macrophages, and monocytes, CD14 for dendritic cells, macrophages, and monocytes), we see that cells are separating by batch rather than by their expected cell-types.\n\npar(mfrow = c(2, 2), mar = rep(2, 4))\ninvisible(\n    lapply(\n        c(\"MS4A1\", \"CD3E\", \"FCGR3A\", \"CD14\"),\n        function(x) {\n            gexp &lt;- log10(mat[x, ] + 1)\n            plotEmbedding(\n                emb, col = gexp, xlab = \"NA\",\n                ylab = NA, main = x,\n                verbose = FALSE\n            )\n        }\n    )\n)\n\nIf we were attempt to identify cell-types using clustering analysis at this step, we would identify a number of sample-specific clusters driven by batch effects.\n\nannot_bad &lt;- getComMembership(pcs, k = 30, method = igraph::cluster_louvain)\npar(mfrow = c(1, 1), mar = rep(2, 4))\nplotEmbedding(\n    emb, groups = annot_bad, show.legend = TRUE,\n    xlab = NA, ylab = NA,\n    main = \"Jointly-indentified cell clusters\",\n    verbose = FALSE\n)\n\n\n### look at cell-type proportion per sample\nt(table(annot_bad, meta))/as.numeric(table(meta))\n# Look at cell-type proportions per sample\n# print(t(table(annot_bad, meta))/as.numeric(table(meta)))"
  },
  {
    "objectID": "blog/2023/11/26/index.html#using-harmony-with-seurat",
    "href": "blog/2023/11/26/index.html#using-harmony-with-seurat",
    "title": "Learning Harmony to integrate single cell RNA-seq data for batch borrection and meta analysis",
    "section": "Using Harmony with Seurat",
    "text": "Using Harmony with Seurat\n\n### load required data\ndata(\"pbmc_stim\")\n\n### generate seurat object\npbmc &lt;- CreateSeuratObject(\n    counts = cbind(pbmc.stim, pbmc.ctrl),\n    project = \"PBMC\",\n    min.cells = 5\n) \n\n### separete conditions\npbmc@meta.data$stim &lt;- c(\n    rep(\"STIM\", ncol(pbmc.stim)),\n    rep(\"CTRL\", ncol(pbmc.ctrl))\n)\n\n### generate a union of highly variable genes\npbmc &lt;- pbmc |&gt; Seurat::NormalizeData(verbose = FALSE)\n\nVariableFeatures(pbmc) &lt;- split(row.names(pbmc@meta.data), pbmc@meta.data$stim) %&gt;% lapply(function(cells_use) {\n    pbmc[,cells_use] %&gt;%\n        FindVariableFeatures(selection.method = \"vst\", nfeatures = 2000) %&gt;% \n        VariableFeatures()\n}) %&gt;% unlist %&gt;% unique\n## Finding variable features for layer counts\n## Finding variable features for layer counts\n\npbmc &lt;- pbmc |&gt; \n    ScaleData(verbose = FALSE) |&gt; \n    RunPCA(features = VariableFeatures(pbmc), npcs = 20, verbose = FALSE)\n\nClear difference between the datasets in the uncorrected PCs\n\np1 &lt;- DimPlot(object = pbmc, reduction = \"pca\", pt.size = .1, group.by = \"stim\")\np2 &lt;- VlnPlot(object = pbmc, features = \"PC_1\", group.by = \"stim\", pt.size = .1)\ncowplot::plot_grid(p1,p2)\n\n\n\n\n\n\n\nRun Harmony\nHarmony works on an existing matrix with cell embeddings and outputs its transformed version with the datasets aligned according to some user-defined experimental conditions.\n\n### run harmony to perform integrated analysis\npbmc &lt;- RunHarmony(pbmc, \"stim\", plot_convergence = TRUE)\n## Transposing data matrix\n## Initializing state using k-means centroids initialization\n## Harmony 1/10\n## Harmony 2/10\n## Harmony 3/10\n## Harmony 4/10\n## Harmony 5/10\n## Harmony 6/10\n## Harmony 7/10\n## Harmony 8/10\n## Harmony 9/10\n## Harmony converged after 9 iterations\n\n\n\n\n\n\n\n### directly access the new harmony embeddings\nharmony_embeddings &lt;- Embeddings(pbmc, \"harmony\")\nharmony_embeddings[1:5, 1:5]\n##                  harmony_1   harmony_2   harmony_3 harmony_4    harmony_5\n## ATCACTTGCTCGAA-1 -6.472885 -0.03395769 -3.37113988  4.104260  0.001600968\n## CCGGAGACTGTGAC-1 -6.901013  1.59104949 -6.36127179  4.635761 -5.605371816\n## CAAGCCCTGTTAGC-1 -6.774086 -1.21811545 -6.49162911 -9.135284 -0.197759676\n## GAGGTACTAACGGG-1 -7.435499 -0.23169621  0.07052885  2.031633 -2.190562901\n## CGCGGATGCCACAA-1 14.686943  4.38600212 -4.49637985  1.595446 -1.448223157\n\n### inspection of the modalities\np1 &lt;- DimPlot(object = pbmc, reduction = \"harmony\", pt.size = .1, group.by = \"stim\")\np2 &lt;- VlnPlot(object = pbmc, features = \"harmony_1\", group.by = \"stim\", pt.size = .1)\nplot_grid(p1,p2)\n\n\n\n\n\n\n\nPlot genes correlated with the harmonized PCs\n\nDimHeatmap(object = pbmc, reduction = \"harmony\", cells = 500, dims = 1:3)\n\n\n\n\n\n\n\nDown stream analysis\n\npbmc &lt;- pbmc |&gt; \n    ### perform clustering using the harmonized vectors of cells\n    FindNeighbors(reduction = \"harmony\", dims = 1:20) |&gt; \n    FindClusters(resolution = 0.5) |&gt; \n    identity()\n## Computing nearest neighbor graph\n## Computing SNN\n## Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n## \n## Number of nodes: 2000\n## Number of edges: 85805\n## \n## Running Louvain algorithm...\n## Maximum modularity in 10 random starts: 0.8883\n## Number of communities: 10\n## Elapsed time: 0 seconds\n### TSNE\npbmc &lt;- pbmc %&gt;%\n    RunTSNE(reduction = \"harmony\")\np1 &lt;- DimPlot(pbmc, reduction = \"tsne\", group.by = \"stim\", pt.size = .1)\np2 &lt;- DimPlot(pbmc, reduction = \"tsne\", label = TRUE, pt.size = .1)\nplot_grid(p1, p2)\n\n\n\n\n\n\n\nOne important observation is to assess that the harmonized data contain biological states of the cells. Therefore by checking the following genes we can see that biological cell states are preserved after harmonization.\n\nFeaturePlot(object = pbmc, features= c(\"CD3D\", \"SELL\", \"CREM\", \"CD8A\", \"GNLY\", \"CD79A\", \"FCGR3A\", \"CCL2\", \"PPBP\"), \n            min.cutoff = \"q9\", cols = c(\"lightgrey\", \"blue\"), pt.size = 0.5)\n\n\n\n\n\n\n\n\n### UMAP\npbmc &lt;- pbmc |&gt; \n    RunUMAP(reduction = \"harmony\", dims = 1:20)\n## 20:34:54 UMAP embedding parameters a = 0.9922 b = 1.112\n## Found more than one class \"dist\" in cache; using the first, from namespace 'BiocGenerics'\n## Also defined by 'spam'\n## 20:34:54 Read 2000 rows and found 20 numeric columns\n## 20:34:54 Using Annoy for neighbor search, n_neighbors = 30\n## Found more than one class \"dist\" in cache; using the first, from namespace 'BiocGenerics'\n## Also defined by 'spam'\n## 20:34:54 Building Annoy index with metric = cosine, n_trees = 50\n## 0%   10   20   30   40   50   60   70   80   90   100%\n## [----|----|----|----|----|----|----|----|----|----|\n## **************************************************|\n## 20:34:54 Writing NN index file to temp file /var/folders/2c/9q3pg2295195bp3gnrgbzrg40000gn/T//RtmpBhrb7C/file51ff59f4665b\n## 20:34:54 Searching Annoy index using 1 thread, search_k = 3000\n## 20:34:54 Annoy recall = 100%\n## 20:34:54 Commencing smooth kNN distance calibration using 1 thread with target n_neighbors = 30\n## 20:34:55 Initializing from normalized Laplacian + noise (using RSpectra)\n## 20:34:55 Commencing optimization for 500 epochs, with 83254 positive edges\n## 20:34:57 Optimization finished\np1 &lt;- DimPlot(pbmc, reduction = \"umap\", group.by = \"stim\", pt.size = .1, split.by = 'stim')\n### identify shared cell types with clustering analysis\np2 &lt;- DimPlot(pbmc, reduction = \"umap\", label = TRUE, pt.size = .1)\nplot_grid(p1, p2)"
  },
  {
    "objectID": "blog/2023/11/26/index.html#reference",
    "href": "blog/2023/11/26/index.html#reference",
    "title": "Learning Harmony to integrate single cell RNA-seq data for batch borrection and meta analysis",
    "section": "Reference",
    "text": "Reference\n\nhttps://portals.broadinstitute.org/harmony/index.html\nSingle-cell RNA-seq: Integration with Harmony"
  },
  {
    "objectID": "blog/2023/11/26/index.html#session-info",
    "href": "blog/2023/11/26/index.html#session-info",
    "title": "Learning Harmony to integrate single cell RNA-seq data for batch borrection and meta analysis",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n## R version 4.3.1 (2023-06-16)\n## Platform: aarch64-apple-darwin20 (64-bit)\n## Running under: macOS Sonoma 14.2\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \n## LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n## \n## locale:\n## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n## \n## time zone: Asia/Singapore\n## tzcode source: internal\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n##  [1] cowplot_1.1.1      here_1.0.1         lubridate_1.9.3    forcats_1.0.0     \n##  [5] stringr_1.5.1      dplyr_1.1.4        purrr_1.0.2        readr_2.1.4       \n##  [9] tidyr_1.3.0        tibble_3.2.1       ggplot2_3.4.4      tidyverse_2.0.0   \n## [13] Seurat_5.0.1       SeuratObject_5.0.1 sp_2.1-2           MUDAN_0.1.0       \n## [17] Matrix_1.6-3       harmony_1.1.0      Rcpp_1.0.11       \n## \n## loaded via a namespace (and not attached):\n##   [1] RcppAnnoy_0.0.21        splines_4.3.1           later_1.3.1            \n##   [4] bitops_1.0-7            polyclip_1.10-6         XML_3.99-0.15          \n##   [7] fastDummies_1.7.3       lifecycle_1.0.4         rprojroot_2.0.4        \n##  [10] edgeR_4.0.1             globals_0.16.2          lattice_0.22-5         \n##  [13] MASS_7.3-60             magrittr_2.0.3          limma_3.58.1           \n##  [16] plotly_4.10.3           rmarkdown_2.25          yaml_2.3.7             \n##  [19] httpuv_1.6.12           sctransform_0.4.1       spam_2.10-0            \n##  [22] spatstat.sparse_3.0-3   reticulate_1.34.0       pbapply_1.7-2          \n##  [25] DBI_1.1.3               RColorBrewer_1.1-3      abind_1.4-5            \n##  [28] zlibbioc_1.48.0         Rtsne_0.16              BiocGenerics_0.48.1    \n##  [31] RCurl_1.98-1.13         sva_3.50.0              GenomeInfoDbData_1.2.11\n##  [34] IRanges_2.36.0          S4Vectors_0.40.2        ggrepel_0.9.4          \n##  [37] irlba_2.3.5.1           listenv_0.9.0           spatstat.utils_3.0-4   \n##  [40] genefilter_1.84.0       goftest_1.2-3           RSpectra_0.16-1        \n##  [43] spatstat.random_3.2-2   annotate_1.80.0         fitdistrplus_1.1-11    \n##  [46] parallelly_1.36.0       leiden_0.4.3.1          codetools_0.2-19       \n##  [49] tidyselect_1.2.0        farver_2.1.1            matrixStats_1.1.0      \n##  [52] stats4_4.3.1            spatstat.explore_3.2-5  jsonlite_1.8.7         \n##  [55] ellipsis_0.3.2          progressr_0.14.0        ggridges_0.5.4         \n##  [58] survival_3.5-7          tools_4.3.1             ica_1.0-3              \n##  [61] glue_1.6.2              gridExtra_2.3           xfun_0.41              \n##  [64] mgcv_1.9-0              MatrixGenerics_1.14.0   GenomeInfoDb_1.38.0    \n##  [67] withr_2.5.2             fastmap_1.1.1           fansi_1.0.5            \n##  [70] digest_0.6.33           timechange_0.2.0        R6_2.5.1               \n##  [73] mime_0.12               colorspace_2.1-0        scattermore_1.2        \n##  [76] tensor_1.5              spatstat.data_3.0-3     RSQLite_2.3.3          \n##  [79] RhpcBLASctl_0.23-42     utf8_1.2.4              generics_0.1.3         \n##  [82] data.table_1.14.8       httr_1.4.7              htmlwidgets_1.6.3      \n##  [85] uwot_0.1.16             pkgconfig_2.0.3         gtable_0.3.4           \n##  [88] blob_1.2.4              lmtest_0.9-40           XVector_0.42.0         \n##  [91] htmltools_0.5.7         dotCall64_1.1-1         scales_1.3.0           \n##  [94] Biobase_2.62.0          png_0.1-8               knitr_1.45             \n##  [97] tzdb_0.4.0              reshape2_1.4.4          nlme_3.1-163           \n## [100] cachem_1.0.8            zoo_1.8-12              KernSmooth_2.23-22     \n## [103] vipor_0.4.5             parallel_4.3.1          miniUI_0.1.1.1         \n## [106] AnnotationDbi_1.64.1    ggrastr_1.0.2           pillar_1.9.0           \n## [109] grid_4.3.1              vctrs_0.6.5             RANN_2.6.1             \n## [112] promises_1.2.1          xtable_1.8-4            cluster_2.1.4          \n## [115] beeswarm_0.4.0          evaluate_0.23           cli_3.6.1              \n## [118] locfit_1.5-9.8          compiler_4.3.1          rlang_1.1.2            \n## [121] crayon_1.5.2            future.apply_1.11.0     labeling_0.4.3         \n## [124] ggbeeswarm_0.7.2        plyr_1.8.9              stringi_1.8.2          \n## [127] viridisLite_0.4.2       deldir_2.0-2            BiocParallel_1.36.0    \n## [130] munsell_0.5.0           Biostrings_2.70.1       lazyeval_0.2.2         \n## [133] spatstat.geom_3.2-7     RcppHNSW_0.5.0          hms_1.1.3              \n## [136] patchwork_1.1.3         bit64_4.0.5             future_1.33.0          \n## [139] KEGGREST_1.42.0         statmod_1.5.0           shiny_1.8.0            \n## [142] ROCR_1.0-11             igraph_1.5.1            memoise_2.0.1          \n## [145] bit_4.0.5"
  },
  {
    "objectID": "blog/2023/11/13/index.html",
    "href": "blog/2023/11/13/index.html",
    "title": "Using ggbeeswarm plot to represent categorical data",
    "section": "",
    "text": "The code is adapted from here\n\n### Load packages\npacman::p_load(ggplot2, dplyr, ggpubr, ggbeeswarm, readxl, rstatix, here)\n\n### Import dataset\ndataset &lt;- read_excel(here(\"learn\", \"Superplots_R_script\", \"data.xlsx\"))\n\n## Defines a colorblind-friendly palette\ncbPalette &lt;- c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\n## Order the variables on x-axis\ndataset$variable &lt;- factor(dataset$variable, levels = c(\"Before\", \"After\"))\n\n## Calculate averages of each replicate\nreplicate_mean &lt;- dataset |&gt; group_by(variable, replicate) |&gt; \n    summarise_at(vars(value), mean, na.rm =  TRUE) |&gt; \n    ungroup()\n### view the data\nreplicate_mean\n## # A tibble: 6 × 3\n##   variable replicate value\n##   &lt;fct&gt;        &lt;dbl&gt; &lt;dbl&gt;\n## 1 Before           1  20.8\n## 2 Before           2  23  \n## 3 Before           3  20.2\n## 4 After            1  51.4\n## 5 After            2  41.2\n## 6 After            3  55.8\n\n## Perform t-test of variable 1 and 2\n# t_test &lt;- t.test(\n#     x = replicate_mean$value[1:3],\n#     y = replicate_mean$value[4:6],\n#     alternative = \"two.sided\",\n#     var.equal =  TRUE\n# )\n### Retrieve the p-value for the t-test of variable 1 and 2\n# pvalue &lt;- t_test[\"p.value\"]\n\npvalue &lt;- replicate_mean |&gt; \n    t_test(value ~ variable) |&gt; \n    add_significance(p.col = \"p\")\n\n## Calculate total average\ntotal_mean &lt;- replicate_mean |&gt; \n    group_by(variable) |&gt; \n    summarise_at(vars(value), mean, na.rm = TRUE)\n\n\n## Plots Superplot based on biological repicate averags\nggplot(dataset, aes(x = variable, y = value, color = factor(replicate))) +\n    ### Add individual data points\n    geom_beeswarm(cex = 3) +\n    #### \"cex\" can be used to spread the data points if the averages are close together\n    \n    ### Add mean values as bars\n    stat_summary(data = total_mean, fun = mean, fun.min = mean, \n    fun.max = mean, geom = \"crossbar\", width = 0.25, color = \"black\") +\n    \n    ### Add error bars\n    stat_summary(data = replicate_mean, fun.data = mean_se, \n    geom = \"errorbar\", width = 0.1, color = \"black\", linewidth = 1) +\n\n    ### Add color palette\n    scale_color_manual(values = cbPalette) +\n\n    ### Add replicate averages as points\n    geom_beeswarm(data = replicate_mean, size = 5, color = \"gray\") +\n\n    ### Add pvalue\n    # stat_pvalue_manual(\n    #     pvalue, y.postion = 80, step.increase = 0.1,\n    #     label = \"p = {p.signif}\"\n    # ) +\n\n    ### Cosmetics and labeling\n    labs(x = \"\", y = \"Total counts\") +\n    theme_bw() + \n    theme(\n        axis.line = element_line(size = 1, colour = \"black\"),\n        legend.position = \"none\",\n        axis.title.y = element_text(family=\"Arial\", size=28, color = \"black\", vjust = 2),\n        axis.text = element_text(family=\"Arial\", size = 28, color = \"black\"),\n        axis.ticks = element_line(size = 1, color = \"black\"), \n        axis.ticks.length = unit(2, \"mm\"),\n        panel.grid.major = element_blank(), \n        panel.grid.minor = element_blank(),\n        panel.background = element_blank(), \n        panel.border = element_blank()\n    )"
  },
  {
    "objectID": "blog/2023/11/03/index.html",
    "href": "blog/2023/11/03/index.html",
    "title": "Best Practise for R programming",
    "section": "",
    "text": "Variables = my_variable\nFunctions = RunThisStuffs()\nConstants = CONSTANTS\nUse 4 spaces (and not tab) for indentations\nAlways writing documentation above function definition\nA function should not be longer than one screen\nAvoid using for loop, learn lapply and vector operations\nNever ever use hard-coded variables in functions\n### ====== to divide function blocks\n### ------ to divide parts in a function\nName and style code consistently\nrm(list =ls()) and gc() to tidy up its memory\nDon’t save a session history\nKeep track of sessionInfo() in project folder\nUse version control"
  },
  {
    "objectID": "blog/2023/10/01/index.html",
    "href": "blog/2023/10/01/index.html",
    "title": "General understanding of scRNA-seq data analysis",
    "section": "",
    "text": "Typical workflows including:\n\nSingle cell dissociation\n\ntissue is digested\n\nSingle cell isolation\n\nerrors can occur that lead to empty droplets, doublets, multiplets, non-viables cells\n\nLibrary construction\n\nwell or droplet contains the chemicals to break down the cell membrances\nintra cellular mRNA is captured, reverse-transcribed to cDNA molecules and amplified\nUniqiue molecular identifed (UMI) allow us to distinguish between amplified copies of the same mRNA molecule and reads from separate mRNA molecules transcribed from the same gene\nAmplification before sequencing is to increase its probility of being measured\n\nSequencing\n\ncDNA libraries are labelled with cellular barcodes\nlibraries are pooled together"
  },
  {
    "objectID": "blog/2023/10/01/index.html#experimental-scrna-seq-workflow",
    "href": "blog/2023/10/01/index.html#experimental-scrna-seq-workflow",
    "title": "General understanding of scRNA-seq data analysis",
    "section": "",
    "text": "Typical workflows including:\n\nSingle cell dissociation\n\ntissue is digested\n\nSingle cell isolation\n\nerrors can occur that lead to empty droplets, doublets, multiplets, non-viables cells\n\nLibrary construction\n\nwell or droplet contains the chemicals to break down the cell membrances\nintra cellular mRNA is captured, reverse-transcribed to cDNA molecules and amplified\nUniqiue molecular identifed (UMI) allow us to distinguish between amplified copies of the same mRNA molecule and reads from separate mRNA molecules transcribed from the same gene\nAmplification before sequencing is to increase its probility of being measured\n\nSequencing\n\ncDNA libraries are labelled with cellular barcodes\nlibraries are pooled together"
  },
  {
    "objectID": "blog/2023/10/01/index.html#file-formats-produced-by-sequencing",
    "href": "blog/2023/10/01/index.html#file-formats-produced-by-sequencing",
    "title": "General understanding of scRNA-seq data analysis",
    "section": "File formats produced by sequencing",
    "text": "File formats produced by sequencing"
  },
  {
    "objectID": "blog/2023/10/01/index.html#quality-control-of-raw-reads",
    "href": "blog/2023/10/01/index.html#quality-control-of-raw-reads",
    "title": "General understanding of scRNA-seq data analysis",
    "section": "Quality control of raw reads",
    "text": "Quality control of raw reads\nQuality control is performed to ensure that the data quality is sufficient for downstream analysis. The QC can be performed in cell level, transcript level and count data directly.\nTo check the integrity of cel, cell QC is commonly performed based on three covariates:\n\nCount depth: the number of counts per barcode\nThe number of genes per barcode\nThe fraction of counts from mitochondrial genes per barcode\n\n\nMake sure all cellular bacode data correspond to viable cells\nall reads assigned to the same barcode may not correspond to reads from the cells as a barcode may mistakenly tag multiple cells (doublet) or may not tag any cells (empty droplet)\n\nThe distribution of these QC covariates are examined for outlier peaks that filtered out by thresholding. Condieration any of these three QC covariates in isolation can lead to misinterpretation of cellular signals. These thresholds shoule be set as permissive as possible to avoid filtering out viable cell populations unintentionally.\n\nCells with high a comparatively high fraction of mitochandrial counts maybe involved in respiratory process\nCells with low counts and/or genes may correspond to quiecent cells population\nCells with high counts maybe larger in size\n\n\n\n\n\n\n\nTip\n\n\n\n\nPerform QC by finding outlier peaks in the number of genes, the count depth and the fraction of mitochondrial reads. Consider these covariates jointly instead of separtely\nBe as permissive of QC thresholding as possible, and revisit QC if downstream clustering cannot be interpreted\nIf the distribution of QC covariates differ between samples, QC thresholds should be determined separately for each sample to account for sample quality differences."
  },
  {
    "objectID": "blog/2023/10/01/index.html#mapping-reads-to-cellular-barcodes-and-origin-mrna-molecules",
    "href": "blog/2023/10/01/index.html#mapping-reads-to-cellular-barcodes-and-origin-mrna-molecules",
    "title": "General understanding of scRNA-seq data analysis",
    "section": "Mapping reads to cellular barcodes and origin mRNA molecules",
    "text": "Mapping reads to cellular barcodes and origin mRNA molecules\n\nTools that same as those used in bulk RNA-seq are available for this procedure, including:\n\nBurrows-Wheeler Aligner (BWA)\nSTAR\nKallisto\nSailfish\nSalmon\n\nOnly reads that map to exonic loci with high mapping quality are considered for generation of the gene expression matrix."
  },
  {
    "objectID": "blog/2023/10/01/index.html#normalization-for-quantification-of-expression",
    "href": "blog/2023/10/01/index.html#normalization-for-quantification-of-expression",
    "title": "General understanding of scRNA-seq data analysis",
    "section": "Normalization for quantification of expression",
    "text": "Normalization for quantification of expression\nWhy need to do normaliztion?\nEach count in a count matrix represents the successful capture, reverse transciption, and sequencing of a molecule of cellular mRNA. Count depths for identical cellss can differ due to the variability inherent in each of these steps. These variables are usually difficult to estimate and thus typically modeled as fixed effects. Thus, when gene expression is compared betwen cells based on count data, any difference may have arisen solely due to sampling effects. So Normalization address this issue by scaling count data to obtain correct relative gene expression abundances between cells.\n\nThese three metrics attempt to normalize for sequencing depth and gene length. Here’s how you do it for RPKM:\n\nCount up the total reads in a sample and divide that number by 1,000,000 – this is our “per million” scaling factor.\nDivide the read counts by the “per million” scaling factor. This normalizes for sequencing depth, giving you reads per million (RPM)\nDivide the RPM values by the length of the gene, in kilobases. This gives you RPKM.\n\nFPKM is very similar to RPKM. RPKM was made for single-end RNA-seq, where every read corresponded to a single fragment that was sequenced. FPKM was made for paired-end RNA-seq. With paired-end RNA-seq, two reads can correspond to a single fragment, or, if one read in the pair did not map, one read can correspond to a single fragment. The only difference between RPKM and FPKM is that FPKM takes into account that two reads can map to one fragment (and so it doesn’t count this fragment twice).\n\nTPM is very similar to RPKM and FPKM. The only difference is the order of operations. Here’s how you calculate TPM:\n\nDivide the read counts by the length of each gene in kilobases. This gives you reads per kilobase (RPK).\nCount up all the RPK values in a sample and divide this number by 1,000,000. This is your “per million” scaling factor.\nDivide the RPK values by the “per million” scaling factor. This gives you TPM.\n\nWhen calculating TPM, the only difference is that you normalize for gene length first, and then normalize for sequencing depth second. However, the effects of this difference are quite profound.\nWhen you use TPM, the sum of all TPMs in each sample are the same. This makes it easier to compare the proportion of reads that mapped to a gene in each sample. In contrast, with RPKM and FPKM, the sum of the normalized reads in each sample may be different, and this makes it harder to compare samples directly.\nHere’s an example. If the TPM for gene A in Sample 1 is 3.33 and the TPM in sample B is 3.33, then I know that the exact same proportion of total reads mapped to gene A in both samples. This is because the sum of the TPMs in both samples always add up to the same number (so the denominator required to calculate the proportions is the same, regardless of what sample you are looking at.)\nWith RPKM or FPKM, the sum of normalized reads in each sample can be different. Thus, if the RPKM for gene A in Sample 1 is 3.33 and the RPKM in Sample 2 is 3.33, I would not know if the same proportion of reads in Sample 1 mapped to gene A as in Sample 2. This is because the denominator required to calculate the proportion could be different for the two samples.\nUsing RPKM/FPKM normalization, the total number of RPKM/FPKM normalized counts for each sample will be different. Therefore, you cannot compare the normalized counts for each gene equally between samples.\n\nSeveral common normalization methods exist to account for these differences:\n\n\nNormalization method\nDescription\nAccounted factors\nRecommendations for use\n\n\n\n\nCPM (counts per million)\ncounts scaled by total number of reads\nsequencing depth\ngene count comparisons between replicates of the same samplegroup; NOT for within sample comparisons or DE analysis\n\n\nTPM (transcripts per kilobase million)\ncounts per length of transcript (kb) per million reads mapped\nsequencing depth and gene length\ngene count comparisons within a sample or between samples of the same sample group; NOT for DE analysis\n\n\nRPKM/FPKM (reads/fragments per kilobase of exon per million reads/fragments mapped)\nsimilar to TPM\nsequencing depth and gene length\ngene count comparisons between genes within a sample; NOT for between sample comparisons or DE analysis\n\n\nDESeq2’s median of ratios [1]\ncounts divided by sample-specific size factors determined by median ratio of gene counts relative to geometric mean per gene\nsequencing depth and RNA composition\ngene count comparisons between samples and for DE analysis; NOT for within sample comparisons\n\n\nEdgeR’s trimmed mean of M values (TMM) [2]\nuses a weighted trimmed mean of the log expression ratios between samples\nsequencing depth, RNA composition\ngene count comparisons between samples and for DE analysis; NOT for within sample comparisons\n\n\n\nSource - StatQuest, RPKM, FPKM and TPM, clearly explained, Count normalization with DESeq2\n\n\n\n\n\n\nNote\n\n\n\n\nWhile TPM and RPKM/FPKM normalization methods both account for sequencing depth and gene length, RPKM/FPKM are not recommended. The reason is that the normalized count values output by the RPKM/FPKM method are not comparable between samples.\nNormalized data should be log(x=1)-transformed for use with downstream analysis methods that assume data are normally distributed"
  },
  {
    "objectID": "blog/2023/10/01/index.html#estimate-confounding-factors",
    "href": "blog/2023/10/01/index.html#estimate-confounding-factors",
    "title": "General understanding of scRNA-seq data analysis",
    "section": "Estimate confounding factors",
    "text": "Estimate confounding factors\nThe observed read counts are affected by a combination of different factors, including biological variables and technical noise.\nBatch effects, systematic differences that are unrelated to any biological variation and result from sample preparation conditions, are often prominent."
  },
  {
    "objectID": "blog/2023/10/01/index.html#data-correction-and-integration",
    "href": "blog/2023/10/01/index.html#data-correction-and-integration",
    "title": "General understanding of scRNA-seq data analysis",
    "section": "Data correction and integration",
    "text": "Data correction and integration\nNormalized data may still contain unwanted variability. Data correction targets further technical and biological variability covariates suchs as\nBiological effects: - Cell cycle effects on transcriptome - mitochondrial gene expression\nTechnical effects: - Count depth - Batch effect - Dropout (noise)\nConsider the correction for biological and technical covariates separtely as these are used for different purpose and present unique challenge."
  },
  {
    "objectID": "blog/2023/10/01/index.html#feature-selection-and-dimensionality-reduction",
    "href": "blog/2023/10/01/index.html#feature-selection-and-dimensionality-reduction",
    "title": "General understanding of scRNA-seq data analysis",
    "section": "Feature selection and dimensionality reduction",
    "text": "Feature selection and dimensionality reduction"
  },
  {
    "objectID": "blog/2023/10/01/index.html#cluster-analysis",
    "href": "blog/2023/10/01/index.html#cluster-analysis",
    "title": "General understanding of scRNA-seq data analysis",
    "section": "Cluster analysis",
    "text": "Cluster analysis\nAfter pre-processing, we can perform downstream anslysis to extract biological insights and describe the underlying biological system. These descriptions are obtained by fitting interpretable models to the data.\n\nGroup of cells with similary gene expression profiles representing cell-type clusters\nSmall changes in gene expression between similar cells denoting continuous (differentiation) trajectories\nGenes with correlated expression profiles indicating co-regulation\n\n\nIdentifying Clusters\nCluster analysis methods attempt to explain the heterogenity in the data based on a categorization of cells into groups.\nClusters are obtained by grouping cells based on the similarity of their gene expression profiles.\nSimilarity scores:\n\nEuclidean distance\nClustering algorithms\n\nK-means\n\nCommunity detection\n\nK-Nearest Neighbour\n\n\n\n\nCluster annotation\nMarker genes characterize the cluster and are used to annotate it with a meanningful biological label.\n\n\n\n\n\n\nNote\n\n\n\n\nIt is not always clear what constitutes a cell type\ncells of the same cell type in different states maybe detected in separte clusters\n\n\n\n\nReference databases\nMarker genes from the literature\nData-drived marker genes\n\nFocus on up-regulated genes in the cluster as marker genes are expected to have strong differential expression effects\nrank-sum test or t-test to rank genes\nTop-ranked genes are regarded as marker genes\n\n\nP-values are often inflated, which can lead to an overestimation of the number of marker genes. However, the ranking of genes based on p-values is unaffected\n\n\nCompositional analysis\nCompositional data analysis revolves around the proporations of cells that fall into each cell-identity cluster.\n\n\nTrajectory inference\nTrajectory analysis in the data are regarded as a snapshot of a dynamic process, which investigate the underlying process.\nThe biological processes that drive the development of the observed heterogenity are continuous process.\nTrajectory inference methods interpret single-cell data as a snapshot of a continuous process. This process is reconstructed by finding paths through cellular space that minimize transcriptional changes between neighbouring cells. The ordering of cells along these paths is described by a pseudotime variable. While this variable is related to transcriptional distances from a root cell, tt is often inter- preted as a proxy for developmental time"
  },
  {
    "objectID": "blog/2023/10/01/index.html#gene-level-downstream-analysis",
    "href": "blog/2023/10/01/index.html#gene-level-downstream-analysis",
    "title": "General understanding of scRNA-seq data analysis",
    "section": "Gene-level downstream analysis",
    "text": "Gene-level downstream analysis\n\nDifferential expression testing\nDE is to answer the question whether any genes are differntially expressed between two experimental conditions\nTools are commonly used:\n\nDESeq2\nEdgeR\nlimma\n\n\n\n\n\n\n\nNote\n\n\n\n\nDE testing should not be performed on corrected data (denoised, batch corrected, etc), but instead on measured data with technical covariates included in the model\n\n\n\n\n\nGene set analsysis\nTo further interpret the long list of candidate genes that maybe differentially expressed between treated and control cells, we can group the genes into sets based on characteristics and testing whether these characteristics are overrepresented in the candidate gene list.\nCommon biological processes labels:\n\nMSigDB\nGene Ontology\nKEGG\nReactome\n\n\n\nGene regulatory networks\nThe expression level of a gene is determined by a complex interplay of regulatory interactions with other genes and small molecules.\nGene regulatory network inference is performed based on measurement of gene co-expression such as correlation, mutual information, or via regression models."
  },
  {
    "objectID": "blog/2023/10/01/index.html#analysis-platforms",
    "href": "blog/2023/10/01/index.html#analysis-platforms",
    "title": "General understanding of scRNA-seq data analysis",
    "section": "Analysis platforms",
    "text": "Analysis platforms\n\nScater (R, Strength in QC and pre-processing)\nSeurat (R, Comprehensive)\nscanpy (Python-based)"
  },
  {
    "objectID": "blog/2023/10/01/index.html#reference",
    "href": "blog/2023/10/01/index.html#reference",
    "title": "General understanding of scRNA-seq data analysis",
    "section": "Reference",
    "text": "Reference\n\nSingle-cell RNA-seq: raw sequencing data to counts\nFile formats produced by sequencing\nRNA-seqlopedia - Created by the Univ. of Orgeon, this is a great resource for understanding the entire RNAseq workflow.\nSequencEnG - An interactive learning resource for next-generation sequencing (NGS) techniques\nNext-Generation Sequencing Analysis - provide hands on experience with analyzing next generation sequencing. Standard pipelines are presented that provide the user with and step-by-step guide to using state of the art bioinformatics tools\nSingle Cell Gene Expression\nThe Essence of scRNA-Seq Clustering: Why and How to Do it Right\nHow to Use t-SNE Effectively\nTen quick tips for effective dimensionality reduction\nHypergeometric test and Fisher’s exact test\nBioinformatics Training at the Harvard Chan Bioinformatics Core\nANALYSIS OF SINGLE CELL RNA-SEQ DATA"
  },
  {
    "objectID": "blog/2023/08/09/index.html",
    "href": "blog/2023/08/09/index.html",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "",
    "text": "Batch effects are sub-groubs of measurements that have qualitatively different behaviour across conditions and unrelated to the biological or scientific variables in a study. - Experiments run on different time - Different technician - Differnt doing the sample preparation - Sequencing at a differnt institute - Prepare the sample at different timepoint - Different lots of reagents, chips or instruments …\nAll of these factors are considered to be factors as batches"
  },
  {
    "objectID": "blog/2023/08/09/index.html#what-is-batch-effect",
    "href": "blog/2023/08/09/index.html#what-is-batch-effect",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "",
    "text": "Batch effects are sub-groubs of measurements that have qualitatively different behaviour across conditions and unrelated to the biological or scientific variables in a study. - Experiments run on different time - Different technician - Differnt doing the sample preparation - Sequencing at a differnt institute - Prepare the sample at different timepoint - Different lots of reagents, chips or instruments …\nAll of these factors are considered to be factors as batches"
  },
  {
    "objectID": "blog/2023/08/09/index.html#why-is-batch-effect-a-problem",
    "href": "blog/2023/08/09/index.html#why-is-batch-effect-a-problem",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "Why is batch effect a problem",
    "text": "Why is batch effect a problem\n\nNot biological difference\nJust the other factors are taking actions, and are showing differences\nMost of the time, batch effect deviate our finding from the real biological relevant information\n\nTry our best to eliminate batch effect to get a real difference between conditions!"
  },
  {
    "objectID": "blog/2023/08/09/index.html#sva-package-for-removing-batch-effects",
    "href": "blog/2023/08/09/index.html#sva-package-for-removing-batch-effects",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "SVA package for removing batch effects",
    "text": "SVA package for removing batch effects\nThe assumption is that you will be trying to analyze the association between the variables of interest and gene expression, adjusting for the adjustment variables"
  },
  {
    "objectID": "blog/2023/08/09/index.html#setting-up-the-data-from-an-expressionset",
    "href": "blog/2023/08/09/index.html#setting-up-the-data-from-an-expressionset",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "Setting up the data from an ExpressionSet",
    "text": "Setting up the data from an ExpressionSet\n\nThe data should be a matrix with features in the rows and samples in the columns.\nThe data should be standardized before applying for correction.\n\n\n\n### Load packages\nlibrary(here)\nlibrary(tidyverse)\nlibrary(sva)\nlibrary(bladderbatch)\nlibrary(pamr)\nlibrary(limma)\nlibrary(survival)\n\n\n### load data\ndata(bladderdata)\n### variable data\npheno &lt;- pData(bladderEset)\nclass(pheno)\n## [1] \"data.frame\"\nhead(pheno, n = 5)\n##              sample outcome batch cancer\n## GSM71019.CEL      1  Normal     3 Normal\n## GSM71020.CEL      2  Normal     2 Normal\n## GSM71021.CEL      3  Normal     2 Normal\n## GSM71022.CEL      4  Normal     3 Normal\n## GSM71023.CEL      5  Normal     3 Normal\n### expression data matrix\nedata &lt;- exprs(bladderEset)\nclass(edata)\n## [1] \"matrix\" \"array\"\nhead(edata[, 1:5])\n##           GSM71019.CEL GSM71020.CEL GSM71021.CEL GSM71022.CEL GSM71023.CEL\n## 1007_s_at    10.115170     8.628044     8.779235     9.248569    10.256841\n## 1053_at       5.345168     5.063598     5.113116     5.179410     5.181383\n## 117_at        6.348024     6.663625     6.465892     6.116422     5.980457\n## 121_at        8.901739     9.439977     9.540738     9.254368     8.798086\n## 1255_g_at     3.967672     4.466027     4.144885     4.189338     4.078509\n## 1294_at       7.775183     7.110154     7.248430     7.017220     7.896419\n### create full model matrix, including both the adjustment variables and the variable of interest (cancer status)\nmod &lt;- model.matrix(~ as.factor(cancer), data = pheno)\n### Create null model matrix, ontains only the adjustment variables.\nmod0 &lt;- model.matrix(~ 1, data = pheno)"
  },
  {
    "objectID": "blog/2023/08/09/index.html#eestimate-batch-effect-and-other-artifacts-using-sva",
    "href": "blog/2023/08/09/index.html#eestimate-batch-effect-and-other-artifacts-using-sva",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "Eestimate batch effect and other artifacts using sva",
    "text": "Eestimate batch effect and other artifacts using sva\n\n### identify the number of latent factors that need to be estimated\nn_sv &lt;- num.sv(edata, mod, method = \"leek\")\nn_sv\n## [1] 2\n## estimate the surrogate variables\nsvaobj &lt;- sva(edata, mod, mod0, n.sv = n_sv)\n## Number of significant surrogate variables is:  2 \n## Iteration (out of 5 ):1  2  3  4  5\nstr(svaobj)\n## List of 4\n##  $ sv       : num [1:57, 1:2] -0.02717 -0.00618 0.07737 -0.00114 -0.02062 ...\n##  $ pprob.gam: num [1:22283] 0.999 0.977 1 1 1 ...\n##  $ pprob.b  : num [1:22283] 0.9956 0.9998 0.0702 0.9998 1 ...\n##  $ n.sv     : num 2\nsummary(lm(svaobj$sv ~ pheno$batch))\n## Response Y1 :\n## \n## Call:\n## lm(formula = Y1 ~ pheno$batch)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.26953 -0.11076  0.00787  0.10399  0.19069 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)\n## (Intercept) -0.018470   0.038694  -0.477    0.635\n## pheno$batch  0.006051   0.011253   0.538    0.593\n## \n## Residual standard error: 0.1345 on 55 degrees of freedom\n## Multiple R-squared:  0.00523,    Adjusted R-squared:  -0.01286 \n## F-statistic: 0.2891 on 1 and 55 DF,  p-value: 0.5929\n## \n## \n## Response Y2 :\n## \n## Call:\n## lm(formula = Y2 ~ pheno$batch)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.23973 -0.07467 -0.02157  0.08116  0.25629 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  0.121112   0.034157   3.546 0.000808 ***\n## pheno$batch -0.039675   0.009933  -3.994 0.000194 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.1187 on 55 degrees of freedom\n## Multiple R-squared:  0.2248, Adjusted R-squared:  0.2107 \n## F-statistic: 15.95 on 1 and 55 DF,  p-value: 0.0001945\nboxplot(svaobj$sv[, 2] ~ pheno$batch)\npoints(svaobj$sv[, 2] ~ jitter(as.numeric(pheno$batch)), col = as.numeric(pheno$batch))\n\n\n\n\n\n\ndev.off()\n## null device \n##           1"
  },
  {
    "objectID": "blog/2023/08/09/index.html#adjusting-for-surrogate-variables-using-f.pvalue-function",
    "href": "blog/2023/08/09/index.html#adjusting-for-surrogate-variables-using-f.pvalue-function",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "Adjusting for surrogate variables using f.pvalue function",
    "text": "Adjusting for surrogate variables using f.pvalue function\n\n### calculate the parametric F-test p-values for each row of a data matrix\npvalues &lt;- f.pvalue(edata, mod, mod0)\n### adjust them for multiple teseting\nqvalues &lt;- p.adjust(pvalues, method = \"BH\")\n\nNearly 70% of the genes are strongly differentially expressed at an FDR of less than 5% between groups.\nThis number seems artifically high.\nGet the adjusted p-values and q-values accounting for surrogate variables.\n\n### include the surrogate variables\nmodsv &lt;- cbind(mod, svaobj$sv)\nmod0sv &lt;- cbind(mod0, svaobj$sv)\npvalues_sv &lt;- f.pvalue(edata, modsv, mod0sv)\nqvalues_sv &lt;- p.adjust(pvalues, method = \"BH\")"
  },
  {
    "objectID": "blog/2023/08/09/index.html#adjusting-for-surrogate-variables-using-the-limma",
    "href": "blog/2023/08/09/index.html#adjusting-for-surrogate-variables-using-the-limma",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "Adjusting for surrogate variables using the limma",
    "text": "Adjusting for surrogate variables using the limma\n\n### fit the linear model with the surrogate variabels\nfit &lt;- lmFit(edata, modsv)\n### compute the contrasts between cancer/normal terms\ncontrast_matrix &lt;- cbind(\n  \"C1\" = c(-1, 1, 0, rep(0, svaobj$n.sv)),\n  \"C2\" = c(0, -1, 1, rep(0, svaobj$n.sv))\n)\nfit_contrasts &lt;- contrasts.fit(fit, contrast_matrix)\n\n### calculate the test statistics\neb &lt;- eBayes(fit_contrasts)\ntopTableF(eb, adjust = \"BH\")\n## topTableF is obsolete and will be removed in a future version of limma. Please considering using topTable instead.\n##                    C1          C2   AveExpr        F      P.Value    adj.P.Val\n## 207783_x_at -13.45607  0.26592268 12.938786 8622.529 1.207531e-69 1.419929e-65\n## 201492_s_at -13.27594  0.15357702 13.336090 8605.649 1.274450e-69 1.419929e-65\n## 208834_x_at -12.76411  0.06134018 13.160201 6939.501 4.749368e-67 3.527673e-63\n## 212869_x_at -13.77957  0.26008165 13.452076 6593.346 1.939773e-66 1.080599e-62\n## 212284_x_at -13.59977  0.29135767 13.070844 5495.716 2.893287e-64 1.289423e-60\n## 208825_x_at -12.70979  0.08250821 13.108072 5414.741 4.350100e-64 1.615555e-60\n## 211445_x_at -10.15890 -0.06633356  9.853817 5256.114 9.845076e-64 3.133969e-60\n## 213084_x_at -12.59345  0.03015520 13.046529 4790.107 1.260201e-62 3.510132e-59\n## 201429_s_at -13.33686  0.28358293 12.941208 4464.995 8.675221e-62 2.147888e-58\n## 214327_x_at -12.60146  0.20934783 11.832607 4312.087 2.257025e-61 5.029329e-58"
  },
  {
    "objectID": "blog/2023/08/09/index.html#adjusting-for-known-batches-using-combat",
    "href": "blog/2023/08/09/index.html#adjusting-for-known-batches-using-combat",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "Adjusting for known batches using Combat",
    "text": "Adjusting for known batches using Combat\nComBat returns a “cleaned” data matrix after batch effects have been removed. Here we pass a model matrix with any known adjustment variables and a second parameter that is the batch variable.\n\n### get known batch variable\nbatch &lt;- pheno$batch\n### model matrix\nmodcombat &lt;- model.matrix(~1, data = pheno)\nmodcancer &lt;- model.matrix(~cancer, data = pheno)\n\n### Using parametric empirical Bayesian adjustments.\ncombat_edata &lt;- ComBat(\n    dat = edata,\n    batch = batch, \n    mod = modcombat,\n    par.prior = TRUE, # performs parametric empirical Bayesian adjustment\n    # par.prior = FALSE, # performs non-parametric empirical Bayesian adjustment\n    prior.plots = FALSE,\n    mean.only = FALSE, # only adjust the mean of the batch effects across batches\n    ref.batch = NULL\n)\n\n### significance analysis\npvalue_combat &lt;- f.pvalue(combat_edata, mod, mod0)\nqvalue_combat &lt;- p.adjust(pvalue_combat, method = \"BH\")\n\ncombat_fit &lt;- lm.fit(modcancer, t(combat_edata))\nhist(combat_fit$coefficients[2, ], col = 4, breaks = 100)"
  },
  {
    "objectID": "blog/2023/08/09/index.html#removing-known-batch-effects-with-a-linear-model",
    "href": "blog/2023/08/09/index.html#removing-known-batch-effects-with-a-linear-model",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "Removing known batch effects with a linear model",
    "text": "Removing known batch effects with a linear model\nIn this case, we use two models. - One with the variable we care about - cancer status - the other is just the known adjustment variables, in this case, we assume none\n\nmod_batch &lt;- model.matrix(~as.factor(cancer) + as.factor(batch), data = pheno)\nmod0_batch &lt;- model.matrix(~as.factor(batch), data = pheno)\npvalues_batch &lt;- f.pvalue(edata, mod_batch, mod0_batch)\nqvalues_batch &lt;- p.adjust(pvalues_batch, method = \"BH\")\n\nfit &lt;- lm.fit(mod_batch, t(edata))\nhist(fit$coefficients[2, ], col = 4, breaks = 100)"
  },
  {
    "objectID": "blog/2023/08/09/index.html#comparing-combat-and-linear-adjustment",
    "href": "blog/2023/08/09/index.html#comparing-combat-and-linear-adjustment",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "Comparing ComBat and linear adjustment",
    "text": "Comparing ComBat and linear adjustment\nWe can compare the estimated coefficients from Combat and linear adjustment by looking at the right coefficients for each model.\n\nplot(\n  fit$coefficients[2, ], combat_fit$coefficients[2, ], col = 4,\n  xlab = \"Linear Model\", ylab = \"Combat\", xlim = c(-5, 5), ylim = c(-5, 5)\n)\nabline(c(0, 1), col = 2, lwd = 3)\n\n\n\n\n\n\ndev.off()\n## null device \n##           1\n\n\n### Add the surrogate variables to the model matrix and perform model fit\nmodsv &lt;- cbind(mod, svaobj$sv)\nfitsv &lt;- lm.fit(modsv, t(edata))\n\n### Compare the fit from surrogate variable analysis to the other two\npar(mfrow = c(1, 2))\nplot(\n  fitsv$coefficients[2,], combat_fit$coefficients[2, ], \n  col = 2, xlab = \"SVA\", ylab = \"Combat\", xlim = c(-5, 5), ylim = c(-5, 5)\n)\nabline(c(0, 1), col = 1, lwd = 3)\nplot(\n  fitsv$coefficients[2,], fit$coefficients[2, ], \n  col = 2, xlab = \"SVA\", ylab = \"Linear model\", xlim = c(-5, 5), ylim = c(-5, 5)\n)\nabline(c(0, 1), col = 1, lwd = 3)\n\n\n\n\n\n\ndev.off()\n## null device \n##           1"
  },
  {
    "objectID": "blog/2023/08/09/index.html#combat-seq-for-batch-adjustment-on-rna-seq-count-data",
    "href": "blog/2023/08/09/index.html#combat-seq-for-batch-adjustment-on-rna-seq-count-data",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "Combat-seq for batch adjustment on RNA-seq count data",
    "text": "Combat-seq for batch adjustment on RNA-seq count data\n\n### expression matrix\ncount_matrix &lt;- matrix(\n  rnbinom(400, size = 10, prob =  0.1),\n  nrow = 50, ncol = 8\n)\n### batch\nbatch &lt;- c(rep(1, 4), rep(2, 4))\n\n### adjust\nadjusted &lt;- ComBat_seq(\n  count_matrix, \n  batch = batch, \n  group = NULL\n)\n## Found 2 batches\n## Using null model in ComBat-seq.\n## Adjusting for 0 covariate(s) or covariate level(s)\n## Estimating dispersions\n## Fitting the GLM model\n## Shrinkage off - using GLM estimates for parameters\n## Adjusting the data\n\n### specify one biological variable\ngroup &lt;- rep(c(0, 1), 4)\nadjusted_counts &lt;- ComBat_seq(\n  count_matrix, \n  batch = batch, \n  group = group\n)\n## Found 2 batches\n## Using full model in ComBat-seq.\n## Adjusting for 1 covariate(s) or covariate level(s)\n## Estimating dispersions\n## Fitting the GLM model\n## Shrinkage off - using GLM estimates for parameters\n## Adjusting the data\n\n### multiple biological variabels\ncov1 &lt;- rep(c(0, 1), 4)\ncov2 &lt;- c(0, 0, 1, 1, 0, 0, 1, 1)\ncovar_mat &lt;- cbind(cov1, cov2)\nadjusted_counts &lt;- ComBat_seq(\n  count_matrix, \n  batch = batch, \n  group = NULL, \n  covar_mod = covar_mat\n)\n## Found 2 batches\n## Using null model in ComBat-seq.\n## Adjusting for 2 covariate(s) or covariate level(s)\n## Estimating dispersions\n## Fitting the GLM model\n## Shrinkage off - using GLM estimates for parameters\n## Adjusting the data"
  },
  {
    "objectID": "blog/2023/08/09/index.html#variance-filtering-to-speed-computations",
    "href": "blog/2023/08/09/index.html#variance-filtering-to-speed-computations",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "Variance filtering to speed computations",
    "text": "Variance filtering to speed computations\n\nn_sv &lt;- num.sv(edata, mod, vfilter = 2000, method = \"leek\")\nsvaobj &lt;- sva(edata, mod, mod0, n.sv = n_sv, vfilter = 2000)\n## Number of significant surrogate variables is:  46 \n## Iteration (out of 5 ):1  2  3  4  5"
  },
  {
    "objectID": "blog/2023/08/09/index.html#applying-the-fsva-function-to-remove-batch-effects-for-prediction",
    "href": "blog/2023/08/09/index.html#applying-the-fsva-function-to-remove-batch-effects-for-prediction",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "Applying the fsva function to remove batch effects for prediction",
    "text": "Applying the fsva function to remove batch effects for prediction\n\n### seprate data to traning and test set\nset.seed(12354)\ntrain_indicator &lt;- sample(1:57, size = 30, replace = FALSE)\ntest_indicator &lt;- (1:57)[-train_indicator]\ntrain_data &lt;- edata[, train_indicator]\ntest_data &lt;- edata[, test_indicator]\ntrain_pheno &lt;- pheno[train_indicator, ]\ntest_pheno &lt;- pheno[test_indicator, ]\n\n### pamr package can be used to train a predictive model and test that prediction\nmydata &lt;- list(x = train_data, y = train_pheno$cancer)\nmytrain &lt;- pamr.train(mydata)\n## 123456789101112131415161718192021222324252627282930\ntable(\n  pamr.predict(mytrain, test_data, threshold = 2),\n  test_pheno$cancer\n)\n##         \n##          Biopsy Cancer Normal\n##   Biopsy      4      0      0\n##   Cancer      0     15      0\n##   Normal      1      4      3\n\n### calculate surrogate variables for training set\ntrain_mod &lt;- model.matrix(~cancer, data = train_pheno)\ntrain_mod0 &lt;- model.matrix(~1, data = train_pheno)\ntrain_sv &lt;- sva(train_data, train_mod, train_mod0)\n## Number of significant surrogate variables is:  5 \n## Iteration (out of 5 ):1  2  3  4  5\n\n### adjust both the training data and the test data\nfsvaobj &lt;- fsva(train_data, train_mod, train_sv, test_data)\nmydata_sv &lt;- list(x = fsvaobj$db, y = train_pheno$cancer)\nmytrain_sv &lt;- pamr.train(mydata_sv)\n## 123456789101112131415161718192021222324252627282930"
  },
  {
    "objectID": "blog/2023/08/09/index.html#reference",
    "href": "blog/2023/08/09/index.html#reference",
    "title": "Combat to remove batch effects in high-throughput experiments",
    "section": "Reference",
    "text": "Reference\n\nBatch effects and confounders\nThe SVA package for removing batch effects and other unwanted variation in high-throughput experiments\nManaging batch effects"
  },
  {
    "objectID": "blog/2023/08/07/index.html",
    "href": "blog/2023/08/07/index.html",
    "title": "Install Conda to manage R/Python environments and packages",
    "section": "",
    "text": "### Download  mambaforge or miniforge\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\n\n### chmod \nchmod +x ./Miniforge3-Linux-x86_64.sh\n\n### Install to /home/usr/opt/miniforge3\nbash ./Miniforge3-Linux-x86_64.sh\n\n### Running a newer MacOS that uses the zsh shell.\nconda init zsh"
  },
  {
    "objectID": "blog/2023/08/07/index.html#install-conda",
    "href": "blog/2023/08/07/index.html#install-conda",
    "title": "Install Conda to manage R/Python environments and packages",
    "section": "",
    "text": "### Download  mambaforge or miniforge\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\n\n### chmod \nchmod +x ./Miniforge3-Linux-x86_64.sh\n\n### Install to /home/usr/opt/miniforge3\nbash ./Miniforge3-Linux-x86_64.sh\n\n### Running a newer MacOS that uses the zsh shell.\nconda init zsh"
  },
  {
    "objectID": "blog/2023/08/07/index.html#configuring-conda",
    "href": "blog/2023/08/07/index.html#configuring-conda",
    "title": "Install Conda to manage R/Python environments and packages",
    "section": "Configuring conda",
    "text": "Configuring conda\n### Make sure conda works\nconda info #to view all the details about your conda set-up\nconda info --envs #to view all the environments available to you (note, since you just installed miniconda, you'll only have a 'base' environment available)\n\n### initialize your shell\n\n\n### Install mamba\nconda install -c conda-forge mamba\n### Access to various channels where many pre-packaged bioinformatics programs can be downloaded with all their dependencies\nconda config --add channels defaults\nconda config --add channels bioconda\nconda config --add channels conda-forge\nconda config --set offline false"
  },
  {
    "objectID": "blog/2023/08/07/index.html#create-environment",
    "href": "blog/2023/08/07/index.html#create-environment",
    "title": "Install Conda to manage R/Python environments and packages",
    "section": "Create environment",
    "text": "Create environment\n\n### Conda environment makes managing dependencies much less frustrating\nconda create --name rnaseq \nconda activate rnaseq \n\n### Install some commonly used RNA-seq software inside this environment\n# conda config --add subdirs osx-64 \n# conda install -c bioconda kallisto # then install kallisto and centrifuge in their respective enivronments\n# conda search -c conda-forge -c bioconda 'kallisto[subdir=osx-arm64]' # for M1 mac user \n\nkallisto # test it works\nconda install -c bioconda fastqc\nconda install -c bioconda multiqc"
  },
  {
    "objectID": "blog/2023/08/07/index.html#using-r-with-conda",
    "href": "blog/2023/08/07/index.html#using-r-with-conda",
    "title": "Install Conda to manage R/Python environments and packages",
    "section": "Using R with Conda",
    "text": "Using R with Conda\n### Create a new conda environment with all the r-essentials conda packages built from CRAN\nconda create -n renv r-essentials r-base\n### Activate the environment: \nconda activate renv\n### When using conda to install R packages, you will need to add r- before the regular package name. \nconda install -c r r-{name_of_package}\n### install a bioconductor package\nconda install -c bioconda bioconductor-{name_of_package}\n### Update all of the packages and their dependencies with one command\nconda update r-caret"
  },
  {
    "objectID": "blog/2023/08/07/index.html#useful-conda-commands",
    "href": "blog/2023/08/07/index.html#useful-conda-commands",
    "title": "Install Conda to manage R/Python environments and packages",
    "section": "Useful conda commands",
    "text": "Useful conda commands\nconda list # shows you everything installed in your current environment\nconda list -n [ENV NAME] # shows you everything installed in the specified environment\nconda info --envs # Viewing a list of your environments\nconda env list # Viewing a list of your environments\nconda remove --name myenv --all # remove any environment (substitute your env name for 'myenv')\nconda search myenv # search your channels for a specific package called 'myenv'\nconda update --all # update conda\nnano $HOME/.condarc # view your list of channels"
  },
  {
    "objectID": "blog/2023/08/07/index.html#conda-tips",
    "href": "blog/2023/08/07/index.html#conda-tips",
    "title": "Install Conda to manage R/Python environments and packages",
    "section": "Conda tips",
    "text": "Conda tips\nWe automatically get a ‘base’ environment after installing conda and we can find it when we open the terminal that you are placed in the base env by default.\n\nNot auto activate base environment\n\nconda config --set auto_activate_base false\n\nAvoid installing lots of software in base or, eventually, we will run into conflicts."
  },
  {
    "objectID": "blog/2023/08/07/index.html#reference",
    "href": "blog/2023/08/07/index.html#reference",
    "title": "Install Conda to manage R/Python environments and packages",
    "section": "Reference",
    "text": "Reference\n\nConda for bioinformatics\nhttps://github.com/conda-forge/miniforge\nUsing Conda to manage R/Python environments and packages"
  },
  {
    "objectID": "blog/2023/07/04/index.html",
    "href": "blog/2023/07/04/index.html",
    "title": "Analyze Omics data using [structToolbox]",
    "section": "",
    "text": "pacman::p_load(\n    ### BiocManager packages\n    structToolbox,\n    pmp,\n    ropls,\n    BiocFileCache,\n    ### CRAN packages\n    cowplot,\n    openxlsx,\n    ggplot2, \n    gridExtra\n)\n\n### use the BiocFileCache\n# bfc &lt;- BiocFileCache(ask = FALSE)"
  },
  {
    "objectID": "blog/2023/07/04/index.html#packages",
    "href": "blog/2023/07/04/index.html#packages",
    "title": "Analyze Omics data using [structToolbox]",
    "section": "",
    "text": "pacman::p_load(\n    ### BiocManager packages\n    structToolbox,\n    pmp,\n    ropls,\n    BiocFileCache,\n    ### CRAN packages\n    cowplot,\n    openxlsx,\n    ggplot2, \n    gridExtra\n)\n\n### use the BiocFileCache\n# bfc &lt;- BiocFileCache(ask = FALSE)"
  },
  {
    "objectID": "blog/2023/07/04/index.html#dataset",
    "href": "blog/2023/07/04/index.html#dataset",
    "title": "Analyze Omics data using [structToolbox]",
    "section": "Dataset",
    "text": "Dataset\n\n### iris dataset\nD &lt;- iris_DatasetExperiment()\nD$sample_meta$class &lt;- D$sample_meta$Species\nD\n## A \"DatasetExperiment\" object\n## ----------------------------\n## name:          Fisher's Iris dataset\n## description:   This famous (Fisher's or Anderson's) iris data set gives the measurements in centimeters of\n##                  the variables sepal length and width and petal length and width,\n##                  respectively, for 50 flowers from each of 3 species of iris. The species are\n##                  Iris setosa, versicolor, and virginica.\n## data:          150 rows x 4 columns\n## sample_meta:   150 rows x 2 columns\n## variable_meta: 4 rows x 1 columns\nhead(D$data[, 1:4])\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width\n## 1          5.1         3.5          1.4         0.2\n## 2          4.9         3.0          1.4         0.2\n## 3          4.7         3.2          1.3         0.2\n## 4          4.6         3.1          1.5         0.2\n## 5          5.0         3.6          1.4         0.2\n## 6          5.4         3.9          1.7         0.4"
  },
  {
    "objectID": "blog/2023/07/04/index.html#using-struct-model-objects",
    "href": "blog/2023/07/04/index.html#using-struct-model-objects",
    "title": "Analyze Omics data using [structToolbox]",
    "section": "Using {struct} model objects",
    "text": "Using {struct} model objects\n\n### Statistical models\nP = PCA(number_components=15)\nP$number_components  &lt;-  5\nP$number_components\n## [1] 5\n### the input for a model can be listed using:\nparam_ids(P)\n## [1] \"number_components\"\nP\n## A \"PCA\" object\n## --------------\n## name:          Principal Component Analysis (PCA)\n## description:   PCA is a multivariate data reduction technique. It summarises the data in a smaller number of\n##                  Principal Components that maximise variance.\n## input params:  number_components \n## outputs:       scores, loadings, eigenvalues, ssx, correlation, that \n## predicted:     that\n## seq_in:        data\n### model sequences\nM = mean_centre() + PCA(number_components = 4)\nM[2]$number_components\n## [1] 4\n### training/testing models\nM = model_train(M, D)\nM = model_predict(M,D)\nM = model_apply(M,D)\noutput_ids(M[2])\n## [1] \"scores\"      \"loadings\"    \"eigenvalues\" \"ssx\"         \"correlation\"\n## [6] \"that\"\n\n### model charts\nchart_names(M[2])\n## [1] \"pca_biplot\"           \"pca_correlation_plot\" \"pca_dstat_plot\"      \n## [4] \"pca_loadings_plot\"    \"pca_scores_plot\"      \"pca_scree_plot\"\n### plot PCA scores plot\nC = pca_scores_plot(factor_name='class') # colour by class\nchart_plot(C,M[2])\n\n\n\n\n\n\n\n# add petal width to meta data of pca scores\nM[2]$scores$sample_meta$example=D$data[,1]\n# update plot\nC$factor_name='example'\nchart_plot(C,M[2])\n## Warning: The following aesthetics were dropped during statistical transformation: colour\n## ℹ This can happen when ggplot fails to infer the correct grouping structure in\n##   the data.\n## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n##   variable into a factor?\n## The following aesthetics were dropped during statistical transformation: colour\n## ℹ This can happen when ggplot fails to infer the correct grouping structure in\n##   the data.\n## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n##   variable into a factor?\n\n\n\n\n\n\n\n# scores plot\nC1 = pca_scores_plot(factor_name='class') # colour by class\ng1 = chart_plot(C1,M[2])\n\n# scree plot\nC2 = pca_scree_plot()\ng2 = chart_plot(C2,M[2])\n\n# arange in grid\ngrid.arrange(grobs=list(g1,g2),nrow=1)"
  },
  {
    "objectID": "blog/2023/07/04/index.html#typical-workflow",
    "href": "blog/2023/07/04/index.html#typical-workflow",
    "title": "Analyze Omics data using [structToolbox]",
    "section": "Typical workflow",
    "text": "Typical workflow\nDataset\nThe MTBLS79 dataset represents a systematic evaluation of the reproducibility of a multi-batch direct-infusion mass spectrometry (DIMS)-based metabolomics study of cardiac tissue extracts. It comprises twenty biological samples (cow vs. sheep) that were analysed repeatedly, in 8 batches across 7 days, together with a concurrent set of quality control (QC) samples. Data are presented from each step of the data processing workflow and are available through MetaboLights (https://www.ebi.ac.uk/metabolights/MTBLS79).\n\n# the pmp SE object\nSE  &lt;-  MTBLS79\n# convert to DE\nDE  &lt;-  as.DatasetExperiment(SE)\nDE$name  &lt;-  \"MTBLS79\"\nDE$description  &lt;-  \"Converted from SE provided by the pmp package\"\n\n# add a column indicating the order the samples were measured in\nDE$sample_meta$run_order  &lt;-  1:nrow(DE)\n\n# add a column indicating if the sample is biological or a QC\nType &lt;- as.character(DE$sample_meta$Class)\nType[Type != 'QC']  &lt;-  \"Sample\"\nDE$sample_meta$Type  &lt;-  factor(Type)\n\n# convert to factors\nDE$sample_meta$Batch = factor(DE$sample_meta$Batch)\nDE$sample_meta$Class = factor(DE$sample_meta$Class)\n\n# print summary\nDE\n## A \"DatasetExperiment\" object\n## ----------------------------\n## name:          MTBLS79\n## description:   Converted from SE provided by the pmp package\n## data:          172 rows x 2488 columns\n## sample_meta:   172 rows x 6 columns\n## variable_meta: 2488 rows x 0 columns\n\nSignal drift and batch correction\nA batch correction algorithm is applied to reduce intra- and inter- batch variations in the dataset. Quality Control-Robust Spline Correction (QC-RSC) is provided in the pmp package, and it has been wrapped into a structToolbox object called sb_corr.\n\n # batch correction\nM &lt;- sb_corr(\n    order_col = \"run_order\",\n    batch_col = \"Batch\",\n    qc_col = \"Type\",\n    qc_label = \"QC\"\n)\n\nM = model_apply(M, DE)\n## The number of NA and &lt;= 0 values in peaksData before QC-RSC: 18222\n\n### plot of a feature vs run order, before and after the correction\nC = feature_profile(\n      run_order='run_order',\n      qc_label='QC',\n      qc_column='Type',\n      colour_by='Batch',\n      feature_to_plot='200.03196'\n  )\n\n# plot and modify using ggplot2 \nchart_plot(C,DE) + ylab('Peak area') + ggtitle('Before')\n\n\n\n\n\n\n\nchart_plot(C,predicted(M))+ylab('Peak area')+ggtitle('After')\n\n\n\n\n\n\n\nM2 = filter_na_count(\n      threshold=3,\n      factor_name='Batch'\n    )\nM2 = model_apply(M2,predicted(M))\n\n# calculate number of features removed\nnc = ncol(DE) - ncol(predicted(M2))\n\ncat(paste0('Number of features removed: ', nc))\n## Number of features removed: 425\n\nFeature filtering"
  },
  {
    "objectID": "blog/2023/07/04/index.html#reference",
    "href": "blog/2023/07/04/index.html#reference",
    "title": "Analyze Omics data using [structToolbox]",
    "section": "Reference",
    "text": "Reference\n\nData analysis of metabolomics and other omics datasets using the structToolbox"
  },
  {
    "objectID": "blog/2023/05/18/index.html",
    "href": "blog/2023/05/18/index.html",
    "title": "PCA Graph Customization",
    "section": "",
    "text": "### Load packages\nlibrary(pacman)\np_load(\n    tidyverse,  # tidy data\n    FactoMineR, # compute principal component methods\n    factoextra,  # extract, visualize and interpretate the results\n    corrplot  # visualize cos2 of variables\n)\n\n### compute pca\nhead(iris, 3)\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n# The variable Species (index = 5) is removed\n# before PCA analysis\niris_pca &lt;- PCA(iris[,-5], graph = FALSE)\niris_pca\n## **Results for the Principal Component Analysis (PCA)**\n## The analysis was performed on 150 individuals, described by 4 variables\n## *The results are available in the following objects:\n## \n##    name               description                          \n## 1  \"$eig\"             \"eigenvalues\"                        \n## 2  \"$var\"             \"results for the variables\"          \n## 3  \"$var$coord\"       \"coord. for the variables\"           \n## 4  \"$var$cor\"         \"correlations variables - dimensions\"\n## 5  \"$var$cos2\"        \"cos2 for the variables\"             \n## 6  \"$var$contrib\"     \"contributions of the variables\"     \n## 7  \"$ind\"             \"results for the individuals\"        \n## 8  \"$ind$coord\"       \"coord. for the individuals\"         \n## 9  \"$ind$cos2\"        \"cos2 for the individuals\"           \n## 10 \"$ind$contrib\"     \"contributions of the individuals\"   \n## 11 \"$call\"            \"summary statistics\"                 \n## 12 \"$call$centre\"     \"mean of the variables\"              \n## 13 \"$call$ecart.type\" \"standard error of the variables\"    \n## 14 \"$call$row.w\"      \"weights for the individuals\"        \n## 15 \"$call$col.w\"      \"weights for the variables\""
  },
  {
    "objectID": "blog/2023/05/18/index.html#compute-pca",
    "href": "blog/2023/05/18/index.html#compute-pca",
    "title": "PCA Graph Customization",
    "section": "",
    "text": "### Load packages\nlibrary(pacman)\np_load(\n    tidyverse,  # tidy data\n    FactoMineR, # compute principal component methods\n    factoextra,  # extract, visualize and interpretate the results\n    corrplot  # visualize cos2 of variables\n)\n\n### compute pca\nhead(iris, 3)\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n# The variable Species (index = 5) is removed\n# before PCA analysis\niris_pca &lt;- PCA(iris[,-5], graph = FALSE)\niris_pca\n## **Results for the Principal Component Analysis (PCA)**\n## The analysis was performed on 150 individuals, described by 4 variables\n## *The results are available in the following objects:\n## \n##    name               description                          \n## 1  \"$eig\"             \"eigenvalues\"                        \n## 2  \"$var\"             \"results for the variables\"          \n## 3  \"$var$coord\"       \"coord. for the variables\"           \n## 4  \"$var$cor\"         \"correlations variables - dimensions\"\n## 5  \"$var$cos2\"        \"cos2 for the variables\"             \n## 6  \"$var$contrib\"     \"contributions of the variables\"     \n## 7  \"$ind\"             \"results for the individuals\"        \n## 8  \"$ind$coord\"       \"coord. for the individuals\"         \n## 9  \"$ind$cos2\"        \"cos2 for the individuals\"           \n## 10 \"$ind$contrib\"     \"contributions of the individuals\"   \n## 11 \"$call\"            \"summary statistics\"                 \n## 12 \"$call$centre\"     \"mean of the variables\"              \n## 13 \"$call$ecart.type\" \"standard error of the variables\"    \n## 14 \"$call$row.w\"      \"weights for the individuals\"        \n## 15 \"$call$col.w\"      \"weights for the variables\""
  },
  {
    "objectID": "blog/2023/05/18/index.html#color-individuals-by-groups",
    "href": "blog/2023/05/18/index.html#color-individuals-by-groups",
    "title": "PCA Graph Customization",
    "section": "Color individuals by groups",
    "text": "Color individuals by groups\n\nfviz_pca_ind(\n  iris_pca,\n  geom.ind = \"point\", # show points only (nbut not \"text\")\n  col.ind = iris$Species, # color by groups\n  palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n  addEllipses = TRUE, # Concentration ellipses\n  legend.title = \"Groups\"\n)"
  },
  {
    "objectID": "blog/2023/05/18/index.html#add-confidence-ellipses",
    "href": "blog/2023/05/18/index.html#add-confidence-ellipses",
    "title": "PCA Graph Customization",
    "section": "Add confidence ellipses",
    "text": "Add confidence ellipses\n\nfviz_pca_ind(\n  iris_pca, \n  geom.ind = \"point\", \n  col.ind = iris$Species, \n  palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n  addEllipses = TRUE, ellipse.type = \"confidence\",\n  legend.title = \"Groups\"\n)\n\n\n\n\n\n\n\n### use color from jco\nfviz_pca_ind(\n  iris_pca,\n  label = \"none\", # hide individual labels\n  habillage = iris$Species, # color by groups\n  addEllipses = TRUE, # Concentration ellipses\n  palette = \"jco\"\n)\n\n\n\n\n\n\n\n# Add confidence ellipses\nfviz_pca_ind(\n  iris_pca, \n  geom.ind = \"point\", \n  col.ind = iris$Species, # color by groups\n  palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n  addEllipses = TRUE, \n  ellipse.type = \"confidence\",\n  legend.title = \"Groups\"\n)\n\n\n\n\n\n\n\n# Convex hull\nfviz_pca_ind(\n  iris_pca, \n  geom.ind = \"point\",\n  col.ind = iris$Species, # color by groups\n  palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n  addEllipses = TRUE, \n  ellipse.type = \"convex\",\n  legend.title = \"Groups\"\n)"
  },
  {
    "objectID": "blog/2023/05/18/index.html#group-mean-points",
    "href": "blog/2023/05/18/index.html#group-mean-points",
    "title": "PCA Graph Customization",
    "section": "Group mean points",
    "text": "Group mean points\n\nfviz_pca_ind(\n  iris_pca,\n  geom.ind = \"point\", # show points only (but not \"text\")\n  group.ind = iris$Species, # color by groups\n  legend.title = \"Groups\",\n  mean.point = FALSE\n)"
  },
  {
    "objectID": "blog/2023/05/18/index.html#graphical-parameters",
    "href": "blog/2023/05/18/index.html#graphical-parameters",
    "title": "PCA Graph Customization",
    "section": "Graphical parameters",
    "text": "Graphical parameters\nTo change easily the graphical of any ggplots, you can use the function ggpar() [ggpubr package]\nThe graphical parameters that can be changed using ggpar() include:\n\nMain titles, axis labels and legend titles\nLegend position. Possible values: “top”, “bottom”, “left”, “right”, “none”.\nColor palette.\nThemes. Allowed values include: theme_gray(), theme_bw(), theme_minimal(), theme_classic(), theme_void().\n\n\nind_p &lt;- fviz_pca_ind(iris_pca, geom = \"point\", col.ind = iris$Species)\n\nggpubr::ggpar(ind_p,\n              title = \"Principal Component Analysis\",\n              subtitle = \"Iris data set\",\n              caption = \"Source: factoextra\",\n              xlab = \"PC1\", ylab = \"PC2\",\n              legend.title = \"Species\", legend.position = \"top\",\n              ggtheme = theme_gray(), palette = \"jco\"\n              )"
  },
  {
    "objectID": "blog/2023/05/18/index.html#biplot",
    "href": "blog/2023/05/18/index.html#biplot",
    "title": "PCA Graph Customization",
    "section": "Biplot",
    "text": "Biplot\n\nfviz_pca_biplot(\n  iris_pca, \n  col.ind = iris$Species, \n  palette = \"jco\", \n  addEllipses = TRUE, \n  label = \"var\",\n  col.var = \"black\", \n  repel = TRUE,\n  legend.title = \"Species\"\n)"
  },
  {
    "objectID": "blog/2023/05/18/index.html#color-by-groups",
    "href": "blog/2023/05/18/index.html#color-by-groups",
    "title": "PCA Graph Customization",
    "section": "Color by groups",
    "text": "Color by groups\n\nfviz_pca_biplot(\n  iris_pca, \n  # Fill individuals by groups\n  geom.ind = \"point\",\n  pointshape = 21,\n  pointsize = 2.5,\n  fill.ind = iris$Species,\n  col.ind = \"black\",\n  # Color variable by groups\n  col.var = factor(c(\"sepal\", \"sepal\", \"petal\", \"petal\")),\n  legend.title = list(fill = \"Species\", color = \"Clusters\"),\n  repel = TRUE        # Avoid label overplotting\n) +\n  ggpubr::fill_palette(\"jco\")+      # Indiviual fill color\n  ggpubr::color_palette(\"npg\")      # Variable colors\n\n\n\n\n\n\n\n\nfviz_pca_biplot(\n  iris_pca, \n  # Individuals\n  geom.ind = \"point\",\n  fill.ind = iris$Species, \n  col.ind = \"black\",\n  pointshape = 21, \n  pointsize = 2,\n  palette = \"jco\",\n  addEllipses = TRUE,\n  # Variables\n  alpha.var =\"contrib\", \n  col.var = \"contrib\",\n  gradient.cols = \"RdYlBu\",\n  legend.title = list(\n    fill = \"Species\", \n    color = \"Contrib\", \n    alpha = \"Contrib\"\n    )\n)"
  },
  {
    "objectID": "blog/2023/05/18/index.html#reference",
    "href": "blog/2023/05/18/index.html#reference",
    "title": "PCA Graph Customization",
    "section": "Reference",
    "text": "Reference\n\nPrincipal Component Methods in R: Practical Guide"
  },
  {
    "objectID": "blog/2023/05/03/index.html",
    "href": "blog/2023/05/03/index.html",
    "title": "Make heatmap using ComplexHeatmap",
    "section": "",
    "text": "Heat maps allow us to simultaneously visualize clusters of samples and features. First hierarchical clustering is done of both the rows and the columns of the data matrix. The columns/rows of the data matrix are re-ordered according to the hierarchical clustering result, putting similar observations close to each other. The blocks of ‘high’ and ‘low’ values are adjacent in the data matrix. Finally, a color scheme is applied for the visualization and the data matrix is displayed. Visualizing the data matrix in this way can help to find the variables that appear to be characteristic for each sample cluster.\nlibrary(tidyverse)\nrequire(RColorBrewer)\nrequire(ComplexHeatmap)\nrequire(circlize)\nrequire(digest)\nrequire(cluster)\n# expr &lt;- readRDS(system.file(package = \"ComplexHeatmap\", \"extdata\", \"gene_expression.rds\"))\n# head(expr)\n# mat &lt;- as.matrix(expr[, grep(\"cell\", colnames(expr))])\n# head(mat)\n# base_mean &lt;- rowMeans(mat)\n\n# mat_scaled &lt;- t(apply(mat, 1, scale))\n# head(mat_scaled)\n\n# type &lt;- gsub(\"s\\\\d+_\", \"\", colnames(mat))\n# type\n\n# ha &lt;- HeatmapAnnotation(type = type, annotation_name_side = \"left\")\n\n# ht_list &lt;- Heatmap(\n#         mat_scaled,\n#         name = \"expression\", row_km = 5,\n#         col = colorRamp2(c(-2, 0, 2), c(\"green\", \"white\", \"red\")),\n#         top_annotation = ha,\n#         show_column_names = FALSE, row_title = NULL, show_row_dend = FALSE\n#     ) +\n#     Heatmap(\n#         base_mean,\n#         name = \"base mean\",\n#         top_annotation = HeatmapAnnotation(summary = anno_summary(\n#             gp = gpar(fill = 2:6),\n#             height = unit(2, \"cm\")\n#         )),\n#         width = unit(15, \"mm\")\n#     ) +\n#     rowAnnotation(\n#         length = anno_points(expr$length,\n#             pch = 16, size = unit(1, \"mm\"),\n#             axis_param = list(\n#                 at = c(0, 2e5, 4e5, 6e5),\n#                 labels = c(\"0kb\", \"200kb\", \"400kb\", \"600kb\")\n#             ),\n#             width = unit(2, \"cm\")\n#         )\n#     ) +\n#     Heatmap(\n#         expr$type,\n#         name = \"gene type\",\n#         top_annotation = HeatmapAnnotation(\n#             summary = anno_summary(height = unit(2, \"cm\"))\n#             ),\n#         width = unit(15, \"mm\")\n#     )\n\n# ht_list &lt;- rowAnnotation(\n#         block = anno_block(gp = gpar(fill = 2:6, col = NA)),\n#         width = unit(2, \"mm\")\n#     ) + ht_list\n\n# draw(ht_list)"
  },
  {
    "objectID": "blog/2023/05/03/index.html#reference",
    "href": "blog/2023/05/03/index.html#reference",
    "title": "Make heatmap using ComplexHeatmap",
    "section": "Reference",
    "text": "Reference\n\nComplexHeatmap Complete Reference\nHeatmap in R: Static and Interactive Visualization\nhttps://github.com/kevinblighe/E-MTAB-6141\nTest Hierarchical Clustering"
  },
  {
    "objectID": "blog/2023/04/05/index.html",
    "href": "blog/2023/04/05/index.html",
    "title": "The best way to perform feature scaling using R",
    "section": "",
    "text": "This article describes the following data rescaling approaches:"
  },
  {
    "objectID": "blog/2023/04/05/index.html#what-is-feature-scaling-normalization",
    "href": "blog/2023/04/05/index.html#what-is-feature-scaling-normalization",
    "title": "The best way to perform feature scaling using R",
    "section": "What is feature scaling (normalization)?",
    "text": "What is feature scaling (normalization)?\nIn short, feature scaling means to scale the data into a fixed range — generally between 0 and 1. Normalization is normally performed when doing a multivariate analysis where you want each feature (variable) to contribute equally to the analysis."
  },
  {
    "objectID": "blog/2023/04/05/index.html#standard-scaling",
    "href": "blog/2023/04/05/index.html#standard-scaling",
    "title": "The best way to perform feature scaling using R",
    "section": "Standard scaling",
    "text": "Standard scaling\nStandard scaling, also known as standardization or Z-score normalization, consists of subtracting the mean and divide by the standard deviation. In such a case, each value would reflect the distance from the mean in units of standard deviation.\nIf we would assume all variables come from some normal distribution, then scaling would bring them all close to the standard normal distribution. The resulting distribution has a mean of 0 and a standard deviation of 1.\nStandard scaling formula:\n\\[Transformed.Values = \\frac{Values - Mean}{Standard.Deviation}\\]\nAn alternative to standardization is the mean normalization, which resulting distribution will have between -1 and 1 with mean = 0.\nMean normalization formula:\n\\[Transformed.Values = \\frac{Values - Mean}{Maximum - Minimum}\\]\nStandardization and Mean Normalization can be used for algorithms that assumes zero centric data like Principal Component Analysis(PCA)."
  },
  {
    "objectID": "blog/2023/04/05/index.html#normalization",
    "href": "blog/2023/04/05/index.html#normalization",
    "title": "The best way to perform feature scaling using R",
    "section": "Normalization",
    "text": "Normalization\nWhen variables in the data comes from possibly different (and non-normal) distributions, other transformations may be in order. Another possibility is to normalize the variables to brings data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\nFormula to normalize data between 0 and 1 :\n\\[Transformed.Values = \\frac{Values - Minimum}{Maximum - Minimum}\\]\nFormula to rescale the data between an arbitrary set of values [a, b]:\n\\[Transformed.Values = a + \\frac{(Values - Minimum)(b-a)}{Maximum - Minimum}\\]\nwhere a,b are the min-max values.\nNormalize data in R. Using the Min-Max normalization function on mtcars data easily reveals columns with only two (am, vs) or three (gear, cyl) variables compared with variables that have a higher resolution of possible values:"
  },
  {
    "objectID": "blog/2023/04/05/index.html#reference",
    "href": "blog/2023/04/05/index.html#reference",
    "title": "The best way to perform feature scaling using R",
    "section": "Reference",
    "text": "Reference\n\nhttps://www.datanovia.com/en/lessons/heatmap-in-r-static-and-interactive-visualization/"
  },
  {
    "objectID": "blog/2023/03/31/index.html",
    "href": "blog/2023/03/31/index.html",
    "title": "Add p-value and significant level at facet boxplot",
    "section": "",
    "text": "How to compute and add p-values to basic ggplots using the rstatix and the ggpubr R packages.\npacman::p_load(\n    tidyverse,\n    ggsci,\n    ggprism,\n    rstatix,\n    ggpubr,\n    gapminder,\n    ggpmisc\n)"
  },
  {
    "objectID": "blog/2023/03/31/index.html#add-t-test-annotation-in-specific-subgroup",
    "href": "blog/2023/03/31/index.html#add-t-test-annotation-in-specific-subgroup",
    "title": "Add p-value and significant level at facet boxplot",
    "section": "Add t-test annotation in specific subgroup",
    "text": "Add t-test annotation in specific subgroup\n\n## subset data\ndf &lt;- gapminder %&gt;%\n    filter(year %in% c(1957, 2002, 2007), continent != \"Oceania\") %&gt;%\n    select(country, year, lifeExp, continent) %&gt;%\n    mutate(paired = rep(1:(n() / 3), each = 3), year = factor(year))\ndf\n## # A tibble: 420 × 5\n##    country     year  lifeExp continent paired\n##    &lt;fct&gt;       &lt;fct&gt;   &lt;dbl&gt; &lt;fct&gt;      &lt;int&gt;\n##  1 Afghanistan 1957     30.3 Asia           1\n##  2 Afghanistan 2002     42.1 Asia           1\n##  3 Afghanistan 2007     43.8 Asia           1\n##  4 Albania     1957     59.3 Europe         2\n##  5 Albania     2002     75.7 Europe         2\n##  6 Albania     2007     76.4 Europe         2\n##  7 Algeria     1957     45.7 Africa         3\n##  8 Algeria     2002     71.0 Africa         3\n##  9 Algeria     2007     72.3 Africa         3\n## 10 Angola      1957     32.0 Africa         4\n## # ℹ 410 more rows\n## statistical analysis\ndf_pval &lt;- df %&gt;%\n    group_by(continent) %&gt;%\n    wilcox_test(lifeExp ~ year) %&gt;%\n    adjust_pvalue(p.col = \"p\", method = \"bonferroni\") %&gt;%\n    add_significance(p.col = \"p.adj\") %&gt;%\n    add_xy_position(x = \"year\", dodge = 0.8)\ndf_pval\n## # A tibble: 12 × 14\n##    continent .y.     group1 group2    n1    n2 statistic        p    p.adj\n##    &lt;fct&gt;     &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n##  1 Africa    lifeExp 1957   2002      52    52       328 2.85e-11 3.42e-10\n##  2 Africa    lifeExp 1957   2007      52    52       255 1.01e-12 1.21e-11\n##  3 Africa    lifeExp 2002   2007      52    52      1214 3.71e- 1 1   e+ 0\n##  4 Americas  lifeExp 1957   2002      25    25        23 9.12e-11 1.09e- 9\n##  5 Americas  lifeExp 1957   2007      25    25        14 8.04e-12 9.65e-11\n##  6 Americas  lifeExp 2002   2007      25    25       250 2.31e- 1 1   e+ 0\n##  7 Asia      lifeExp 1957   2002      33    33        73 1.23e-11 1.48e-10\n##  8 Asia      lifeExp 1957   2007      33    33        56 9.62e-13 1.15e-11\n##  9 Asia      lifeExp 2002   2007      33    33       476 3.86e- 1 1   e+ 0\n## 10 Europe    lifeExp 1957   2002      30    30        19 3.53e-14 4.24e-13\n## 11 Europe    lifeExp 1957   2007      30    30        13 6.31e-15 7.57e-14\n## 12 Europe    lifeExp 2002   2007      30    30       358 1.77e- 1 1   e+ 0\n## # ℹ 5 more variables: p.adj.signif &lt;chr&gt;, y.position &lt;dbl&gt;,\n## #   groups &lt;named list&gt;, xmin &lt;dbl&gt;, xmax &lt;dbl&gt;\n\n\ndf %&gt;%\n    ggplot(aes(x = year, y = lifeExp)) +\n    stat_boxplot(aes(ymin = ..lower.., ymax = ..upper..), outlier.shape = NA, width = 0.5) +\n    stat_boxplot(geom = \"errorbar\", aes(ymin = ..ymax..), width = 0.2, size = 0.35) +\n    stat_boxplot(geom = \"errorbar\", aes(ymax = ..ymin..), width = 0.2, size = 0.35) +\n    geom_boxplot(aes(fill = year), color = \"black\", outlier.shape = NA, linetype = \"dashed\", width = 0.5, size = 0.3) +\n    stat_summary(geom = \"crossbar\", fun = \"median\", width = 0.5, color = \"black\", size = 0.38) +\n    scale_size_continuous(range = c(1, 3)) +\n    facet_wrap(. ~ continent, nrow = 1) +\n    scale_fill_npg() +\n    scale_y_continuous(limits = c(0, 95), breaks = seq(0, 95, 15), guide = \"prism_offset_minor\") +\n    labs(x = NULL, y = NULL) +\n    theme(\n        plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), units = \"cm\"),\n        strip.text = element_text(size = 12),\n        axis.line = element_line(color = \"black\", size = 0.4),\n        panel.grid.major = element_line(size = 0.2, color = \"#e5e5e5\"),\n        panel.grid.minor = element_blank(),\n        panel.background = element_blank(),\n        panel.spacing = unit(0.1, \"lines\"),\n        axis.text.y = element_text(color = \"black\", size = 10),\n        # axis.text.x = element_blank(),\n        # axis.ticks.x = element_blank(),\n        legend.position = \"none\"\n    ) +\n    coord_cartesian() +\n    ### add p-value\n    stat_pvalue_manual(\n        df_pval %&gt;% filter(\n            continent %in% c(\"Asia\", \"Americas\"), group1 == \"1957\", group2 == \"2002\"\n        ),\n        label = \"p.adj.signif\", label.size = 5, hide.ns = F\n    )\n## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n## ℹ Please use `linewidth` instead.\n## Warning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\n## ℹ Please use the `linewidth` argument instead.\n## Warning: The dot-dot notation (`..lower..`) was deprecated in ggplot2 3.4.0.\n## ℹ Please use `after_stat(lower)` instead."
  },
  {
    "objectID": "blog/2023/03/31/index.html#paried-t-test-in-subgroup-facet",
    "href": "blog/2023/03/31/index.html#paried-t-test-in-subgroup-facet",
    "title": "Add p-value and significant level at facet boxplot",
    "section": "Paried t-test in subgroup facet",
    "text": "Paried t-test in subgroup facet\n\n### Boxplot Parired t-test multiple group\ndf %&gt;%\n    ggplot(aes(year, lifeExp)) +\n    stat_boxplot(geom = \"errorbar\", position = position_dodge(width = 0.2), width = 0.1) +\n    geom_boxplot(position = position_dodge(width = 0.2), width = 0.4) +\n    geom_line(aes(group = paired), position = position_dodge(0.2), color = \"grey80\") +\n    geom_point(aes(fill = year, group = paired, size = lifeExp, alpha = lifeExp),\n        pch = 21,\n        position = position_dodge(0.2)\n    ) +\n    stat_pvalue_manual(df_pval, label = \"p.adj.signif\", label.size = 6, hide.ns = T) +\n    scale_size_continuous(range = c(1, 3)) +\n    facet_wrap(. ~ continent, nrow = 1) +\n    scale_fill_npg() +\n    scale_x_discrete(guide = \"prism_bracket\") +\n    scale_y_continuous(limits = c(0, 90), minor_breaks = seq(0, 90, 5), guide = \"prism_offset_minor\") +\n    labs(x = NULL, y = NULL) +\n    theme_prism(base_line_size = 0.5) +\n    theme(\n        plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), units = , \"cm\"),\n        axis.line = element_line(color = \"black\", size = 0.4),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(size = 0.2, color = \"#e5e5e5\"),\n        axis.text.y = element_text(color = \"black\", size = 10),\n        axis.text.x = element_text(margin = margin(t = -5), color = \"black\", size = 10),\n        legend.position = \"none\",\n        panel.spacing = unit(0, \"lines\")\n    ) +\n    coord_cartesian()\n\n\n\n\n\n\n# ggsave(\n#     here(\"blog\", \"2023\", \"03\", \"07\", \"plot.png\")\n# )"
  },
  {
    "objectID": "blog/2023/03/31/index.html#boxplot",
    "href": "blog/2023/03/31/index.html#boxplot",
    "title": "Add p-value and significant level at facet boxplot",
    "section": "Boxplot",
    "text": "Boxplot\n\ndf %&gt;%\n    ggplot(aes(year, lifeExp)) +\n    stat_boxplot(geom = \"errorbar\", position = position_dodge(width = 0.2), width = 0.1) +\n    geom_boxplot(position = position_dodge(width = 0.2), width = 0.4) +\n    #  geom_line(aes(group=paired),position = position_dodge(0.2),color=\"grey80\") +\n    geom_point(aes(fill = year, group = paired, size = lifeExp, alpha = lifeExp),\n        pch = 21,\n        position = position_dodge(0.2)\n    ) +\n    stat_pvalue_manual(df_pval, label = \"p.adj.signif\", label.size = 5, hide.ns = F) +\n    scale_size_continuous(range = c(1, 3)) +\n    geom_smooth(method = \"lm\", formula = NULL, size = 1, se = T, color = \"black\", linetype = \"dashed\", aes(group = 1)) +\n    stat_cor(\n        label.y = 25, aes(label = paste(..rr.label.., ..p.label.., sep = \"~`,`~\"), group = 1), color = \"black\",\n        label.x.npc = \"left\"\n    ) +\n    stat_regline_equation(label.y = 19, aes(group = 1), color = \"red\") +\n    facet_wrap(. ~ continent, nrow = 1) +\n    scale_fill_npg() +\n    scale_x_discrete(guide = \"prism_bracket\") +\n    scale_y_continuous(limits = c(0, 95), minor_breaks = seq(0, 95, 5), guide = \"prism_offset_minor\") +\n    labs(x = NULL, y = NULL) +\n    theme_prism(base_line_size = 0.5) +\n    theme(\n        plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), units = , \"cm\"),\n        strip.text = element_text(size = 12),\n        axis.line = element_line(color = \"black\", size = 0.4),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(size = 0.2, color = \"#e5e5e5\"),\n        axis.text.y = element_text(color = \"black\", size = 10),\n        axis.text.x = element_text(margin = margin(t = -5), color = \"black\", size = 10),\n        legend.position = \"none\",\n        panel.spacing = unit(0, \"lines\")\n    ) +\n    coord_cartesian()\n## `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "blog/2023/03/11/index.html",
    "href": "blog/2023/03/11/index.html",
    "title": "Barplot with negative and positive value",
    "section": "",
    "text": "Coloring Negative and Positive Bars Differently using ggplot2\nlibrary(readxl)\nlibrary(tidyverse)\n\nx &lt;- c(\"Vcam1\", \"Pecam1\", \"Alcam\", \"Icam1\", \"Gja4\", \"Gja5\", \"F11r\")\ny &lt;- c(0.1, 0.05, -0.08, -0.12, 0.15, -0.18, 0.2)\n\nfig3r.df &lt;- data.frame(x, y)\n\n\nfig3r.df %&gt;% \n  mutate(x=factor(x,levels = c(\"Vcam1\",\"Pecam1\",\"Alcam\",\"Icam1\",\"Gja4\",\"Gja5\",\"F11r\"))) %&gt;% \n  ggplot(aes(x, y)) +\n  geom_col(aes(fill = ifelse(y &lt; 0, \"Negative\", \"Positive\")), color = \"black\") +\n  geom_text(aes(y = ifelse(y &lt; 0, y - 0.02, y + 0.02),\n                label = x, color = ifelse(y &lt; 0, \"Negative\", \"Positive\")),\n            angle = 90, hjust = ifelse(y &lt; 0, 1, 0)) +\n  scale_fill_manual(values = c(\"Positive\" = \"#ee7770\", \"Negative\" = \"#77b5fe\"), \n                    guide = \"none\") +\n  scale_color_manual(values = c(\"Positive\" = \"#ee7770\", \"Negative\" = \"#77b5fe\")) +\n  theme_classic() +\n  theme(axis.line.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        legend.position = \"none\",\n        panel.grid.major.y = element_line(),\n        plot.title = element_text(hjust = 0.5)) +\n  scale_y_continuous(limits = c(-0.25,0.25),\n                     breaks = c(-0.25,seq(-0.2,0.2,by=0.1),0.25),\n                     expand = expansion(mult = c(0,0)),\n                     labels = c(\"\",seq(-0.2,0.2,by=0.1),\"\")) +\n  labs(x = NULL, y = \"log(FC)\", title = \"Art\")"
  },
  {
    "objectID": "blog/2023/03/11/index.html#reference",
    "href": "blog/2023/03/11/index.html#reference",
    "title": "Barplot with negative and positive value",
    "section": "Reference",
    "text": "Reference\n\nhttps://r-graphics.org/recipe-bar-graph-color-neg"
  },
  {
    "objectID": "blog/2023/03/06/index.html",
    "href": "blog/2023/03/06/index.html",
    "title": "ggplot2 with p-value and significant level",
    "section": "",
    "text": "A sample example to add p-value and significant level to barpot.\nlibrary(tidyverse)\nlibrary(rstatix)\nlibrary(ggprism)\nlibrary(ggpubr)\nlibrary(ggsci)\n\n# package.list=c(\"tidyverse\",\"rstatix\",\"ggtext\")\n\n# for (package in package.list) {\n#   if (!require(package,character.only=T, quietly=T)) {\n#     install.packages(package)\n#     library(package, character.only=T)\n#   }\n# }"
  },
  {
    "objectID": "blog/2023/03/06/index.html#single-group",
    "href": "blog/2023/03/06/index.html#single-group",
    "title": "ggplot2 with p-value and significant level",
    "section": "Single group",
    "text": "Single group\n\ndf &lt;- ToothGrowth %&gt;%\n    mutate(dose = as.factor(dose)) %&gt;%\n    group_by(dose) %&gt;%\n    summarise(value_mean = mean(len), sd = sd(len), se = sd(len) / sqrt(n()))\n\n\nstat.test &lt;- ToothGrowth %&gt;%\n    t_test(data = ., len ~ dose, ref.group = \"0.5\") %&gt;%\n    mutate(p.adj.signif = replace_na(p.adj.signif, \"\"), across(\"p.adj.signif\", str_replace, \"ns\", \"\")) %&gt;%\n    select(group1, group2, p.adj, p.adj.signif) %&gt;%\n    left_join(., df, by = c(\"group2\" = \"dose\")) %&gt;%\n    mutate(y.position = value_mean + sd + 0.3)\n## Warning: There was 1 warning in `mutate()`.\n## ℹ In argument: `across(\"p.adj.signif\", str_replace, \"ns\", \"\")`.\n## Caused by warning:\n## ! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\n## Supply arguments directly to `.fns` through an anonymous function instead.\n## \n##   # Previously\n##   across(a:b, mean, na.rm = TRUE)\n## \n##   # Now\n##   across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\ntheme_niwot &lt;- function() {\n    theme_minimal() +\n        theme(\n            axis.title.x = element_blank(),\n            axis.line = element_line(color = \"#3D4852\"),\n            axis.ticks = element_line(color = \"#3D4852\"),\n            panel.grid.major.y = element_line(color = \"#DAE1E7\"),\n            panel.grid.major.x = element_blank(),\n            panel.background = element_rect(fill = \"white\"),\n            plot.background = element_rect(fill = \"white\"),\n            plot.margin = unit(rep(0.2, 4), \"cm\"),\n            axis.text = element_text(size = 12, color = \"#22292F\"),\n            axis.title = element_text(size = 12, hjust = 1),\n            axis.title.y = element_text(margin = margin(r = 12)),\n            axis.text.y = element_text(margin = margin(r = 5)),\n            axis.text.x = element_text(margin = margin(t = 5)),\n            legend.position = \"non\"\n        )\n}\n\n\ndf %&gt;% ggplot(., aes(dose, value_mean)) +\n    geom_errorbar(aes(ymax = value_mean + sd, ymin = value_mean - sd), width = 0.1, color = \"grey30\") +\n    geom_col(width = 0.4, aes(fill = dose)) +\n    add_pvalue(stat.test,\n        label = \"p.adj.signif\", label.size = 6,\n        coord.flip = TRUE, remove.bracket = TRUE\n    ) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 33)) +\n    theme_niwot() +\n    scale_fill_brewer(palette = \"Blues\")\n\n\n\n\n\n\n\n\n df %&gt;% ggplot(., aes(dose, value_mean)) +\n     geom_errorbar(aes(ymax = value_mean + sd, ymin = value_mean - sd), width = 0.1, color = \"grey30\") +\n     geom_col(width = 0.4, aes(fill = dose)) +\n     stat_pvalue_manual(stat.test %&gt;% slice(1),\n         label = \"p.adj.signif\",\n         label.size = 6, tip.length = c(0.35, 0.003), linetype = 2\n     ) +\n     add_pvalue(stat.test %&gt;% slice(2), label = \"p.adj.signif\", label.size = 6, tip.length = c(0.1, 0.003)) +\n     scale_y_continuous(expand = c(0, 0), limits = c(0, 33)) +\n     theme_niwot() +\n     scale_fill_brewer(palette = \"Blues\")\n\n\n\n\n\n\n # ggsave(\n #     here(\"blog\", \"2023\", \"03\", \"06\", \"plot.png\")\n # )"
  },
  {
    "objectID": "blog/2023/03/06/index.html#multiple-group",
    "href": "blog/2023/03/06/index.html#multiple-group",
    "title": "ggplot2 with p-value and significant level",
    "section": "Multiple group",
    "text": "Multiple group\n\nstat.test &lt;- iris %&gt;%\n    pivot_longer(-Species) %&gt;%\n    filter(Species != \"versicolor\") %&gt;%\n    mutate(group = str_sub(name, start = 1, end = 5)) %&gt;%\n    group_by(group, name) %&gt;%\n    t_test(value ~ Species) %&gt;%\n    adjust_pvalue() %&gt;%\n    add_significance(\"p.adj\") %&gt;%\n    add_xy_position(x = \"name\", scales = \"free\", fun = \"max\") %&gt;%\n    select(-3, -6, -7, -8, -9, -10) %&gt;%\n    mutate(\n        across(\"xmin\", str_replace, \"2.8\", \"0.8\"),\n        across(\"xmin\", str_replace, \"3.8\", \"1.8\"),\n        across(\"xmax\", str_replace, \"3.2\", \"1.2\"),\n        across(\"xmax\", str_replace, \"4.2\", \"2.2\")\n    ) %&gt;%\n    mutate(xmin = as.numeric(xmin), xmax = as.numeric(xmax))\n\nstat.test\n## # A tibble: 4 × 11\n##   name   group group1 group2    p.adj p.adj.signif y.position groups     x  xmin\n##   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt; &lt;name&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 Petal… Petal setosa virgi… 3.71e-49 ****               7.5  &lt;chr&gt;      1   0.8\n## 2 Petal… Petal setosa virgi… 7.32e-48 ****               2.73 &lt;chr&gt;      2   1.8\n## 3 Sepal… Sepal setosa virgi… 7.94e-25 ****               8.15 &lt;chr&gt;      3   0.8\n## 4 Sepal… Sepal setosa virgi… 4.57e- 9 ****               4.47 &lt;chr&gt;      4   1.8\n## # ℹ 1 more variable: xmax &lt;dbl&gt;\n\n\niris %&gt;%\n    pivot_longer(-Species) %&gt;%\n    filter(Species != \"versicolor\") %&gt;%\n    mutate(group = str_sub(name, start = 1, end = 5)) %&gt;%\n    ggplot(., aes(x = name, y = value)) +\n    stat_summary(geom = \"bar\", position = \"dodge\", aes(fill = Species)) +\n    stat_summary(\n        geom = \"errorbar\", fun.data = \"mean_sdl\",\n        fun.args = list(mult = 1),\n        aes(fill = Species),\n        position = position_dodge(0.9), width = 0.2, color = \"black\"\n    ) +\n    stat_pvalue_manual(stat.test,\n        label = \"p.adj.signif\", label.size = 6, hide.ns = T,\n        tip.length = 0.01\n    ) +\n    facet_wrap(. ~ group, scale = \"free_x\", nrow = 1) +\n    labs(x = NULL, y = NULL) +\n    scale_fill_manual(values = c(\"#BA7A70\", \"#829BAB\")) +\n    scale_y_continuous(limits = c(0, 9), expand = c(0, 0)) +\n    theme(\n        axis.title.x = element_blank(),\n        axis.title.y = element_text(color = \"black\", size = 12, margin = margin(r = 3)),\n        axis.ticks.x = element_blank(),\n        axis.text.y = element_text(color = \"black\", size = 10, margin = margin(r = 2)),\n        axis.text.x = element_text(color = \"black\"),\n        panel.background = element_rect(fill = NA, color = NA),\n        panel.grid.minor = element_line(size = 0.2, color = \"#e5e5e5\"),\n        panel.grid.major = element_line(size = 0.2, color = \"#e5e5e5\"),\n        panel.border = element_rect(fill = NA, color = \"black\", size = 0.3, linetype = \"solid\"),\n        legend.key = element_blank(),\n        legend.title = element_blank(),\n        legend.text = element_text(color = \"black\", size = 8),\n        legend.spacing.x = unit(0.1, \"cm\"),\n        legend.key.width = unit(0.5, \"cm\"),\n        legend.key.height = unit(0.5, \"cm\"),\n        legend.position = c(1, 1), legend.justification = c(1, 1),\n        legend.background = element_blank(),\n        legend.box.margin = margin(0, 0, 0, 0),\n        strip.text = element_text(color = \"black\", size = 10),\n        panel.spacing.x = unit(0.3, \"cm\")\n    )\n## Warning in stat_summary(geom = \"errorbar\", fun.data = \"mean_sdl\", fun.args =\n## list(mult = 1), : Ignoring unknown aesthetics: fill\n## Warning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\n## ℹ Please use the `linewidth` argument instead.\n## Warning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\n## ℹ Please use the `linewidth` argument instead.\n## No summary function supplied, defaulting to `mean_se()`\n## No summary function supplied, defaulting to `mean_se()`\n## Warning: Computation failed in `stat_summary()`\n## Caused by error in `fun.data()`:\n## ! The package \"Hmisc\" is required.\n## Warning: Computation failed in `stat_summary()`\n## Caused by error in `fun.data()`:\n## ! The package \"Hmisc\" is required."
  },
  {
    "objectID": "blog/2023/03/01/index.html",
    "href": "blog/2023/03/01/index.html",
    "title": "Equalizing Bar Widths",
    "section": "",
    "text": "Make the widths of bars to be same when the level of subgroups are not equal\n\n### ---------\nlibrary(ggplot2)\nlibrary(ggsci)\n\ntheme_set(\n    theme(\n        text = element_text(size = 10, family = \"Arial\"),\n        panel.background = element_rect(fill = NA, color = NA),\n        axis.title = element_text(size = 10, color = \"black\"),\n        axis.text = element_text(size = 10, color = \"black\"),\n        # axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),\n        axis.ticks.length.x = unit(0.3, \"lines\"),\n        axis.line = element_line(colour = \"Black\"),\n        axis.ticks = element_line(colour = \"black\", linewidth = 0.6),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 10)\n    )\n)\n# Create a sample dataframe\ndf &lt;- data.frame(\n    group = c(\"A\", \"B\", \"B\", \"C\", \"C\"),\n    variant = c(\"v1\", \"v1\", \"v2\", \"v1\", \"v2\"),\n    value = c(10, 20, 30, 15, 25)\n)\n\n# Specify the widths for each group and variant\nwidths &lt;- data.frame(\n    group = c(\"A\", \"B\", \"C\"),\n    v1 = c(0.4, 0.8, 0.8),\n    v2 = c(0, 0.8, 0.8) # set width to 0 for variant v2 in group A\n)\n\n# Create the barplot with position_dodge2\nggplot(df, aes(x = group, y = value, fill = variant)) +\n    geom_bar(\n        stat = \"identity\",\n        position = position_dodge2(preserve = \"single\", width = widths)\n    ) +\n    scale_fill_jco() +\n    scale_y_continuous(\n        expand = expansion(mult = c(0, 0.1))\n    ) +\n    scale_x_discrete(breaks = c(\"A\", \"B\", \"C\")) # Ensure all groups are displayed in x-axis\n\n\n\n\n\n\n# ggsave(\n#   plot = p,\n#   filename = \"barplot.png\",\n#   width = 4,\n#   height = 3,\n# )\n\nIn this example, we set widths to be a data frame that specifies the widths for each group and variant. We set the width for v2 in group A to 0 to hide the bar for that variant. Then, we use position_dodge2 with preserve = “single” and the width argument set to widths to create the barplot with different bar widths for each group and variant."
  },
  {
    "objectID": "blog/2022/05/02/index.html",
    "href": "blog/2022/05/02/index.html",
    "title": "Make scatter plot with truncated axis",
    "section": "",
    "text": "Load data\n\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(ggh4x)\nlibrary(latex2exp)\n\nfig1a &lt;- read_excel(here(\"projects\", \"data\", \"data.xlsx\"), sheet = \"Figure_1A\")\nfig1a %&gt;% head()\n## # A tibble: 6 × 5\n##   animal.number genotype Fat.mass Lean.Mass sex  \n##           &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;\n## 1           109 WT           3.87      31.4 Male \n## 2           140 WT           6.98      28.0 Male \n## 3           141 WT           5.66      29.6 Male \n## 4           144 WT           4.37      30.8 Male \n## 5           145 WT           4.32      29.1 Male \n## 6           199 WT           1.62      27.7 Male\n\n\np1 &lt;- fig1a %&gt;%\n  filter(genotype == \"WT\") %&gt;%\n  ggplot(aes(x = Lean.Mass, y = Fat.mass)) +\n  geom_point(shape = 21, size = 5, fill = \"#929292\", color = \"black\") +\n  scale_x_continuous(\n    limits = c(20, 40),\n    breaks = seq(20, 40, 5),\n    guide = \"axis_minor\",\n    minor_breaks = seq(22.5, 37.5, by = 5)\n  ) +\n  scale_y_continuous(\n    limits = c(0, 25),\n    breaks = seq(0, 25, 5),\n    guide = \"axis_minor\",\n    minor_breaks = c(8, 12)\n  ) +\n  theme_classic() +\n  theme(\n    ggh4x.axis.ticks.length.minor = rel(0.5),\n    axis.ticks.length.x = unit(0.5, \"lines\")\n  ) +\n  guides(\n    x = guide_axis_minor(trunc_lower = 20, trunc_upper = 40),\n    y = guide_axis_truncated(trunc_lower = 0, trunc_upper = 25)\n  ) +\n  geom_vline(xintercept = 32.5, lty = \"dashed\") +\n  geom_hline(yintercept = 10, lty = \"dashed\") +\n  labs(\n    x = NULL,\n    y = \"Fat mass (g)\"\n  ) +\n  annotate(geom = \"point\", x = 20, y = 23 + 1, shape = 21, size = 5, fill = \"#929292\") +\n  annotate(geom = \"text\", x = 20.5, y = 23 + 1, label = \"WT\", size = 5, hjust = 0) +\n  annotate(geom = \"point\", x = 20, y = 22 - 1, shape = 21, size = 5, fill = \"#0533ff\") +\n  annotate(geom = \"text\", x = 20.5, y = 22 - 1, label = TeX(r\"(\\textit{Nnat}${^+}{^/}{^-}{^p}$)\"), size = 5, hjust = 0)\n\n\np2 &lt;- fig1a %&gt;%\n  filter(genotype == \"Nnat+/-p\") %&gt;%\n  ggplot(aes(x = Lean.Mass, y = Fat.mass)) +\n  geom_point(shape = 21, size = 5, fill = \"#0533ff\", color = \"black\") +\n  scale_x_continuous(\n    limits = c(20, 40),\n    breaks = seq(20, 40, 5),\n    guide = \"axis_minor\",\n    minor_breaks = seq(22.5, 37.5, by = 5)\n  ) +\n  scale_y_continuous(\n    limits = c(0, 25),\n    breaks = seq(0, 25, 5),\n    guide = \"axis_minor\",\n    minor_breaks = c(8, 12)\n  ) +\n  theme_classic() +\n  theme(\n    ggh4x.axis.ticks.length.minor = rel(0.5),\n    axis.ticks.length.x = unit(0.5, \"lines\"),\n    axis.line.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.text.y = element_blank()\n  ) +\n  guides(\n    x = guide_axis_minor(\n      trunc_lower = 20,\n      trunc_upper = 40\n    ),\n    y = guide_axis_truncated(\n      trunc_lower = 0,\n      trunc_upper = 25\n    )\n  ) +\n  geom_vline(xintercept = 32.5, lty = \"dashed\") +\n  geom_hline(yintercept = 10, lty = \"dashed\") +\n  labs(x = NULL, y = NULL)\n\nlibrary(patchwork)\np1 + p2 + labs(x = \"Lean mass (g)\") + theme(axis.title.x = element_text(hjust = -0.12))\n## Warning: The S3 guide system was deprecated in ggplot2 3.5.0.\n## ℹ It has been replaced by a ggproto system that can be extended.\n## Warning in is.na(x): is.na() applied to non-(list or vector) of type\n## 'expression'"
  },
  {
    "objectID": "blog/2022/02/01/index.html",
    "href": "blog/2022/02/01/index.html",
    "title": "Add errorbar and p-value on barplot with ggsignif",
    "section": "",
    "text": "library(tidyverse)\nlibrary(here)\nlibrary(ggsignif)\nlibrary(ggh4x)\ndfb &lt;- read.csv(here(\"projects\", \"data\", \"221001_barplot.csv\"), header = FALSE)\ndfb\n##                    V1   V2   V3   V4   V5   V6   V7 V8\n## 1             Control 0.06 0.00 0.39 0.22 0.22 0.36 NA\n## 2                  F5 0.99 1.00 0.95 0.97 0.97   NA NA\n## 3 pAtUbi3:CDS-Rps11-1 1.00 0.67 0.94 1.00 1.00   NA NA\n## 4 pAtUbi3:CDS-Rps11-2 0.94 1.00 0.94 0.94 1.00 1.00  1\ndfb.1 &lt;- dfb %&gt;%\n    pivot_longer(!V1) %&gt;%\n    select(V1, value) %&gt;%\n    na.omit()\ndfb.1\n## # A tibble: 23 × 2\n##    V1      value\n##    &lt;chr&gt;   &lt;dbl&gt;\n##  1 Control  0.06\n##  2 Control  0   \n##  3 Control  0.39\n##  4 Control  0.22\n##  5 Control  0.22\n##  6 Control  0.36\n##  7 F5       0.99\n##  8 F5       1   \n##  9 F5       0.95\n## 10 F5       0.97\n## # ℹ 13 more rows"
  },
  {
    "objectID": "blog/2022/02/01/index.html#prepare-data",
    "href": "blog/2022/02/01/index.html#prepare-data",
    "title": "Add errorbar and p-value on barplot with ggsignif",
    "section": "",
    "text": "library(tidyverse)\nlibrary(here)\nlibrary(ggsignif)\nlibrary(ggh4x)\ndfb &lt;- read.csv(here(\"projects\", \"data\", \"221001_barplot.csv\"), header = FALSE)\ndfb\n##                    V1   V2   V3   V4   V5   V6   V7 V8\n## 1             Control 0.06 0.00 0.39 0.22 0.22 0.36 NA\n## 2                  F5 0.99 1.00 0.95 0.97 0.97   NA NA\n## 3 pAtUbi3:CDS-Rps11-1 1.00 0.67 0.94 1.00 1.00   NA NA\n## 4 pAtUbi3:CDS-Rps11-2 0.94 1.00 0.94 0.94 1.00 1.00  1\ndfb.1 &lt;- dfb %&gt;%\n    pivot_longer(!V1) %&gt;%\n    select(V1, value) %&gt;%\n    na.omit()\ndfb.1\n## # A tibble: 23 × 2\n##    V1      value\n##    &lt;chr&gt;   &lt;dbl&gt;\n##  1 Control  0.06\n##  2 Control  0   \n##  3 Control  0.39\n##  4 Control  0.22\n##  5 Control  0.22\n##  6 Control  0.36\n##  7 F5       0.99\n##  8 F5       1   \n##  9 F5       0.95\n## 10 F5       0.97\n## # ℹ 13 more rows"
  },
  {
    "objectID": "blog/2022/02/01/index.html#define-errorbar-function",
    "href": "blog/2022/02/01/index.html#define-errorbar-function",
    "title": "Add errorbar and p-value on barplot with ggsignif",
    "section": "Define errorbar function",
    "text": "Define errorbar function\n\nebtop &lt;- function(x) {\n    return(mean(x) + sd(x) / sqrt(length(x)))\n}\nebbottom &lt;- function(x) {\n    return(mean(x) - sd(x) / sqrt(length(x)))\n}"
  },
  {
    "objectID": "blog/2022/02/01/index.html#add-errorbar-and-p-value",
    "href": "blog/2022/02/01/index.html#add-errorbar-and-p-value",
    "title": "Add errorbar and p-value on barplot with ggsignif",
    "section": "Add errorbar and p-value",
    "text": "Add errorbar and p-value\n\np &lt;- ggplot(data = dfb.1, aes(x = V1, y = value)) +\n    stat_summary(\n        geom = \"bar\",\n        fun = mean,\n        fill = \"#c6c3c3\"\n    ) +\n    stat_summary(\n        geom = \"errorbar\",\n        fun.min = ebbottom,\n        fun.max = ebtop,\n        width = 0.2\n    ) +\n    geom_jitter(width = 0.3) +\n    geom_signif(\n        comparisons = list(\n            c(\"Control\", \"F5\"),\n            c(\"Control\", \"pAtUbi3:CDS-Rps11-1\"),\n            c(\"Control\", \"pAtUbi3:CDS-Rps11-2\")\n        ),\n        test = t.test,\n        test.args = list(\n            var.equal = T,\n            alternative = \"two.side\"\n        ),\n        y_position = c(1.1, 1.3, 1.5),\n        annotations = c(\"\"),\n        parse = T\n    ) +\n    annotate(\n        geom = \"text\",\n        x = 1.5, y = 1.15,\n        label = expression(italic(P) ~ \"=\" ~ 1.83 %*% 10^-6)\n    ) +\n    annotate(\n        geom = \"text\",\n        x = 2, y = 1.35,\n        label = expression(italic(P) ~ \"=\" ~ 2.71 %*% 10^-5)\n    ) +\n    annotate(\n        geom = \"text\",\n        x = 2.5, y = 1.55,\n        label = expression(italic(P) ~ \"=\" ~ 5.75 %*% 10^-8)\n    ) +\n    scale_y_continuous(\n        expand = c(0, 0),\n        limits = c(0, 1.6),\n        breaks = seq(0, 1, 0.2)\n    ) +\n    theme_minimal() +\n    theme(\n        panel.grid = element_blank(),\n        axis.line.y = element_line(),\n        axis.ticks.y = element_line(),\n        axis.title.y = element_text(\n            hjust = 0.25,\n            size = 15\n        ),\n        axis.text.x = element_text(\n            angle = 30,\n            hjust = 1,\n            size = 10\n        )\n    ) +\n    guides(y = guide_axis_truncated(\n        trunc_lower = 0,\n        trunc_upper = 1\n    )) +\n    labs(x = NULL, y = \"Survival Rate\")\np"
  },
  {
    "objectID": "blog/2022/02/01/index.html#reference",
    "href": "blog/2022/02/01/index.html#reference",
    "title": "Add errorbar and p-value on barplot with ggsignif",
    "section": "Reference",
    "text": "Reference\n\nhttps://www.nature.com/articles/s41467-021-26554-8#Sec23\nhttps://statisticsglobe.com/ggsignif-package-r"
  },
  {
    "objectID": "blog/2022/08/01/index.html",
    "href": "blog/2022/08/01/index.html",
    "title": "View data from 96/384 multi-well plates",
    "section": "",
    "text": "# library(plater)\npacman::p_load(platetools, ggplot2, viridis)\nnumbers &lt;- 1:96\nnum_to_well(numbers)\n##  [1] \"A01\" \"A02\" \"A03\" \"A04\" \"A05\" \"A06\" \"A07\" \"A08\" \"A09\" \"A10\" \"A11\" \"A12\"\n## [13] \"B01\" \"B02\" \"B03\" \"B04\" \"B05\" \"B06\" \"B07\" \"B08\" \"B09\" \"B10\" \"B11\" \"B12\"\n## [25] \"C01\" \"C02\" \"C03\" \"C04\" \"C05\" \"C06\" \"C07\" \"C08\" \"C09\" \"C10\" \"C11\" \"C12\"\n## [37] \"D01\" \"D02\" \"D03\" \"D04\" \"D05\" \"D06\" \"D07\" \"D08\" \"D09\" \"D10\" \"D11\" \"D12\"\n## [49] \"E01\" \"E02\" \"E03\" \"E04\" \"E05\" \"E06\" \"E07\" \"E08\" \"E09\" \"E10\" \"E11\" \"E12\"\n## [61] \"F01\" \"F02\" \"F03\" \"F04\" \"F05\" \"F06\" \"F07\" \"F08\" \"F09\" \"F10\" \"F11\" \"F12\"\n## [73] \"G01\" \"G02\" \"G03\" \"G04\" \"G05\" \"G06\" \"G07\" \"G08\" \"G09\" \"G10\" \"G11\" \"G12\"\n## [85] \"H01\" \"H02\" \"H03\" \"H04\" \"H05\" \"H06\" \"H07\" \"H08\" \"H09\" \"H10\" \"H11\" \"H12\"\nnumbers &lt;- 320:384\nnum_to_well(numbers, plate = 384)\n##  [1] \"N08\" \"N09\" \"N10\" \"N11\" \"N12\" \"N13\" \"N14\" \"N15\" \"N16\" \"N17\" \"N18\" \"N19\"\n## [13] \"N20\" \"N21\" \"N22\" \"N23\" \"N24\" \"O01\" \"O02\" \"O03\" \"O04\" \"O05\" \"O06\" \"O07\"\n## [25] \"O08\" \"O09\" \"O10\" \"O11\" \"O12\" \"O13\" \"O14\" \"O15\" \"O16\" \"O17\" \"O18\" \"O19\"\n## [37] \"O20\" \"O21\" \"O22\" \"O23\" \"O24\" \"P01\" \"P02\" \"P03\" \"P04\" \"P05\" \"P06\" \"P07\"\n## [49] \"P08\" \"P09\" \"P10\" \"P11\" \"P12\" \"P13\" \"P14\" \"P15\" \"P16\" \"P17\" \"P18\" \"P19\"\n## [61] \"P20\" \"P21\" \"P22\" \"P23\" \"P24\"\n# example dataframe\ndf &lt;- data.frame(vals = rnorm(384),\n                 well = num_to_well(1:384, plate = 384))\n\nraw_map(data = df$vals,\n        well = df$well,\n        plate = 384) +\n    ggtitle(\"Example 384-well plate\") +\n    theme_dark() +\n    scale_fill_viridis()\ndf01 &lt;- data.frame(well = num_to_well(1:96),\n  vals = rnorm(96),\n  plate = 1)\n\ndf02 &lt;- data.frame(well = num_to_well(1:96),\n  vals = rnorm(96),\n  plate = 2)\n\ndf &lt;- rbind(df01, df02)\n\nraw_grid(data = df$vals,\n    well = df$well,\n    plate_id = df$plate,\n    plate = 96)"
  },
  {
    "objectID": "blog/2022/08/01/index.html#reference",
    "href": "blog/2022/08/01/index.html#reference",
    "title": "View data from 96/384 multi-well plates",
    "section": "Reference",
    "text": "Reference\n\nhttps://gist.github.com/Swarchal/b938933ae9ded94b3c14d6485b27cf69\nhttps://rpubs.com/Swarchal/phenoScreen\nhttps://ropensci.org/blog/2017/02/06/plater-blog-post/\nhttps://cran.r-project.org/web/packages/plater/vignettes/plater-basics.html"
  },
  {
    "objectID": "blog/2023/03/05/index.html",
    "href": "blog/2023/03/05/index.html",
    "title": "Scatter plot with ggplot2",
    "section": "",
    "text": "Make a nice scatter plot\n\npacman::p_load(\n    tidyverse,\n    ggpubr,\n    ggprism,\n    patchwork,\n    ggsci,\n    gapminder,\n    here,\n    ggthemes,\n    countrycode,\n    mapproj\n)\n\n\n### subset data\ndf &lt;- gapminder %&gt;%\n    filter(year == \"2007\") %&gt;%\n    mutate(\n        pop2 = pop + 1,\n        continent = case_when(\n            continent == \"Oceania\" ~ \"Asia\",\n            TRUE ~ as.character(continent)\n        ) %&gt;% as.factor() %&gt;%\n            fct_relevel(\"Asia\", \"Americas\", \"Europe\", \"Africa\")\n    )\ndf\n## # A tibble: 142 × 7\n##    country     continent  year lifeExp       pop gdpPercap      pop2\n##    &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;     &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n##  1 Afghanistan Asia       2007    43.8  31889923      975.  31889924\n##  2 Albania     Europe     2007    76.4   3600523     5937.   3600524\n##  3 Algeria     Africa     2007    72.3  33333216     6223.  33333217\n##  4 Angola      Africa     2007    42.7  12420476     4797.  12420477\n##  5 Argentina   Americas   2007    75.3  40301927    12779.  40301928\n##  6 Australia   Asia       2007    81.2  20434176    34435.  20434177\n##  7 Austria     Europe     2007    79.8   8199783    36126.   8199784\n##  8 Bahrain     Asia       2007    75.6    708573    29796.    708574\n##  9 Bangladesh  Asia       2007    64.1 150448339     1391. 150448340\n## 10 Belgium     Europe     2007    79.4  10392226    33693.  10392227\n## # ℹ 132 more rows\n\n\nggplot(data = df, aes(x = gdpPercap, y = lifeExp)) +\n    geom_point(aes(size = pop, color = continent)) +\n    geom_point(aes(size = pop2), color = \"black\", shape = 21) +\n    scale_x_log10(breaks = c(\n        500, 1000, 2000, 4000,\n        8000, 16000, 32000, 64000\n    )) +\n    scale_y_continuous(breaks = seq(0, 90, by = 10)) +\n    scale_color_manual(values = c(\n        \"#F15772\", \"#7EEB03\",\n        \"#FBE700\", \"#54D5E9\"\n    )) +\n    scale_size_continuous(range = c(1, 30)) +\n    # guides(size = FALSE, color = FALSE) +\n    guides(fill = guide_legend(override.aes = list(size =5))) +\n    labs(x = \"Income\", y = \"Life expectancy\") +\n    theme_minimal() +\n    #   annotate(\"text\", x = 4000, y = 45, hjust = 0.5,\n    #            size = 85, color = \"#999999\",\n    #            label = \"2007\", alpha = .3,\n    #            family = \"Helvetica Neue\") +\n    annotate(\"segment\",\n        x = 0, xend = 2014, y = 46.9, yend = 46.9,\n        color = \"#606F7B\", linetype = 2, linewidth = .2\n    ) +\n    annotate(\"segment\",\n        x = 2014, xend = 2014, y = 0, yend = 46.9,\n        color = \"#606F7B\", linetype = 2, linewidth = .2\n    ) +\n    annotate(\"text\",\n        x = 28200, y = 2,\n        label = \"per person (GDP/capita, PPP$ inflation-adjusted)\",\n        size = 2.8, color = \"#999999\"\n    ) +\n    annotate(\"text\",\n        x = 2304, y = 42, hjust = 0,\n        size = 3.5,\n        label = paste0(\n            \"Nigeria had a life expectancy of\\n\",\n            \"46.9 years and an annual income of\",\n            \"\\n$2014 per year per person in 2007\"\n        )\n    ) +\n    theme(\n        panel.background = element_rect(fill = \"white\"),\n        plot.background = element_rect(fill = \"white\"),\n        plot.margin = unit(rep(1, 4), \"cm\"),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(\n            linewidth = 0.2,\n            color = \"#e5e5e5\"\n        ),\n        axis.title.y = element_text(\n            margin = margin(r = 15),\n            size = 11,\n            family = \"Helvetica Neue Light\"\n        ),\n        axis.title.x = element_text(\n            margin = margin(t = 15),\n            size = 11,\n            family = \"Helvetica Neue Light\"\n        ),\n        axis.text = element_text(family = \"Helvetica Neue Light\"),\n        axis.line = element_line(\n            color = \"#999999\",\n            size = 0.2\n        )\n    ) +\n    coord_cartesian(ylim = c(4.1, 86))\n## Warning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\n## ℹ Please use the `linewidth` argument instead.\n## Warning: Transformation introduced infinite values in continuous x-axis\n\n\n\n\n\n\n\n# ggsave(\n#     here(\"blog\", \"2023\", \"03\", \"05\", \"plot.png\")\n# )"
  },
  {
    "objectID": "blog/2023/03/08/index.html",
    "href": "blog/2023/03/08/index.html",
    "title": "Ridgeline plots in ggplot2",
    "section": "",
    "text": "Visualizing changes in distributions over time or space nicely usning ggrigges.\n\npacman::p_load(\n    tidyverse,\n    ggsci,\n    ggridges,\n    ggtext,\n    ggh4x,\n    gapminder,\n    here\n)\n\n\n### subset data\ndf &lt;- gapminder %&gt;% filter(continent %in% c(\"Asia\",\"Europe\"))\ndf\n## # A tibble: 756 × 6\n##    country     continent  year lifeExp      pop gdpPercap\n##    &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n##  1 Afghanistan Asia       1952    28.8  8425333      779.\n##  2 Afghanistan Asia       1957    30.3  9240934      821.\n##  3 Afghanistan Asia       1962    32.0 10267083      853.\n##  4 Afghanistan Asia       1967    34.0 11537966      836.\n##  5 Afghanistan Asia       1972    36.1 13079460      740.\n##  6 Afghanistan Asia       1977    38.4 14880372      786.\n##  7 Afghanistan Asia       1982    39.9 12881816      978.\n##  8 Afghanistan Asia       1987    40.8 13867957      852.\n##  9 Afghanistan Asia       1992    41.7 16317921      649.\n## 10 Afghanistan Asia       1997    41.8 22227415      635.\n## # ℹ 746 more rows\n\n\nggplot(df, aes(y = country, x = lifeExp, fill = continent)) +\n    geom_density_ridges(size = .15, color = \"black\") +\n    scale_x_continuous(\n        ### converse x axis\n        trans = \"log10\", expand = c(0, 0),\n        labels = scales::comma_format(suffix = \"k\", scale = 1e-4)\n    ) +\n    scale_y_discrete(expand = c(0, 0)) +\n    scale_fill_futurama(alpha = .95) +\n    ### facet continent\n    facet_wrap(vars(continent), scales = \"free_y\") +\n    coord_cartesian(clip = \"off\") +\n    theme_minimal() +\n    theme(\n        legend.position = \"bottom\",\n        legend.justification = \"right\",\n        axis.title.x = element_text(margin = margin(t = 10), color = \"black\"),\n        axis.title.y = element_blank(),\n        axis.text.x = element_text(size = 8, color = \"black\"),\n        axis.text.y = element_text(face = \"bold\", color = \"black\"),\n        panel.grid.minor = element_blank(),\n        panel.grid.major.x = element_line(\n            linewidth = .3, linetype = \"dashed\",\n            color = \"grey75\"\n        ),\n        panel.grid.major.y = element_blank(),\n        axis.ticks.x = element_line(linewidth = .3, color = \"black\"),\n        panel.spacing = unit(1, \"lines\"),\n        strip.text = element_text(\n            face = \"bold\", margin = margin(b = 10),\n            color = \"black\", size = 12\n        ),\n        plot.background = element_rect(fill = \"white\", color = NA),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.title = element_blank()\n    ) +\n    guides(fill = guide_legend(\n        override.aes = list(color = NA),\n        label.theme = element_text(color = \"white\", size = 8)\n    ))\n## Picking joint bandwidth of 0.035\n## Picking joint bandwidth of 0.0125\n\n\n\n\n\n\n\n# ggsave(\n#     here(\"blog\", \"2023\", \"03\", \"08\", \"plot.png\")\n#     # width = 6,\n#     # height = 3.8\n#     # units = \"in\",\n#     # type = \"cairo\"\n# )"
  },
  {
    "objectID": "blog/2023/03/30/index.html",
    "href": "blog/2023/03/30/index.html",
    "title": "Add p-values onto basic barplot or boxplot",
    "section": "",
    "text": "How to compute and add p-values to basic ggplots using the rstatix and the ggpubr R packages.\nlibrary(tidyverse)\nlibrary(ggpubr)         # creat easily publication plots\nlibrary(rstatix)        # pipe-friendly tools for easy statistical analyses\nlibrary(patchwork)"
  },
  {
    "objectID": "blog/2023/03/30/index.html#basic-barplot-or-boxplot-with-p-value",
    "href": "blog/2023/03/30/index.html#basic-barplot-or-boxplot-with-p-value",
    "title": "Add p-values onto basic barplot or boxplot",
    "section": "Basic Barplot or Boxplot with p-value",
    "text": "Basic Barplot or Boxplot with p-value\nComparing two means\n\n# Transform `dose` into factor variable\ndf &lt;- ToothGrowth\ndf$dose &lt;- as.factor(df$dose)\nhead(df, 3)\n##    len supp dose\n## 1  4.2   VC  0.5\n## 2 11.5   VC  0.5\n## 3  7.3   VC  0.5\n\n### statistical test to compare two independent groups\n\nstat_test &lt;- df %&gt;% \n    t_test(len ~ supp) %&gt;%\n    add_significance() %&gt;% \n    add_xy_position(x = \"supp\")\n\nstat_test\n## # A tibble: 1 × 13\n##   .y.   group1 group2    n1    n2 statistic    df      p p.signif y.position\n##   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n## 1 len   OJ     VC        30    30      1.92  55.3 0.0606 ns             34.3\n## # ℹ 3 more variables: groups &lt;named list&gt;, xmin &lt;dbl&gt;, xmax &lt;dbl&gt;\n\np1 &lt;- ggboxplot(df, x = \"supp\", y = \"len\", fill = \"#00AFBB\") +\n    stat_pvalue_manual(stat_test, label = \"p\")\n\n### Customize p-value labels using glue expression\np2 &lt;- ggboxplot(df, x = \"supp\", y = \"len\", fill = \"#00AFBB\") +\n    stat_pvalue_manual(\n        stat_test, \n        label = \"T-test, p = {p}\", \n        vjust = -1, #vertically adjust the position of the p-values labels \n        bracket.nudge.y = 1 # move up or to move down the brackets. \n        ) +\n    scale_y_continuous(expand = expansion(mult = c(0.05, 0.15)))\np1 + p2\n\n\n\n\n\n\n\n\n### grouped data\nstat_test &lt;- df %&gt;%\n    group_by(dose) %&gt;%\n    t_test(len ~ supp) %&gt;%\n    adjust_pvalue() %&gt;%\n    add_significance() %&gt;% \n    add_xy_position(x = \"supp\")\n\nstat_test\n## # A tibble: 3 × 15\n##   dose  .y.   group1 group2    n1    n2 statistic    df       p   p.adj\n##   &lt;fct&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n## 1 0.5   len   OJ     VC        10    10    3.17    15.0 0.00636 0.0127 \n## 2 1     len   OJ     VC        10    10    4.03    15.4 0.00104 0.00312\n## 3 2     len   OJ     VC        10    10   -0.0461  14.0 0.964   0.964  \n## # ℹ 5 more variables: p.adj.signif &lt;chr&gt;, y.position &lt;dbl&gt;,\n## #   groups &lt;named list&gt;, xmin &lt;dbl&gt;, xmax &lt;dbl&gt;\n\nggboxplot(df,\n    x = \"supp\", y = \"len\", fill = \"#00AFBB\",\n    facet.by = \"dose\"\n    ) +\n    stat_pvalue_manual(stat_test, label = \"p.adj\") +\n    scale_y_continuous(expand = expansion(mult = c(0.05, 0.10)))\n\n\n\n\n\n\n\n\n### Show p-values if significant otherwise show ns\nstat_test &lt;- df %&gt;%\n    group_by(dose) %&gt;%\n    t_test(len ~ supp) %&gt;%\n    adjust_pvalue() %&gt;%\n    add_significance() %&gt;%\n    add_xy_position(\"supp\")\n\nstat_test$custom_label &lt;- ifelse(stat_test$p.adj &lt;= 0.05, stat_test$p.adj, \"ns\")\n\nstat_test\n## # A tibble: 3 × 16\n##   dose  .y.   group1 group2    n1    n2 statistic    df       p   p.adj\n##   &lt;fct&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n## 1 0.5   len   OJ     VC        10    10    3.17    15.0 0.00636 0.0127 \n## 2 1     len   OJ     VC        10    10    4.03    15.4 0.00104 0.00312\n## 3 2     len   OJ     VC        10    10   -0.0461  14.0 0.964   0.964  \n## # ℹ 6 more variables: p.adj.signif &lt;chr&gt;, y.position &lt;dbl&gt;,\n## #   groups &lt;named list&gt;, xmin &lt;dbl&gt;, xmax &lt;dbl&gt;, custom_label &lt;chr&gt;\n\nggboxplot(df,\n    x = \"supp\", y = \"len\", fill = \"#00AFBB\",\n    facet.by = \"dose\"\n    ) +\n    stat_pvalue_manual(stat_test, label = \"custom_label\") +\n    scale_y_continuous(expand = expansion(mult = c(0.05, 0.10)))\n\n\n\n\n\n\n\n\n### Compare paired samples\n# Statistical test\nstat_test &lt;- df %&gt;%\n  t_test(len ~ supp, paired = TRUE) %&gt;%\n  add_significance() %&gt;% \n  add_xy_position(x = \"supp\")\n\n### boxplot with pvalue\np1 &lt;- ggpaired(df, x = \"supp\", y = \"len\", fill = \"#E7B800\",\n                 line.color = \"gray\", line.size = 0.4)+\n                 stat_pvalue_manual(stat_test, label = \"p.signif\")+\n                 scale_y_continuous(expand = expansion(mult = c(0.05, 0.10)))\n\n### combined with significane level\np2 &lt;- ggpaired(df,\n    x = \"supp\", y = \"len\", fill = \"#E7B800\",\n    line.color = \"gray\", line.size = 0.4\n) +\n    stat_pvalue_manual(stat_test, label = \"{p}{p.signif}\") +\n    scale_y_continuous(expand = expansion(mult = c(0.05, 0.10)))\n\np1 + p2\n\n\n\n\n\n\n\nPairwise comparisons\n\n### boxplot\nstat_test &lt;- df %&gt;% t_test(len ~ dose) %&gt;% \n    add_xy_position(x = \"dose\")\n\nbxp &lt;- ggboxplot(df,\n    x = \"dose\", y = \"len\", fill = \"dose\",\n    palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\") # Box plots\n    ) + \n    stat_pvalue_manual(\n      stat_test,\n      label = \"p.adj.signif\",\n      tip.length = 0.01\n)\n\n### Specify manually the y position of p-value labels and shorten the width of the brackets\nbxp_man &lt;- bxp + \n  stat_pvalue_manual(\n    stat_test, label = \"p.adj.signif\", tip.length = 0.01,\n    y.position = c(35, 40, 35), bracket.shorten = 0.05\n    )\n\n### Bar plot\nstat_test &lt;- df %&gt;% \n    t_test(len ~ dose) %&gt;%  \n    add_xy_position(fun = \"mean_sd\", x = \"dose\")\n\n# Bar plots showing mean +/- SD\nbp &lt;- ggbarplot(df,\n        x = \"dose\", y = \"len\", add = \"mean_sd\", fill = \"dose\",\n        palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\")\n    ) +\n    stat_pvalue_manual(\n        stat_test, \n        label = \"p.adj.signif\", \n        tip.length = 0.01\n        )\n\nbxp + bxp_man + bp\n\n\n\n\n\n\n\nComparsions against reference groups\n\nstat_test &lt;- df %&gt;% \n    t_test(len ~ dose, ref.group = \"0.5\") %&gt;% \n    add_xy_position(x = \"dose\")\n\nbxp &lt;- ggboxplot(df,\n    x = \"dose\", y = \"len\", fill = \"dose\",\n    palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\") # Box plots\n    ) + \n    stat_pvalue_manual(\n      stat_test,\n      label = \"p.adj.signif\",\n      tip.length = 0.01\n)\n\nbp &lt;- ggbarplot(df,\n        x = \"dose\", y = \"len\", add = \"mean_sd\", fill = \"dose\",\n        palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\")\n    ) +\n    stat_pvalue_manual(\n        stat_test, \n        label = \"p.adj.signif\", \n        tip.length = 0.01\n        )\n\nbxp + bp\n\n\n\n\n\n\n\nComparsions against all (basemean)\n\nstat_test &lt;- df %&gt;% \n    t_test(len ~ dose, ref.group = \"all\") %&gt;% \n    add_xy_position(x = \"dose\") \n\nbxp &lt;- ggboxplot(df,\n    x = \"dose\", y = \"len\", fill = \"dose\",\n    palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\") # Box plots\n) +\n    stat_pvalue_manual(\n        stat_test,\n        label = \"p.adj.signif\",\n        y.position = 35\n    )\n\nstat_test &lt;- df %&gt;% \n    t_test(len ~ dose, ref.group = \"all\") %&gt;% \n    add_xy_position(fun = \"mean_sd\", x = \"dose\")\n\nbp &lt;- ggbarplot(df,\n    x = \"dose\", y = \"len\", add = \"mean_sd\", fill = \"dose\",\n    palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\")\n) +\n    stat_pvalue_manual(\n        stat_test,\n        label = \"p.adj.signif\"\n\n    )\n\nbxp + bp"
  },
  {
    "objectID": "blog/2023/03/30/index.html#add-p-values-to-horizontal-ggplots",
    "href": "blog/2023/03/30/index.html#add-p-values-to-horizontal-ggplots",
    "title": "Add p-values onto basic barplot or boxplot",
    "section": "Add p-values to horizontal ggplots",
    "text": "Add p-values to horizontal ggplots\n\n# Transform `dose` into factor variable\ndf &lt;- ToothGrowth\ndf$dose &lt;- as.factor(df$dose)\n\nhead(df, 3)\n##    len supp dose\n## 1  4.2   VC  0.5\n## 2 11.5   VC  0.5\n## 3  7.3   VC  0.5\n\nstat_test &lt;- df %&gt;% \n    t_test(len ~ dose) %&gt;%\n    add_significance() %&gt;% \n    add_xy_position(x = \"dose\")\n\nstat_test\n## # A tibble: 3 × 14\n##   .y.   group1 group2    n1    n2 statistic    df        p    p.adj p.adj.signif\n##   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       \n## 1 len   0.5    1         20    20     -6.48  38.0 1.27e- 7 2.54e- 7 ****        \n## 2 len   0.5    2         20    20    -11.8   36.9 4.40e-14 1.32e-13 ****        \n## 3 len   1      2         20    20     -4.90  37.1 1.91e- 5 1.91e- 5 ****        \n## # ℹ 4 more variables: y.position &lt;dbl&gt;, groups &lt;named list&gt;, xmin &lt;dbl&gt;,\n## #   xmax &lt;dbl&gt;\n\n# Box plots\nggboxplot(df,\n    x = \"dose\", y = \"len\", fill = \"dose\",\n    palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\")\n) +\n    stat_pvalue_manual(\n        stat_test,\n        # use the adjusted p-value significance levels as labels\n        label = \"p.adj.signif\", tip.length = 0.01,\n        coord.flip = TRUE\n    ) +\n    coord_flip()\n\n\n\n\n\n\n\nggboxplot(df,\n    x = \"dose\", y = \"len\", fill = \"dose\",\n    palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\")\n) +\n    stat_pvalue_manual(\n        stat_test,\n        ### use adjusted p-values as labels\n        label = \"p.adj\", tip.length = 0.01,\n        coord.flip = TRUE\n    ) +\n    coord_flip()"
  },
  {
    "objectID": "blog/2023/03/30/index.html#reference",
    "href": "blog/2023/03/30/index.html#reference",
    "title": "Add p-values onto basic barplot or boxplot",
    "section": "Reference",
    "text": "Reference\n\nHow to Add P-Values onto Basic GGPLOTS\nHow to Add P-Values onto Horizontal GGPLOTS\nHow to Add P-Values onto a Grouped GGPLOT using the GGPUBR R Package\nHow to Add P-values to GGPLOT Facets\nAdd P-values to GGPLOT Facets with Different Scales\nGGPUBR: How to Add P-Values Generated Elsewhere to a GGPLOT\nGGPLOT Facet: How to Add Space Between Labels on the Top of the Chart and the Plot Border"
  },
  {
    "objectID": "blog/2023/04/10/index.html",
    "href": "blog/2023/04/10/index.html",
    "title": "Using Tmux and Screen for Persistent Terminal in VSCode Remote Session",
    "section": "",
    "text": "Advanced commands & shortcodes\n\n\n\ntmux list-sessions\ntmux attach-session -t target-session\nCtrl + B + (     # Cycle through all the available sessions and switch to the lastest active one\nCtrl + B + (     # Cycle through all the available sessions and switch to the lastest active one\nCtrl + B + L     # Switch to the lastest session, regardless of whether it was detached or attached\nCtrl + B + D     # Detach from linux screen session\n\n\n\nCtrl + B + W     # List all windows (the current window is marked with \"*\") .\nCtrl + B + N     # Switch to the next window.                                \nCtrl + B + P     # Switch to the previous window.                            \nCtrl + B + C     # create a new window (with shell).                         \nCtrl + B + 0-9   # go to a window numbered 0-9 .                             \nCtrl + B + K     # kill the current window.                                  \n\n\n\nCtrl + B + Q     # List all the panes and theri number\nCtrl + B + ↑     # Switch to the pane above the current one\nCtrl + B + ↓     # Switch to the pane below the current one\nCtrl + B + ←     # Switch to the pane left of the current one\nCtrl + B + →     # Switch to the pane right of the current one\n\n\n\n\nCreate session\nSetup session\nWork\nDetach\nAttach\nWork\nTo 4\n\n\n\n\nalias t=\"tmux\"\nalias ta=\"t a -t\"\nalias tls=\"t ls\"\nalias tn=\"t new -t\"\nNow we can run any tmux commands by just typing t (saved 3 characters and much cognitive load! Yeah!), create a new session with t {session-name}, attach to an existing session with ta {session-name} and list all your sessions with tls.\n\n\n\n\nAdd the below snippet to your remote settings in VSCode.\n\n{\n  \"terminal.integrated.profiles.linux\": {\n    \"tmux\": {\n      \"path\": \"/usr/bin/tmux\",\n      \"args\": [\n        \"new-session\",\n        \"-A\",\n        \"-s\",\n        \"main\"\n      ],\n    },\n  },\n  \"terminal.integrated.defaultProfile.linux\": \"tmux\",\n}\n\n\n\n\nUse vscode variables to make one tmux-session per project,\n\n{\n  \"terminal.integrated.profiles.linux\": {\n    \"tmux\": {\n      \"path\": \"/usr/bin/tmux\",\n      \"args\": [\n        \"new-session\",\n        \"-A\",\n        \"-s\",\n        \"vscode-${workspaceFolderBasename}\"\n      ],\n    },\n  },\n  \"terminal.integrated.defaultProfile.linux\": \"tmux\",\n}\n\n\n\n// 2023-04-10 updated\n{\n    \"r.rterm.linux\": \"/home/zhonggr/.local/bin/radian\",\n    // \"r.rterm.linux\": \"/bin/R\",\n    \"r.rpath.linux\": \"/bin/R\",\n    \"r.alwaysUseActiveTerminal\": true,\n    \"r.bracketedPaste\": true,\n    \"r.sessionWatcher\": true,\n    // \"terminal.integrated.defaultProfile.linux\": \"R Terminal\",\n    // \"terminal.integrated.defaultProfile.linux\": \"bash\",\n    \"r.plot.useHttpgd\": true,\n    \"editor.tabCompletion\": \"on\",\n    \"editor.acceptSuggestionOnEnter\": \"off\",\n    \"terminal.integrated.profiles.linux\": {\n        \"tmux\": {\n            \"path\": \"/usr/bin/tmux\",\n            \"args\": [\n                \"new-session\",\n                \"-A\",\n                \"-s\",\n                \"main\"\n            ],\n        },\n    },\n    \"terminal.integrated.defaultProfile.linux\": \"tmux\"\n}\nsource-file ~/.tmux.conf"
  },
  {
    "objectID": "blog/2023/04/10/index.html#tmux",
    "href": "blog/2023/04/10/index.html#tmux",
    "title": "Using Tmux and Screen for Persistent Terminal in VSCode Remote Session",
    "section": "",
    "text": "Advanced commands & shortcodes\n\n\n\ntmux list-sessions\ntmux attach-session -t target-session\nCtrl + B + (     # Cycle through all the available sessions and switch to the lastest active one\nCtrl + B + (     # Cycle through all the available sessions and switch to the lastest active one\nCtrl + B + L     # Switch to the lastest session, regardless of whether it was detached or attached\nCtrl + B + D     # Detach from linux screen session\n\n\n\nCtrl + B + W     # List all windows (the current window is marked with \"*\") .\nCtrl + B + N     # Switch to the next window.                                \nCtrl + B + P     # Switch to the previous window.                            \nCtrl + B + C     # create a new window (with shell).                         \nCtrl + B + 0-9   # go to a window numbered 0-9 .                             \nCtrl + B + K     # kill the current window.                                  \n\n\n\nCtrl + B + Q     # List all the panes and theri number\nCtrl + B + ↑     # Switch to the pane above the current one\nCtrl + B + ↓     # Switch to the pane below the current one\nCtrl + B + ←     # Switch to the pane left of the current one\nCtrl + B + →     # Switch to the pane right of the current one\n\n\n\n\nCreate session\nSetup session\nWork\nDetach\nAttach\nWork\nTo 4\n\n\n\n\nalias t=\"tmux\"\nalias ta=\"t a -t\"\nalias tls=\"t ls\"\nalias tn=\"t new -t\"\nNow we can run any tmux commands by just typing t (saved 3 characters and much cognitive load! Yeah!), create a new session with t {session-name}, attach to an existing session with ta {session-name} and list all your sessions with tls.\n\n\n\n\nAdd the below snippet to your remote settings in VSCode.\n\n{\n  \"terminal.integrated.profiles.linux\": {\n    \"tmux\": {\n      \"path\": \"/usr/bin/tmux\",\n      \"args\": [\n        \"new-session\",\n        \"-A\",\n        \"-s\",\n        \"main\"\n      ],\n    },\n  },\n  \"terminal.integrated.defaultProfile.linux\": \"tmux\",\n}\n\n\n\n\nUse vscode variables to make one tmux-session per project,\n\n{\n  \"terminal.integrated.profiles.linux\": {\n    \"tmux\": {\n      \"path\": \"/usr/bin/tmux\",\n      \"args\": [\n        \"new-session\",\n        \"-A\",\n        \"-s\",\n        \"vscode-${workspaceFolderBasename}\"\n      ],\n    },\n  },\n  \"terminal.integrated.defaultProfile.linux\": \"tmux\",\n}\n\n\n\n// 2023-04-10 updated\n{\n    \"r.rterm.linux\": \"/home/zhonggr/.local/bin/radian\",\n    // \"r.rterm.linux\": \"/bin/R\",\n    \"r.rpath.linux\": \"/bin/R\",\n    \"r.alwaysUseActiveTerminal\": true,\n    \"r.bracketedPaste\": true,\n    \"r.sessionWatcher\": true,\n    // \"terminal.integrated.defaultProfile.linux\": \"R Terminal\",\n    // \"terminal.integrated.defaultProfile.linux\": \"bash\",\n    \"r.plot.useHttpgd\": true,\n    \"editor.tabCompletion\": \"on\",\n    \"editor.acceptSuggestionOnEnter\": \"off\",\n    \"terminal.integrated.profiles.linux\": {\n        \"tmux\": {\n            \"path\": \"/usr/bin/tmux\",\n            \"args\": [\n                \"new-session\",\n                \"-A\",\n                \"-s\",\n                \"main\"\n            ],\n        },\n    },\n    \"terminal.integrated.defaultProfile.linux\": \"tmux\"\n}\nsource-file ~/.tmux.conf"
  },
  {
    "objectID": "blog/2023/04/10/index.html#screen",
    "href": "blog/2023/04/10/index.html#screen",
    "title": "Using Tmux and Screen for Persistent Terminal in VSCode Remote Session",
    "section": "Screen",
    "text": "Screen\n\nGeneral commands\nscreen                   # start a screen session\nscreen -S session_name   # start a named session\nscreen -r                # reattach to a linux screen\nscreen -ls               # list the current running screen session\nCommon commands for managing Linux Screen Windows:\nCtrl + A + C            # create a new window (with shell).\nCtrl + A + K            # kill the current window.\nCtrl + A + W            # list all windows (the current window is marked with \"*\") .\nCtrl + A + 0-9          # go to a window numbered 0-9 .\nCtrl + A + N            # go to the next window.\nCtrl + A  Ctrl + A      # toggle between the current and previous window.\nCtrl + A + A            # rename the current window.\nCtrl + A + S            # split current region horizontally into two regions.\nCtrl + A + |            # split current region vertically into two regions.\nCtrl + A + Tab          # switch the input focus to the next region.\nCtrl + A + Ctrl + A     # toggle between the current and previous windows\nCtrl + A + Q            # close all regions but the current one.\nCtrl + A + X            # close the current region.\nCtrl + A + D            # detach from linux screen session\nCtrl + A + [            # start copy mode\nCtrl + A + ]            # paste copied text\nCtrl + A + ?            # help, display  a list commands\nCtrl + A + Ctrl + \\     # quit screen\nscreen -ls\n## Output\nThere are screens on:\n    10835.pts-0.linuxize-desktop   (Detached)\n    10366.pts-0.linuxize-desktop   (Detached)\n2 Sockets in /run/screens/S-linuxize.\nIf want to restore screen 10835.pts-0, then\nscreen -r 10835\nPress the Spacebar or Enter to end a command.\n\n\nTo copy a block\nTo get into copy mode, press Ctrl-a [ .\nTo move the cursor, press the h, j, k, and l (the letter l) keys. The 0 (the number 0) or ^ (the caret) moves to the start of the line and $ (the dollar sign) moves to the end of the line. Ctrl-b scrolls the cursor back one page and Ctrl-f scrolls forward one page. To set the left and right margins of copy, press c and C (Shift-c). The Spacebar starts selecting the text and ends selecting the text. To abort copy mode, press Ctrl-g.\n\n\nTo paste a block\nTo paste the copied text to the current window (as many times as you want), press Ctrl-a ]."
  },
  {
    "objectID": "blog/2023/04/10/index.html#reference",
    "href": "blog/2023/04/10/index.html#reference",
    "title": "Using Tmux and Screen for Persistent Terminal in VSCode Remote Session",
    "section": "Reference",
    "text": "Reference\n\nhttps://www.zdyn.net/system/hacks/2020/09/19/vscode-term-session.html\nhttps://arcolinux.com/everthing-you-need-to-know-about-tmux-introduction/\nhttps://www.barbarianmeetscoding.com/blog/jaimes-guide-to-tmux-the-most-awesome-tool-you-didnt-know-you-needed\nCustomizing TMUX for Efficiency and Aesthetics: Part 1\nCustomizing TMUX for Efficiency and Aesthetics: Part 2"
  },
  {
    "objectID": "blog/2023/05/17/index.html",
    "href": "blog/2023/05/17/index.html",
    "title": "Perform Principal Component Analysis",
    "section": "",
    "text": "Principle component analysis is used to extract the important information from a multivariate data table and to express this information as a set of few new variables called principle components. These new variables correspond to a linear combination of the originals. The number of principal components is less than or equal to the number of original variables.\nPCA assumes that the directions with the largest variances are the most “important” (i.e, the most principal).\nTechnically speaking, the amount of variance retained by each principal component is measured by the so-called eigenvalue.\nNote that, the PCA method is particularly useful when the variables within the data set are highly correlated. Correlation indicates that there is redundancy in the data. Due to this redundancy, PCA can be used to reduce the original variables into a smaller number of new variables ( = principal components) explaining most of the variance in the original variables.\nTaken together, the main purpose of principal component analysis is to:"
  },
  {
    "objectID": "blog/2023/05/17/index.html#compute-pca",
    "href": "blog/2023/05/17/index.html#compute-pca",
    "title": "Perform Principal Component Analysis",
    "section": "Compute PCA",
    "text": "Compute PCA\n\n### Load packages\nlibrary(pacman)\np_load(\n    tidyverse,  # tidy data\n    FactoMineR, # compute principal component methods\n    factoextra,  # extract, visualize and interpretate the results\n    corrplot  # visualize cos2 of variables\n)\n\n### subset active individuals and active variables\ndata(decathlon2)\ndecathlon2_active &lt;- decathlon2[1:23, 1:10]\nhead(decathlon2_active[, 1:6], 4)\n##         X100m Long.jump Shot.put High.jump X400m X110m.hurdle\n## SEBRLE  11.04      7.58    14.83      2.07 49.81        14.69\n## CLAY    10.76      7.40    14.26      1.86 49.37        14.05\n## BERNARD 11.02      7.23    14.25      1.92 48.93        14.99\n## YURKOV  11.34      7.09    15.19      2.10 50.42        15.31\n\n### compute pca\nres_pca &lt;- PCA(decathlon2_active, graph = FALSE)\nres_pca\n## **Results for the Principal Component Analysis (PCA)**\n## The analysis was performed on 23 individuals, described by 10 variables\n## *The results are available in the following objects:\n## \n##    name               description                          \n## 1  \"$eig\"             \"eigenvalues\"                        \n## 2  \"$var\"             \"results for the variables\"          \n## 3  \"$var$coord\"       \"coord. for the variables\"           \n## 4  \"$var$cor\"         \"correlations variables - dimensions\"\n## 5  \"$var$cos2\"        \"cos2 for the variables\"             \n## 6  \"$var$contrib\"     \"contributions of the variables\"     \n## 7  \"$ind\"             \"results for the individuals\"        \n## 8  \"$ind$coord\"       \"coord. for the individuals\"         \n## 9  \"$ind$cos2\"        \"cos2 for the individuals\"           \n## 10 \"$ind$contrib\"     \"contributions of the individuals\"   \n## 11 \"$call\"            \"summary statistics\"                 \n## 12 \"$call$centre\"     \"mean of the variables\"              \n## 13 \"$call$ecart.type\" \"standard error of the variables\"    \n## 14 \"$call$row.w\"      \"weights for the individuals\"        \n## 15 \"$call$col.w\"      \"weights for the variables\""
  },
  {
    "objectID": "blog/2023/05/17/index.html#variances",
    "href": "blog/2023/05/17/index.html#variances",
    "title": "Perform Principal Component Analysis",
    "section": "Variances",
    "text": "Variances\n\n### eigenvalues measure the amount of variation retained by each principal component\neig_val &lt;- get_eigenvalue(res_pca)\neig_val\n##        eigenvalue variance.percent cumulative.variance.percent\n## Dim.1   4.1242133        41.242133                    41.24213\n## Dim.2   1.8385309        18.385309                    59.62744\n## Dim.3   1.2391403        12.391403                    72.01885\n## Dim.4   0.8194402         8.194402                    80.21325\n## Dim.5   0.7015528         7.015528                    87.22878\n## Dim.6   0.4228828         4.228828                    91.45760\n## Dim.7   0.3025817         3.025817                    94.48342\n## Dim.8   0.2744700         2.744700                    97.22812\n## Dim.9   0.1552169         1.552169                    98.78029\n## Dim.10  0.1219710         1.219710                   100.00000\n\n### scree plot to visualize the eigenvalues\nfviz_eig(res_pca, addlabels = TRUE, ylim = c(0, 50))"
  },
  {
    "objectID": "blog/2023/05/17/index.html#variables",
    "href": "blog/2023/05/17/index.html#variables",
    "title": "Perform Principal Component Analysis",
    "section": "Variables",
    "text": "Variables\n\n### graph of variables\nvar &lt;- get_pca_var(res_pca)\nvar\n## Principal Component Analysis Results for variables\n##  ===================================================\n##   Name       Description                                    \n## 1 \"$coord\"   \"Coordinates for the variables\"                \n## 2 \"$cor\"     \"Correlations between variables and dimensions\"\n## 3 \"$cos2\"    \"Cos2 for the variables\"                       \n## 4 \"$contrib\" \"contributions of the variables\"\n### coordinates of variables to create a scatter plot\nhead(var$coord)\n##                   Dim.1       Dim.2      Dim.3       Dim.4      Dim.5\n## X100m        -0.8506257 -0.17939806  0.3015564  0.03357320 -0.1944440\n## Long.jump     0.7941806  0.28085695 -0.1905465 -0.11538956  0.2331567\n## Shot.put      0.7339127  0.08540412  0.5175978  0.12846837 -0.2488129\n## High.jump     0.6100840 -0.46521415  0.3300852  0.14455012  0.4027002\n## X400m        -0.7016034  0.29017826  0.2835329  0.43082552  0.1039085\n## X110m.hurdle -0.7641252 -0.02474081  0.4488873 -0.01689589  0.2242200\n\n### represents the quality of representation for variables on the factor map. \n### It’s calculated as the squared coordinates: var.cos2 = var.coord * var.coord.\nhead(var$cos2)\n##                  Dim.1        Dim.2      Dim.3        Dim.4      Dim.5\n## X100m        0.7235641 0.0321836641 0.09093628 0.0011271597 0.03780845\n## Long.jump    0.6307229 0.0788806285 0.03630798 0.0133147506 0.05436203\n## Shot.put     0.5386279 0.0072938636 0.26790749 0.0165041211 0.06190783\n## High.jump    0.3722025 0.2164242070 0.10895622 0.0208947375 0.16216747\n## X400m        0.4922473 0.0842034209 0.08039091 0.1856106269 0.01079698\n## X110m.hurdle 0.5838873 0.0006121077 0.20149984 0.0002854712 0.05027463\n\n### contains the contributions (in percentage) of the variables to the principal components. \n### The contribution of a variable (var) to a given principal component is (in percentage) : (var.cos2 * 100) / (total cos2 of the component).\nhead(var$contrib)\n##                  Dim.1      Dim.2     Dim.3       Dim.4     Dim.5\n## X100m        17.544293  1.7505098  7.338659  0.13755240  5.389252\n## Long.jump    15.293168  4.2904162  2.930094  1.62485936  7.748815\n## Shot.put     13.060137  0.3967224 21.620432  2.01407269  8.824401\n## High.jump     9.024811 11.7715838  8.792888  2.54987951 23.115504\n## X400m        11.935544  4.5799296  6.487636 22.65090599  1.539012\n## X110m.hurdle 14.157544  0.0332933 16.261261  0.03483735  7.166193\n\n### plot variables. it shows the relationship between all variables\nfviz_pca_var(res_pca, col.var = \"black\")\n\n\n\n\n\n\n\n### quality of representation\nhead(var$cos2, 4)\n##               Dim.1       Dim.2      Dim.3      Dim.4      Dim.5\n## X100m     0.7235641 0.032183664 0.09093628 0.00112716 0.03780845\n## Long.jump 0.6307229 0.078880629 0.03630798 0.01331475 0.05436203\n## Shot.put  0.5386279 0.007293864 0.26790749 0.01650412 0.06190783\n## High.jump 0.3722025 0.216424207 0.10895622 0.02089474 0.16216747\ncorrplot(var$cos2, is.corr=FALSE)\n\n\n\n\n\n\n\n### bar plot total cos2 of variables on Dim.1 and Dim.2\nfviz_cos2(res_pca, choice = \"var\", axes = 1:2)\n\n\n\n\n\n\n\n### Color by cos2 values: quality on the factor map\nfviz_pca_var(\n  res_pca, \n  col.var = \"cos2\",\n  gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n  repel = TRUE # Avoid text overlapping\n)\n\n\n\n\n\n\n\n### Change the transparency by cos2 values\nfviz_pca_var(res_pca, alpha.var = \"cos2\")\n\n\n\n\n\n\n\n### contribution of variables to PCs\nhead(var$contrib, 4)\n##               Dim.1      Dim.2     Dim.3     Dim.4     Dim.5\n## X100m     17.544293  1.7505098  7.338659 0.1375524  5.389252\n## Long.jump 15.293168  4.2904162  2.930094 1.6248594  7.748815\n## Shot.put  13.060137  0.3967224 21.620432 2.0140727  8.824401\n## High.jump  9.024811 11.7715838  8.792888 2.5498795 23.115504\n\n### highlight the most contributing variables for each dimension\ncorrplot(var$contrib, is.corr=FALSE)\n\n\n\n\n\n\n\n# Contributions of variables to PC1\nfviz_contrib(res_pca, choice = \"var\", axes = 1, top = 10)\n\n\n\n\n\n\n\n# Contributions of variables to PC2\nfviz_contrib(res_pca, choice = \"var\", axes = 2, top = 10)\n\n\n\n\n\n\n\n### total contribution to PC1 and PC2 \nfviz_contrib(res_pca, choice = \"var\", axes = 1:2, top = 10)\n\n\n\n\n\n\n\n### highlight most important variables on the correlation plot\nfviz_pca_var(\n  res_pca, \n  col.var = \"contrib\",\n  gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\")\n)\n\n\n\n\n\n\n\n### Change the transparency by contrib values\nfviz_pca_var(res_pca, alpha.var = \"contrib\")\n\n\n\n\n\n\n\n### color variables by custom continus variable\n# Create a random continuous variable of length 10\nset.seed(123)\nmy_cont_var &lt;- rnorm(10)\n### Color variables by the continuous variable\nfviz_pca_var(\n  res_pca, \n  col.var = my_cont_var,\n  gradient.cols = c(\"blue\", \"yellow\", \"red\"),\n  legend.title = \"Cont.Var\"\n)\n\n\n\n\n\n\n\n### color by groups, create a grouping variables using kmeans\nset.seed(123)\nres_km &lt;- kmeans(var$coord, centers = 3, nstart = 25)\ngrp &lt;- as.factor(res_km$cluster)\n\n# Color variables by groups\nfviz_pca_var(\n  res_pca, \n  col.var = grp, \n  palette = c(\"#0073C2FF\", \"#EFC000FF\", \"#868686FF\"),\n  legend.title = \"Cluster\"\n)\n\n\n\n\n\n\n\n### dimension description\nres_desc &lt;- dimdesc(res_pca, axes = c(1,2), proba = 0.05)\n# Description of dimension 1\nres_desc$Dim.1\n## \n## Link between the variable and the continuous variables (R-square)\n## =================================================================================\n##              correlation      p.value\n## Long.jump      0.7941806 6.059893e-06\n## Discus         0.7432090 4.842563e-05\n## Shot.put       0.7339127 6.723102e-05\n## High.jump      0.6100840 1.993677e-03\n## Javeline       0.4282266 4.149192e-02\n## X400m         -0.7016034 1.910387e-04\n## X110m.hurdle  -0.7641252 2.195812e-05\n## X100m         -0.8506257 2.727129e-07\n# Description of dimension 2\nres_desc$Dim.2\n## \n## Link between the variable and the continuous variables (R-square)\n## =================================================================================\n##            correlation      p.value\n## Pole.vault   0.8074511 3.205016e-06\n## X1500m       0.7844802 9.384747e-06\n## High.jump   -0.4652142 2.529390e-02"
  },
  {
    "objectID": "blog/2023/05/17/index.html#individuals",
    "href": "blog/2023/05/17/index.html#individuals",
    "title": "Perform Principal Component Analysis",
    "section": "Individuals",
    "text": "Individuals\n\n### extract results for individuals\nind &lt;- get_pca_ind(res_pca)\nind\n## Principal Component Analysis Results for individuals\n##  ===================================================\n##   Name       Description                       \n## 1 \"$coord\"   \"Coordinates for the individuals\" \n## 2 \"$cos2\"    \"Cos2 for the individuals\"        \n## 3 \"$contrib\" \"contributions of the individuals\"\n# Coordinates of individuals\nhead(ind$coord)\n##                Dim.1      Dim.2      Dim.3       Dim.4       Dim.5\n## SEBRLE     0.1955047  1.5890567  0.6424912  0.08389652  1.16829387\n## CLAY       0.8078795  2.4748137 -1.3873827  1.29838232 -0.82498206\n## BERNARD   -1.3591340  1.6480950  0.2005584 -1.96409420  0.08419345\n## YURKOV    -0.8889532 -0.4426067  2.5295843  0.71290837  0.40782264\n## ZSIVOCZKY -0.1081216 -2.0688377 -1.3342591 -0.10152796 -0.20145217\n## McMULLEN   0.1212195 -1.0139102 -0.8625170  1.34164291  1.62151286\n### Quality of individuals\nhead(ind$cos2)\n##                 Dim.1      Dim.2       Dim.3       Dim.4        Dim.5\n## SEBRLE    0.007530179 0.49747323 0.081325232 0.001386688 0.2689026575\n## CLAY      0.048701249 0.45701660 0.143628117 0.125791741 0.0507850580\n## BERNARD   0.197199804 0.28996555 0.004294015 0.411819183 0.0007567259\n## YURKOV    0.096109800 0.02382571 0.778230322 0.061812637 0.0202279796\n## ZSIVOCZKY 0.001574385 0.57641944 0.239754152 0.001388216 0.0054654972\n## McMULLEN  0.002175437 0.15219499 0.110137872 0.266486530 0.3892621478\n### Contributions of individuals\nhead(ind$contrib)\n##                Dim.1      Dim.2      Dim.3       Dim.4       Dim.5\n## SEBRLE    0.04029447  5.9714533  1.4483919  0.03734589  8.45894063\n## CLAY      0.68805664 14.4839248  6.7537381  8.94458283  4.21794385\n## BERNARD   1.94740183  6.4234107  0.1411345 20.46819433  0.04393073\n## YURKOV    0.83308415  0.4632733 22.4517396  2.69663605  1.03075263\n## ZSIVOCZKY 0.01232413 10.1217143  6.2464325  0.05469230  0.25151025\n## McMULLEN  0.01549089  2.4310854  2.6102794  9.55055888 16.29493304\n\n### quality and contribution\n### individuals that are similar are grouped together on the plot\nfviz_pca_ind(\n  res_pca, \n  col.ind = \"cos2\", \n  gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n  repel = TRUE # Avoid text overlapping (slow if many points)\n)\n\n\n\n\n\n\n\n### change the point size according to the cos2 of corresponding individuals\nfviz_pca_ind(\n  res_pca, \n  pointsize = \"cos2\", \n  pointshape = 21, \n  fill = \"#E7B800\",\n  repel = TRUE # Avoid text overlapping (slow if many points)\n)\n\n\n\n\n\n\n\n### change both point size and color by cos2\nfviz_pca_ind(\n  res_pca, \n  col.ind = \"cos2\", \n  pointsize = \"cos2\",\n  gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n  repel = TRUE # Avoid text overlapping (slow if many points)\n)\n\n\n\n\n\n\n\n### total contribution on PC1 and PC2\nfviz_contrib(res_pca, choice = \"ind\", axes = 1:2)\n\n\n\n\n\n\n\n### color by custom continus variable\nset.seed(123)\nmy_cont_var &lt;- rnorm(23)\n# Color individuals by the continuous variable\nfviz_pca_ind(\n  res_pca, \n  col.ind = my_cont_var,\n  gradient.cols = c(\"blue\", \"yellow\", \"red\"),\n  legend.title = \"Cont.Var\"\n)"
  },
  {
    "objectID": "blog/2023/05/17/index.html#other-dimensions",
    "href": "blog/2023/05/17/index.html#other-dimensions",
    "title": "Perform Principal Component Analysis",
    "section": "Other Dimensions",
    "text": "Other Dimensions\n\n### visualize variables/individuals on dimension 2 and 3\n\n# Variables on dimensions 2 and 3\nfviz_pca_var(res_pca, axes = c(2, 3))\n\n\n\n\n\n\n# Individuals on dimensions 2 and 3\nfviz_pca_ind(res_pca, axes = c(2, 3))"
  },
  {
    "objectID": "blog/2023/05/17/index.html#reference",
    "href": "blog/2023/05/17/index.html#reference",
    "title": "Perform Principal Component Analysis",
    "section": "Reference",
    "text": "Reference\n\nPrincipal Component Methods in R: Practical Guide\nFactoextra R Package: Easy Multivariate Data Analyses and Elegant Visualization"
  },
  {
    "objectID": "blog/2023/05/28/index.html",
    "href": "blog/2023/05/28/index.html",
    "title": "Tips for using shapes for ggplot2",
    "section": "",
    "text": "In ggplot, point shapes can be specified in the function geom_point(). Key arguments include:\nggpubr::show_point_shapes()\n## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\nlibrary(ggplot2)\n# Change shape, color and size\nggplot(iris, aes(Sepal.Length, Sepal.Width)) +\n  geom_point(shape = 18, color = \"#FC4E07\", size = 3)+\n  theme_minimal()\n\n\n\n\n\n\n\n# Change background fill and line color\nggplot(iris, aes(Sepal.Length, Sepal.Width)) +\n  geom_point(shape = 21, fill = \"lightgray\",\n             color = \"black\", size = 3)+\n  theme_minimal()\n\n\n\n\n\n\n\n# Change point shapes and colors by groups\nggplot(iris, aes(Sepal.Length, Sepal.Width)) +\n  geom_point(aes(shape = Species, color = Species), size = 3) +\n  scale_shape_manual(values = c(5, 16, 17)) +\n  scale_color_manual(values = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"))+\n  theme_minimal() +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "blog/2023/05/28/index.html#reference",
    "href": "blog/2023/05/28/index.html#reference",
    "title": "Tips for using shapes for ggplot2",
    "section": "Reference",
    "text": "Reference\n\nHow To Get the Default Color Codes of ggplot2?\npch in R : built-in shapes in R"
  },
  {
    "objectID": "blog/2023/06/08/index.html",
    "href": "blog/2023/06/08/index.html",
    "title": "Regular expression with R",
    "section": "",
    "text": "Regular expressions are also called regex or regexp. A regex is a text string that defines a search pattern. Regex can be used to manipulate and extract information from text strings. Regex are universally supported din many programming languages like R, Python, Java and SQL.\n\ngrep(), grepl() – return the indices of strings containing a match (grep()) or a logical vector showing which strings contain a match (grepl()).\nregexpr(), gregexpr() – return the index for each string where the match begins and the length of that match. While regexpr() provides this information only for the first match (from the left), gregexpr() does the same for all the matches.\nsub(), gsub() – replace a detected match in each string with a specified string (sub() – only for the first match, gsub() – for all the matches).\nregexec() – works like regexpr() but returns the same information also for a specified sub-expression inside the match.\nregmatches() – works like regexec() but returns the exact strings detected for the overall match and a specified sub-expression."
  },
  {
    "objectID": "blog/2023/07/05/index.html",
    "href": "blog/2023/07/05/index.html",
    "title": "Learning [ropls] for multivariate analysis and feature selection of omics data",
    "section": "",
    "text": "PCA (also called eigenvector analysis) is unsupervised pattern recognition technique mostly utilized as data reduction and modelling technique. It determines the degree or extent to which variables are related. Large data of many variables are unavoidably superfluous and overlap, the use of correlation matrix generally quantifies these anomalies by extracting the eigenvalues and eigenvectors from the square matrix originated by multiplying the data matrix. The purpose of PCA is to find orthogonal variables that capture the maximum amount of variance in the data without considering class information. PCA provide the information about the relationships and patterns and help identify major sources of variation and potential outliers\nPLS discriminant analysis is a supervised technique that uses the PLS algorithm to explain and predict the membership of observations to several classes using quantitative or qualitative explanatory variables or parameters. The purpose of PLS-DA is to identify the latent variables that maximize the discrimination between the predefined classes in the data. PLS-DA focus on the the separation of classes in the dataset and provide information on important features that serparate classes."
  },
  {
    "objectID": "blog/2023/07/05/index.html#packages-and-data",
    "href": "blog/2023/07/05/index.html#packages-and-data",
    "title": "Learning [ropls] for multivariate analysis and feature selection of omics data",
    "section": "Packages and Data",
    "text": "Packages and Data\n\npacman::p_load(ropls, tidyverse, ggsci)\n\n### load data\ndata(sacurine)\nnames(sacurine)\n\n[1] \"dataMatrix\"       \"sampleMetadata\"   \"variableMetadata\" \"se\"              \n[5] \"eset\"            \n\nattach(sacurine)\nstrF(dataMatrix)\n\n       dim  class    mode typeof   size NAs  min mean median max\n 183 x 109 matrix numeric double 0.2 Mb   0 -0.3  4.2    4.3   6\n       (2-methoxyethoxy)propanoic acid isomer (gamma)Glu-Leu/Ile ...\nHU_011                            3.019766011        3.888479324 ...\nHU_014                             3.81433889        4.277148905 ...\n...                                       ...                ... ...\nHU_208                            3.748127215        4.523763202 ...\nHU_209                            4.208859398        4.675880567 ...\n       Valerylglycine isomer 2  Xanthosine\nHU_011             3.889078716 4.075879575\nHU_014             4.181765852 4.195761901\n...                        ...         ...\nHU_208             4.634338821 4.487781609\nHU_209              4.47194762 4.222953354\n\nstrF(variableMetadata)\n\n msiLevel      hmdb chemicalClass\n  numeric character     character\n nRow nCol size NAs\n  109    3 0 Mb   0\n                                       msiLevel      hmdb chemicalClass\n(2-methoxyethoxy)propanoic acid isomer        2                  Organi\n(gamma)Glu-Leu/Ile                            2                  AA-pep\n...                                         ...       ...           ...\nValerylglycine isomer 2                       2           AA-pep:AcyGly\nXanthosine                                    1 HMDB00299        Nucleo\n\n# View(dataMatrix)\n# View(variableMetadata)\n# View(sampleMetadata)"
  },
  {
    "objectID": "blog/2023/07/05/index.html#pca",
    "href": "blog/2023/07/05/index.html#pca",
    "title": "Learning [ropls] for multivariate analysis and feature selection of omics data",
    "section": "PCA",
    "text": "PCA\n\npca &lt;- opls(dataMatrix)\n\nPCA\n183 samples x 109 variables\nstandard scaling of predictors\n      R2X(cum) pre ort\nTotal    0.501   8   0\n\n\n\n\n\n\n\ngenderFc &lt;- sampleMetadata[, \"gender\"]\n\nplot(pca,\n     typeVc = \"x-score\",\n     parAsColFcVn = genderFc,\n     parEllipsesL = TRUE\n)\n\n\n\n\n\n\ndev.off()\n\nnull device \n          1 \n\nplot(pca,\n     typeVc = \"x-score\",\n     parAsColFcVn = genderFc,\n     parLabVc = as.character(sampleMetadata[, \"age\"]),\n     parPaletteVc = c(\"green4\", \"magenta\"))\ndev.off()\n\nnull device \n          1"
  },
  {
    "objectID": "blog/2023/07/05/index.html#pls-da",
    "href": "blog/2023/07/05/index.html#pls-da",
    "title": "Learning [ropls] for multivariate analysis and feature selection of omics data",
    "section": "PLS-DA",
    "text": "PLS-DA\n\n### PLSDA analysis\nplsda &lt;- opls(dataMatrix, genderFc)\n\nPLS-DA\n183 samples x 109 variables and 1 response\nstandard scaling of predictors and response(s)\n      R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y  pQ2\nTotal    0.275     0.73   0.584 0.262   3   0 0.05 0.05\n\n\n\n\n\n\n\n### sample scores plot\nsample_score &lt;- plsda@scoreMN |&gt; \n     as.data.frame() |&gt; \n     mutate(gender = sacurine[[\"sampleMetadata\"]][[\"gender\"]])\n### plot\nggplot(sample_score, aes(x = p1, y = p2, color = gender)) +\n    geom_hline(yintercept = 0, linetype = \"dashed\", linewidth = 0.5) +\n    geom_vline(xintercept = 0, linetype = \"dashed\", linewidth = 0.5) +\n    geom_point() +\n    geom_point(aes(x = -10, y = -10), color = \"white\") +\n    labs(x = \"P1(10.0%)\", y = \"P2(9%)\") +\n    stat_ellipse(\n        level = 0.95, linetype = \"solid\", size = 1, show.legend = FALSE\n    ) +\n    scale_color_manual(values = c(\"#3CB371\", \"#FF6347\")) +\n    theme_bw() +\n    theme(\n        legend.position = c(0.9, 0.8),\n        legend.text = element_text(color = \"black\", size = 12, family = \"Arial\", face = \"plain\"),\n        panel.background = element_blank(),\n        panel.grid = element_blank(),\n        axis.text = element_text(color = \"black\", size = 15, family = 'Arial', face = \"plain\"),\n        axis.title = element_text(color = \"black\", size = 15, family = 'Arial', face = \"plain\"),\n        axis.ticks = element_line(color = \"black\")\n    )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n### find the discrinminative variable that VIP greater than 1\n\n### VIP scores plot\nvip_score &lt;- as.data.frame(plsda@vipVn)\ncolnames(vip_score)  &lt;- \"vip\"\nvip_score$metabolites &lt;- rownames(vip_score)\nvip_score &lt;- vip_score[order(-vip_score$vip), ]\nvip_score$metabolites &lt;- factor(\n    vip_score$metabolites, levels = vip_score$metabolites)\nloading_score &lt;- plsda@loadingMN |&gt; \n    as.data.frame()\nloading_score$metabolites &lt;- rownames(loading_score)\nall_score &lt;- merge(vip_score, loading_score, by = \"metabolites\")\nall_score$cat &lt;- paste(\"feature\", 1:nrow(all_score), sep = \"\")\n\n### plot\nggplot(all_score[all_score$vip &gt;=1, ], aes(x = cat, y = vip)) + \n    geom_segment(aes(x = cat, xend = cat,\n                    y = 0, yend = vip)) +\n    geom_point(shape = 21, size = 5, color = \"#008000\", fill = \"#008000\")+\n    geom_point(aes(1, 2.5), color = \"white\") +\n    geom_hline(yintercept = 1, linetype = \"dashed\") +\n    scale_y_continuous(expand = c(0, 0)) +\n    labs(x = \"\", y = \"VIP value\") +\n    theme_bw() +\n    theme(\n        legend.position = \"none\",\n        legend.text = element_text(color = \"black\", size = 12, family = \"Arial\", face = \"plain\"),\n        panel.background = element_blank(),\n        panel.grid = element_blank(),\n        axis.text = element_text(color = \"black\", size = 15, family = 'Arial', face = \"plain\"),\n        axis.text.x = element_text(angle = 90),\n        axis.title = element_text(color = \"black\", size = 15, family = 'Arial', face = \"plain\"),\n        axis.ticks = element_line(color = \"black\"),\n        axis.ticks.x = element_blank()\n    )"
  },
  {
    "objectID": "blog/2023/07/05/index.html#opls-da",
    "href": "blog/2023/07/05/index.html#opls-da",
    "title": "Learning [ropls] for multivariate analysis and feature selection of omics data",
    "section": "OPLS-DA",
    "text": "OPLS-DA\n\n### OPLS-DA analysis\noplsda &lt;- opls(dataMatrix, genderFc, predI = 1, orthoI = NA)\n\nOPLS-DA\n183 samples x 109 variables and 1 response\nstandard scaling of predictors and response(s)\n      R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y  pQ2\nTotal    0.275     0.73   0.602 0.262   1   2 0.05 0.05\n\n\n\n\n\n\n\n### sample scores plot\nsample_score &lt;- oplsda@scoreMN |&gt; \n    as.data.frame() |&gt; \n    mutate(\n        gender = sacurine[[\"sampleMetadata\"]][[\"gender\"]],\n        o1 = oplsda@orthoScoreMN[, 1]\n    )\n### plot\nggplot(sample_score, aes(p1, o1, color = gender)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", size = 0.5) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", size = 0.5) +\n  geom_point() +\n  #geom_point(aes(-10,-10), color = 'white') +\n  labs(x = \"P1(5.0%)\", y = \"to1\") +\n  stat_ellipse(level = 0.95, linetype = \"solid\", \n               size = 1, show.legend = FALSE) +\n  scale_color_manual(values = c(\"#3CB371\", \"#FF6347\")) +\n  theme_bw() +\n  theme(legend.position = c(0.1, 0.85),\n        legend.title = element_blank(),\n        legend.text = element_text(color = \"black\", size = 12, family = \"Arial\", \n            face = \"plain\"),\n        panel.background = element_blank(),\n        panel.grid = element_blank(),\n        axis.text = element_text(color = \"black\", size = 15, family = \"Arial\", face = \"plain\"),\n        axis.title = element_text(color = \"black\", size = 15, family = \"Arial\", face = \"plain\"),\n        axis.ticks = element_line(color = 'black'))\n\n\n\n\n\n\n\n\n### VIP scores plot\nvip_score &lt;- as.data.frame(oplsda@vipVn)\ncolnames(vip_score)  &lt;- \"vip\"\nvip_score$metabolites &lt;- rownames(vip_score)\nvip_score &lt;- vip_score[order(-vip_score$vip), ]\nvip_score$metabolites &lt;- factor(\n    vip_score$metabolites, levels = vip_score$metabolites)\nloading_score &lt;- oplsda@loadingMN |&gt; \n    as.data.frame()\nloading_score$metabolites &lt;- rownames(loading_score)\nall_score &lt;- merge(vip_score, loading_score, by = \"metabolites\")\nall_score$cat &lt;- paste(\"feature\", 1:nrow(all_score), sep = \"\")\n\n### plot\nggplot(all_score[all_score$vip &gt;=1, ], aes(x = cat, y = vip)) + \n    geom_segment(aes(x = cat, xend = cat,\n                    y = 0, yend = vip)) +\n    geom_point(shape = 21, size = 5, color = \"#FFA07A\", fill = \"#FFA07A\")+\n    geom_point(aes(1, 2.5), color = \"white\") +\n    geom_hline(yintercept = 1, linetype = \"dashed\") +\n    scale_y_continuous(expand = c(0, 0)) +\n    labs(x = \"\", y = \"VIP value\") +\n    theme_bw() +\n    theme(\n        legend.position = \"none\",\n        legend.text = element_text(color = \"black\", size = 12, family = \"Arial\", face = \"plain\"),\n        panel.background = element_blank(),\n        panel.grid = element_blank(),\n        axis.text = element_text(color = \"black\", size = 15, family = 'Arial', face = \"plain\"),\n        axis.text.x = element_text(angle = 90),\n        axis.title = element_text(color = \"black\", size = 15, family = 'Arial', face = \"plain\"),\n        axis.ticks = element_line(color = \"black\"),\n        axis.ticks.x = element_blank()\n    )"
  },
  {
    "objectID": "blog/2023/07/05/index.html#predict-models",
    "href": "blog/2023/07/05/index.html#predict-models",
    "title": "Learning [ropls] for multivariate analysis and feature selection of omics data",
    "section": "Predict models",
    "text": "Predict models\n\n### OPLS-DA model training\noplsda.2  &lt;-  opls(dataMatrix, genderFc, predI = 1, orthoI = NA,subset = \"odd\") \n\nWarning: 'permI' set to 0 because train/test partition is selected\n\n\nOPLS-DA\n92 samples x 109 variables and 1 response\nstandard scaling of predictors and response(s)\n      R2X(cum) R2Y(cum) Q2(cum) RMSEE RMSEP pre ort\nTotal     0.26    0.825   0.608 0.213 0.341   1   2\n\n\n\n\n\n\n\n### training dataset  accuracy\ntrainVi  &lt;-  getSubsetVi(oplsda.2)\ntab  &lt;-  table(genderFc[trainVi], fitted(oplsda.2))\nprint(paste(\"model accuracy：\", round(sum(diag(tab))/sum(tab)*100, 2), \"%\", sep = \"\"))\n\n[1] \"model accuracy：100%\"\n\n### testing dataset accuracy\ntab2  &lt;-  table(genderFc[-trainVi], predict(oplsda.2, dataMatrix[-trainVi, ]))\nprint(paste(\"model accuracy：\", round(sum(diag(tab2))/sum(tab2)*100, 2),'%', sep = ''))\n\n[1] \"model accuracy：84.62%\""
  },
  {
    "objectID": "blog/2023/07/05/index.html#other",
    "href": "blog/2023/07/05/index.html#other",
    "title": "Learning [ropls] for multivariate analysis and feature selection of omics data",
    "section": "Other",
    "text": "Other\n\n# volcano plot\ndf  &lt;-  dataMatrix %&gt;% as.data.frame()\ndf$gender  &lt;-  sacurine[[\"sampleMetadata\"]][[\"gender\"]]\ndf  &lt;-  df[order(df$gender), ]\ndf  &lt;-  df[,-110]\n\nM.mean  &lt;-  apply(df[1:100,], 2, FUN = mean)\nF.mean  &lt;-  apply(df[101:183,], 2, FUN = mean)\n\nFC  &lt;-  M.mean / F.mean\nlog2FC  &lt;-  log(FC, 2)\n\npvalue  &lt;-  apply(df, 2, function(x) {t.test(x[1:100],x[101:183])$p.value})\n\np.adj  &lt;-  p.adjust(pvalue, method = 'BH')\np.adj.log  &lt;-  -log10(p.adj)\n\ncolcano.df  &lt;-  data.frame(log2FC, p.adj, p.adj.log)\ncolcano.df$cat  &lt;-  ifelse(colcano.df$log2FC &gt;= 1 & colcano.df$p.adj &lt; 0.05, \"Up\",\n                        ifelse(colcano.df$log2FC &lt;= -1 & colcano.df$p.adj &lt; 0.05, \"Down\",\"NS\"))\n\nggplot(colcano.df, aes(log2FC, p.adj.log)) +\n    geom_point(colour = \"#A9A9A9\", size = 1) +\n    labs(y = \"-log10(p-value.adj)\") +\n    theme_bw() +\n    scale_x_continuous(limits = c(-2, 2)) +\n    theme(legend.position = 'none',\n        legend.text = element_text(color = 'black', size = 12, family = 'Arial', face = 'plain'),\n        panel.background = element_blank(),\n        panel.grid = element_blank(),\n        axis.text = element_text(color = 'black', size = 15, family = 'Arial', face = 'plain'),\n        axis.text.x = element_text(angle = 90),\n        axis.title = element_text(color = 'black', size = 15, family = 'Arial', face = 'plain'),\n        axis.ticks = element_line(color = 'black'),\n        axis.ticks.x = element_blank())"
  },
  {
    "objectID": "blog/2023/08/08/index.html",
    "href": "blog/2023/08/08/index.html",
    "title": "Using renv to manage R environment for reproducible coding",
    "section": "",
    "text": "R works by defaultly by installing packages to a central library and shares them between the projects. It sounds like a good and time-saving feature. After all, you don’t need to install the same package in every project. But that’s where the problems arise. You might have a newer version of some package than your coworkers – resulting in a deprecated or not-implemented functionality."
  },
  {
    "objectID": "blog/2023/08/08/index.html#install-renv",
    "href": "blog/2023/08/08/index.html#install-renv",
    "title": "Using renv to manage R environment for reproducible coding",
    "section": "Install renv",
    "text": "Install renv\npacman::p_load(renv)\n\nrenv create separate, reproducible environment that you and your coworkers can use, hassle free\nThis nice post introduced how to use it to manage dependencies in R projects easily"
  },
  {
    "objectID": "blog/2023/08/08/index.html#remove-renv",
    "href": "blog/2023/08/08/index.html#remove-renv",
    "title": "Using renv to manage R environment for reproducible coding",
    "section": "Remove renv",
    "text": "Remove renv\n\nDeactivate renv in a project\n\nrenv::deactivate()\n\nRemove auto loader .Rprofile, but doesn’t touch any other renv files used in the project.\nTo completely remove renv from a project, delete the project’s renv folder and renv.lock lockfile as desired.\nIf you want to completely remove any installed renv infrastructure components from your entire system\n\nroot &lt;- renv::paths$root()\nunlink(root, recursive = TRUE)\n### Remove packages\nutils::remove.packages(\"renv\")"
  },
  {
    "objectID": "blog/2023/08/08/index.html#reference",
    "href": "blog/2023/08/08/index.html#reference",
    "title": "Using renv to manage R environment for reproducible coding",
    "section": "Reference",
    "text": "Reference\n\nR renv: How to Manage Dependencies in R Projects Easily"
  },
  {
    "objectID": "blog/2023/08/11/index.html",
    "href": "blog/2023/08/11/index.html",
    "title": "Commonly used Vim commands",
    "section": "",
    "text": "Basics commands\nAdvanced commands"
  },
  {
    "objectID": "blog/2023/08/11/index.html#essentials",
    "href": "blog/2023/08/11/index.html#essentials",
    "title": "Commonly used Vim commands",
    "section": "Essentials",
    "text": "Essentials\nCursor movement (Normal/Visual Mode)\n\n\nh j k l - Arrow keys\n\nw / b - Next/previous word\n\nW / B - Next/previous word (space seperated)\n\ne / ge - Next/previous end of word\n\n0 / $ - Start/End of line\n\n^ - First non-blank character of line (same as 0w)\n\nEditing text\n\n\ni / a - Start insert mode at/after cursor\n\nI / A - Start insert mode at the beginning/end of the line\n\no / O - Add blank line below/above current line\n\nEsc or Ctrl+[ - Exit insert mode\n\nd - Delete\n\ndd - Delete line\n\nc - Delete, then start insert mode\n\ncc - Delete line, then start insert mode\n\nOperators\n\nOperators also work in Visual Mode\n\nd - Deletes from the cursor to the movement location\n\nc - Deletes from the cursor to the movement location, then starts insert mode\n\ny - Copy from the cursor to the movement location\n\n&gt; - Indent one level\n\n&lt; - Unindent one level\nYou can also combine operators with motions. Ex: d$ deletes from the cursor to the end of the line.\n\nMarking text (visual mode)\n\n\nv - Start visual mode\n\nV - Start linewise visual mode\n\nCtrl+v - Start visual block mode\n\nEsc or Ctrl+[ - Exit visual mode\n\nClipboard\n\n\nyy - Yank (copy) a line\n\np - Paste after cursor\n\nP - Paste before cursor\n\ndd - Delete (cut) a line\n\nx - Delete (cut) current character\n\nX - Delete (cut) previous character\n\nd / c - By default, these copy the deleted text\n\nExiting\n\n\n:w - Write (save) the file, but don’t quit\n\n:wq - Write (save) and quit\n\n:q - Quit (fails if anything has changed)\n\n:q! - Quit and throw away changes\n\nSearch/Replace\n\n\n/pattern - Search for pattern\n\n?pattern - Search backward for pattern\n\nn - Repeat search in same direction\n\nN - Repeat search in opposite direction\n\n:%s/old/new/g - Replace all old with new throughout file (gn is better though)\n\n:%s/old/new/gc - Replace all old with new throughout file with confirmations\n\nGeneral\n\n\nu - Undo\n\nCtrl+r - Redo"
  },
  {
    "objectID": "blog/2023/08/11/index.html#advanced",
    "href": "blog/2023/08/11/index.html#advanced",
    "title": "Commonly used Vim commands",
    "section": "Advanced",
    "text": "Advanced\nCursor movement\n\n\nCtrl+d - Move down half a page\n\nCtrl+u - Move up half a page\n\n} - Go forward by paragraph (the next blank line)\n\n{ - Go backward by paragraph (the next blank line)\n\ngg - Go to the top of the page\n\nG- Go the bottom of the page\n\n: [num] [enter] - Go to that line in the document\n\nctrl+e / ctrl+y - Scroll down/up one line\n\nCharacter search\n\n\nf [char] - Move forward to the given char\n\nF [char] - Move backward to the given char\n\nt [char] - Move forward to before the given char\n\nT [char] - Move backward to before the given char\n\n; / , - Repeat search forwards/backwards\n\nEditing text\n\n\nJ - Join line below to the current one\n\nr [char] - Replace a single character with the specified char (does not use Insert mode)\n\nVisual mode\n\n\nO - Move to other corner of block\n\no - Move to other end of marked area\n\nFile Tabs\n\n\n:e filename - Edit a file\n\n:tabe - Make a new tab\n\ngt - Go to the next tab\n\ngT - Go to the previous tab\n\n:vsp - Vertically split windows\n\nctrl+ws - Split windows horizontally\n\nctrl+wv- Split windows vertically\n\nctrl+ww- Switch between windows\n\nctrl+wq- Quit a window\n\nMarks\n\nMarks allow you to jump to designated points in your code.\n\nm{a-z} - Set mark {a-z} at cursor position\nA capital mark {A-Z} sets a global mark and will work between files\n\n'{a-z} - Move the cursor to the start of the line where the mark was set\n\n'' - Go back to the previous jump location\n\nText Objects\n\nSay you have def (arg1, arg2, arg3), where your cursor is somewhere in the middle of the parenthesis.\n\ndi( deletes everything between the parenthesis. That says “change everything inside the nearest parenthesis”. Without text objects, you would need to do T(dt).\nLearn more\n\nGeneral\n\n\n. - Repeat last command\n\nCtrl+r + 0 in insert mode inserts the last yanked text (or in command mode)\n\ngv - reselect (select last selected block of text, from visual mode)\n\n% - jumps between matching () or {}"
  },
  {
    "objectID": "blog/2023/08/11/index.html#reference",
    "href": "blog/2023/08/11/index.html#reference",
    "title": "Commonly used Vim commands",
    "section": "Reference",
    "text": "Reference\n\nVim cheatsheet"
  },
  {
    "objectID": "blog/2023/11/25/index.html",
    "href": "blog/2023/11/25/index.html",
    "title": "Learning Seruat for scRNA-seq data analysis",
    "section": "",
    "text": "# Library packages\nlibrary(here)\nlibrary(tidyverse)\nlibrary(Seurat)\nlibrary(SingleR)\nlibrary(ggrepel)\nlibrary(patchwork)\n\n# Load PBMC dataset\npbmc_data &lt;- Read10X(data.dir = \"./learn/2023_scRNA_Seurat/pbmc3k/hg19/\")\n\n# Initialize the seurat boject witht raw (non-normalized data)\npbmc &lt;- CreateSeuratObject(\n    counts = pbmc_data, project = \"pbmc3k\", min.cells = 3, min.features = 200\n)\n# View the data\npbmc\n## An object of class Seurat \n## 13714 features across 2700 samples within 1 assay \n## Active assay: RNA (13714 features, 0 variable features)\n##  1 layer present: counts\ndim(pbmc_data)\n## [1] 32738  2700\n\n# Example a few genes in the first thirty cells\npbmc_data[c(\"CD3D\", \"TCL1A\", \"MS4A1\"), 1:30]\n## 3 x 30 sparse Matrix of class \"dgCMatrix\"\n##                                                                    \n## CD3D  4 . 10 . . 1 2 3 1 . . 2 7 1 . . 1 3 . 2  3 . . . . . 3 4 1 5\n## TCL1A . .  . . . . . . 1 . . . . . . . . . . .  . 1 . . . . . . . .\n## MS4A1 . 6  . . . . . . 1 1 1 . . . . . . . . . 36 1 2 . . 2 . . . ."
  },
  {
    "objectID": "blog/2023/11/25/index.html#load-packages-and-data",
    "href": "blog/2023/11/25/index.html#load-packages-and-data",
    "title": "Learning Seruat for scRNA-seq data analysis",
    "section": "",
    "text": "# Library packages\nlibrary(here)\nlibrary(tidyverse)\nlibrary(Seurat)\nlibrary(SingleR)\nlibrary(ggrepel)\nlibrary(patchwork)\n\n# Load PBMC dataset\npbmc_data &lt;- Read10X(data.dir = \"./learn/2023_scRNA_Seurat/pbmc3k/hg19/\")\n\n# Initialize the seurat boject witht raw (non-normalized data)\npbmc &lt;- CreateSeuratObject(\n    counts = pbmc_data, project = \"pbmc3k\", min.cells = 3, min.features = 200\n)\n# View the data\npbmc\n## An object of class Seurat \n## 13714 features across 2700 samples within 1 assay \n## Active assay: RNA (13714 features, 0 variable features)\n##  1 layer present: counts\ndim(pbmc_data)\n## [1] 32738  2700\n\n# Example a few genes in the first thirty cells\npbmc_data[c(\"CD3D\", \"TCL1A\", \"MS4A1\"), 1:30]\n## 3 x 30 sparse Matrix of class \"dgCMatrix\"\n##                                                                    \n## CD3D  4 . 10 . . 1 2 3 1 . . 2 7 1 . . 1 3 . 2  3 . . . . . 3 4 1 5\n## TCL1A . .  . . . . . . 1 . . . . . . . . . . .  . 1 . . . . . . . .\n## MS4A1 . 6  . . . . . . 1 1 1 . . . . . . . . . 36 1 2 . . 2 . . . ."
  },
  {
    "objectID": "blog/2023/11/25/index.html#preprocess-data",
    "href": "blog/2023/11/25/index.html#preprocess-data",
    "title": "Learning Seruat for scRNA-seq data analysis",
    "section": "Preprocess data",
    "text": "Preprocess data\nQC\n\n# The [[ operator can add columns to object metadata. This is a great place to stash QC stats\npbmc[[\"percent.mt\"]] &lt;- PercentageFeatureSet(pbmc, pattern = \"^MT-\")\n\n# Show QC metrics for the first 5 cells\nhead(pbmc@meta.data, 5)\n##                  orig.ident nCount_RNA nFeature_RNA percent.mt\n## AAACATACAACCAC-1     pbmc3k       2419          779  3.0177759\n## AAACATTGAGCTAC-1     pbmc3k       4903         1352  3.7935958\n## AAACATTGATCAGC-1     pbmc3k       3147         1129  0.8897363\n## AAACCGTGCTTCCG-1     pbmc3k       2639          960  1.7430845\n## AAACCGTGTATGCG-1     pbmc3k        980          521  1.2244898\n\n# Visualize QC metrics as a violin plot\nVlnPlot(pbmc, features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\"), ncol = 3)\n\n\n\n\n\n\n\n# FeatureScatter is typically used to visualize feature-feature relationships, but can be used\n# for anything calculated by the object, i.e. columns in object metadata, PC scores etc.\nplot1 &lt;- FeatureScatter(pbmc, feature1 = \"nCount_RNA\", feature2 = \"percent.mt\")\nplot2 &lt;- FeatureScatter(pbmc, feature1 = \"nCount_RNA\", feature2 = \"nFeature_RNA\")\nplot1 + plot2\n\n\n\n\n\n\n\npbmc &lt;- subset(pbmc, subset = nFeature_RNA &gt; 200 & nFeature_RNA &lt; 2500 & percent.mt &lt; 5)\n\nNormalizing the data\n\npbmc &lt;- NormalizeData(pbmc, normalization.method = \"LogNormalize\", scale.factor = 10000)\n# pbmc &lt;- NormalizeData(pbmc)\n# pbmc@assays$RNA@counts is the raw count data\nstr(pbmc)\n## Formal class 'Seurat' [package \"SeuratObject\"] with 13 slots\n##   ..@ assays      :List of 1\n##   .. ..$ RNA:Formal class 'Assay5' [package \"SeuratObject\"] with 8 slots\n##   .. .. .. ..@ layers    :List of 2\n##   .. .. .. .. ..$ counts:Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n##   .. .. .. .. .. .. ..@ i       : int [1:2238732] 29 73 80 148 163 184 186 227 229 230 ...\n##   .. .. .. .. .. .. ..@ p       : int [1:2639] 0 779 2131 3260 4220 4741 5522 6304 7094 7626 ...\n##   .. .. .. .. .. .. ..@ Dim     : int [1:2] 13714 2638\n##   .. .. .. .. .. .. ..@ Dimnames:List of 2\n##   .. .. .. .. .. .. .. ..$ : NULL\n##   .. .. .. .. .. .. .. ..$ : NULL\n##   .. .. .. .. .. .. ..@ x       : num [1:2238732] 1 1 2 1 1 1 1 41 1 1 ...\n##   .. .. .. .. .. .. ..@ factors : list()\n##   .. .. .. .. ..$ data  :Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n##   .. .. .. .. .. .. ..@ i       : int [1:2238732] 29 73 80 148 163 184 186 227 229 230 ...\n##   .. .. .. .. .. .. ..@ p       : int [1:2639] 0 779 2131 3260 4220 4741 5522 6304 7094 7626 ...\n##   .. .. .. .. .. .. ..@ Dim     : int [1:2] 13714 2638\n##   .. .. .. .. .. .. ..@ Dimnames:List of 2\n##   .. .. .. .. .. .. .. ..$ : NULL\n##   .. .. .. .. .. .. .. ..$ : NULL\n##   .. .. .. .. .. .. ..@ x       : num [1:2238732] 1.64 1.64 2.23 1.64 1.64 ...\n##   .. .. .. .. .. .. ..@ factors : list()\n##   .. .. .. ..@ cells     :Formal class 'LogMap' [package \"SeuratObject\"] with 1 slot\n##   .. .. .. .. .. ..@ .Data: logi [1:2638, 1:2] TRUE TRUE TRUE TRUE TRUE TRUE ...\n##   .. .. .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. .. .. .. ..$ : chr [1:2] \"counts\" \"data\"\n##   .. .. .. .. .. ..$ dim     : int [1:2] 2638 2\n##   .. .. .. .. .. ..$ dimnames:List of 2\n##   .. .. .. .. .. .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   .. .. .. .. .. .. ..$ : chr [1:2] \"counts\" \"data\"\n##   .. .. .. ..@ features  :Formal class 'LogMap' [package \"SeuratObject\"] with 1 slot\n##   .. .. .. .. .. ..@ .Data: logi [1:13714, 1:2] TRUE TRUE TRUE TRUE TRUE TRUE ...\n##   .. .. .. .. .. .. ..- attr(*, \"dimnames\")=List of 2\n##   .. .. .. .. .. .. .. ..$ : chr [1:13714] \"AL627309.1\" \"AP006222.2\" \"RP11-206L10.2\" \"RP11-206L10.9\" ...\n##   .. .. .. .. .. .. .. ..$ : chr [1:2] \"counts\" \"data\"\n##   .. .. .. .. .. ..$ dim     : int [1:2] 13714 2\n##   .. .. .. .. .. ..$ dimnames:List of 2\n##   .. .. .. .. .. .. ..$ : chr [1:13714] \"AL627309.1\" \"AP006222.2\" \"RP11-206L10.2\" \"RP11-206L10.9\" ...\n##   .. .. .. .. .. .. ..$ : chr [1:2] \"counts\" \"data\"\n##   .. .. .. ..@ default   : int 1\n##   .. .. .. ..@ assay.orig: chr(0) \n##   .. .. .. ..@ meta.data :'data.frame':  13714 obs. of  0 variables\n##   .. .. .. ..@ misc      : Named list()\n##   .. .. .. ..@ key       : chr \"rna_\"\n##   ..@ meta.data   :'data.frame': 2638 obs. of  4 variables:\n##   .. ..$ orig.ident  : Factor w/ 1 level \"pbmc3k\": 1 1 1 1 1 1 1 1 1 1 ...\n##   .. ..$ nCount_RNA  : num [1:2638] 2419 4903 3147 2639 980 ...\n##   .. ..$ nFeature_RNA: int [1:2638] 779 1352 1129 960 521 781 782 790 532 550 ...\n##   .. ..$ percent.mt  : num [1:2638] 3.02 3.79 0.89 1.74 1.22 ...\n##   ..@ active.assay: chr \"RNA\"\n##   ..@ active.ident: Factor w/ 1 level \"pbmc3k\": 1 1 1 1 1 1 1 1 1 1 ...\n##   .. ..- attr(*, \"names\")= chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n##   ..@ graphs      : list()\n##   ..@ neighbors   : list()\n##   ..@ reductions  : list()\n##   ..@ images      : list()\n##   ..@ project.name: chr \"pbmc3k\"\n##   ..@ misc        : list()\n##   ..@ version     :Classes 'package_version', 'numeric_version'  hidden list of 1\n##   .. ..$ : int [1:3] 5 0 1\n##   ..@ commands    :List of 1\n##   .. ..$ NormalizeData.RNA:Formal class 'SeuratCommand' [package \"SeuratObject\"] with 5 slots\n##   .. .. .. ..@ name       : chr \"NormalizeData.RNA\"\n##   .. .. .. ..@ time.stamp : POSIXct[1:1], format: \"2023-12-16 20:46:32\"\n##   .. .. .. ..@ assay.used : chr \"RNA\"\n##   .. .. .. ..@ call.string: chr [1:2] \"NormalizeData(pbmc, normalization.method = \\\"LogNormalize\\\", \" \"    scale.factor = 10000)\"\n##   .. .. .. ..@ params     :List of 5\n##   .. .. .. .. ..$ assay               : chr \"RNA\"\n##   .. .. .. .. ..$ normalization.method: chr \"LogNormalize\"\n##   .. .. .. .. ..$ scale.factor        : num 10000\n##   .. .. .. .. ..$ margin              : num 1\n##   .. .. .. .. ..$ verbose             : logi TRUE\n##   ..@ tools       : list()\n\n# Simply look at the data after normalization\n# par(mfrow = c(1,2))\n# hist(colSums(pbmc$RNA@counts@i),breaks = 50)\n# hist(colSums(pbmc$RNA@data@i),breaks = 50)\n\nHighly variable features\n\npbmc &lt;- FindVariableFeatures(pbmc, selection.method = \"vst\", nfeatures = 2000)\n\n# Identify the 10 most highly variable genes\ntop10 &lt;- head(VariableFeatures(pbmc), 10)\n\n# Plot variable features with and without labels\nplot1 &lt;- VariableFeaturePlot(pbmc)\nplot2 &lt;- LabelPoints(plot = plot1, points = top10, repel = TRUE)\nplot1 + plot2\n\n\n\n\n\n\n\nScaling the data\n\nall_genes &lt;- rownames(pbmc)\npbmc &lt;- ScaleData(pbmc, features = all_genes)\n# Remove unwanted sources of variation\n# pbmc &lt;- ScaleData(pbmc, vars.to.regress = \"percent.mt\")"
  },
  {
    "objectID": "blog/2023/11/25/index.html#perform-linear-dimensional-reduction",
    "href": "blog/2023/11/25/index.html#perform-linear-dimensional-reduction",
    "title": "Learning Seruat for scRNA-seq data analysis",
    "section": "Perform linear dimensional reduction",
    "text": "Perform linear dimensional reduction\nPCA\n\npbmc &lt;- RunPCA(pbmc, features = VariableFeatures(object = pbmc))\n# Examine and visualize PCA results a few different ways\nprint(pbmc[[\"pca\"]], dims = 1:5, nfeatures = 5)\n## PC_ 1 \n## Positive:  CST3, TYROBP, LST1, AIF1, FTL \n## Negative:  MALAT1, LTB, IL32, IL7R, CD2 \n## PC_ 2 \n## Positive:  CD79A, MS4A1, TCL1A, HLA-DQA1, HLA-DQB1 \n## Negative:  NKG7, PRF1, CST7, GZMB, GZMA \n## PC_ 3 \n## Positive:  HLA-DQA1, CD79A, CD79B, HLA-DQB1, HLA-DPB1 \n## Negative:  PPBP, PF4, SDPR, SPARC, GNG11 \n## PC_ 4 \n## Positive:  HLA-DQA1, CD79B, CD79A, MS4A1, HLA-DQB1 \n## Negative:  VIM, IL7R, S100A6, IL32, S100A8 \n## PC_ 5 \n## Positive:  GZMB, NKG7, S100A8, FGFBP2, GNLY \n## Negative:  LTB, IL7R, CKB, VIM, MS4A7\n\nVisualize it\n\nVizDimLoadings(\n    pbmc, dims = 1:2, \n    nfeatures = 20,\n    reduction = \"pca\"\n)\n\n\n\n\n\n\n# PCA dotplot\nDimPlot(pbmc, reduction = \"pca\") + NoLegend()\n\n\n\n\n\n\n\n# PCA heatmap\nDimHeatmap(pbmc, dims = 1, cells = 500, balanced = TRUE)\n\n\n\n\n\n\nDimHeatmap(pbmc, dims = 1:15, cells = 500, balanced = TRUE)"
  },
  {
    "objectID": "blog/2023/11/25/index.html#determine-the-dimensionality-of-the-dataset",
    "href": "blog/2023/11/25/index.html#determine-the-dimensionality-of-the-dataset",
    "title": "Learning Seruat for scRNA-seq data analysis",
    "section": "Determine the dimensionality of the dataset",
    "text": "Determine the dimensionality of the dataset\nJackStrawPlot\n\n# NOTE: This process can take a long time for big datasets, comment out for expediency. More\n# approximate techniques such as those implemented in ElbowPlot() can be used to reduce\n\n# Computation time\npbmc &lt;- JackStraw(pbmc, num.replicate = 100)\npbmc &lt;- ScoreJackStraw(pbmc, dims = 1:20)\n\nJackStrawPlot(pbmc, dims = 1:15)\n\n\n\n\n\n\n\nElbow plot\n\nElbowPlot(pbmc)\n\n\n\n\n\n\n\nSignificant related genes\n\n# Returns a set of genes, based on the JackStraw analysis, that have statistically significant associations with a set of PCs.\n# ?PCASigGenes\nhead(PCASigGenes(pbmc,pcs.use=2,pval.cut = 0.7))\n## [1] \"PPBP\"   \"LYZ\"    \"S100A9\" \"IGLL5\"  \"GNLY\"   \"FTL\""
  },
  {
    "objectID": "blog/2023/11/25/index.html#cluster-the-cells",
    "href": "blog/2023/11/25/index.html#cluster-the-cells",
    "title": "Learning Seruat for scRNA-seq data analysis",
    "section": "Cluster the cells",
    "text": "Cluster the cells\n\npbmc &lt;- FindNeighbors(pbmc, dims = 1:10)\npbmc &lt;- FindClusters(pbmc, resolution = 0.5)\n## Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n## \n## Number of nodes: 2638\n## Number of edges: 95927\n## \n## Running Louvain algorithm...\n## Maximum modularity in 10 random starts: 0.8728\n## Number of communities: 9\n## Elapsed time: 0 seconds\n\n# Look at cluster IDs of the first 5 cells\nhead(Idents(pbmc), 5)\n## AAACATACAACCAC-1 AAACATTGAGCTAC-1 AAACATTGATCAGC-1 AAACCGTGCTTCCG-1 \n##                2                3                2                1 \n## AAACCGTGTATGCG-1 \n##                6 \n## Levels: 0 1 2 3 4 5 6 7 8\n\n# Look at the cells of specific cluster\nhead(subset(as.data.frame(pbmc@active.ident),pbmc@active.ident==\"2\"))\n##                  pbmc@active.ident\n## AAACATACAACCAC-1                 2\n## AAACATTGATCAGC-1                 2\n## AAACGCACTGGTAC-1                 2\n## AAAGAGACGAGATA-1                 2\n## AAAGCCTGTATGCG-1                 2\n## AAATCAACTCGCAA-1                 2\n\n# Retrieve the cells of a cluster\nsubpbmc &lt;- subset(x = pbmc,idents=\"2\")\nsubpbmc\n## An object of class Seurat \n## 13714 features across 476 samples within 1 assay \n## Active assay: RNA (13714 features, 2000 variable features)\n##  3 layers present: counts, data, scale.data\n##  1 dimensional reduction calculated: pca\nhead(subpbmc@active.ident,5)\n## AAACATACAACCAC-1 AAACATTGATCAGC-1 AAACGCACTGGTAC-1 AAAGAGACGAGATA-1 \n##                2                2                2                2 \n## AAAGCCTGTATGCG-1 \n##                2 \n## Levels: 2"
  },
  {
    "objectID": "blog/2023/11/25/index.html#run-non-linear-dimensional-reduction",
    "href": "blog/2023/11/25/index.html#run-non-linear-dimensional-reduction",
    "title": "Learning Seruat for scRNA-seq data analysis",
    "section": "Run non-linear dimensional reduction",
    "text": "Run non-linear dimensional reduction\nUMAP\n\n# If you haven't installed UMAP, you can do so via \n# reticulate::py_install(packages = \"umap-learn\")\n\npbmc &lt;- RunUMAP(pbmc, dims = 1:10)\n\n# Note that you can set `label = TRUE` or use the LabelClusters function to help label\n# Individual clusters\nDimPlot(pbmc, reduction = \"umap\")\n\n\n\n\n\n\n\ntSNE\n\npbmc &lt;- RunTSNE(pbmc, dims = 1:10)\n\nhead(pbmc@reductions$tsne@cell.embeddings)\n##                      tSNE_1     tSNE_2\n## AAACATACAACCAC-1 -12.721811   6.420117\n## AAACATTGAGCTAC-1 -20.682526 -22.307703\n## AAACATTGATCAGC-1  -3.067779  23.686369\n## AAACCGTGCTTCCG-1  30.350720  -9.899162\n## AAACCGTGTATGCG-1 -35.994115   9.507508\n## AAACGCACTGGTAC-1  -3.124182  12.680105\n\nDimPlot(pbmc, reduction = \"tsne\")\n\n\n\n\n\n\n\nCompare\n\n# Note that you can set `label = TRUE` or use the LabelClusters function to help label\n# Individual clusters\nplot1 &lt;- DimPlot(pbmc, reduction = \"umap\", label = TRUE)\nplot2 &lt;- DimPlot(pbmc, reduction = \"tsne\", label = TRUE)\nplot1 + plot2"
  },
  {
    "objectID": "blog/2023/11/25/index.html#finding-cluster-biomarkers",
    "href": "blog/2023/11/25/index.html#finding-cluster-biomarkers",
    "title": "Learning Seruat for scRNA-seq data analysis",
    "section": "Finding cluster biomarkers",
    "text": "Finding cluster biomarkers\nFind clusters\n\n# Find all markers of cluster 2\ncluster2_markers &lt;- FindMarkers(pbmc, ident.1 = 2)\nhead(cluster2_markers, n = 5)\n##             p_val avg_log2FC pct.1 pct.2    p_val_adj\n## IL32 2.892340e-90  1.3070772 0.947 0.465 3.966555e-86\n## LTB  1.060121e-86  1.3312674 0.981 0.643 1.453850e-82\n## CD3D 8.794641e-71  1.0597620 0.922 0.432 1.206097e-66\n## IL7R 3.516098e-68  1.4377848 0.750 0.326 4.821977e-64\n## LDHB 1.642480e-67  0.9911924 0.954 0.614 2.252497e-63\n\n# Find all markers distinguishing cluster 5 from clusters 0 and 3\ncluster5_markers &lt;- FindMarkers(pbmc, ident.1 = 5, ident.2 = c(0, 3))\nhead(cluster5_markers, n = 5)\n##                       p_val avg_log2FC pct.1 pct.2     p_val_adj\n## FCGR3A        8.246578e-205   6.794969 0.975 0.040 1.130936e-200\n## IFITM3        1.677613e-195   6.192558 0.975 0.049 2.300678e-191\n## CFD           2.401156e-193   6.015172 0.938 0.038 3.292945e-189\n## CD68          2.900384e-191   5.530330 0.926 0.035 3.977587e-187\n## RP11-290F20.3 2.513244e-186   6.297999 0.840 0.017 3.446663e-182\n\n# Find markers for every cluster compared to all remaining cells, report only the positive ones\npbmc_markers &lt;- FindAllMarkers(pbmc, only.pos = TRUE)\npbmc_markers %&gt;%\n    group_by(cluster) %&gt;%\n    dplyr::filter(avg_log2FC &gt; 1)\n## # A tibble: 7,019 × 7\n## # Groups:   cluster [9]\n##        p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene     \n##        &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;chr&gt;    \n##  1 3.75e-112       1.21 0.912 0.592 5.14e-108 0       LDHB     \n##  2 9.57e- 88       2.40 0.447 0.108 1.31e- 83 0       CCR7     \n##  3 1.15e- 76       1.06 0.845 0.406 1.58e- 72 0       CD3D     \n##  4 1.12e- 54       1.04 0.731 0.4   1.54e- 50 0       CD3E     \n##  5 1.35e- 51       2.14 0.342 0.103 1.86e- 47 0       LEF1     \n##  6 1.94e- 47       1.20 0.629 0.359 2.66e- 43 0       NOSIP    \n##  7 2.81e- 44       1.53 0.443 0.185 3.85e- 40 0       PIK3IP1  \n##  8 6.27e- 43       1.99 0.33  0.112 8.60e- 39 0       PRKCQ-AS1\n##  9 1.16e- 40       2.70 0.2   0.04  1.59e- 36 0       FHIT     \n## 10 1.34e- 34       1.96 0.268 0.087 1.84e- 30 0       MAL      \n## # ℹ 7,009 more rows\n# ?FindAllMarkers\n\ncluster0_markers &lt;- FindMarkers(\n    pbmc, ident.1 = 0, logfc.threshold = 0.25, test.use = \"roc\", \n    only.pos = TRUE\n)\n\nVisualization\n\n### Show expression probability distributions across clusters\nVlnPlot(pbmc, features = c(\"MS4A1\", \"CD79A\"))\n\n\n\n\n\n\n# You can plot raw counts as well\nVlnPlot(pbmc, features = c(\"NKG7\", \"PF4\"), layer = \"counts\", log = TRUE)\n\n\n\n\n\n\n\n# Visualizes feature expression on a tSNE or PCA plot\nFeaturePlot(\n    pbmc, features = c(\n        \"MS4A1\", \"GNLY\", \"CD3E\", \"CD14\", \"FCER1A\", \"FCGR3A\", \n        \"LYZ\", \"PPBP\",\"CD8A\"\n    )\n)\n\n\n\n\n\n\n\n# Expression heatmap for given cells and features\ntop10 &lt;- pbmc_markers %&gt;%\n    group_by(cluster) %&gt;%\n    top_n(n = 10, wt = avg_log2FC)\nDoHeatmap(pbmc, features = top10$gene) + NoLegend()"
  },
  {
    "objectID": "blog/2023/11/25/index.html#assign-cell-type-identity-to-clusters",
    "href": "blog/2023/11/25/index.html#assign-cell-type-identity-to-clusters",
    "title": "Learning Seruat for scRNA-seq data analysis",
    "section": "Assign cell type identity to clusters",
    "text": "Assign cell type identity to clusters\nFortunately in the case of this dataset, we can use canonical markers to easily match the unbiased clustering to known cell types:\nCluster ID Markers Cell Type 0 IL7R, CCR7 Naive CD4+ T 1 CD14, LYZ CD14+ Mono 2 IL7R, S100A4 Memory CD4+ 3 MS4A1 B 4 CD8A CD8+ T 5 FCGR3A, MS4A7 FCGR3A+ Mono 6 GNLY, NKG7 NK 7 FCER1A, CST3 DC 8 PPBP Platelet\n\nnew_cluster_ids &lt;- c(\n    \"Naive CD4 T\", \"CD14+ Mono\", \"Memory CD4 T\", \"B\", \"CD8 T\", \"FCGR3A+ Mono\",\"NK\", \"DC\", \"Platelet\"\n)\nnames(new_cluster_ids) &lt;- levels(pbmc)\npbmc &lt;- RenameIdents(pbmc, new_cluster_ids)\nDimPlot(pbmc, reduction = \"umap\", label = TRUE, pt.size = 0.5) +\n    NoLegend()\n\n\n\n\n\n\n\n\n# p &lt;- DimPlot(pbmc, reduction = \"umap\", label = TRUE, label.size = 4.5) + \n#     xlab(\"UMAP 1\") + ylab(\"UMAP 2\") +\n#     theme(\n#         axis.title = element_text(size = 18), \n#         legend.text = element_text(size = 18)) + \n#         guides(colour = guide_legend(override.aes = list(size = 10))\n#     )\n# Save plot\n# ggsave(\n#     filename = \"../output/images/pbmc3k_umap.jpg\", \n#     height = 7, width = 12, plot = p, quality = 50\n# )\n# Save data\n# saveRDS(pbmc, file = \"./learn/pbmc3k/pbmc3k_final.rds\")\n\n\nsessionInfo()\n## R version 4.3.1 (2023-06-16)\n## Platform: aarch64-apple-darwin20 (64-bit)\n## Running under: macOS Sonoma 14.2\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \n## LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n## \n## locale:\n## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n## \n## time zone: Asia/Singapore\n## tzcode source: internal\n## \n## attached base packages:\n## [1] stats4    stats     graphics  grDevices utils     datasets  methods  \n## [8] base     \n## \n## other attached packages:\n##  [1] patchwork_1.1.3             ggrepel_0.9.4              \n##  [3] SingleR_2.2.0               SummarizedExperiment_1.30.2\n##  [5] Biobase_2.62.0              GenomicRanges_1.52.1       \n##  [7] GenomeInfoDb_1.38.0         IRanges_2.36.0             \n##  [9] S4Vectors_0.40.2            BiocGenerics_0.48.1        \n## [11] MatrixGenerics_1.14.0       matrixStats_1.1.0          \n## [13] Seurat_5.0.1                SeuratObject_5.0.1         \n## [15] sp_2.1-2                    lubridate_1.9.3            \n## [17] forcats_1.0.0               stringr_1.5.1              \n## [19] dplyr_1.1.4                 purrr_1.0.2                \n## [21] readr_2.1.4                 tidyr_1.3.0                \n## [23] tibble_3.2.1                ggplot2_3.4.4              \n## [25] tidyverse_2.0.0             here_1.0.1                 \n## \n## loaded via a namespace (and not attached):\n##   [1] RcppAnnoy_0.0.21          splines_4.3.1            \n##   [3] later_1.3.1               bitops_1.0-7             \n##   [5] R.oo_1.25.0               polyclip_1.10-6          \n##   [7] fastDummies_1.7.3         lifecycle_1.0.4          \n##   [9] rprojroot_2.0.4           globals_0.16.2           \n##  [11] lattice_0.22-5            MASS_7.3-60              \n##  [13] magrittr_2.0.3            limma_3.58.1             \n##  [15] plotly_4.10.3             rmarkdown_2.25           \n##  [17] yaml_2.3.7                httpuv_1.6.12            \n##  [19] sctransform_0.4.1         spam_2.10-0              \n##  [21] spatstat.sparse_3.0-3     reticulate_1.34.0        \n##  [23] cowplot_1.1.1             pbapply_1.7-2            \n##  [25] RColorBrewer_1.1-3        abind_1.4-5              \n##  [27] zlibbioc_1.48.0           Rtsne_0.16               \n##  [29] R.utils_2.12.3            RCurl_1.98-1.13          \n##  [31] GenomeInfoDbData_1.2.11   irlba_2.3.5.1            \n##  [33] listenv_0.9.0             spatstat.utils_3.0-4     \n##  [35] goftest_1.2-3             RSpectra_0.16-1          \n##  [37] spatstat.random_3.2-2     fitdistrplus_1.1-11      \n##  [39] parallelly_1.36.0         DelayedMatrixStats_1.22.6\n##  [41] leiden_0.4.3.1            codetools_0.2-19         \n##  [43] DelayedArray_0.26.7       tidyselect_1.2.0         \n##  [45] farver_2.1.1              ScaledMatrix_1.8.1       \n##  [47] spatstat.explore_3.2-5    jsonlite_1.8.7           \n##  [49] ellipsis_0.3.2            progressr_0.14.0         \n##  [51] ggridges_0.5.4            survival_3.5-7           \n##  [53] tools_4.3.1               ica_1.0-3                \n##  [55] Rcpp_1.0.11               glue_1.6.2               \n##  [57] gridExtra_2.3             xfun_0.41                \n##  [59] withr_2.5.2               fastmap_1.1.1            \n##  [61] fansi_1.0.5               digest_0.6.33            \n##  [63] rsvd_1.0.5                timechange_0.2.0         \n##  [65] R6_2.5.1                  mime_0.12                \n##  [67] colorspace_2.1-0          scattermore_1.2          \n##  [69] tensor_1.5                spatstat.data_3.0-3      \n##  [71] R.methodsS3_1.8.2         utf8_1.2.4               \n##  [73] generics_0.1.3            data.table_1.14.8        \n##  [75] httr_1.4.7                htmlwidgets_1.6.3        \n##  [77] S4Arrays_1.0.6            uwot_0.1.16              \n##  [79] pkgconfig_2.0.3           gtable_0.3.4             \n##  [81] lmtest_0.9-40             XVector_0.42.0           \n##  [83] htmltools_0.5.7           dotCall64_1.1-1          \n##  [85] scales_1.3.0              png_0.1-8                \n##  [87] knitr_1.45                tzdb_0.4.0               \n##  [89] reshape2_1.4.4            nlme_3.1-163             \n##  [91] zoo_1.8-12                KernSmooth_2.23-22       \n##  [93] parallel_4.3.1            miniUI_0.1.1.1           \n##  [95] vipor_0.4.5               ggrastr_1.0.2            \n##  [97] pillar_1.9.0              grid_4.3.1               \n##  [99] vctrs_0.6.5               RANN_2.6.1               \n## [101] promises_1.2.1            BiocSingular_1.16.0      \n## [103] beachmat_2.16.0           xtable_1.8-4             \n## [105] cluster_2.1.4             beeswarm_0.4.0           \n## [107] evaluate_0.23             cli_3.6.1                \n## [109] compiler_4.3.1            rlang_1.1.2              \n## [111] crayon_1.5.2              future.apply_1.11.0      \n## [113] labeling_0.4.3            plyr_1.8.9               \n## [115] ggbeeswarm_0.7.2          stringi_1.8.2            \n## [117] viridisLite_0.4.2         deldir_2.0-2             \n## [119] BiocParallel_1.36.0       munsell_0.5.0            \n## [121] lazyeval_0.2.2            spatstat.geom_3.2-7      \n## [123] Matrix_1.6-3              RcppHNSW_0.5.0           \n## [125] hms_1.1.3                 sparseMatrixStats_1.12.2 \n## [127] future_1.33.0             statmod_1.5.0            \n## [129] shiny_1.8.0               ROCR_1.0-11              \n## [131] igraph_1.5.1"
  },
  {
    "objectID": "blog/2023/11/27/index.html",
    "href": "blog/2023/11/27/index.html",
    "title": "Practise Seurat for single cell data analysis",
    "section": "",
    "text": "# Load packages\nlibrary(Seurat)\n## Loading required package: SeuratObject\n## Loading required package: sp\n## \n## Attaching package: 'SeuratObject'\n## The following object is masked from 'package:base':\n## \n##     intersect\nlibrary(harmony)\n## Loading required package: Rcpp\nlibrary(Matrix)\nlibrary(tidyverse)\n## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n## ✔ dplyr     1.1.4     ✔ readr     2.1.4\n## ✔ forcats   1.0.0     ✔ stringr   1.5.1\n## ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n## ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n## ✔ purrr     1.0.2\n## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n## ✖ tidyr::expand() masks Matrix::expand()\n## ✖ dplyr::filter() masks stats::filter()\n## ✖ dplyr::lag()    masks stats::lag()\n## ✖ tidyr::pack()   masks Matrix::pack()\n## ✖ tidyr::unpack() masks Matrix::unpack()\n## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nlibrary(here)\n## here() starts at /Users/zhonggr/Library/CloudStorage/OneDrive-Personal/quarto\nlibrary(httpgd)"
  },
  {
    "objectID": "blog/2023/11/27/index.html#packages",
    "href": "blog/2023/11/27/index.html#packages",
    "title": "Practise Seurat for single cell data analysis",
    "section": "",
    "text": "# Load packages\nlibrary(Seurat)\n## Loading required package: SeuratObject\n## Loading required package: sp\n## \n## Attaching package: 'SeuratObject'\n## The following object is masked from 'package:base':\n## \n##     intersect\nlibrary(harmony)\n## Loading required package: Rcpp\nlibrary(Matrix)\nlibrary(tidyverse)\n## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n## ✔ dplyr     1.1.4     ✔ readr     2.1.4\n## ✔ forcats   1.0.0     ✔ stringr   1.5.1\n## ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n## ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n## ✔ purrr     1.0.2\n## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n## ✖ tidyr::expand() masks Matrix::expand()\n## ✖ dplyr::filter() masks stats::filter()\n## ✖ dplyr::lag()    masks stats::lag()\n## ✖ tidyr::pack()   masks Matrix::pack()\n## ✖ tidyr::unpack() masks Matrix::unpack()\n## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nlibrary(here)\n## here() starts at /Users/zhonggr/Library/CloudStorage/OneDrive-Personal/quarto\nlibrary(httpgd)"
  },
  {
    "objectID": "blog/2023/11/27/index.html#retrieve-data",
    "href": "blog/2023/11/27/index.html#retrieve-data",
    "title": "Practise Seurat for single cell data analysis",
    "section": "Retrieve data",
    "text": "Retrieve data\n\nThe source data is from Single-cell transcriptome analysis of tumor and stromal compartments of pancreatic ductal adenocarcinoma primary tumors and metastatic lesions\n\nDown load data GSE154778_RAW.tar from here to data and unzip it.\nPreprocess sequencing data\n\n\n\n# Change working directory\nsetwd(\"./learn/2023_scRNA_Seurat/data/GSE154778_RAW/\")\n# getwd()\n# Check files\nfs &lt;- list.files(\"./\", \"^GSM\")\n# Get the sample names\nsamples &lt;- str_split(fs, \"_\", simplify = TRUE)[, 2]\nunique(samples)\n# Create folders for each sample, and rename\nlapply(\n  unique(samples), function(x) {\n    y  &lt;- fs[grepl(x, fs)]\n    folder &lt;- paste(str_split(y[1], \"_\", simplify = TRUE)[, 2], collapse = \"\")\n    dir.create(folder, recursive = TRUE)\n    file.rename(y[1], file.path(folder, \"barcodes.tsv.gz\"))\n    # Note the seurat version to check features.tsv.gz or genes.tsv.gz\n    file.rename(y[2], file.path(folder, \"features.tsv.gz\")) \n    file.rename(y[3], file.path(folder, \"matrix.mtx.gz\"))\n  }\n)"
  },
  {
    "objectID": "blog/2023/11/27/index.html#load-batch-data",
    "href": "blog/2023/11/27/index.html#load-batch-data",
    "title": "Practise Seurat for single cell data analysis",
    "section": "Load batch data",
    "text": "Load batch data\n\n# Change working directory\nsetwd(\"./learn/2023_scRNA_Seurat/data/GSE154778_RAW/\")\nfolders &lt;- list.files(\"./\")\nfolders\nsceList &lt;- lapply(\n  folders, function(folder) {\n    CreateSeuratObject(counts = Read10X(folder), project = folder)\n  }\n)"
  },
  {
    "objectID": "blog/2023/11/27/index.html#merage-samples-data",
    "href": "blog/2023/11/27/index.html#merage-samples-data",
    "title": "Practise Seurat for single cell data analysis",
    "section": "Merage samples data",
    "text": "Merage samples data\nDirectly merge\n\n# Use Seurat merge\nsce.all &lt;- merge(\n  x = sceList[[1]],\n  y = c(sceList[[2]], sceList[[3]], sceList[[4]], sceList[[5]], sceList[[6]], \n  sceList[[7]], sceList[[8]], sceList[[9]], sceList[[10]], sceList[[11]], \n  sceList[[12]], sceList[[13]], sceList[[14]], sceList[[5]], sceList[[16]]),\n  ## Sample names\n  add.cell.ids = folders,  \n  project = \"scRNA\"\n)\nsaveRDS(sce.all, here(\"learn\", \"2023_scRNA_Seurat\", \"sce.all.rds\"))\n\nFilter\n\nsce.all &lt;- readRDS(here(\"learn\", \"2023_scRNA_Seurat\", \"sce.all.rds\"))\nhead(sce.all@meta.data)\n##                         orig.ident nCount_RNA nFeature_RNA\n## K16733_AAACATACTCGTTT-1     K16733       2464          965\n## K16733_AAACCGTGGGTAGG-1     K16733        689          336\n## K16733_AAAGCAGAACGTTG-1     K16733       7145         1919\n## K16733_AAAGCAGACTGAGT-1     K16733       1655          621\n## K16733_AAAGGCCTGCTCCT-1     K16733      14272         2771\n## K16733_AAATACTGTGGATC-1     K16733      13832         2541\ntable(sce.all@meta.data$orig.ident)\n## \n## K16733    T10     T2     T3     T4     T5     T6     T8     T9 Y00006 Y00008 \n##    585   1570    837   1026   1826    769   1098   1139    898    786    533 \n## Y00013 Y00014 Y00016 Y00027 \n##    745    526    272   2484\n# Mitochandrial genes\nsce.all[[\"percent.mt\"]] &lt;- PercentageFeatureSet(sce.all, pattern = \"^MT-\")\n# Ribonucleoprotein \nsce.all[[\"percent.rp\"]] &lt;- PercentageFeatureSet(sce.all, pattern = \"^RP\")\n\n# Specific gene set\nHB.genes &lt;- c(\"HBA1\",\"HBA2\",\"HBB\",\"HBD\",\"HBE1\",\"HBG1\",\"HBG2\",\"HBM\",\"HBQ1\",\"HBZ\") \n# Red blood cells genes\nsce.all[[\"percent.HB\"]]&lt;-PercentageFeatureSet(sce.all, features = HB.genes)\n\nhead(sce.all@meta.data)\n##                         orig.ident nCount_RNA nFeature_RNA percent.mt\n## K16733_AAACATACTCGTTT-1     K16733       2464          965 12.6623377\n## K16733_AAACCGTGGGTAGG-1     K16733        689          336  2.1770682\n## K16733_AAAGCAGAACGTTG-1     K16733       7145         1919  2.4492652\n## K16733_AAAGCAGACTGAGT-1     K16733       1655          621  2.1752266\n## K16733_AAAGGCCTGCTCCT-1     K16733      14272         2771  1.5414798\n## K16733_AAATACTGTGGATC-1     K16733      13832         2541  0.3181029\n##                         percent.rp percent.HB\n## K16733_AAACATACTCGTTT-1   13.35227          0\n## K16733_AAACCGTGGGTAGG-1   29.02758          0\n## K16733_AAAGCAGAACGTTG-1   36.72498          0\n## K16733_AAAGCAGACTGAGT-1   35.52870          0\n## K16733_AAAGGCCTGCTCCT-1   38.81026          0\n## K16733_AAATACTGTGGATC-1   40.73164          0\n\n\nsce &lt;- subset(\n    sce.all, subset = nFeature_RNA &gt; 500 &\n        nFeature_RNA &lt; 5000 & percent.mt &lt; 30\n)\nVlnPlot(sce, features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\"), ncol = 3)\n\n\n\n\n\n\n\nSeurat workflow\n\nsce &lt;- NormalizeData(sce)\n## Normalizing layer: counts.1\n## Normalizing layer: counts.2\n## Normalizing layer: counts.3\n## Normalizing layer: counts.4\n## Normalizing layer: counts.5\n## Normalizing layer: counts.6\n## Normalizing layer: counts.7\n## Normalizing layer: counts.8\n## Normalizing layer: counts.9\n## Normalizing layer: counts.10\n## Normalizing layer: counts.11\n## Normalizing layer: counts.12\n## Normalizing layer: counts.13\n## Normalizing layer: counts.14\n## Normalizing layer: counts.15\n## Normalizing layer: counts.16\nsce &lt;- FindVariableFeatures(sce, selection.method = \"vst\", nfeatures = 2000)\n## Finding variable features for layer counts.1\n## Finding variable features for layer counts.2\n## Finding variable features for layer counts.3\n## Finding variable features for layer counts.4\n## Finding variable features for layer counts.5\n## Finding variable features for layer counts.6\n## Finding variable features for layer counts.7\n## Finding variable features for layer counts.8\n## Finding variable features for layer counts.9\n## Finding variable features for layer counts.10\n## Finding variable features for layer counts.11\n## Finding variable features for layer counts.12\n## Finding variable features for layer counts.13\n## Finding variable features for layer counts.14\n## Finding variable features for layer counts.15\n## Finding variable features for layer counts.16\nall.genes &lt;- rownames(sce)\nsce &lt;- ScaleData(sce, features = all.genes)\n## Centering and scaling data matrix\nsce &lt;- RunPCA(sce, npcs = 50)\n## PC_ 1 \n## Positive:  KRT19, KRT8, KRT18, SMIM22, MAL2, SPINT2, TSPAN8, CLDN4, GPRC5A, PERP \n##     C19orf33, ELF3, TM4SF1, TMC5, LSR, LGALS4, NQO1, TACSTD2, CLDN7, SPINK1 \n##     MUC1, C12orf75, GPX2, TSPAN1, ERBB3, SFTA2, MMP7, CYP3A5, CDH1, TMPRSS4 \n## Negative:  VIM, COL1A2, BGN, COL1A1, SERPINF1, FN1, C1R, MGP, CTHRC1, TAGLN \n##     PMP22, NUPR1, THY1, FBLN1, RARRES2, TIMP3, MXRA8, TCF4, CLEC11A, INHBA \n##     RAB31, CCDC80, ASPN, THBS2, APOD, ISLR, TUBA1A, FSTL1, ANTXR1, MEG3 \n## PC_ 2 \n## Positive:  LAPTM5, AIF1, SRGN, LST1, HLA-DPA1, HLA-DRA, HLA-DPB1, MS4A6A, HLA-DQA1, MS4A7 \n##     HLA-DQB1, C1orf162, OLR1, HLA-DRB1, CD53, CD74, CYBB, FCGR2A, CLEC7A, ALOX5AP \n##     CD37, ITGB2, CD14, CD83, MS4A4A, IFI30, RGS1, RNASE6, CD86, HLA-DQA2 \n## Negative:  BGN, C1R, TPM1, COL1A1, RARRES2, COL1A2, NBL1, MXRA8, CTHRC1, FSTL1 \n##     THY1, FBLN1, CCDC80, IGFBP4, TAGLN, NNMT, THBS2, MGP, ASPN, TIMP3 \n##     ISLR, MEG3, APOD, EFEMP2, MFGE8, DKK3, SPON2, FBN1, ANTXR1, EMILIN1 \n## PC_ 3 \n## Positive:  CTSE, VSIG2, AGR3, FOS, MUC5AC, CYSTM1, ATF3, JUN, FOSB, ELF3 \n##     RHOB, LINC01133, IER3, CAPN8, NEAT1, KLF6, TFF3, MUC1, DUSP1, EGR1 \n##     BACE2, PIGR, KLF4, KLF2, CREB3L1, REG4, EDN1, HSPA1B, PLAC8, ZG16B \n## Negative:  TUBA1B, TOP2A, MKI67, PTTG1, UBE2C, H2AFZ, CENPW, TPX2, HMGB2, CDK1 \n##     STMN1, RRM2, RBP1, ASPM, KLK6, PRC1, HMGB1, ATAD2, NUSAP1, GTSE1 \n##     CDKN3, KIF20B, CEP55, HMMR, DTYMK, CDCA3, CLSPN, CENPU, CCNB1, UBE2T \n## PC_ 4 \n## Positive:  MDK, TMEM176B, COL11A1, NBL1, TMEM176A, FAM3C, LYZ, INHBA, THBS2, C1QTNF3 \n##     GCNT3, GPNMB, FBLN1, KLK6, RARRES2, IGFL2, COL8A1, C12orf75, FNDC1, MMP7 \n##     GREM1, PERP, NTM, CLDN3, GJB2, COMP, ISLR, CXCL14, MEG3, RBP1 \n## Negative:  PLVAP, RAMP2, VWF, ECSCR, AQP1, CDH5, CALCRL, BCAM, RAMP3, NOTCH4 \n##     CLDN5, MMRN2, FAM167B, ADAMTS9, EMCN, CD34, CD93, STC1, CYYR1, GPR4 \n##     S1PR1, ANGPT2, PODXL, MYCT1, ARHGAP29, RGS5, CRIP2, ROBO4, GJA4, HIGD1B \n## PC_ 5 \n## Positive:  TOP2A, UBE2C, ATAD2, NUCKS1, PRC1, STMN1, SLPI, GTSE1, CENPW, HMGB1 \n##     TPX2, CTSD, RAD51AP1, PLAT, CDK1, RRM2, DTYMK, CLSPN, ANLN, MYBL2 \n##     FAM83A, CCNB1, NUSAP1, CENPU, ASPM, UBE2T, PRR11, MKI67, CEP55, CRIP2 \n## Negative:  CD3D, CD2, PTPRCAP, CD7, C12orf75, CCL5, CD3G, RBP1, GCNT3, CD27 \n##     KLRB1, LTB, ZFAS1, CA12, GZMM, RHOH, SPINK1, VNN1, ICOS, CLDN3 \n##     CYTIP, TIGIT, PTPN7, GZMB, CDHR2, RUNX3, SLC7A11, CCR7, CD8A, FAM3C\nsce &lt;- FindNeighbors(sce, dims = 1:30)\n## Computing nearest neighbor graph\n## Computing SNN\nsce &lt;- FindClusters(sce, resolution = 0.5)\n## Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n## \n## Number of nodes: 11914\n## Number of edges: 436451\n## \n## Running Louvain algorithm...\n## Maximum modularity in 10 random starts: 0.9419\n## Number of communities: 18\n## Elapsed time: 1 seconds\nsce &lt;- RunUMAP(sce, dims = 1:30)\n## 15:18:03 UMAP embedding parameters a = 0.9922 b = 1.112\n## 15:18:03 Read 11914 rows and found 30 numeric columns\n## 15:18:03 Using Annoy for neighbor search, n_neighbors = 30\n## 15:18:03 Building Annoy index with metric = cosine, n_trees = 50\n## 0%   10   20   30   40   50   60   70   80   90   100%\n## [----|----|----|----|----|----|----|----|----|----|\n## **************************************************|\n## 15:18:03 Writing NN index file to temp file /var/folders/2c/9q3pg2295195bp3gnrgbzrg40000gn/T//RtmpjzstFL/file2afb9bffbb\n## 15:18:03 Searching Annoy index using 1 thread, search_k = 3000\n## 15:18:05 Annoy recall = 100%\n## 15:18:05 Commencing smooth kNN distance calibration using 1 thread with target n_neighbors = 30\n## 15:18:06 Initializing from normalized Laplacian + noise (using RSpectra)\n## 15:18:06 Commencing optimization for 200 epochs, with 492128 positive edges\n## 15:18:10 Optimization finished\n# sce &lt;- RunTSNE(sce, dims = 1:30)\n\nUMAP\n\n# Rename sample\nsce@meta.data$sample[sce@meta.data$orig.ident == \"K16733\"] &lt;- \"P01\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"Y00006\"] &lt;- \"P02\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"T2\"] &lt;- \"P03\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"T3\"] &lt;- \"P04\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"T4\"] &lt;- \"P05\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"T5\"] &lt;- \"P06\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"T6\"] &lt;- \"P07\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"T8\"] &lt;- \"P08\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"T9\"] &lt;- \"P09\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"T10\"] &lt;- \"P10\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"Y00008\"] &lt;- \"MET01\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"Y00013\"] &lt;- \"MET02\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"Y00014\"] &lt;- \"MET03\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"Y00016\"] &lt;- \"MET04\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"Y00019\"] &lt;- \"MET05\"\nsce@meta.data$sample[sce@meta.data$orig.ident == \"Y00027\"] &lt;- \"MET06\"\n\n# Add group information\nsce@meta.data$group &lt;- ifelse( grepl(\"MET\",sce@meta.data$sample ) ,\"MET\" ,\"PT\" )\n\n\n# Global\np1 &lt;- DimPlot(\n  sce, reduction = \"umap\", pt.size=0.5, label = F,repel = TRUE\n)\n# Sample\np2 &lt;- DimPlot(\n  sce, reduction = \"umap\",group.by = \"sample\", pt.size=0.5, label = F,\n  repel = TRUE\n)\n# group\np3 &lt;- DimPlot(\n  sce, reduction = \"umap\",group.by = \"group\", pt.size=0.5, label = F,\n  repel = TRUE\n)\n\np1 + p2 +p3\n\n\n\n\n\n\n\nHarmony to remove batch effect\n\nsce2 &lt;- sce  |&gt;  RunHarmony(\"sample\", plot_convergence = TRUE)\n## Transposing data matrix\n## Initializing state using k-means centroids initialization\n## Harmony 1/10\n## Harmony 2/10\n## Harmony 3/10\n## Harmony 4/10\n## Harmony 5/10\n## Harmony 6/10\n## Harmony 7/10\n## Harmony 8/10\n## Harmony 9/10\n## Harmony 10/10\n## Harmony converged after 10 iterations\n\n\n\n\n\n\nsce2\n## An object of class Seurat \n## 51911 features across 11914 samples within 1 assay \n## Active assay: RNA (51911 features, 2000 variable features)\n##  33 layers present: counts.1, counts.2, counts.3, counts.4, counts.5, counts.6, counts.7, counts.8, counts.9, counts.10, counts.11, counts.12, counts.13, counts.14, counts.15, counts.16, data.1, data.2, data.3, data.4, data.5, data.6, data.7, data.8, data.9, data.10, data.11, data.12, data.13, data.14, data.15, data.16, scale.data\n##  3 dimensional reductions calculated: pca, umap, harmony\n# Same workflow\nsce2 &lt;- sce2  |&gt;  \n  RunUMAP(reduction = \"harmony\", dims = 1:30)  |&gt;  \n  FindNeighbors(reduction = \"harmony\", dims = 1:30)  |&gt;  \n  FindClusters(resolution = 0.5)  |&gt;  \n  identity()\n## 15:19:42 UMAP embedding parameters a = 0.9922 b = 1.112\n## 15:19:42 Read 11914 rows and found 30 numeric columns\n## 15:19:42 Using Annoy for neighbor search, n_neighbors = 30\n## 15:19:42 Building Annoy index with metric = cosine, n_trees = 50\n## 0%   10   20   30   40   50   60   70   80   90   100%\n## [----|----|----|----|----|----|----|----|----|----|\n## **************************************************|\n## 15:19:42 Writing NN index file to temp file /var/folders/2c/9q3pg2295195bp3gnrgbzrg40000gn/T//RtmpjzstFL/file2afb17134535\n## 15:19:42 Searching Annoy index using 1 thread, search_k = 3000\n## 15:19:44 Annoy recall = 100%\n## 15:19:45 Commencing smooth kNN distance calibration using 1 thread with target n_neighbors = 30\n## 15:19:45 Initializing from normalized Laplacian + noise (using RSpectra)\n## 15:19:46 Commencing optimization for 200 epochs, with 516614 positive edges\n## 15:19:50 Optimization finished\n## Computing nearest neighbor graph\n## Computing SNN\n## Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n## \n## Number of nodes: 11914\n## Number of edges: 465972\n## \n## Running Louvain algorithm...\n## Maximum modularity in 10 random starts: 0.9043\n## Number of communities: 14\n## Elapsed time: 1 seconds\n\np11 &lt;- DimPlot(sce2, reduction = \"umap\", pt.size=0.5, label = F,repel = TRUE)\np22 &lt;- DimPlot(sce2, reduction = \"umap\",group.by = \"sample\", pt.size=0.5, label = F,repel = TRUE)\np33 &lt;- DimPlot(sce2, reduction = \"umap\",group.by = \"group\", pt.size=0.5, label = F,repel = TRUE)\np11 + p22 +p33"
  },
  {
    "objectID": "blog/2023/11/27/index.html#visualize-marker-genes",
    "href": "blog/2023/11/27/index.html#visualize-marker-genes",
    "title": "Practise Seurat for single cell data analysis",
    "section": "Visualize marker genes",
    "text": "Visualize marker genes\n\nMarker  &lt;-  list(\n  Epi = c(\"EPCAM\"),\n  Endo = c(\"PECAM1\",\"PLVAP\"),\n  Fibroblast = c(\"COL3A1\",\"COL1A1\",\"COL1A2\"),\n  IM = c(\"PTPRC\"),\n  B = c(\"CD79A\",\"CD79B\",\"CD19\"),\n  T = c(\"CD3D\",\"CD3E\",\"CD8A\",\"CD4\"),\n  Myeloid = c(\"C1QA\",\"C1QB\",\"CD163\",\"CD1C\")\n)\n\nMarker2 = c(\n    \"EPCAM\",\n    \"PECAM1\",\"PLVAP\",\n    \"COL3A1\",\"COL1A1\",\"COL1A2\",\n    'PTPRC',\n    \"CD79A\",\"CD79B\",\"CD19\",\n    \"CD3D\",\"CD3E\",\"CD8A\",\"CD4\",\n    \"C1QA\",\"C1QB\",\"CD163\",\"CD1C\"\n)\n\n\nDotPlot(sce2, features = Marker2, group.by = \"RNA_snn_res.0.5\")\n\n\n\n\n\n\n\n\nVlnPlot(sce2, features = Marker2, pt.size = 0, ncol = 5)\n\n\n\n\n\n\n\n\nFeaturePlot(\n    sce2,\n    features = c(\n        \"EPCAM\", \"PECAM1\", \"COL3A1\", 'PTPRC',\n        \"CD79A\", \"CD79B\", \"CD3D\", \"CD3E\", \"C1QA\", \"C1QB\"\n    )\n)"
  },
  {
    "objectID": "blog/2023/11/27/index.html#annotate-clusters",
    "href": "blog/2023/11/27/index.html#annotate-clusters",
    "title": "Practise Seurat for single cell data analysis",
    "section": "Annotate clusters",
    "text": "Annotate clusters\nUsing Vector\n\nnew.cluster.ids &lt;- c(\n  'Epi','Epi','Myeloid','Fibroblast','Epi','Epi','Fibroblast','Epi','T','Epi','Fibroblast','Epi','Endo','un','Epi','Epi','Fibroblast','un','Fibroblast'\n)\nnames(new.cluster.ids) &lt;- levels(sce2)\n\nsce2 &lt;- RenameIdents(sce2, new.cluster.ids)\n\n# Add to metadata, for \nsce2@meta.data$new.cluster.ids &lt;- Idents(sce2)\n\nDimPlot(sce2, reduction = \"umap\", label = TRUE, pt.size = 0.5) +      NoLegend()\n\n\n\n\n\n\n\nDirectly assign\n\nIdents(sce2) &lt;- \"seurat_clusters\"\nsce2 &lt;- RenameIdents(sce2,\n    \"0\" = \"Epi\",\n    \"1\" = \"Epi\",\n    \"2\" = \"Myeloid\",\n    \"3\" = \"Fibroblast\",\n    \"4\" = \"Epi\",\n    \"5\" = \"Epi\",\n    \"6\" = \"Fibroblast\",\n    \"7\" = \"Epi\",\n    \"8\" = \"T\",\n    \"9\" = \"Epi\",\n    \"10\" = \"Fibroblast\",\n    \"11\" = \"Epi\",\n    \"12\" = \"Endo\",\n    \"13\" = \"un\",\n    \"14\" = \"Epi\",\n    \"15\" = \"Epi\",\n    \"16\" = \"Fibroblast\",\n    \"17\" = \"un\",\n    \"18\" = \"Fibroblast\"\n)\nsce2@meta.data$celltype &lt;- Idents(sce2)\nDimPlot(sce2, reduction = \"umap\",label = TRUE, pt.size = 0.5) + \n  NoLegend()\n\n\n\n\n\n\n\nAdd annotation to meta data\n\nsce2$Anno &lt;- \"NA\"\ncelltype &lt;- c(\n    'Epi', 'Epi', 'Myeloid', 'Fibroblast', 'Epi', 'Epi', 'Fibroblast', 'Epi', 'T', 'Epi', 'Fibroblast', 'Epi', 'Endo', 'un', 'Epi', 'Epi', 'Fibroblast', 'un', 'Fibroblast'\n)\n\n# Note:cluster start from 0\n# For loop to add\nsub_length &lt;- length(unique(sce2$seurat_clusters)) - 1\nfor (i in 0:sub_length) {\n    sce2$Anno[sce2$seurat_clusters == i] = celltype[i + 1]\n}\n\n# UMAP\nDimPlot(\n    sce2, reduction = \"umap\", group.by = 'Anno', label = TRUE, pt.size = 0.5) +\n    NoLegend()\n\n\n\n\n\n\n\n\nDimPlot(\n  sce2, reduction = \"umap\",label = TRUE, pt.size = 0.5\n) + \n  NoLegend()\n\n\n\n\n\n\n\nhead(sce2@meta.data)\n##                         orig.ident nCount_RNA nFeature_RNA percent.mt\n## K16733_AAACATACTCGTTT-1     K16733       2464          965 12.6623377\n## K16733_AAAGCAGAACGTTG-1     K16733       7145         1919  2.4492652\n## K16733_AAAGCAGACTGAGT-1     K16733       1655          621  2.1752266\n## K16733_AAAGGCCTGCTCCT-1     K16733      14272         2771  1.5414798\n## K16733_AAATACTGTGGATC-1     K16733      13832         2541  0.3181029\n## K16733_AAATTCGAGACGAG-1     K16733       4207         1183  0.1188495\n##                         percent.rp percent.HB RNA_snn_res.0.5 seurat_clusters\n## K16733_AAACATACTCGTTT-1   13.35227          0              11              11\n## K16733_AAAGCAGAACGTTG-1   36.72498          0               5               5\n## K16733_AAAGCAGACTGAGT-1   35.52870          0               2               2\n## K16733_AAAGGCCTGCTCCT-1   38.81026          0               2               2\n## K16733_AAATACTGTGGATC-1   40.73164          0               2               2\n## K16733_AAATTCGAGACGAG-1   42.33420          0               6               6\n##                         sample group new.cluster.ids   celltype       Anno\n## K16733_AAACATACTCGTTT-1    P01    PT             Epi        Epi        Epi\n## K16733_AAAGCAGAACGTTG-1    P01    PT             Epi        Epi        Epi\n## K16733_AAAGCAGACTGAGT-1    P01    PT         Myeloid    Myeloid    Myeloid\n## K16733_AAAGGCCTGCTCCT-1    P01    PT         Myeloid    Myeloid    Myeloid\n## K16733_AAATACTGTGGATC-1    P01    PT         Myeloid    Myeloid    Myeloid\n## K16733_AAATTCGAGACGAG-1    P01    PT      Fibroblast Fibroblast Fibroblast\n\n# save(sce2, here(\"learn\", \"2023_scRNA\", \"sce.anno.RData\"))"
  },
  {
    "objectID": "blog/2023/12/01/index.html",
    "href": "blog/2023/12/01/index.html",
    "title": "Use colorblind-friendly palette for visualization",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggsci)\nlibrary(Seurat)\nlibrary(RColorBrewer)\nlibrary(viridis)\nlibrary(paletteer)\nlibrary(cols4all)\nlibrary(RImagePalette)\nlibrary(scales)"
  },
  {
    "objectID": "blog/2023/12/01/index.html#color-packages",
    "href": "blog/2023/12/01/index.html#color-packages",
    "title": "Use colorblind-friendly palette for visualization",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggsci)\nlibrary(Seurat)\nlibrary(RColorBrewer)\nlibrary(viridis)\nlibrary(paletteer)\nlibrary(cols4all)\nlibrary(RImagePalette)\nlibrary(scales)"
  },
  {
    "objectID": "blog/2023/12/01/index.html#basic-colors",
    "href": "blog/2023/12/01/index.html#basic-colors",
    "title": "Use colorblind-friendly palette for visualization",
    "section": "Basic colors",
    "text": "Basic colors\n\n# gray colors\ncbp &lt;- c(\"gray\", \"lightgray\", \"darkgray\", \"black\")\nbarplot(1:4, col = cbp)\n\n\n\n\n\n\n# 4 colors\ncbp &lt;- c(\n  \"#b8b8b8\", \"#02ff00\", \"#f9a506\", \"#ff3c31\"\n)\nbarplot(1:4, col = cbp)\n\n\n\n\n\n\n# 6 colors\ncbp &lt;- c(\n  \"#4C72B0\", \"#55A868\", \"#C44E52\", \"#8172B2\", \"#CCB974\", \"#64B5CD\"\n)\nbarplot(1:6, col = cbp)\n\n\n\n\n\n\n\n\n# 8 colors\ncbp &lt;- c(\n  \"#999999\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \n  \"#D55E00\", \"#CC79A7\"\n)\nbarplot(1:8, col = cbp)\n\n\n\n\n\n\n# 9 colors\ncbp &lt;- c(\n    \"#000000\", \"#999999\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \n    \"#0072B2\", \"#D55E00\", \"#CC79A7\"\n)\nbarplot(1:9, col = cbp)"
  },
  {
    "objectID": "blog/2023/12/01/index.html#color",
    "href": "blog/2023/12/01/index.html#color",
    "title": "Use colorblind-friendly palette for visualization",
    "section": "Color()",
    "text": "Color()\n\nload(here(\"projects\", \"2023_scRNA_Seurat\", \"pbmc_tutorial.RData\"))\n# 657 colors\nlength(colors())\n## [1] 657\nshow_col(colors()[1:50])\n\n\n\n\n\n\ncbp &lt;-c(\n  \"#80d7e1\",\"#e4cbf2\",\"#ffb7ba\",\"#bf5046\",\"#b781d2\",\"#ece7a3\",          \"#f5cbe1\",\"#e6e5e3\",\"#d2b5ab\",\"#d9e3f5\",\"#f29432\",\"#9c9895\"\n)\nshow_col(cbp)\n\n\n\n\n\n\n## Single cell plot\np1 &lt;- DimPlot(pbmc, reduction = \"umap\",label = T) + NoLegend()\np2 &lt;- DimPlot(pbmc, reduction = \"umap\",cols = cbp,label = T)+ NoLegend()\np1 + p2"
  },
  {
    "objectID": "blog/2023/12/01/index.html#rcolorbrewer",
    "href": "blog/2023/12/01/index.html#rcolorbrewer",
    "title": "Use colorblind-friendly palette for visualization",
    "section": "RColorBrewer",
    "text": "RColorBrewer\n\nlibrary(RColorBrewer)\ndisplay.brewer.all()\n\n\n\n\n\n\ncol &lt;- brewer.pal(9, \"Set1\")\nb1 &lt;- brewer.pal(9, \"Set1\")\nb2 &lt;- brewer.pal(8, \"Set2\")\nmycolor &lt;- c(b1,b2)"
  },
  {
    "objectID": "blog/2023/12/01/index.html#ggsci",
    "href": "blog/2023/12/01/index.html#ggsci",
    "title": "Use colorblind-friendly palette for visualization",
    "section": "ggsci",
    "text": "ggsci\n\nlibrary(ggsci)\n# vignette(\"ggsci\")\nDimPlot(pbmc, reduction = \"umap\", label = TRUE) + \n  scale_color_nejm() +\n  NoLegend()\n\n\n\n\n\n\nmycolor &lt;- pal_nejm(\"default\", alpha = 0.5)(8)"
  },
  {
    "objectID": "blog/2023/12/01/index.html#paletteer",
    "href": "blog/2023/12/01/index.html#paletteer",
    "title": "Use colorblind-friendly palette for visualization",
    "section": "paletteer",
    "text": "paletteer\n\nlibrary(paletteer)  \npaletteer_c(\"scico::berlin\", n = 10)\n## &lt;colors&gt;\n## #9EB0FFFF #5AA3DAFF #2D7597FF #194155FF #11181DFF #270C01FF #501802FF #8A3F2AFF #C37469FF #FFACACFF\npaletteer_d(\"RColorBrewer::Paired\",n=12)\n## &lt;colors&gt;\n## #A6CEE3FF #1F78B4FF #B2DF8AFF #33A02CFF #FB9A99FF #E31A1CFF #FDBF6FFF #FF7F00FF #CAB2D6FF #6A3D9AFF #FFFF99FF #B15928FF\npaletteer_dynamic(\"cartography::green.pal\", 20)\n## &lt;colors&gt;\n## #E5F0DAFF #D9E8CEFF #CDE1C2FF #C1D9B6FF #B5D2AAFF #A9CB9FFF #9DC393FF #91BC87FF #85B47BFF #75AA6BFF #65A15CFF #55974CFF #458D3DFF #35832DFF #287721FF #22651DFF #1C5319FF #164116FF #102F12FF #0A1E0FFF"
  },
  {
    "objectID": "blog/2023/12/01/index.html#cols4all",
    "href": "blog/2023/12/01/index.html#cols4all",
    "title": "Use colorblind-friendly palette for visualization",
    "section": "cols4all",
    "text": "cols4all\n\n# remotes::install_github(\"mtennekes/cols4all\")\nlibrary(cols4all)\n# c4a_gui()\nmycolor &lt;-c4a(\"light24\", 9)\n\n\n# Color from：Nat Med. 2019 Aug;25(8):1251-1259. \ncbp &lt;-c(\n    \"#80d7e1\",\"#e4cbf2\",\"#ffb7ba\",\"#bf5046\",\"#b781d2\",\"#ece7a3\",\n    \"#f5cbe1\",\"#e6e5e3\",\"#d2b5ab\",\"#d9e3f5\",\"#f29432\",\"#9c9895\"\n)\nshow_col(cbp, labels = TRUE)\n\n\n\n\n\n\nDimPlot(pbmc, reduction = \"umap\", group.by='seurat_clusters', label = T) +\n  scale_color_manual(values = cbp)+\n  NoLegend()\n\n\n\n\n\n\n\n# Color from：Immunity. 2020 May 19;52(5):808-824.e7.\ncbp &lt;- c(\n   \"#e41e25\",\"#307eb9\",\"#4cb049\",\"#974e9e\",\"#f57f21\",\"#f4ed35\",\n  \"#a65527\",\"#9bc7e0\",\"#b11f2b\",\"#f6b293\"\n)\nshow_col(cbp, labels = TRUE)\n\n\n\n\n\n\nDimPlot(pbmc, reduction = \"umap\", group.by='seurat_clusters', label=T) + \n  scale_color_manual(values = cbp)+\n  NoLegend()\n\n\n\n\n\n\n\n# Color from：Cell. 2019 Oct 31;179(4):829-845.e20.\ncbp &lt;- c(\n  \"#b38a8f\",\"#bba6a6\",\"#d5b3a5\",\"#e69db8\",\"#c5ae8d\",\"#87b2d4\",\n  \"#babb72\",\"#4975a5\",\"#499994\",\"#8e8786\",\"#93a95d\",\"#f19538\",\n  \"#fcba75\",\"#8ec872\",\"#ad9f35\",\"#8ec872\",\"#d07794\",\"#ff9796\",\n  \"#b178a3\",\"#e56464\",\"#6cb25e\",\"#ca9abe\",\"#d6b54c\"\n)\nshow_col(cbp, labels = TRUE)\n\n\n\n\n\n\nDimPlot(pbmc, reduction = \"umap\", group.by='seurat_clusters', label = T) + \n  scale_color_manual(values = cbp) +\n  NoLegend()"
  },
  {
    "objectID": "blog/2023/12/01/index.html#pick-color-from-images",
    "href": "blog/2023/12/01/index.html#pick-color-from-images",
    "title": "Use colorblind-friendly palette for visualization",
    "section": "Pick color from images",
    "text": "Pick color from images\n\n# devtools::install_github(\"joelcarlson/RImagePalette\")\nlibrary(RImagePalette)\nlifeAquatic &lt;- jpeg::readJPEG(\"color.jpg\")\ndisplay_image(lifeAquatic)\nmycolor &lt;- image_palette(lifeAquatic, n=16) \nshow_col(mycolor)"
  },
  {
    "objectID": "blog/2023/12/03/index.html",
    "href": "blog/2023/12/03/index.html",
    "title": "Save ggplot2 plots with custom fonts using Cairo graphics across OS",
    "section": "",
    "text": "This content is credited from here.\nR and ggplot can create fantastic graphs, but the default Arial/Helvetica font is too boring and standard. You can change the font used in a plot fairly easily three different ways:\n# Save the plot as a PDF with ggsave and Cairo\n# R will want to autocomplete cairo_pdf to cairo_pdf() (note the parentheses)\n# This will not work with the parentheses; ensure there aren't any\nggsave(p, filename = \"example.pdf\", device = cairo_pdf,\n       width = 4, height = 3, units = \"in\")\n\n# You can also save the plot as a high resolution PNG using \n# AGG or Cairo\n# With {ragg}\nggsave(p, filename = \"whatever.png\",\n       device = ragg::agg_png, res = 300,\n       width = 4, height = 3, units = \"in\")\n\n# With Cairo\nggsave(p, filename = \"whatever.png\",\n       device = png, type = \"cairo\", dpi = 300,\n       width = 4, height = 3, units = \"in\")"
  },
  {
    "objectID": "blog/2023/12/03/index.html#reference",
    "href": "blog/2023/12/03/index.html#reference",
    "title": "Save ggplot2 plots with custom fonts using Cairo graphics across OS",
    "section": "Reference",
    "text": "Reference\n\nSaving R Graphics across OSs\nWorking with R, Cairo graphics, custom fonts, and ggplot"
  },
  {
    "objectID": "blog/2024/03/01/index.html",
    "href": "blog/2024/03/01/index.html",
    "title": "Seurat V5 | 10X course example",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\nlibrary(Seurat)\nlibrary(SCINA)\ntheme_set(theme_bw(base_size = 14))\n\n\ndir &lt;- here(\"projects/babraham_training_bioinformatics/10X_scRNAseq_Course\")\ndata &lt;- Read10X_h5(here(dir, \"data/filtered_feature_bc_matrix.h5\"))\ndata &lt;- CreateSeuratObject(\n    counts = data,\n    project = \"course\",\n    min.cells = 3,\n    min.features = 200\n)\ndata\n\nhead(rownames(data))"
  },
  {
    "objectID": "blog/2024/03/01/index.html#load-packages-and-data",
    "href": "blog/2024/03/01/index.html#load-packages-and-data",
    "title": "Seurat V5 | 10X course example",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\nlibrary(Seurat)\nlibrary(SCINA)\ntheme_set(theme_bw(base_size = 14))\n\n\ndir &lt;- here(\"projects/babraham_training_bioinformatics/10X_scRNAseq_Course\")\ndata &lt;- Read10X_h5(here(dir, \"data/filtered_feature_bc_matrix.h5\"))\ndata &lt;- CreateSeuratObject(\n    counts = data,\n    project = \"course\",\n    min.cells = 3,\n    min.features = 200\n)\ndata\n\nhead(rownames(data))"
  },
  {
    "objectID": "blog/2024/03/01/index.html#explore-qc-metrics",
    "href": "blog/2024/03/01/index.html#explore-qc-metrics",
    "title": "Seurat V5 | 10X course example",
    "section": "Explore QC metrics",
    "text": "Explore QC metrics\n\n### Amount of MT genes\ngrep(\"^MT-\", rownames(data), value = TRUE)\ndata$percent_MT &lt;- PercentageFeatureSet(data, pattern = \"^MT-\")\nhead(data$percent_MT)\n\n### Amount of Ribosomal genes\ngrep(\"^RP[LS]\", rownames(data), value = TRUE)\ndata$percent_Ribosomal &lt;- PercentageFeatureSet(data, pattern = \"^RP[LS]\")\nhead(data$percent_Ribosomal)\n\n### Percentage of Largest Gene\ndata_nomalat &lt;- data[rownames(data) != \"MALAT1\", ]\n\ndata_nomalat$largest_count &lt;- apply(\n    data_nomalat@assays$RNA@layers$counts,\n    2,\n    max\n)\n\ndata_nomalat$largest_index &lt;- apply(\n    data_nomalat@assays$RNA@layers$counts,\n    2,\n    which.max\n)\n\ndata_nomalat$largest_gene &lt;- rownames(data_nomalat)[data_nomalat$largest_index]\n\ndata_nomalat$percent.Largest.Gene &lt;- 100 * data_nomalat$largest_count /\n    data_nomalat$nCount_RNA\n\ndata_nomalat[[]][1:10, ]\n\ndata$largest_gene &lt;- data_nomalat$largest_gene\ndata$percent.Largest.Gene &lt;- data_nomalat$percent.Largest.Gene\n\ndata[[]][1:10, ]\nrm(data_nomalat)\n\n\n### For some metrics it’s better to view on a log scale.\nVlnPlot(\n    data,\n    layer = \"counts\",\n    features = c(\n        \"nCount_RNA\", \"percent_MT\", \"percent_Ribosomal\", \"percent.Largest.Gene\"\n    ),\n    ncol = 2,\n    log = TRUE\n)\n\nFeatureScatter(\n    data,\n    feature1 = \"nCount_RNA\", \n    feature2 = \"percent.Largest.Gene\"\n)\n\n\n## ggplot\nqc_metrics &lt;- dplyr::as_tibble(\n    data[[]],\n    rownames = \"Cell.Barcode\"\n)\n\nhead(qc_metrics)\n\nqc_metrics |&gt;\n    arrange(percent_MT) |&gt;\n    ggplot(aes(nCount_RNA, nFeature_RNA, colour = percent_MT)) +\n    geom_point() +\n    scale_color_gradientn(colors = c(\"black\", \"blue\", \"green2\", \"red\", \"yellow\")) +\n    ggtitle(\"Example of plotting QC metrics\") +\n    geom_hline(yintercept = 750) +\n    geom_hline(yintercept = 2000)\n\n## Log scale\nqc_metrics |&gt;\n    arrange(percent_MT) |&gt;\n    ggplot(aes(nCount_RNA, nFeature_RNA, colour = percent_MT)) +\n    geom_point(size = 0.7) +\n    scale_color_gradientn(colors = c(\"black\", \"blue\", \"green2\", \"red\", \"yellow\")) +\n    ggtitle(\"Example of plotting QC metrics\") +\n    geom_hline(yintercept = 750) +\n    geom_hline(yintercept = 2000) +\n    scale_x_log10() +\n    scale_y_log10()\n\n\n### Complexity \nqc_metrics &lt;- qc_metrics |&gt;\n  mutate(complexity=log10(nFeature_RNA) / log10(nCount_RNA))\n\ncomplexity.lm &lt;- lm(log10(qc_metrics$nFeature_RNA)~log10(qc_metrics$nCount_RNA)) \n\ncomplexity.lm\n\nqc_metrics &lt;- qc_metrics |&gt;\n  mutate(\n    complexity_diff = log10(nFeature_RNA) - ((log10(qc_metrics$nCount_RNA)*complexity.lm$coefficients[2])+complexity.lm$coefficients[1])\n  )\n\nqc_metrics |&gt;\n  ggplot(aes(x=complexity_diff)) +\n  geom_density(fill=\"yellow\") \n\ncomplexity_scale &lt;- min(c(max(qc_metrics$complexity_diff),0-min(qc_metrics$complexity_diff)))\n\nqc_metrics |&gt;\n  mutate(complexity_diff=replace(complexity_diff,complexity_diff&lt; -0.1,-0.1)) |&gt;\n  ggplot(aes(x=log10(nCount_RNA), y=log10(nFeature_RNA), colour=complexity_diff)) +\n  geom_point(size=0.5) +\n  geom_abline(slope=complexity.lm$coefficients[2], intercept = complexity.lm$coefficients[1]) +\n  scale_colour_gradient2(low=\"blue2\",mid=\"grey\",high=\"red2\")\n\nqc_metrics |&gt;\n  ggplot(aes(x=complexity_diff, y=percent.Largest.Gene)) +\n  geom_point()\n\n\n### Largest gene\nlargest_gene_list &lt;- qc_metrics |&gt;\n    group_by(largest_gene) |&gt;\n    count() |&gt;\n    arrange(desc(n))\n\nlargest_genes_to_plot &lt;- largest_gene_list |&gt;\n    filter(n &gt; 140) |&gt;\n    pull(largest_gene)\n\nqc_metrics |&gt;\n    filter(largest_gene %in% largest_genes_to_plot) |&gt;\n    mutate(\n      largest_gene = factor(largest_gene, levels = largest_genes_to_plot)\n    ) |&gt;\n    arrange(largest_gene) |&gt;\n    ggplot(\n      aes(x = log10(nCount_RNA), y = log10(nFeature_RNA), colour = largest_gene)\n    ) +\n    geom_point(size = 1) +\n    scale_colour_manual(\n      values = c(\"grey\", RColorBrewer::brewer.pal(9, \"Set1\"))\n    )\n\nqc_metrics |&gt;\n    filter(largest_gene %in% largest_genes_to_plot) |&gt;\n    mutate(\n      largest_gene = factor(largest_gene, levels = largest_genes_to_plot)\n    ) |&gt;\n    arrange(largest_gene) |&gt;\n    ggplot(\n      aes(x = complexity_diff, y = percent.Largest.Gene, colour = largest_gene)\n    ) +\n    geom_point() +\n    scale_colour_manual(values = c(\"grey\", RColorBrewer::brewer.pal(9, \"Set1\")))\n\nqc_metrics |&gt;\n    arrange(percent_MT) |&gt;\n    ggplot(\n      aes(x = complexity_diff, y = percent.Largest.Gene, colour = percent_MT)\n    ) +\n    geom_point() +\n    scale_colour_gradient(low = \"grey\", high = \"red2\")\n\nqc_metrics |&gt;\n    arrange(percent_Ribosomal) |&gt;\n    ggplot(\n      aes(x = complexity_diff, y = percent.Largest.Gene, colour = percent_Ribosomal)\n    ) +\n    geom_point() +\n    scale_colour_gradient(low = \"grey\", high = \"red2\")"
  },
  {
    "objectID": "blog/2024/03/01/index.html#setting-qc-cutoff-and-filtering",
    "href": "blog/2024/03/01/index.html#setting-qc-cutoff-and-filtering",
    "title": "Seurat V5 | 10X course example",
    "section": "Setting QC Cutoff and Filtering",
    "text": "Setting QC Cutoff and Filtering\n\nqc_metrics |&gt;\n    ggplot(aes(percent_MT)) +\n    geom_histogram(binwidth = 0.5, fill = \"yellow\", colour = \"black\") +\n    ggtitle(\"Distribution of Percentage Mitochondrion\") +\n    geom_vline(xintercept = 10)\n\nqc_metrics |&gt;\n    ggplot(aes(percent.Largest.Gene)) +\n    geom_histogram(binwidth = 0.7, fill = \"yellow\", colour = \"black\") +\n    ggtitle(\"Distribution of Percentage Largest Gene\") +\n    geom_vline(xintercept = 10) ### Filtering\n\ndata &lt;- subset(\n    data,\n    nFeature_RNA &gt; 750 &\n        nFeature_RNA &lt; 2000 &\n        percent_MT &lt; 10 &\n        percent.Largest.Gene &lt; 10\n)\n\ndata"
  },
  {
    "objectID": "blog/2024/03/01/index.html#normalisation-selection-and-scaling",
    "href": "blog/2024/03/01/index.html#normalisation-selection-and-scaling",
    "title": "Seurat V5 | 10X course example",
    "section": "Normalisation, Selection and Scaling",
    "text": "Normalisation, Selection and Scaling\n\n### Normalization\ndata &lt;- NormalizeData(data, normalization.method = \"LogNormalize\")\n\ngene_expression &lt;- apply(data@assays$RNA@layers$data, 1, mean)\ngene_expression &lt;- names(gene_expression) &lt;- rownames(data)\ngene_expression &lt;- sort(gene_expression, decreasing = TRUE)\nhead(gene_expression, n = 10)\n\nggplot(mapping = aes(data[\"GAPDH\", ]@assays$RNA@layers$data)) +\n    geom_histogram(binwidth = 0.05, fill = \"yellow\", colour = \"black\") +\n    ggtitle(\"GAPDH expression\")\n\n\nas_tibble(\n    data@assays$RNA@layers$data[, 1:100]\n) |&gt;\n    pivot_longer(\n        cols = everything(),\n        names_to = \"cell\",\n        values_to = \"expression\"\n    ) |&gt;\n    ggplot(aes(x = cell, y = expression)) +\n    stat_summary(geom = \"crossbar\", fun.data = mean_sdl)\n\n\n### Cell Cycle Scoring\ncc.genes.updated.2019\n\ndata &lt;- CellCycleScoring(\n    data,\n    s.features = cc.genes.updated.2019$s.genes,\n    g2m.features = cc.genes.updated.2019$g2m.genes,\n    set.ident = TRUE\n)\n\nas_tibble(data[[]])\n\nas_tibble(data[[]]) |&gt;\n    ggplot(aes(Phase)) + geom_bar()\n\nas_tibble(data[[]]) |&gt;\n    ggplot(aes(x = S.Score, y = G2M.Score, color = Phase)) +\n    geom_point() +\n    coord_cartesian(xlim = c(-0.15, 0.15), ylim = c(-0.15, 0.15))\n\n\n### Gene selection\ndata &lt;- FindVariableFeatures(\n    data,\n    selection.method = \"vst\",\n    nfeatures = 500\n)\n\nvariance_data &lt;- as_tibble(\n    HVFInfo(data), rownames = \"Gene\"\n)\n\nvariance_data &lt;- variance_data |&gt;\n    mutate(\n        hypervariable = Gene %in% VariableFeatures(data)\n    )\n\nhead(variance_data, n = 10)\n\nvariance_data |&gt;\n    ggplot(aes(log(mean), log(variance), color = hypervariable)) +\n    geom_point() +\n    scale_color_manual(values = c(\"black\", \"red\"))\n\n\n### Scaling\ndata &lt;- ScaleData(data, features = rownames(data))"
  },
  {
    "objectID": "blog/2024/03/01/index.html#dimensionality-reduction",
    "href": "blog/2024/03/01/index.html#dimensionality-reduction",
    "title": "Seurat V5 | 10X course example",
    "section": "Dimensionality reduction",
    "text": "Dimensionality reduction\n\nPCA\n\n### Calculate all PCs\n### list of genes which are most highly and lowly weighted in the different PCs\ndata &lt;- RunPCA(data, features = VariableFeatures(data))\n\n### See if the cell cycle is having a big effect on the clusters we’re picking out\nDimPlot(data, reduction = \"pca\")\n\nDimPlot(\n    data, reduction = \"pca\",\n    group.by = \"largest_gene\",\n    label = TRUE,\n    label.size = 3\n) + NoLegend()\n\n### This nicely shows us the power, but also the limitations of PCA in that we \n### can see that not all of the useful information is captured in the first two \n### principal components.\nDimPlot(data, reduction = \"pca\", dims = c(3, 4))\n\n### How far down the set of PCs do we need to go to capture all of the \n### biologically relevant information.\nElbowPlot(data)\n\n### Plots of PCA weightings for the most highly and lowly weighted genes, \n### shown against the set of cells which are most highly influenced by the PC. \n### The idea is that as long as we’re seeing clear structure in one of these \n### plots then we’re still adding potentially useful information to the analysis.\nDimHeatmap(data, dims = 1:15, cells = 500)\n\n\n\ntSNE\n\n### Setting this to a low value will help resolve small clusters, \n### but at the expense of large clusters becoming more diffuse\nsaved_seed &lt;- 8482\nset.seed(saved_seed)\n\ndata &lt;- RunTSNE(data, dims = 1:15, seed.use = saved_seed, perplexity = 10)\nDimPlot(data, reduction = \"tsne\", pt.size = 1) +\n    ggtitle(\"tSNE with Perplexity 10\")\n\ndata &lt;- RunTSNE(data, dims = 1:15, seed.use = saved_seed, perplexity = 200)\nDimPlot(data, reduction = \"tsne\", pt.size = 1) +\n    ggtitle(\"tSNE with Perplexity 200\")\n\ndata &lt;- RunTSNE(data, dims = 1:15, seed.use = saved_seed)\nDimPlot(data, reduction = \"tsne\", pt.size = 1) +\n    ggtitle(\"tSNE with default Perplexity (30)\")"
  },
  {
    "objectID": "blog/2024/03/01/index.html#defining-cell-clusters",
    "href": "blog/2024/03/01/index.html#defining-cell-clusters",
    "title": "Seurat V5 | 10X course example",
    "section": "Defining Cell Clusters",
    "text": "Defining Cell Clusters\n\n### Finds the ‘k’ nearest neighbours to each cell and makes this into a graph\ndata &lt;- FindNeighbors(data, dims = 1:15)\n\n### Get another sparse matrix of distances.\ndata@graphs$RNA_snn[1:10, 1:10]\n\n\n### Segment the graph, \n### Larger resolution give larger clusters, smaller values gives smaller clusters.\ndata &lt;- FindClusters(data, resolution = 0.5)\n\nhead(data$seurat_clusters, n = 5)\n\n\n### Some of the clusters don't resolve very well in PC1 vs PC2\nDimPlot(data, reduction = \"pca\", label = TRUE) +\n    ggtitle(\"PC1 vs PC2 with Clusters\")\n\n### Some of the clusters which are overlaid in PC1 start to separate in other PCs\n### These differences represent a small proportion of the overall variance\n### but can be important in resolving changes.\nDimPlot(data, reduction = \"pca\", dims = c(4, 9), label = TRUE) +\n    ggtitle(\"PC4 vs PC9 with Clusters\")\n\n### tSNE plot showing all of the information across the PCs used is preserved\n### and we see the overall similarity of the cells\nDimPlot(data, reduction = \"tsne\", pt.size = 1, label = TRUE, label.size = 7)\n\n\n### Check the clusters to see if they are influenced by any of the QC metrics\n### We can see that some of the clusters are skewed in one or more of the\n### metrics we’ve calculated so we will want to take note of this.\n### Some of these skews could be biological in nature,\n### but they could be noise coming from the data.\nVlnPlot(data, features = \"nCount_RNA\")\n\n### Cluster 8, 9, 11, and 12 could be GEMs where two or more cells were captured\n### Since they all usually high coverage and diversity\n### Theya are also small and tightly clustered away from the main groups of points\nVlnPlot(data, features = \"nFeature_RNA\")\n\nVlnPlot(data, features = \"percent_MT\")\n\nVlnPlot(data, features = \"MALAT1\")\n\nVlnPlot(data,features=\"percent.Largest.Gene\")\n\n### Which largest gene\ndata[[]] |&gt;\n    group_by(seurat_clusters, largest_gene) |&gt;\n    count() |&gt;\n    arrange(desc(n)) |&gt;\n    group_by(seurat_clusters) |&gt;\n    slice(1:2) |&gt;\n    ungroup() |&gt;\n    arrange(seurat_clusters, desc(n))\n\n### Cell cycle\ndata@meta.data |&gt;\n    group_by(seurat_clusters, Phase) |&gt;\n    count() |&gt;\n    group_by(seurat_clusters) |&gt;\n    mutate(percent = 100 * n / sum(n)) |&gt;\n    ungroup() |&gt;\n    ggplot(aes(x = seurat_clusters, y = percent, fill = Phase)) +\n    geom_col() +\n    ggtitle(\"Percentage of cell cycle phases per cluster\")\n\n\n### That’s already quite nice for explaining some of the functionality of the \n### clusters, but there’s more in there than just the behaviour of the most \n### expressed gene\ndata@reductions$tsne@cell.embeddings |&gt;\n    as_tibble() |&gt;\n    add_column(\n      seurat_clusters = data$seurat_clusters, largest_gene = data$largest_gene\n    ) |&gt;\n    filter(largest_gene %in% largest_genes_to_plot) |&gt;\n    ggplot(aes(x = tSNE_1, y = tSNE_2, colour = seurat_clusters)) +\n    geom_point() +\n    facet_wrap(vars(largest_gene))"
  },
  {
    "objectID": "blog/2024/03/01/index.html#find-markers",
    "href": "blog/2024/03/01/index.html#find-markers",
    "title": "Seurat V5 | 10X course example",
    "section": "Find Markers",
    "text": "Find Markers\n\n### Evaluate the cluster by identifying genes whose expression definies each\n### cluster which has been identified\n\n### Find genes appears to be upregulated in a specific cluster compared to all\n### cells not in that cluster\nFindMarkers(data, ident.1 = 0, min.pct = 0.25)[1:5, ]\n\n### Show the expression levels of these genes in the cells in each cluster\n### VCAN gene is more highly expressed in cluster 0 than any of the other \n### clusters, but we can also see that it is also reasonably highly expressed \n### in clusters 9 and 12. These were both clusters we suspected of being \n### multiple cells though\nVlnPlot(data, features = \"VCAN\")\n\n\n### FindMarkers function on all of the clusters\ncluster_markers &lt;- lapply(\n    levels(data[[\"seurat_clusters\"]][[1]]),\n    function(x) FindMarkers(data, ident.1 = x, min.pct = 0.25)\n)\n\n### Adds the cluster number to the results of FindMarkers\nsapply(\n    0:(length(cluster_markers) - 1),\n    function(x) {\n        cluster_markers[[x + 1]]$gene &lt;&lt;- rownames(cluster_markers[[x + 1]])\n        cluster_markers[[x + 1]]$cluster &lt;&lt;- x\n    }\n)\n\n### Generate tibble and sort by FDR to put the most significant ones first\ncluster_markers &lt;- as_tibble(do.call(rbind, cluster_markers)) |&gt;\n    arrange(p_val_adj)\n\ncluster_markers\n\n### Extract the most upregulated gene from each cluster\nbest_wilcox_gene_per_cluster &lt;- cluster_markers |&gt;\n    group_by(cluster) |&gt;\n    slice(1) |&gt;\n    pull(gene)\n\n### We can see that for some clusters (eg Cluster 8 - CDKN1C) We really do have\n### a gene which can uniquely predict, but for many others (eg cluster 7 IL7R)\n### we have a hit which also picks up other clusters (clusters 1, 3 and 4 in this case).\nVlnPlot(data, features = best_wilcox_gene_per_cluster)\n\n### Clean this up for any individual cluster by using the roc analysis.\nFindMarkers(\n    data, ident.1 = 7, ident.2 = 4, test.use = \"roc\", only.pos = TRUE\n)[1:5, ]\n\n### Slightly better job at separating cluster 5 from cluster 4, but it also\n### comes up all over the place in other clusters\nVlnPlot(data, features = \"LTB\")\n\n### This could actually be a better option to use as a marker for this cluster.\nVlnPlot(data, features = \"TPT1\")"
  },
  {
    "objectID": "blog/2024/03/01/index.html#automated-cell-type-annotation",
    "href": "blog/2024/03/01/index.html#automated-cell-type-annotation",
    "title": "Seurat V5 | 10X course example",
    "section": "Automated Cell Type Annotation",
    "text": "Automated Cell Type Annotation\n\nscina_data &lt;- as.data.frame(GetAssayData(data, layer = \"data\"))\n\nsignatures &lt;- get(\n    load(system.file(\"extdata\", \"example_signatures.RData\", package = \"SCINA\"))\n)\n\nsignatures\n\nscina_results &lt;- SCINA(\n    scina_data,\n    signatures,\n    max_iter = 100,\n    convergence_n = 10,\n    convergence_rate = 0.999,\n    sensitivity_cutoff = 0.9,\n    rm_overlap = TRUE,\n    allow_unknown = TRUE\n)\n\ndata$scina_labels &lt;- scina_results$cell_labels\n\n### plot out the tsne spread coloured by the automatic annotation\nDimPlot(\n    data, reduction = \"tsne\", pt.size = 1, label = TRUE,\n    group.by = \"scina_labels\", label.size = 5\n)\n\n### Relate this to the clusters which we automatically detected.\ntibble(\n    cluster = data$seurat_clusters,\n    cell_type = data$scina_labels\n) |&gt;\n    group_by(cluster, cell_type) |&gt;\n    count() |&gt;\n    group_by(cluster) |&gt;\n    mutate(\n        percent = (100 * n) / sum(n)\n    ) |&gt;\n    ungroup() |&gt;\n    mutate(\n        cluster = paste(\"Cluster\", cluster)\n    ) |&gt;\n    ggplot(aes(x = \"\", y = percent, fill = cell_type)) +\n    geom_col(width = 1) +\n    coord_polar(\"y\", start = 0) +\n    facet_wrap(vars(cluster)) +\n    theme(axis.text.x = element_blank()) +\n    xlab(NULL) +\n    ylab(NULL)\n\n\n### Colouring by genes\n### Some of these genes very specifically isolate to their own cluster, but for\n### others we see expression which is more widely spread over a number of clusters\nFeaturePlot(data, features = best_wilcox_gene_per_cluster, ncol = 3)\n\n\ndata@reductions$tsne@cell.embeddings[1:10, ]\n\n# data@reductions$tsne@cell.embeddings[, ] |&gt;\n#     as_tibble(rownames = \"barcode\") |&gt;\n#     mutate(barcode = paste0(barcode, \"-1\")) |&gt;\n#     write_csv(\"for_loupe_import.csv\")"
  },
  {
    "objectID": "blog/2024/03/01/index.html#reference",
    "href": "blog/2024/03/01/index.html#reference",
    "title": "Seurat V5 | 10X course example",
    "section": "Reference",
    "text": "Reference\n\nSeurat Example\nSingle-cell RNA-seq data analysis workshop"
  },
  {
    "objectID": "blog/2024/03/01/index.html#session-info",
    "href": "blog/2024/03/01/index.html#session-info",
    "title": "Seurat V5 | 10X course example",
    "section": "Session info",
    "text": "Session info\n\n\nCode\nsessionInfo()"
  },
  {
    "objectID": "blog/2024/03/15/index.html",
    "href": "blog/2024/03/15/index.html",
    "title": "Analysis of single cell RNA-seq data with {SingleCellExperiment}",
    "section": "",
    "text": "Note\n\n\n\nAll the contents are credited or adapted from Analysis of single cell RNA-seq data for leaning purpose."
  },
  {
    "objectID": "blog/2024/03/15/index.html#initial-general-setup",
    "href": "blog/2024/03/15/index.html#initial-general-setup",
    "title": "Analysis of single cell RNA-seq data with {SingleCellExperiment}",
    "section": "Initial general setup",
    "text": "Initial general setup\n\n### Install and load packatges \n# if (!require(\"BiocManager\", quietly = TRUE))\n#     install.packages(\"BiocManager\")\n# BiocManager::install(version = \"3.18\")\n# BiocManager::install(\n#     c(\n#         \"scater\", \"SingleCellExperiment\", \"AnnotationDbi\", \"org.Hs.eg.db\",\n#         \"EnsDb.Hsapiens.v86\"\n#     ),\n#     force = TRUE\n# )\nlibrary(here)\nlibrary(tidyverse)\nlibrary(scater)\nlibrary(SingleCellExperiment)\nlibrary(AnnotationDbi)\nlibrary(org.Hs.eg.db)\nlibrary(EnsDb.Hsapiens.v86)\nlibrary(scales)\n\n### Project dir\ndir &lt;- here(\"projects/2024_SCE_Course\")"
  },
  {
    "objectID": "blog/2024/03/15/index.html#qualtity-control",
    "href": "blog/2024/03/15/index.html#qualtity-control",
    "title": "Analysis of single cell RNA-seq data with {SingleCellExperiment}",
    "section": "Qualtity control",
    "text": "Qualtity control\n\n### Creating a SingleCellExperiment object \nmolecules &lt;- read.delim(here(dir, \"data/tung/molecules.txt\"), row.names = 1)\nannotation &lt;- read.delim(\n    here(dir, \"data/tung/annotation.txt\"), stringsAsFactors = TRUE\n)\n\nhead(molecules[, 1:3])\nhead(annotation)\n\numi &lt;- SingleCellExperiment(\n    assays = list(counts = as.matrix(molecules)), \n    colData = annotation\n)\numi\n\n\n## Remove ERCC spike-ins features\naltExp(umi,\"ERCC\") &lt;- umi[grep(\"^ERCC-\",rownames(umi)), ]\numi &lt;- umi[grep(\"^ERCC-\",rownames(umi), invert = TRUE), ]\numi\n\n## Map Ensembl IDs to gene symbols\ngene_names &lt;- mapIds(\n    org.Hs.eg.db,\n    keys = rownames(umi),\n    keytype = \"ENSEMBL\",\n    columns = \"SYMBOL\",\n    column = \"SYMBOL\"\n)\n\nhead(gene_names)\nclass(gene_names)\n\n## 903 returned NA\nrowData(umi)$SYMBOL &lt;- gene_names\ntable(is.na(gene_names))\n\n\n## Remove all genes for which no symbols were found\numi &lt;- umi[!is.na(rowData(umi)$SYMBOL), ]\n\n##  Returns no mitrochandrial proteins in the newly annotated symbols\ngrep(\"^MT-\", rowData(umi)$SYMBOL, value = TRUE)\n\n## Find rebosomal proteins\ngrep(\"^RP[LS]\", rowData(umi)$SYMBOL, value = TRUE)\n\n## Annotation problems: mitochondrial protein ATP8 can be found\ngrep(\"ATP8\", rowData(umi)$SYMBOL, value = TRUE)\n\ncolumns(org.Hs.eg.db)\n\n## Use a more detailed database\nensdb_genes &lt;- genes(EnsDb.Hsapiens.v86)\n\n## Find 13 protein-coding genes located in the mitochondrion\nMT_names &lt;- ensdb_genes[seqnames(ensdb_genes) == \"MT\"]$gene_id\n\n# MT_names &lt;- ensdb_genes[seqnames(ensdb_genes) == \"MT\"]$gene_name\nis_mito &lt;- rownames(umi) %in% MT_names\ntable(is_mito)\n\nBaseic QC\n\numi_cell &lt;- scater::perCellQCMetrics(umi, subsets = list(Mito = is_mito))\nhead(umi_cell)\n\numi_feature &lt;- scater::perFeatureQCMetrics(umi)\nhead(umi_feature)\n\n## Add the metrics\numi &lt;- addPerCellQC(umi, subsets = list(Mito = is_mito))\numi &lt;- addPerFeatureQC(umi)\n\n## Manual filtering\nhist(umi$total, breaks = 100)\nabline(v = 25000, col = \"red\")\n\nhist(umi_cell$detected, breaks = 100)\nabline(v = 7000, col = \"red\")\n\nLow number of detected genes, but high MT gene percentage, are hallmarks of a low quality cell\n\n## adaptive threshold can help us identify points that are more than\n## 3 median absolute deviations (MADs)\nqc.lib2 &lt;- isOutlier(umi_cell$sum, log = TRUE, type = \"lower\")\nattr(qc.lib2, \"thresholds\")\n\nqc.nexprs2 &lt;- isOutlier(umi_cell$detected, log = TRUE, type = \"lower\")\nattr(qc.nexprs2, \"thresholds\")\n\nqc.spike2 &lt;- isOutlier(umi_cell$altexps_ERCC_percent, type = \"higher\")\nattr(qc.spike2, \"thresholds\")\n\nqc.mito2 &lt;- isOutlier(umi_cell$subsets_Mito_percent, type = \"higher\")\nattr(qc.mito2, \"thresholds\")\n\ndiscard2 &lt;- qc.lib2 | qc.nexprs2 | qc.spike2 | qc.mito2\n\nDataFrame(\n    LibSize = sum(qc.lib2), NExprs = sum(qc.nexprs2),\n    SpikeProp = sum(qc.spike2), MitoProp = sum(qc.mito2), Total = sum(discard2)\n)\n\nreasons &lt;- quickPerCellQC(\n    umi_cell,\n    sub.fields = c(\"subsets_Mito_percent\", \"altexps_ERCC_percent\")\n)\ncolSums(as.matrix(reasons))\n\numi$discard &lt;- reasons$discard\n\n\n## Plotting various coldata (cell-level medadata) assays against each other\nplotColData(umi, x = \"sum\", y = \"subsets_Mito_percent\", colour_by = \"discard\")\nplotColData(umi, x = \"sum\", y = \"detected\", colour_by = \"discard\")\nplotColData(\n    umi, x = \"altexps_ERCC_percent\", \n    y = \"subsets_Mito_percent\", colour_by = \"discard\"\n)\n\n\n## splitting by batches to see if there are substantial batch-specific differences\nplotColData(\n    umi, x = \"sum\", y = \"detected\", colour_by = \"discard\", \n    other_fields = \"individual\"\n) +\n    facet_wrap(~individual) + \n    scale_x_continuous(labels = unit_format(unit = \"k\", scale = 1e-3))\n\n\nplotColData(\n    umi, x = \"sum\", y = \"detected\", colour_by = \"discard\", other_fields = \"replicate\"\n) +\n    facet_wrap(~replicate) +\n    scale_x_continuous(labels = unit_format(unit = \"k\", scale = 1e-3))\n\nHighly expressed genes\n\n## Most of the genes we see are mitochondrial or ribosomal proteins, which is pretty typical for most scRNA-seq datasets.\nplotHighestExprs(\n    umi, exprs_values = \"counts\",\n    feature_names_to_plot = \"SYMBOL\", colour_cells_by = \"detected\"\n)\n\nkeep the genes which were detected (expression value &gt; 1) in 2 or more cells. We’ll discard approximately 4,000 weakly expressed genes.\n\nkeep_feature &lt;- nexprs(umi, byrow = TRUE, detection_limit = 1) &gt;= 2\nrowData(umi)$discard &lt;- !keep_feature\ntable(rowData(umi)$discard)\n\n\nassay(umi, \"logcounts_raw\") &lt;- log2(counts(umi) + 1)\n# saveRDS(umi, file = here(dir, \"data/tung/umi.rds\"))"
  },
  {
    "objectID": "blog/2024/03/15/index.html#dimensionality-reduction",
    "href": "blog/2024/03/15/index.html#dimensionality-reduction",
    "title": "Analysis of single cell RNA-seq data with {SingleCellExperiment}",
    "section": "Dimensionality reduction",
    "text": "Dimensionality reduction\n\n## Remove unnecessary poorly expressed genes and low quality cells\numi.qc &lt;- umi[!rowData(umi)$discard, !colData(umi)$discard]\numi.qc\n\nWithout log-transformation or normalization, PCA plot fails to separate the datasets by replicate or individual. We mostly see the effects of sequencing depth - samples (cells) with lots of expression, and particularly highly expressed genes, dominate the PCs\nBefore QC\n\n## Before QC, Without log-transformation or normalization\numi &lt;- runPCA(umi, exprs_values = \"counts\")\ndim(reducedDim(umi, \"PCA\"))\np1 &lt;- plotPCA(\n    umi, \n    colour_by = \"batch\", \n    size_by = \"detected\", \n    shape_by = \"individual\"\n)\n\nWith log-transformation, we equalize the large difference between strongly and weakly expressed genes, and immediately see cells form groups by replicate, individual, and sequencing depth.\n\numi &lt;- runPCA(umi, exprs_values = \"logcounts_raw\")\ndim(reducedDim(umi, \"PCA\"))\np2 &lt;- plotPCA(\n    umi,\n    colour_by = \"batch\",\n    size_by = \"detected\",\n    shape_by = \"individual\"\n)   \n\npatchwork::wrap_plots(p1, p2, ncol = 1)\n\n\nset.seed(123456)\numi &lt;- runTSNE(umi, exprs_values = \"logcounts_raw\", perplexity = 130)\nplotTSNE(\n    umi,\n    colour_by = \"batch\",\n    size_by = \"detected\",\n    shape_by = \"individual\"\n)\n\nAfter QC\n\numi.qc &lt;- runPCA(umi.qc, exprs_values = \"logcounts_raw\")\ndim(reducedDim(umi.qc, \"PCA\"))\nplotPCA(\n    umi.qc,\n    colour_by = \"batch\",\n    size_by = \"detected\",\n    shape_by = \"individual\"\n)\n\nset.seed(123456)\numi.qc &lt;- runTSNE(umi.qc, exprs_values = \"logcounts_raw\", perplexity = 130)\nplotTSNE(\n    umi.qc, \n    colour_by = \"batch\",\n    size_by = \"detected\",\n    shape_by = \"individual\"\n)\n\nIdentifying confounding factors\n\n### Detected genes\nlogcounts(umi.qc) &lt;- assay(umi.qc, \"logcounts_raw\")\ngetExplanatoryPCs(umi.qc,variables = \"sum\")\n\n## PC1 can be almost completely (86%) explained by the total UMI counts (sequencing depth)\nplotExplanatoryPCs(umi.qc,variables = \"sum\") \nlogcounts(umi.qc) &lt;- NULL\n\n\nplotExplanatoryVariables(\n    umi.qc,\n    exprs_values = \"logcounts_raw\",\n    variables = c(\n        \"detected\", \"sum\", \"batch\",\n        \"individual\", \"altexps_ERCC_percent\", \"subsets_Mito_percent\"\n    )\n)"
  },
  {
    "objectID": "blog/2024/04/03/index.html",
    "href": "blog/2024/04/03/index.html",
    "title": "A comprehensive single-cell map of T cell exhaustion-associated immune environments in human breast cancer",
    "section": "",
    "text": "### Install and Load required packages\n# if (!any(rownames(installed.packages()) == \"DoubletFinder\")){\n#   remotes::install_github('chris-mcginnis-ucsf/DoubletFinder')\n# }\n\nlibrary(fs)\nlibrary(here)\nlibrary(patchwork)\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggpubr)\nlibrary(rstatix)\nlibrary(Seurat)\nlibrary(DoubletFinder)\nlibrary(magrittr)\nlibrary(clustree)\nlibrary(magrittr)\nlibrary(RColorBrewer)\nlibrary(corrplot)\nlibrary(pheatmap)\nlibrary(ComplexHeatmap)\nlibrary(scales)\nlibrary(viridis)\nlibrary(circlize)\nlibrary(ggrepel)\nlibrary(edgeR)\n\noptions(future.globals.maxSize = 8e9)\noutput_path &lt;- here(\"projects/2023_NC_BCexh/BCexh_scRNAseq/output\")"
  },
  {
    "objectID": "blog/2024/04/03/index.html#load-libraries-and-data-setup",
    "href": "blog/2024/04/03/index.html#load-libraries-and-data-setup",
    "title": "A comprehensive single-cell map of T cell exhaustion-associated immune environments in human breast cancer",
    "section": "",
    "text": "### Install and Load required packages\n# if (!any(rownames(installed.packages()) == \"DoubletFinder\")){\n#   remotes::install_github('chris-mcginnis-ucsf/DoubletFinder')\n# }\n\nlibrary(fs)\nlibrary(here)\nlibrary(patchwork)\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggpubr)\nlibrary(rstatix)\nlibrary(Seurat)\nlibrary(DoubletFinder)\nlibrary(magrittr)\nlibrary(clustree)\nlibrary(magrittr)\nlibrary(RColorBrewer)\nlibrary(corrplot)\nlibrary(pheatmap)\nlibrary(ComplexHeatmap)\nlibrary(scales)\nlibrary(viridis)\nlibrary(circlize)\nlibrary(ggrepel)\nlibrary(edgeR)\n\noptions(future.globals.maxSize = 8e9)\noutput_path &lt;- here(\"projects/2023_NC_BCexh/BCexh_scRNAseq/output\")"
  },
  {
    "objectID": "blog/2024/04/03/index.html#preprocess-scrnaseq-data",
    "href": "blog/2024/04/03/index.html#preprocess-scrnaseq-data",
    "title": "A comprehensive single-cell map of T cell exhaustion-associated immune environments in human breast cancer",
    "section": "Preprocess scRNAseq Data",
    "text": "Preprocess scRNAseq Data\nSave raw Data\n\n\n### Project directory\nproject_dir &lt;- here(\"projects/2023_NC_BCexh\")\n\n### Directory for scRNA data\ninput_path &lt;- here(project_dir, \"BCexh_scRNAseq/data\")\noutput_path &lt;- here(\"projects/2023_NC_BCexh/BCexh_scRNAseq/output\")\n\n### Get a list of sample names for creating seurat object from clinical info\nsample_list &lt;- read_excel(\n    here(project_dir, \"supp_data\", \"Supplementary Data1.xlsx\"),\n    ### start from row3\n    skip = 2\n) |&gt;\n    pull(\"Patient ID\") |&gt;\n    map_chr(~ glue::glue(\"T{.x}\"))\n\n### load data to a list\nobj_list &lt;- list()\nfor (sample in sample_list) {\n\n    ### Read counts matrix\n    counts &lt;- read.table(\n        here(input_path, paste0(sample, \"_singlecell_count_matrix.txt\")),\n        sep = \"\\t\"\n    )\n\n    ### Create seurat object\n    obj &lt;- CreateSeuratObject(\n        counts = counts,\n        min.cells = 5, min.features = 200, project = sample\n    )\n\n    ### Retrieve cell barcodes after filtering\n    cell_ids &lt;- colnames(obj)\n\n    ### Read metadata with annotation\n    metadata &lt;- read.table(\n        here(input_path, paste0(sample, \"_complete_singlecell_metadata.txt\")),\n        sep = \"\\t\",\n        header = TRUE\n    )\n\n    ### Align the cell barcode\n    metadata &lt;- metadata |&gt;\n        separate_wider_delim(\n            cellID, delim = \"_\", names = c(\"sample_id\", \"cell_barcode\"),\n            cols_remove = FALSE\n        ) |&gt;\n        mutate(cell_barcode = paste0(cell_barcode, \".1\")) |&gt;\n        column_to_rownames(var = \"cell_barcode\") |&gt;\n        select(-sample_id)\n\n    metadata &lt;- metadata[cell_ids, ]\n\n    metadata$nCount_RNA &lt;- obj$nCount_RNA\n    metadata$nFeature_RNA &lt;- obj$nFeature_RNA\n\n    # all(rownames(metadata) == colnames(obj))\n\n    ### Assign metadata with new cell barcode\n    # obj &lt;- AddMetaData(object = obj, metadata = metadata)\n\n    obj@meta.data &lt;- metadata\n\n    ### Save new obj\n    obj_list[[sample]] &lt;- obj\n\n}\n\n### There are 4,.75 GB\nlobstr::obj_size(obj_list)\n\n### Look at the cells and genes for each sample\ndo.call(rbind, lapply(obj_list, dim))\n\n### Save data for later exploration\nfs::dir_create(output_path)\n\nfor (sample in names(obj_list)) {\n\n    obj &lt;- obj_list[[sample]]\n\n    ### Calculate mitotic/ribosomal percentage\n    obj &lt;- PercentageFeatureSet(\n        obj, pattern = \"^MT-\", col.name = \"percent_mito\"\n    )\n\n    obj &lt;- PercentageFeatureSet(\n        obj, pattern = \"^RP[LS]\", col.name = \"percent_ribo\"\n    )\n    \n    ### Save \n    saveRDS(\n        obj, here(output_path, paste0(sample, \".rds\")), \n        compress = \"xz\"\n    )\n}\n\n\n### Load data\noutput_path &lt;- here(\"projects/2023_NC_BCexh/BCexh_scRNAseq/output\")\n\n# obj_list$TBB011[[]] |&gt; head()\n\n### Inspect PCA\nplots &lt;- list()\nfor (sample in names(obj_list)) {\n\n    plots[[sample]] &lt;- ElbowPlot(object = obj_list[[sample]], ndim = 30) +\n        labs(title = sample) + \n        FontSize(x.text = 8, y.text = 8, x.title = 8, y.title = 8, main = 8)\n\n}\npatchwork::wrap_plots(plots[1:4], ncol = 2)\n\n# DimHeatmap(obj_list$TBB102, dims = 10:30, cells = 500, balanced = TRUE)\n# FeaturePlot(obj_list$TBB102, reduction = \"tsne\", features = \"nFeature_RNA\")\n# DimPlot(obj_list$TBB102, label = TRUE, group.by = \"RNA_snn_res.0.4\")\n# DimPlot(obj_list$TBB102, label = TRUE, reduction = \"tsne\")\n\n# obj_list$TBB011[[]] |&gt; head()\n\n### Glimpse QC metrics\nVlnPlot(\n    obj_list$TBB011,\n    features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent_mito\"),\n    ncol = 1, pt.size = 0, sort = FALSE, log = TRUE\n)\n\n### Cell type\nFeaturePlot(\n    obj_list$TBB011, reduction = \"umap\", ncol = 2,\n    features = c(\"CD3E\", \"CD14\", \"PTPRC\", \"EPCAM\", \"PECAM1\", \"FAP\")\n)\n\n### Varify DoubletFinder\ntable(obj_list$TBB011$excl_doublet)\nUMAPPlot(\n    obj_list$TBB011, group.by = \"excl_doublet\",\n    # order = c(TRUE, FALSE),\n    cols = c(\"black\", \"red\")\n)\n\ntable(\n  obj_list$TBB011@meta.data$excl_doublet, \n  obj_list$TBB011@meta.data$RNA_snn_res.0.4\n)\n\nobj_list$TBB011[[]] |&gt; head()\n### Sanity checks\nDimPlot(obj_list$TBB011, label = TRUE)\nDotPlot(obj_list$TBB011, features = c(\"CD3E\", \"CD14\", \"PTPRC\", \"EPCAM\"))\nFeaturePlot(obj_list$TBB011, features = c(\"CD3E\", \"CD14\", \"PTPRC\", \"EPCAM\"))\nFeaturePlot(obj_list$TBB011, features = c(\"FAP\", \"PECAM1\", \"PTPRC\", \"EPCAM\"))\nFeaturePlot(obj_list$TBB011, features = c(\"CD14\", \"CD3E\"))\nFeaturePlot(obj_list$TBB011, features = c(\"MKI67\"), split.by = \"excl_doublet\")\n\nAggregate samples data\n\n### Clear environment\nrm(list = ls())\ngc()\n\n### Output directory\noutput_path &lt;- here(\"projects/2023_NC_BCexh/BCexh_scRNAseq/output\")\n\n### Samples to load\nsample_list &lt;- c(\n    ### IE1 \n        \"TBB011\",\n        \"TBB111\",\n        \"TBB129\",\n        \"TBB165\",\n        \"TBB171\",\n        \"TBB184\",\n        \"TBB338\",\n    \n    ### IE2\n        \"TBB035\",\n        \"TBB075\",\n        \"TBB102\",\n        \"TBB212\",\n        \"TBB214\",\n        \"TBB226\",\n        \"TBB330\"\n    )\n\n### Load IE1 vs IE2 samples for easier processing\nobj_list &lt;- list()\nfor (sample in sample_list) {\n    ### Load data\n    obj &lt;- readRDS(here(output_path, paste0(sample, \".rds\")))\n    \n    obj_list[[sample]] &lt;- obj\n}\n\n### Merge objects\nmerged_pre_filter &lt;- merge(\n    x = obj_list[[1]], y = obj_list[-1], add.cell.ids = names(obj_list)\n)\n### 4.75GB\nlobstr::obj_size(merged_pre_filter)\n\n### Remove for efficient memory\nrm(obj_list, obj)\n\n### Need to Join layers in Seurat V5\nmerged_pre_filter[[\"RNA\"]] &lt;- JoinLayers(merged_pre_filter[[\"RNA\"]])\n\n### Excluding high-confidence doublets\ntable(merged_pre_filter$sample, merged_pre_filter$excl_doublet)\nmerged_pre_filter &lt;- subset(merged_pre_filter, subset = excl_doublet == FALSE)\n\n### Save cell count data for each sample\ncells_per_sample &lt;- table(merged_pre_filter@meta.data$sample)\nwrite.csv(\n    cells_per_sample, \n    here(output_path, \"CellsPerSample_preFilter.csv\"),\n    row.names = FALSE\n)\n\n### 4.26 GB\nlobstr::obj_size(merged_pre_filter)\n\nInspect the quality metrics\n\n### Load data\nmerged_pre_filter &lt;- readRDS(here(output_path, \"merged_pre_filter.rds\"))\n\n### Vlnplot\nVlnPlot(\n    merged_pre_filter, \n    features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent_mito\"),\n    ncol = 1, pt.size = 0, sort = FALSE, log = TRUE\n)\n\n### Density plot\nplot(\n    density(merged_pre_filter@meta.data$percent_mito), \n    main = \"Mitochondrial Percentage Density Plot\", \n    xlab = \"Percent Mitochondrial Genes\"\n)\nplot(\n    density(merged_pre_filter@meta.data$nCount_RNA), \n    main = \"Total Reads\", \n    xlab = \"Total Reads per Cell\"\n)\nplot(\n    density(merged_pre_filter@meta.data$nFeature_RNA), \n    main = \"Number of detected genes\", \n    xlab = \"Deteced Genes per cell\"\n)\n\n\n### Filtering low quality cells\nmerged_post_filter &lt;- subset(\n    merged_pre_filter,\n    subset = nFeature_RNA &gt; 200 &\n        nFeature_RNA &lt; 7500 &\n        percent_mito &lt; 20 &\n        nCount_RNA &lt; 75000\n)\n\n### Save cell count data for each sample post filtering\ncells_per_sample &lt;- table(merged_post_filter@meta.data$sample)\nwrite.csv(\n    cells_per_sample, \n    here(output_path, \"CellsPerSample_postFilter.csv\"),\n    row.names = FALSE\n)\n\n### Save mean reads and median gene counts per cell for each sample\nmean_reads &lt;- as_tibble(\n    merged_post_filter@meta.data[, c(\"sample\", \"nCount_RNA\", \"nFeature_RNA\")]\n) |&gt; \ngroup_by(sample) |&gt; \nsummarise(\n    mean_reads = mean(nCount_RNA), \n    median_genes = median(nFeature_RNA),\n    .groups = \"drop\"\n)\nwrite.csv(mean_reads, here(output_path, \"postfilter_stats.csv\"))\n\n### Save\nsaveRDS(\n    merged_post_filter, here(output_path, \"merged_post_filter.rds\"), \n    compress = \"xz\"\n)\n\nRun general workflow\n\n### Maxmize memory usage\n# future::plan(\"multiprocess\", workers = 2)\n# options(future.globals.maxSize = 5* 1000 * 1024^2)\n\n### Load data\nmerged_post_filter &lt;- readRDS(here(output_path, \"merged_post_filter.rds\"))\n\n### Option: Apply sctransform normalization: replaces FindVariableFeatures,\n### Normalize and ScaleData. For a start, don't regress out anything\n### Note! This step comsumes a lot memory\n# merged_post_filter &lt;- SCTransform(merged_post_filter, verbose = TRUE)\n\n### Standard normalization\nmerged_post_filter &lt;- NormalizeData(merged_post_filter)\nmerged_post_filter &lt;- ScaleData(merged_post_filter)\nmerged_post_filter &lt;- FindVariableFeatures(\n    merged_post_filter,\n    x.low.cutoff = 0.0125, y.cutoff = 0.25, do.plot = FALSE\n)\n\nmerged_post_filter &lt;- RunPCA(\n    merged_post_filter,\n    features = VariableFeatures(merged_post_filter),\n    verbose = FALSE\n)\n\n### Find the resolution: Clustree analysis\n# clustree(merged_post_filter, prefix = \"RNA_snn_res.\", exprs = \"scale.data\")\n\n### Graph-based clustering\nmerged_post_filter &lt;- FindNeighbors(merged_post_filter, dims = 1:27) \nmerged_post_filter &lt;- FindClusters(merged_post_filter, resolution = 2)\nmerged_post_filter &lt;- RunUMAP(merged_post_filter, dims = 1:27)\n\n### If the clusters are not ordered correctly:\n# cluster_order &lt;- c(0:57)\n# merged_post_filter@active.ident &lt;- factor(x = merged_post_filter@active.ident, levels = cluster_order)\n\n### Save object to easily load it back without re-running computationally\n### intensive steps above\nsaveRDS(\n    merged_post_filter,\n    here(output_path, \"merged_complete_umap.rds\"),\n    compress = \"xz\"\n)\n\n\n### Load processed data from output directory\noutput_path &lt;- here(\"projects/2023_NC_BCexh/BCexh_scRNAseq/output\")\nmerged_post_filter &lt;- readRDS(here(output_path, \"merged_complete_umap.rds\"))\n\n### Examine and visualize PCA results in a few different ways\nprint(\n    x = merged_post_filter[[\"pca\"]],\n    dims = 1:5, nfeatures = 5, projected = FALSE\n)\n\n### For easy exploration of the primary sources of heterogeneity in a dataset\n# DimHeatmap(merged_post_filter, dims = 1:6, cells = 500, balanced = TRUE)\n# VizDimLoadings(merged_post_filter, dims = 1:2)\nElbowPlot(merged_post_filter, ndim = 50)\n\n### Inspect cluster\np1 &lt;- DimPlot(merged_post_filter, reduction = \"umap\", group.by = \"sample\") +\n    theme(legend.position = \"top\")\np2 &lt;- DimPlot(merged_post_filter, reduction = \"umap\", group.by = \"cell_type\") +\n    theme(legend.position = \"top\")\np1 + p2 + plot_layout(nrow = 1)\n\n### Check some marker expression\nFeaturePlot(\n    merged_post_filter, reduction = \"umap\",\n    features = c(\"PECAM1\", \"EPCAM\", \"FAP\", \"PTPRC\", \"CD3E\", \"CD14\")\n)\n\n### Save number of clusters and cells per cluster post filtering\ncells_per_cluster &lt;- table(merged_post_filter@meta.data$SCT_snn_res.2)\nwrite.csv(\n    cells_per_cluster, \n    here(outpath, \"dim27_res2_CellsPerCluster.csv\"), row.names = FALSE\n)\n\n### Save cluster proportions by sample\ncluster_sample &lt;- table(\n    Idents(merged_post_filter), merged_post_filter$sample\n)\nwrite.csv(\n    cluster_sample, \n    here(output_path, \"cellnr_per_cluster_bySample.csv\"), \n    row.names = TRUE\n)\ncluster_sample_prop &lt;- prop.table(\n    table(Idents(merged_post_filter), merged_post_filter$sample), \n    margin = 2\n)\nwrite.csv(\n    cluster_sample_prop, \n    here(output_path, \"cluster_samples_proportions.csv\"), \n    row.names = TRUE\n)\n\nFinding DEG for clusters\n\nIdents(merged_post_filter) &lt;- merged_post_filter$seurat_clusters\ncluster_markers_mast &lt;- FindAllMarkers(\n    merged_post_filter,\n    test.use = \"MAST\",\n    only.pos = TRUE, min.pct = 0.25,\n    logfc.threshold = 0.25,\n)\nwrite.csv(\n    cluster_markers_mast,\n    here(output_path, \"DE_cluster_AllMarkerGenes_MAST.csv\"),\n    row.names = FALSE\n)\n\n### Top10 DEG for each cluster\nmarker_genes &lt;- cluster_markers_mast |&gt;\n    group_by(cluster) |&gt;\n    slice_max(avg_log2FC, n = 10)\nwrite.csv(\n    marker_genes,\n    here(output_path, \"DE_cluster_MarkerGenesTop10.csv\"),\n    row.names = TRUE\n)\n\nAnnotate cell types\nCell type frequencies\n\n### Load processed scRNA data\nmerged_post_filter &lt;- readRDS(here(output_path, \"merged_complete_umap.rds\"))\n\n### Extract group info\nsample_info &lt;- merged_post_filter[[]] |&gt;\n    select(sample, IE) |&gt;\n    distinct()\n\n### Assign pDC or cDC to dendritic cell\n# merged_post_filter$cell_type[merged_post_filter$cell_type == \"pDC\"] &lt;- \"dendritic cell\"\n\n### Reset active IDs to cell type\nIdents(merged_post_filter) &lt;- \"cell_type\"\nlevels(Idents(merged_post_filter))\ntable(Idents(merged_post_filter))\n\n### Save cell number of cell type\ncelltype_sample &lt;- table(\n    merged_post_filter$cell_type, merged_post_filter$sample\n)\nwrite.csv(\n    celltype_sample, here(output_path, \"celltype_samples.csv\"),\n    row.names = TRUE\n)\n\n### Save proportions of cell type for each sample\ncelltype_sample_prop &lt;- prop.table(\n    table(merged_post_filter$cell_type, merged_post_filter$sample),\n    margin = 2\n)\nwrite.csv(\n    celltype_sample_prop,\n    here(output_path, \"celltype_samples_proportions.csv\"),\n    row.names = TRUE\n)\n\n### Ploty cell type frequencies using stacked barplot\ncelltype_sample_prop &lt;- read.csv(\n    here(output_path, \"celltype_samples_proportions.csv\")\n) |&gt;\n    pivot_longer(\n        starts_with(\"TB\"), names_to = \"sample\", values_to = \"percentage\"\n    ) |&gt;\n    dplyr::rename(cell_type = X) |&gt;\n    ### Factor cell type\n    mutate(\n        cell_type = factor(\n            cell_type,\n            levels = c(\n                \"T/NK cell\", \"myeloid\", \"B cell\", \"granulocyte\",\n                \"dendritic cell\", # \"cDC\", \"pDC\",\n                \"plasma cell\", \"epithelial\", \"fibroblast\", \"endothelial\"\n            )\n        )\n    ) |&gt;\n    left_join(sample_info, by = \"sample\")\n\n### Plot\ncelltype_sample_prop |&gt;\n    as_tibble() |&gt;\n    ggplot(aes(x = sample, y = percentage, fill = cell_type)) +\n    geom_bar(stat = \"identity\") +\n    theme(\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        panel.background = element_blank(),\n        axis.text.x = element_text(angle = 30)\n    ) +\n    # coord_flip()+\n    ggtitle(\"Sample composition by cell type\")\n\n### Cell type proportions by IE1 vs IE2\nstat_res &lt;- celltype_sample_prop |&gt;\n    group_by(cell_type) |&gt;\n    wilcox_test(percentage ~ IE) |&gt;\n    add_significance() |&gt;\n    add_xy_position(x = \"cell_type\")\n\nggplot(celltype_sample_prop, aes(x = IE, y = percentage, fill = IE)) +\n    geom_boxplot() +\n    geom_point() +\n    facet_wrap(~ cell_type, scales = \"free\", ncol = 5, strip.position = \"bottom\") +\n    theme(\n        axis.ticks.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.title.x = element_blank()\n    ) +\n    # theme(panel.background = element_blank())+\n    ylab(\"proportion\")\n    # stat_pvalue_manual(stat_res, hide.ns = TRUE)\n\nCytof vs 10x Cell type\n\n## Cytof cell type percentages\ncytof_dir &lt;- here(\"projects/2023_NC_BCexh/BCexh_scRNAseq/03_Additional_files\")\ncytof_perc &lt;- read.csv(\n    here(cytof_dir, \"cytof_celltype_prop.csv\")\n) |&gt;\n    pivot_longer(\n        starts_with(\"TBB\"), names_to = \"sample\", values_to = \"percentage\"\n    ) |&gt;\n    rename(cell_type = cell_type) |&gt;\n    left_join(sample_info, by = \"sample\") |&gt;\n    mutate(method = \"cytof\")\n\nggplot(cytof_perc, aes(sample, y = percentage, fill = cell_type)) +\n    geom_bar(stat = \"identity\") +\n    theme(axis.title.x = element_blank(), axis.title.y = element_blank()) +\n    # coord_flip()+\n    theme(panel.background = element_blank()) +\n    ggtitle(\"CyTOF percentages\")\n\n### Adapt 10x celltypes to fit CyTOF celltypes\n# merged_post_filter$cell_type &lt;- factor(\n#     merged_post_filter$cell_type,\n#     levels = c(\n#         \"T/NK cell\",\n#         \"myeloid\",\n#         \"B cell\",\n#         \"dendritic cell\",\n#         \"granulocyte\",\n#         \"plasma cell\",\n#         \"epithelial\",\n#         \"endothelial\",\n#         \"fibroblast\"\n#         # \"cDC\",\n#         # \"pDC\"\n#     )\n# )\ncelltype_sample_prop |&gt;\n    ggplot(aes(sample, y = percentage, fill = cell_type)) +\n    geom_bar(stat = \"identity\") +\n    theme(axis.title.x = element_blank(), axis.title.y = element_blank()) +\n    # coord_flip()+\n    theme(panel.background = element_blank()) +\n    ggtitle(\"10x percentages\")\n\n### Combine cytof and 10x percentages\ncelltype_pct &lt;- bind_rows(\n    cytof_perc,\n    celltype_sample_prop |&gt; mutate(method = \"10x\")\n)\n\ncelltype_pct$cell_type &lt;- factor(\n    celltype_pct$cell_type,\n    levels = c(\n        \"T/NK cell\", \"myeloid\", \"B cell\", \"dendritic cell\", \"granulocyte\",\n        \"plasma cell\", \"epithelial\", \"endothelial\", \"fibroblast\", \"other\"\n    )\n)\n\ncelltype_pct$method &lt;- factor(celltype_pct$method, levels = c(\"cytof\", \"10x\"))\ncelltype_pct &lt;- celltype_pct |&gt; drop_na()\n\nggplot(celltype_pct, aes(method, y = percentage, fill = cell_type)) +\n    geom_bar(stat = \"identity\") +\n    facet_wrap(~sample, ncol = 6) +\n    theme(\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        panel.background = element_blank()\n    ) +\n    # coord_flip()+\n    ggtitle('Celltype percentages: CyTOF vs. scRNA-seq')\n\nInspect some chemokine features\n\nCCLs &lt;- paste0(\"CCL\", c(1:28))\nCX_XCs &lt;- c(paste0(\"CXCL\", c(1:17)), \"CXCL4L1\", \"XCL1\", \"XCL2\", \"CX3CL1\")\nILs  &lt;- paste0(\"IL\", c(1:33))\nother_cytokines &lt;- c(\n    \"TNF\", \"IFNG\", \"IFNA1\", \"IFNB1\", \"TGFB1\", \"CSF1\", \"CSF2\", \"CSF3\", \"EPO\"\n)\ninteraction_other &lt;- c(\n    \"CD47\", \"SIRPG\", \"SIRPA\", \"FASLG\", \"FAS\", \"CD80\", \"CD86\", \"CTLA4\"\n)\ncytokine_receptor &lt;- c(\n    'CCR1', 'CCR2', 'CCR3', 'CCR4', 'CCR5', 'CCR6', 'CCR7', 'CCR8', 'CCR9', \n    'CCR10', 'CCR11', 'IL10RA', 'IL4R', 'CXCR1', 'CXCR2', 'CXCR3', 'CXCR4', \n    'CXCR5', 'CXCR6', 'CXCR7'\n)\n\n# example_data &lt;- readRDS(here(output_path, \"\"))\nVlnPlot(\n    merged_post_filter, features = c(\"nFeature_RNA\"), pt.size = 0\n) + \nNoLegend()\n# theme(legend.position = \"right\") +\n# guides(fill = guide_legend(ncol = 2))\n\nDotPlot(merged_post_filter, features = c(\"PTPRC\", \"CD3E\", \"CD14\", \"CD68\"))\nFeaturePlot(merged_post_filter, features = c(\"nFeature_RNA\", \"nCount_RNA\"))\n\nChemkine expression per cell type\n\nchemokines &lt;- c(\n    \"CXCL9\", \"CXCL10\", \"CXCL13\", \"CCL4\", \"CCL5\", \"CCL3\", \"CXCL8\",\n    \"CCL17\", \"CCL22\"\n)\n\nchemokine_tab &lt;- data.frame(celltype = merged_post_filter$cell_type)\n\n### Seurat V5, the counts data do not have colnames and rownames\ncounts &lt;- merged_post_filter@assays$RNA@layers$counts\nrownames(counts) &lt;- Features(merged_post_filter)\ncolnames(counts) &lt;- Cells(merged_post_filter)\n\nfor (i in chemokines) {\n    chemokine_tab[, i] &lt;- ifelse(counts[i, ] &gt; 0, 1, 0)\n}\n\nchemokine_add  &lt;-  data.frame(celltype = unique(chemokine_tab$celltype))\n\nfor (i in chemokines) {\n    count_i &lt;- as.data.frame(\n        table(chemokine_tab$celltype, chemokine_tab[, i])[, \"1\"]\n    )\n    colnames(count_i) &lt;- i\n    count_i$celltype &lt;- rownames(count_i)\n    chemokine_add &lt;- merge(chemokine_add, count_i, by = \"celltype\")\n}\n\nSave immune subsets\n\n### Load data\nmerged_post_filter &lt;- readRDS(here(output_path, \"merged_complete_umap.rds\"))\n\n### Immune subset\nimmune &lt;- subset(\n    merged_post_filter,\n    idents = c(\n        \"T/NK cell\", \n        \"myeloid\", \n        \"B cell\", \n        \"granulocyte\", \n        # \"dendritic cell\",\n        # \"cDC\",\n        \"pDC\", \n        \"plasma cell\"\n    )\n)\nsaveRDS(immune, here(output_path, \"immune.rds\"), compress = \"xz\")\nrm(immune)\n\n## T/NK cell subset\nTNK &lt;- subset(merged_post_filter, idents = \"T/NK cell\")\nsaveRDS(\n    TNK,\n    here(output_path, \"T_NK_cells.rds\"),\n    compress = \"xz\"\n)\nrm(TNK)\n\n### Myeloid subset (incl. DCs)\nmyeloid &lt;- subset(\n    merged_post_filter, idents = c(\n        \"myeloid\", \n        \"dendritic cell\"\n        # \"cDC\", \n        # \"pDC\"\n    )\n)\nsaveRDS(myeloid, here(output_path, \"myeloid_inclDC.rds\"), compress = \"xz\")\nrm(myeloid)\n\n### B cell subset\nB &lt;- subset(merged_post_filter, idents = \"B cell\")\nsaveRDS(B, here(output_path, \"B_cells.rds\"))\nrm(B)\n\n### Plasma cell subset\nPC &lt;- subset(x = merged_post_filter, idents = \"plasma cell\")\nsaveRDS(PC, here(output_path, \"plasma_cells.rds\"))\nrm(PC)\n\n### Granulocyte subset\ngran &lt;- subset(x = merged_post_filter, idents = \"granulocyte\")\nsaveRDS(gran, here(output_path, \"granulocytes.rds\"))\nrm(gran)\n\n### tumor cell subset\nep &lt;- subset(x = merged_post_filter, idents = \"epithelial\")\nsaveRDS(ep, here(output_path, \"epithelial.rds\"))\nrm(ep)\n\n### fibroblast subset\nfib &lt;- subset(x = merged_post_filter, idents = \"fibroblast\")\nsaveRDS(fib, here(output_path, \"fibroblast.rds\"))\nrm(fib)\n\n### endothelial cell subset\nendo &lt;- subset(x = merged_post_filter, idents = \"endothelial\")\nsaveRDS(endo, here(output_path, \"endothelial.rds\"))\nrm(endo)"
  },
  {
    "objectID": "blog/2024/04/03/index.html#t-cells-subclustering",
    "href": "blog/2024/04/03/index.html#t-cells-subclustering",
    "title": "A comprehensive single-cell map of T cell exhaustion-associated immune environments in human breast cancer",
    "section": "T cells subclustering",
    "text": "T cells subclustering\nProcess T cells subset\n\n### Load T cells subset\npath &lt;- here(\"projects/2023_NC_BCexh/BCexh_scRNAseq/output\")\nrun1_Tcell &lt;- readRDS(here(path, \"T_NK_cells.rds\"))\n### 6,77GB is too big for running\nlobstr::obj_size(run1_Tcell)\n\n### Use subset data example\nTcell &lt;- subset(\n    run1_Tcell, \n    subset = sample == c(\n        \"TBB011\", \"TBB165\", \"TBB338\", \"TBB075\", \"TBB330\", \"TBB214\")\n    )\nlobstr::obj_size(Tcell)\nrm(run1_Tcell)\n\n### Store Keratin and MGP percentage in object meta data\nTcells &lt;- PercentageFeatureSet(\n    Tcells, pattern = \"^KRT\", col.name = \"percent_krt\"\n)\nTcells &lt;- PercentageFeatureSet(\n    Tcells, pattern = \"MGP\", col.name = \"percent_MGP\"\n)\ncolnames(Tcells[[]])\n\n### Run Normalization, ScaleData, and FindVariableFeatures\nTcells &lt;- SCTransform(\n    Tcells,\n    vars.to.regress = c(\"percent_mito\", \"percent_krt\", \"percent_MGP\"),\n    verbose = TRUE\n)\n\n### Dimensional reduction\nTcells &lt;- RunPCA(Tcells, verbose = FALSE)\nTcells &lt;- RunUMAP(Tcells, dims = 1:15)\nTcells &lt;-  FindNeighbors(Tcells, dims = 1:15)\nTcells &lt;- FindClusters(Tcells, resolution = 1)\n\n### Save object\nsaveRDS(\n    Tcells, here(path, \"Tcells.rds\"),\n    compress = \"xz\"\n)\n\n\n### Load T cells subset\npath &lt;- here(\"projects/2023_NC_BCexh/BCexh_scRNAseq/output\")\nTcells &lt;- readRDS(here(path, \"Tcells.rds\"))\ncolnames(Tcells[[]])\n\nElbowPlot(Tcell, ndims = 25)\n# VizDimLoadings(Tcell, dims = 1:2)\n# PCAPlot(Tcell)\n# DimHeatmap(Tcell, dims = 15:20, cells = 500, balanced = TRUE)\nDimPlot(Tcell, reduction = \"umap\", label = TRUE)\nDimPlot(Tcell, reduction = \"umap\", group.by = \"sample\")\nDimPlot(Tcell, reduction = \"umap\", group.by = \"sample\")\n\n### Clustree analysis\n# clustree(Tcell, prefix = \"SCT_snn_res.\") +\n#     scale_edge_color_continuous(low = \"black\", high = \"black\")\n\n### QC plots\nVlnPlot(\n    Tcell,\n    features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent_mito\"),\n    ncol = 1, pt.size = 0, sort = FALSE\n)\nVlnPlot(\n    Tcell,\n    features = c(\"percent_krt\", \"percent_MGP\"),\n    pt.size = 0, sort = FALSE, ncol = 1\n)\n\nDimPlot(Tcell, group.by = \"Tcell_cluster\")\nDimPlot(Tcell, group.by = \"Tcell_metacluster\")\nDimPlot(Tcell, group.by = \"SCT_snn_res.1\")\nFeaturePlot(Tcell, features = c(\"PDCD1\", \"CD4\", \"CD8A\", \"FOXP3\"))\nVlnPlot(Tcell, features = c(\"MKI67\"), pt.size = 0, sort = FALSE)\n\n### Highlight individual clusters\nIdents(Tcell) &lt;- Tcell$Tcell_metacluster\ncells_CD4ex &lt;- WhichCells(\n    Tcell, ident = c(\"CD4_exhausted\", \"CD8_exhausted\")\n)\nDimPlot(Tcell, reduction = \"umap\", cells.highlight = cells_CD4ex)\n\nCluster proportions\n\n### Load processed data\nTcell_dir &lt;- here(\"projects/2023_NC_BCexh/BCexh_scRNAseq/output/Tcells\")\nfs::dir_create(Tcell_dir)\n\n### Extract group info\nsample_info &lt;- Tcells[[]] |&gt;\n    select(sample, IE) |&gt;\n    distinct()\n\n### Which cluster is each sample made of? (by cluster)\ncluster_samples_count &lt;- table(Tcells$SCT_snn_res.1, Tcells$sample) |&gt;\n    as.data.frame() |&gt;\n    as_tibble() |&gt;\n    dplyr::rename(cluster = Var1, sample = Var2, prop = Freq)\n# write.csv(\n#     cluster_samples_count,\n#     here(Tcell_dir, \"cluster_samples_count.csv\"),\n#     row.names = TRUE\n# )\nggplot(cluster_samples_count, aes(sample, y = prop, fill = cluster)) +\n    geom_bar(stat = \"identity\") +\n    theme(axis.title.x = element_blank(), axis.title.y = element_blank()) +\n    coord_flip() +\n    theme(panel.background = element_blank()) +\n    ggtitle(\"Sample composition (T/NK clusters)\")\n\n\n### How many cells of each sample in each cluster? (by sample)\ncluster_samples_prop &lt;- prop.table(\n    table(Tcells$SCT_snn_res.1, Tcells$sample),\n    margin = 1\n) |&gt;\n    as.data.frame() |&gt;\n    as_tibble() |&gt;\n    dplyr::rename(cluster = Var1, sample = Var2, prop = Freq)\n# write.csv(\n#     cluster_samples_prop,\n#     here(Tcell_dir, \"cluster_samples_proportion.csv\"),\n#     row.names = TRUE\n# )\nggplot(cluster_samples_prop, aes(cluster, y = prop, fill = sample)) +\n    geom_bar(stat = \"identity\") +\n    theme(\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        panel.background = element_blank()\n    ) +\n    # coord_flip()+\n    ggtitle(\"T/NK cell cluster composition\")\n\n### How many cells of each IE are in each cluster\ncluster_IE_count &lt;- table(Tcells$SCT_snn_res.1, Tcells$IE) |&gt; \n    as.data.frame() |&gt;\n    as_tibble() |&gt;\n    dplyr::rename(cluster = Var1, IE = Var2, count = Freq)\nggplot(cluster_IE_count, aes(cluster, y = count, fill=IE)) +\n  geom_bar(stat=\"identity\")+\n  theme(axis.title.x=element_blank(), axis.title.y = element_blank())+\n  #coord_flip()+\n  theme(panel.background = element_blank())+\n  ggtitle(\"T/NK cell cluster composition\")\n\n### What percentage of each IE is in which cluster?\ncluster_IE_prop &lt;- prop.table(\n    table(Tcells$SCT_snn_res.1, Tcells$IE),\n    margin = 1\n) |&gt;\n    as.data.frame() |&gt;\n    as_tibble() |&gt;\n    dplyr::rename(cluster = Var1, IE = Var2, prop = Freq)\nggplot(cluster_IE_prop, aes(cluster, y = prop, fill = IE)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    theme(axis.title.x = element_blank(), axis.title.y = element_blank()) +\n    # coord_flip()+\n    theme(panel.background = element_blank()) +\n    ggtitle(\"Proportion of each TIG belonging to a specific cluster\")\n\nggplot(cluster_IE_prop, aes(x = IE, y = prop, fill = IE)) +\n    geom_boxplot() +\n    geom_point() +\n    facet_wrap(\n        ~ cluster, scales = \"free\", \n        ncol = 3, \n        strip.position = \"bottom\"\n    ) +\n    theme(\n        axis.title.x = element_text(\"cluster\"),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank()\n    ) +\n    # theme(panel.background = element_blank())+\n    xlab(\"cluster\")\n\nFinding cluster DEG\n\nIdents(Tcells) &lt;- Tcells$SCT_snn_res.1\nTcells_markers &lt;- FindAllMarkers(\n    Tcells, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25\n)\nmarker_genes_top10 &lt;- Tcells_markers |&gt;  \n    group_by(cluster) |&gt; \n    slice_max(avg_log2FC, n = 10)\n\n\n### Feature list\nfeatures &lt;- c(\"FOXP3\", \"CCL18\", \"IL2RA\")\nfeatures_cytof &lt;- c(\n    'CD3E', 'CD8A', 'CD4', 'FOXP3', 'HAVCR2', 'PDCD1', 'CTLA4', 'ICOS', \n    'IL2RA', 'PTPRC', 'CD68', 'CD14', 'CD274', 'CCR7', 'HLA-DRA', 'MRC1', \n    'SIGLEC1', 'MSR1', 'CD163', 'FCGR2A', 'FCGR2B', 'FCGR2C', 'FCGR1A', \n    'ITGAM', 'ITGAX', 'FCGR3A', 'CD93', 'IL3RA', 'CD86', 'CD36', 'CD38', \n    'CCR2', 'SLAMF7'\n)\nfeatures_cytof_T_01 &lt;- c('CD3E', 'CD8A', 'FOXP3', 'HAVCR2', 'PDCD1', 'CTLA4')\nfeatures_cytof_T_02 &lt;- c('ICOS', 'IL2RA', 'PTPRC', 'CD4', 'CCR7', 'CD38')\nfeatures_cytof_T &lt;- c(\n    'CD3E', 'CD8A', 'FOXP3', 'HAVCR2', 'PDCD1', 'CTLA4', 'ICOS', 'IL2RA', \n    'PTPRC', 'CD4', 'CCR7', 'CD38', 'NCAM1'\n)\nfeatures_T_extended &lt;- c(\n    'CD3E', 'CD8A', 'FOXP3', 'HAVCR2', 'PDCD1', 'CTLA4', 'ICOS', 'IL2RA', \n    'PTPRC', 'CD4', 'CCR7', 'CD38', 'NCAM1', 'ENTPD1', 'ITGAE', 'SELL', \n    'CD40LG', \"FCGR3A\", \"CD27\", \"IL7R\", \"HLA-DRA\", \"TBX21\", \"CD69\", \"NCR1\", \n    \"IRF4\"\n)\ncytokine &lt;- c(\n    'CCL20', 'CCL22', 'CXCL2', 'CXCL3', 'CXCL8', 'CCL8', 'CCL18', 'CCL2', \n    'CCL3', 'CCL4', 'CCL4L2', 'CCL5', 'CXCL10', 'CXCL12', 'CCL13', 'CXCL1', \n    'CXCL13', \"IL4\", \"IL13\", \"IFNG\", \"TNF\"\n)\nchemokine_01 &lt;- c('CCL20', 'CCL22', 'CXCL2', 'CXCL3', 'CXCL8')\nchemokine_02 &lt;- c('CCL8', 'CCL18', 'CCL2', 'CCL3', 'CCL4')\nchemokine_03 &lt;- c('CCL4L2', 'CXCL10', 'CXCL12', 'CCL13', 'CXCL1')\ncytokine_receptor &lt;- c(\n    'CCR1', 'CCR10', 'CCR2', 'CCR7', 'CCR4', 'CCR5', 'CCR6', 'IL10RA', \n    'IL4R', 'CXCR2', 'CXCR3', 'CXCR4', 'CXCR5', 'CCR8'\n)\nTF &lt;- c(\n    'IRF2', 'IRF5', 'IRF8', 'IRF9', 'IRF4', 'IRF7', 'STAT1', 'STAT2', 'STAT4', \n    'TCF12', 'TCF19', 'BCL6', 'ZBTB31', 'ZBTB33', 'ZBTB47', 'CIITA'\n)\nfeatures_plitas &lt;- c(\n    'CCR8', 'CCR10', 'CX3CR1', 'IL1RL1', 'IL2RA', 'IL1R2', 'TNFRSF8', \n    'TNFRSF4', 'TNFRSF9', 'TNFRSF18', 'CD177', 'CARD16'\n)\nTh1 &lt;- c(\n    'CCL4', 'CD38', 'CXCL9', 'CXCL10', 'CXCL11', 'FN1', 'GNLY', 'GZMA', \n    'GZMB', 'IFNA', 'IFNG', 'IL2', 'IL8', 'IL10', 'IL12B', 'IL18', 'LTA', \n    'MAP3K8', 'OSM', 'STAT1', 'STAT4', 'TBX21', 'TIA1', 'TNF'\n)\nTh2 &lt;- c(\n    'GATA3', 'IL4', 'IL5', 'IL10', 'IL13', 'MAF', 'STAT5A', 'STAT5B', 'STAT6'\n)\n\nTh17 &lt;- c(\n    'BATF', 'CCL20', 'IL1A', 'IL1B', 'IL6', 'IL17A', 'IL17F', 'IL18', 'IL21', \n    'IL22', 'LTA', 'RORC', 'STAT3', 'TGFB1', 'TGFB2', 'TGFB3'\n)\ntumor_reactive &lt;- c(\n    \"PDCD1\", \"LAG3\", \"HAVCR2\", \"TNFRSF9\", \"TNFRSF18\", \"ENTPD1\", \"ITGAE\", \n    \"CXCL13\", \"IRF4\", \"BATF\"\n)\ncytotoxic &lt;- c(\n    \"GZMB\", \"GZMA\", \"GZMK\", \"TNF\", \"IFNG\", \"GNLY\", \"FASLG\", \"IL2\"\n)\nM1M2_rec &lt;- c(\n    \"IL10RA\", \"IL10RB\", \"CXCR3\", \"CCR4\", \"CCR1\", \"CCR5\", \"IGF2R\", \"TFGBR2\", \n    \"TGFBR1\", \"TGFBR3\", \"ITGAV\", \"ITGA5\", \"LRP8\", \"LRP1\", \"SCARB1\", \"C3AR1\"\n)\nM1M2_lig &lt;- c(\n    \"CALM1\", \"CALM2\", \"CALM3\", \"TGFB1\", \"TLN1\", \"HSP90AA1\", \"VEGFA\", \"GNAI2\", \n    \"PGF\", \"MDK\", \"FGF2\"\n)\n\n\nDimPlot(Tcells, reduction = \"umap\", group.by = \"Tcell_metacluster\")\nDimPlot(Tcells, reduction = \"umap\", group.by = \"Tcell_cluster\")\nDimPlot(Tcells, reduction = \"umap\", group.by = \"cell_type\")\n\nCorrelation matrix\n\nIdents(Tcells) &lt;- Tcells$SCT_snn_res.1\ncluster_perc &lt;- prop.table(table(Idents(Tcells), Tcells$sample), margin = 2)\ncluster_perc &lt;- t(cluster_perc)\ncorr &lt;- cor(cluster_perc)\n\n### For metaclusters\nT_mcluster_perc &lt;- prop.table(\n    table(Tcells$Tcell_metacluster, Tcells$sample), margin = 2\n)\nT_mcluster_perc &lt;- t(T_mcluster_perc)\n\n### Plot\ncorrplot(\n    corr, method = \"color\", type = \"upper\", tl.srt = 0, tl.offset = 1,\n    tl.cex = 1, tl.col = \"black\", title = \"Tcell cluster correlations\"\n)\n\n# compute p-values\np_corr &lt;- cor.mtest(corr, method = \"pearson\")\np_corr2 &lt;- p_corr[[1]]\n\n\n### Plot with p-values below zero in white\ncorrplot(\n    corr, method = \"color\", type = \"upper\", tl.srt = 0, tl.col = \"black\", tl.offset = 1, p.mat = p_corr2, \n    sig.level = 0.005, insig = \"label_sig\", \n    pch = \"*\", pch.cex = 1, title = \"Tcell cluster correlations (P&lt;0.05)\"\n)\n\nCD4/CD8 ratio\n\n# Idents(Tcells) &lt;- Tcells$Tcell_metacluster\n# levels(Idents(Tcells))\n# T_only &lt;- subset(\n#     Tcells, idents = c(\"NKT\", \"NK_activated\", \"NK\", \"proliferating\"), \n#     invert = TRUE\n# )\n\n# cluster_averages &lt;- AverageExpression(T_only, return.seurat = TRUE)\n# dim(cluster_averages)\n# dim(cluster_averages_df)\n# rownames(cluster_averages_df) &lt;- rownames(cluster_averages)\n# cluster_averages_df &lt;- as.data.frame(cluster_averages@assays$RNA@layers$counts)\n# colnames(cluster_averages_df)\n# colnames(cluster_averages)\n\n# CD8_CD4_df &lt;- as.data.frame(\n#     t(cluster_averages_df[c(\"CD8A\", \"CD8B\", \"CD4\"), ])\n# )\n# CD8_CD4_df$cluster &lt;- rownames(CD8.CD4.df)\n# CD8.CD4.df &lt;- mutate(CD8.CD4.df, ratio = (CD8A + CD8B) / 2 / CD4)\n\n# p &lt;- ggplot(CD8.CD4.df, aes(cluster, ratio)) +\n#     geom_point() +\n#     ylab(\"CD8/CD4 ratio\") +\n#     theme(panel.background = element_blank(),\n#         panel.border = element_rect(color = \"black\", fill = NA, size = 1))"
  },
  {
    "objectID": "blog/2024/04/03/index.html#t-cells-edger-pseudobulk",
    "href": "blog/2024/04/03/index.html#t-cells-edger-pseudobulk",
    "title": "A comprehensive single-cell map of T cell exhaustion-associated immune environments in human breast cancer",
    "section": "T cells EdgeR pseudobulk",
    "text": "T cells EdgeR pseudobulk\n\n### Cluster-indepenent IE comparsion\nsamples &lt;- c(\"TBB011\", \"TBB165\", \"TBB338\", \"TBB075\", \"TBB214\", \"TBB330\")\nraw_counts &lt;- as.data.frame(Tcells@assays$RNA@layers$counts)\ndim(raw_counts)\nAssays(Tcells)\ncolnames(raw_counts) &lt;- colnames(Tcells)\nrownames(raw_counts) &lt;- rownames(Tcells[[\"RNA\"]])\n\n### Get the counts matrix\nraw_counts$TBB011 &lt;- rowSums(raw_counts[,grep(\"TBB011\", names(raw_counts))])\nraw_counts$TBB165 &lt;- rowSums(raw_counts[,grep(\"TBB165\", names(raw_counts))])\nraw_counts$TBB338 &lt;- rowSums(raw_counts[,grep(\"TBB338\", names(raw_counts))])\nraw_counts$TBB075 &lt;- rowSums(raw_counts[,grep(\"TBB075\", names(raw_counts))])\nraw_counts$TBB330 &lt;- rowSums(raw_counts[,grep(\"TBB330\", names(raw_counts))])\nraw_counts$TBB214 &lt;- rowSums(raw_counts[,grep(\"TBB214\", names(raw_counts))])\n\nraw_sums &lt;- raw_counts[, samples]\nwrite.csv(raw_sums, here(Tcell_dir, \"sample_sum_counts.csv\"), row.names = TRUE)\n\n\n### Load count data\nscrna_dir &lt;- here(\"projects/2023_NC_BCexh/BCexh_scRNAseq\")\ncounts &lt;- read.csv(here(Tcell_dir, \"sample_sum_counts.csv\"), row.names = \"X\")\ncolnames(counts)\n\n### Get group information\nclinical_data &lt;- read_csv(\n    here(scrna_dir, \"03_Additional_files/clinical_data.csv\"),\n    show_col_types = FALSE\n) |&gt; mutate(sample = str_glue(\"T{Patient_ID}\")) |&gt;\n    dplyr::filter(sample %in% samples) |&gt;\n    relocate(sample, IE, .before = Patient_ID) |&gt;\n    arrange(IE)\n\n### Preapre a DGElist object\nobj &lt;- edgeR::DGEList(\n    counts = counts, group = clinical_data$IE, samples = clinical_data\n)\n\n### Filter out lowly expressed genes\nkeep &lt;- edgeR::filterByExpr(\n    obj, group = clinical_data$IE,\n    min.count = 30, min.total.count = 300, large.n = 4, min.prop = 0.6\n)\ntable(keep)\nobj &lt;- obj[keep, , keep.lib.sizes = FALSE]\n\n### Normalisation for RNA composition using TMM (trimmed mean of M-values)\nobj &lt;- edgeR::calcNormFactors(obj)\nobj$samples\n\n### Setup the design matrix\nsample &lt;- factor(clinical_data$sample)\nIE &lt;- factor(clinical_data$IE)\nIE &lt;- relevel(IE, \"IE2\")\ndesign &lt;- model.matrix(~IE)\n\n### Estimate dispersion (estimates common dispersion, trended dispersions and\n### tagwise dispersions in one run)\nobj &lt;- estimateDisp(obj, design)\nplotBCV(obj)\n\n### Calcualte differential expression\n### exact test (only for single-factor experiments)\net &lt;- exactTest(obj)\ntopTags(et)\n\n### Number of up/downregulated genes at 5% FDR\nsummary(decideTests(et))\nplotMD(et)\nabline(h=c(-1,1), col =\"blue\")\n\n### Export results\nwrite.csv(\n    as.data.frame(topTags(et, n=Inf)), \n    here(Tcell_dir, \"IE1vsIE2_EdgeR_samplesums_exactT_filtered.csv\")\n)"
  },
  {
    "objectID": "blog/2024/04/03/index.html#figure1",
    "href": "blog/2024/04/03/index.html#figure1",
    "title": "A comprehensive single-cell map of T cell exhaustion-associated immune environments in human breast cancer",
    "section": "Figure1",
    "text": "Figure1\nUMAP plots\n\npath &lt;- here(\"projects/2023_NC_BCexh/BCexh_scRNAseq\")\nall_merged &lt;- readRDS(here(path, \"output/merged_complete_umap.rds\"))\ncolnames(all_merged[[]])\n\n### Color palette\ncolors &lt;- hue_pal()(50)\nshow_col(colors)\n\n### Classify pDCs as myeloid cells for this large overview\nunique(all_merged[[]]$cell_type)\nall_merged$cell_type &lt;- factor(all_merged$cell_type)\nct_levels &lt;- levels(all_merged$cell_type)\nct_levels[6] &lt;- \"mast cell/basophil\"\nlevels(all_merged$cell_type) &lt;- ct_levels\n\n### Reorder patient levels\nall_merged$sample &lt;- factor(all_merged$sample)\n\n### Subset to very few cells to get small pdfs\ncells &lt;- WhichCells(all_merged)\ncells_sub &lt;- sample(cells, 100)\nobject &lt;- subset(all_merged, cells = cells_sub)\n\n### Color by celltype\numap_celltype &lt;- DimPlot(\n    object, group.by = \"cell_type\",\n    cols = c(\n        \"#FF5F50\", \"darkorange2\", \"gold3\", \"#77C900\", \"#00AA5C\", \"#00C0BD\", \"#1F99FF\", \"#0044DB\", \"gray\")\n) +\n    theme_void()\n\n### Color by sample\numap_patient &lt;- DimPlot(object, group.by = \"sample\") +\n    theme_void()\n\numap_celltype +  umap_patient\n\n### Color by sample group\numap_IE &lt;- DimPlot(object, group.by = \"IE\") + \n    theme_void()\n\n### Color by clusters\nDimPlot(all_merged, group.by = \"RNA_snn_res.2\", label = TRUE) +\n    theme_void()\n\nHighlight fibroblast\n\nIdents(all_merged) &lt;- all_merged$cell_type\nfibroblasts  &lt;-  WhichCells(object = all_merged, ident = c(\"fibroblast\"))\nDimPlot(\n    all_merged, reduction = \"umap\", cells.highlight = fibroblasts, \n    cols.highlight = \"#00C1AA\", sizes.highlight = 0.7, pt.size = 0.7\n)\n\nFeature plots\n\n### save as png (Inkscape/Illustrator cannot handle UMAPs with lots of cells)\ngenes &lt;- c(\"PTPRC\", \"PDGFRB\", \"CD3E\", \"CD14\", \"EPCAM\", \"PECAM1\")\nFeaturePlot(all_merged, genes, max.cutoff = 3) + theme_void()\n\n### save one plot as pdf to get vectorized legend (with very few cells)\ncells &lt;- WhichCells(all_merged)\ncells_sub &lt;- sample(cells, 1000)\nobj_sub &lt;- subset(all_merged, cells = cells_sub)\nFeaturePlot(obj_sub, \"HLA-DRA\", max.cutoff = 3)\n\nDotplots for lineage markers\n\n### Features\ngenes &lt;- c(\n    \"EPCAM\", \"CDH1\", \"PECAM1\", \"CAV1\", \"VWF\", \"PDGFRB\", \"FAP\", \"PTPRC\", \"CD3E\", \"NCAM1\", \"CD14\", \"HLA-DRA\", \"ITGAX\", \"MS4A1\", \"MS4A2\", \"IGKC\"\n)\ngenes_PDL1 &lt;- c(\"CD274\", \"LAMP3\", \"CCR7\")\n\n### Main cell types only\nIdents(all_merged) &lt;- all_merged$cell_type\nDotPlot(all_merged, features = genes_PDL1) +\n    coord_flip() +\n    theme(\n        axis.text.x = element_text(angle = 90, hjust = 1),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank()\n    )\n\n### all clusters\nIdents(all_merged) &lt;- all_merged$RNA_snn_res.2\nDotPlot(all_merged, features = genes_PDL1) +\n    coord_flip() +\n    theme(\n        axis.text.x = element_text(angle = 90, hjust = 1),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank()\n    )\n\nGene expression heatmap\n\nIdents(all_merged) &lt;- all_merged$cell_type\ncluster_averages_table &lt;- AverageExpression(\n    all_merged, return.seurat = FALSE, assays = \"RNA\"\n)\n\nRNA_average &lt;- as.matrix(cluster_averages_table[[1]])\n\n### Normalize between 0 and 1\nRNA_average_norm &lt;- apply(\n    RNA_average, 1, function(x) (x - min(x)) / (max(x) - min(x))\n)\nRNA_average_znorm &lt;- apply(RNA_average, 1, function(x) (x - mean(x)) / sd(x))\n\nT_supp &lt;- c(\n    \"CD274\", \"PDCD1LG2\", \"IDO1\", \"CD80\", \"CD86\", \"CCL17\", \"CCL19\", \"CCL22\", \"IL15\"\n)\n\nHeatmap(\n    t(subset(RNA_average_norm, select = T_supp)),\n    show_row_names = TRUE,\n    row_dend_side = \"left\",\n    heatmap_legend_param = list(title = \"Normalized\\nmean counts\"),\n    col = viridis(100),\n    cluster_rows = FALSE,\n    cluster_columns = FALSE,\n    row_names_side = \"left\",\n    column_names_side = \"top\",\n    column_names_rot = 90,\n    column_dend_side = \"bottom\",\n    row_names_gp = gpar(fontsize = 6),\n    cluster_column_slices = FALSE\n)\n\nCell type frequence\n\n### classify pDCs as myeloid cells for this large overview\nsample_info &lt;- all_merged[[]] |&gt; \n    select(sample, IE) |&gt; \n    distinct() |&gt; \n    as_tibble()\n\n\n### Full clusters by sample\ncluster_prop &lt;- as.data.frame(\n    prop.table(\n        table(all_merged$sample, all_merged$RNA_snn_res.2), margin = 2\n    )\n)\ncolnames(cluster_prop) &lt;- c(\"sample\", \"cluster\", \"proportion\")\n\nggplot(cluster_prop, aes(cluster, y = proportion, fill = sample)) +\n    geom_bar(stat = \"identity\") +\n    theme(axis.title.x = element_blank(), axis.title.y = element_blank(), axis.ticks.x = element_blank()) +\n    # coord_flip()+\n    theme(panel.background = element_blank(), axis.text.x = element_text(angle = 90, hjust = 1)) +\n    ggtitle(\"Sample composition by cell type\")\n\n\n### Compare cell type frequencies\ncelltype_freq &lt;- as.data.frame(table(all_merged$cell_type, all_merged$sample))\ncolnames(celltype_freq) &lt;- c(\"cell_type\", \"sample\", \"cell_number\")\n\n### Absolute frequency\nggplot(celltype_freq, aes(sample, y = cell_number, fill = cell_type)) +\n    geom_bar(stat = \"identity\") +\n    theme(axis.title.x = element_blank(), axis.title.y = element_blank(), axis.ticks.x = element_blank()) +\n    # coord_flip()+\n    theme(panel.background = element_blank(), axis.text.x = element_text(angle = 90, hjust = 1)) +\n    ggtitle(\"Sample composition by cell type (absolute)\") ## Figure2\n\n### Relative frequency\ncelltype_prop &lt;- as.data.frame(\n    prop.table(table(all_merged$cell_type, all_merged$sample), margin = 2)\n)\ncolnames(celltype_prop) &lt;- c(\"cell_type\", \"sample\", \"proportion\")\n\nggplot(celltype_prop, aes(sample, y = proportion, fill = cell_type)) +\n    geom_bar(stat = \"identity\") +\n    theme(axis.title.x = element_blank(), axis.title.y = element_blank(), axis.ticks.x = element_blank()) +\n    # coord_flip()+\n    theme(\n        panel.background = element_blank(),\n        axis.text.x = element_text(angle = 90, hjust = 1)\n    ) +\n    ggtitle(\"Sample composition by cell type\")\n\n### Cell type proporations by sample group\ncelltype_prop &lt;- celltype_prop |&gt;\n    left_join(sample_info, by = \"sample\")\n\nggplot(celltype_prop, aes(x = IE, y = proportion, color = IE)) +\n    geom_boxplot() +\n    geom_point() +\n    facet_wrap(~cell_type, scales = \"fixed\", ncol = 4, strip.position = \"top\") +\n    theme(\n        axis.ticks.x = element_blank(),\n        axis.text.x = element_text(angle = 90, hjust = 1),\n        axis.title.x = element_blank(),\n        panel.background = element_blank(),\n        panel.border = element_rect(color = \"black\", fill = NA, linewidth = 1),\n        strip.background = element_blank(),\n        legend.background = element_blank()\n    ) +\n    ylab(\"Of total [%]\")\n\nCytof vs 10x\nCell numbers before and after filtering\n\ncell_numbers &lt;- read.csv(\n    here(path, \"03_Additional_files/CellsPerSample_PrePostFilter.csv\")\n)[-15, -4]\n\ncell_numbers$preFilter &lt;- cell_numbers$preFilter - cell_numbers$postFilter\ncell_numbers &lt;- cell_numbers |&gt; \n    pivot_longer(\n        matches(\"Filter\"), names_to = \"filter\", values_to = \"cell_number\"\n    ) |&gt; \n    mutate(\n        filter = factor(\n            filter, levels = c(\"preFilter\", \"postFilter\")\n        )\n    )\n\nggplot(cell_numbers, aes(Sample, cell_number, fill = filter)) +\n    geom_bar(stat = \"identity\") +\n    scale_fill_manual(\n        values = c(\"preFilter\" = \"dodgerblue\", \"postFilter\" = \"green4\")\n    ) +\n    theme(axis.title.x = element_blank(), axis.title.y = element_blank()) +\n    theme(axis.ticks.x = element_blank(),\n        axis.text.x = element_text(angle = 90, hjust = 1),\n        axis.title.x = element_blank(),\n        panel.background = element_blank(),\n        strip.background = element_blank(),\n        legend.background = element_blank()) +\n    ylab(\"Cell number\")\n\nClinical information\n\ndf &lt;- read.csv(here(path, \"03_Additional_files/subtype_table.csv\"))[, -(28:32)]\n\n### Subtype distribution by TIG (stacked barplot)\ndf$Clinical.Subtype &lt;- factor(\n    df$Clinical.Subtype, levels = c(\"LumA\", \"LumB\", \"LumB-HER2\", \"HER2\", \"TN\")\n)\np_type &lt;- ggplot(df, aes(Clinical.Subtype, fill = Tumor.Immune.Group..CyTOF.based.))+\n  geom_bar()+\n  scale_x_discrete(drop=FALSE)+\n  scale_y_continuous(breaks = c(2,4,6,8))+\n   theme(axis.title.x=element_blank(), \n         axis.title.y = element_blank(),\n         panel.background = element_blank(),\n         panel.border = element_rect(color = \"black\", fill = \"NA\"),\n         axis.text.x = element_text(angle = 90, hjust=1),\n         legend.title = element_blank(),\n         axis.ticks.x = element_blank()) +\n  ggtitle(\"Clinical Subtypes by TIG\")\n\n### Age distribution by TIG (boxplots)\np_age &lt;- ggplot(df, aes(x = Tumor.Immune.Group..CyTOF.based., y = Age.at.Surgery))+\n  geom_boxplot()+\n  geom_point()+\n   theme(axis.title.x=element_blank(), \n         axis.title.y = element_blank(),\n         panel.background = element_blank(),\n         panel.border = element_rect(color = \"black\", fill = \"NA\"),\n         axis.text.x = element_text(angle = 90, hjust=1),\n         legend.title = element_blank(),\n         axis.ticks.x = element_blank()) +\n  ggtitle(\"Age by TIG\")\n\n### Grade distribution by TIG (stacked barplot)\np_grade &lt;- ggplot(df, aes(Grade, fill = Tumor.Immune.Group..CyTOF.based.))+\n  geom_bar()+\n  scale_x_discrete(drop=FALSE)+\n  scale_y_continuous(breaks = c(2,4,6,8))+\n   theme(axis.title.x=element_blank(), \n         axis.title.y = element_blank(),\n         panel.background = element_blank(),\n         panel.border = element_rect(color = \"black\", fill = \"NA\"),\n         axis.text.x = element_text(angle = 90, hjust=1),\n         legend.title = element_blank(),\n         axis.ticks.x = element_blank()) +\n  ggtitle(\"Grade by TIG\")\n\n### Combine plots\n(p_type | p_age | p_grade) + plot_layout(guides = \"collect\")\n\n\n### Cell type freq distribution by clinical subtype (boxplots)\ncelltype_prop &lt;- read.csv(\n    here(path, \"03_Additional_files/celltype_prop_sample_v2.csv\"), \n    header = TRUE\n) |&gt; \n    left_join(df, by = \"Patient.ID\") |&gt; \n    pivot_longer(\n        cols = 2:9, names_to = \"cell_type\", values_to = \"proportion\"\n    ) |&gt; \n    relocate(cell_type, proportion, .after = \"Patient.ID\")\n\nsign_testing &lt;- compare_means(\n    proportion ~ Clinical.Subtype, data = celltype_prop, \n    group.by = \"cell_type\"\n)\n\nggplot(celltype_prop, aes(x = Clinical.Subtype, y = proportion))+\n  geom_boxplot()+\n  geom_point()+\n  facet_wrap(~cell_type, scales=\"fixed\", ncol=4)+\n   theme(axis.title.x=element_blank(), \n         axis.title.y = element_blank(),\n         panel.background = element_blank(),\n         panel.border = element_rect(color = \"black\", fill = \"NA\"),\n         axis.text.x = element_text(angle = 90, hjust=1),\n         legend.title = element_blank(),\n         axis.ticks.x = element_blank(),\n         strip.background = element_blank()) +\n  ggtitle(\"Cell type frequency by subtype\")+\n  scale_y_continuous(limits = c(0,0.7))+\n  stat_compare_means(comparisons=list(c(\"LumA\", \"LumB\")), label = \"p.signif\")\n\n### Cell type freq distribution by grade (boxplots)\nsign_testing &lt;- compare_means(\n    proportion~Grade, data = celltype_prop, group.by = \"cell_type\")\n\nmy_comparisons &lt;- list(c(\"G1\", \"G2\"), c(\"G1\", \"G3\"), c(\"G2\", \"G3\"))\n\nggplot(celltype_prop, aes(x = Grade, y = proportion))+\n  geom_boxplot()+\n  geom_point()+\n  facet_wrap(~cell_type, scales=\"fixed\", ncol=4)+\n   theme(axis.title.x=element_blank(), \n         axis.title.y = element_blank(),\n         panel.background = element_blank(),\n         panel.border = element_rect(color = \"black\", fill = \"NA\"),\n         axis.text.x = element_text(angle = 90, hjust=1),\n         legend.title = element_blank(),\n         axis.ticks.x = element_blank(),\n         strip.background = element_blank()) +\n  ggtitle(\"Cell type frequency by subtype\")+\n  scale_y_continuous(limits = c(0,0.7))+\n  stat_compare_means(comparisons = my_comparisons, label = \"p.signif\")\n\n### Cell type freq by age (correlation plots)\nggplot(celltype_prop, aes(proportion, Age.at.Surgery))+\n  geom_point()+\n  facet_wrap(~cell_type, scales = \"free\", ncol = 4)+\n  stat_cor()+\n     theme(panel.background = element_blank(),\n         panel.border = element_rect(color = \"black\", fill = \"NA\"),\n         strip.background = element_blank()) +\n  ggtitle(\"Cell type frequency by age\")"
  },
  {
    "objectID": "blog/2024/04/03/index.html#figure2",
    "href": "blog/2024/04/03/index.html#figure2",
    "title": "A comprehensive single-cell map of T cell exhaustion-associated immune environments in human breast cancer",
    "section": "Figure2",
    "text": "Figure2\n\nTcells &lt;- readRDS(here(scrna_dir, \"output/Tcells.rds\"))\n\nIE1 vs IE2 Volcano Plot\n\nedger &lt;- read.csv(\n    here(Tcell_dir, \"IE1vsIE2_EdgeR_samplesums_exactT_filtered.csv\")\n)\nedger$logFC &lt;- -(edger$logFC)\n\n### Remove keratins\nedger &lt;- filter(edger, !str_detect(X, \"^KRT\"))\nedger$X &lt;- as.character(edger$X)\n\n### Remove all genes with logCPM &lt; 1.5\nedger &lt;- filter(edger, logCPM &gt; 1.5)\n\nhighlight &lt;- c(\n    \"HAVCR\", \"CDK1\", \"PTMS\", \"CSF1\", \"CD55\", \"GZMB\", \"PDCD1\", \"IL13\",\n    \"MKI67\", \"TNFRSF18\", \"CD276\", \"IRF4\", \"ITGAE\", \"CD8B\", \"TCF7\",\n    \"PDCD4\", \"GPR183\", \"CAMK1\", \"HAVCR2\", \"BATF\", \"TOX\", \"CCL3\", \"CXCR6\"\n)\n\nedger$color &lt;- as.character(\n    ifelse(\n        edger$FDR &lt; 0.1 & edger$logFC &gt; 0.5, \"#F8766D\",\n        ifelse(edger$FDR &lt; 0.1 & edger$logFC &lt; -0.5, \"#00BFC4\", \"grey\")\n    )\n)\n\n# Plot with ggplot\nggplot(edger) +\n    geom_point(aes(logFC, -log(FDR)), color = edger$color) +\n    geom_label_repel(\n        data = subset(edger, X %in% highlight), aes(logFC, -log(FDR), label = X), min.segment.length = 0.1\n    ) +\n    geom_vline(xintercept = 0.5, linetype = \"dotted\", color = \"grey20\") +\n    geom_vline(xintercept = -0.5, linetype = \"dotted\", color = \"grey20\") +\n    geom_hline(\n        yintercept = -log(0.1), linetype = \"dotted\", color = \"grey20\"\n    ) +\n    theme(\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.background = element_blank(),\n        panel.border = element_rect(colour = \"black\", fill = \"NA\")\n    )\n\nIE1 vs IE2 BoxPlot\n\ncounts &lt;- read.csv(\n    here(Tcell_dir, \"sample_sum_counts.csv\"),\n    row.names = \"X\"\n)\ncolnames(counts)\n\n###  setup data table ###\nrawdat &lt;- data.table::as.data.table(counts)\n\n### Normalize counts by dividing through library size\nrawdat_cpm &lt;- apply(counts,2, function(x) (x/sum(x))*1000000)\ntdat = t(rawdat_cpm)\ntrnames &lt;- row.names(tdat)\ntdat &lt;- data.table::as.data.table(tdat)\ncolnames(tdat) = rownames(counts)\ntdat[, condition := trnames]\nTIG_list &lt;- c(\n    \"IE1\", \"IE1\", \"IE1\", \"IE2\", \"IE2\", \"IE2\"\n)\ntdat[, TIG := TIG_list]\n\n### format the tables\ndat = data.table::melt(\n    tdat, id.vars=c('condition', 'TIG'), variable.name='gene', value.name = 'cpm' , variable.factor = FALSE\n)\n\n# gene list\nGOI &lt;- c(\n    \"BATF\", \"IRF4\", \"CD55\", \"CD46\",  \"CSF1\", \"IL13\", \"CCL3\", \"CXCR6\", \n    \"TCF7\", \"TOX\"\n)\n\n### plot together with edger values\nedger$gene &lt;- edger$X\nedger$FDR_x = paste0('FDR = ',signif(edger$FDR, digits=3))\nedger$p = paste0('p = ',signif(edger$PValue, digits=2))\n\nsubset(dat, gene %in% GOI) |&gt; \n  merge(edger, by='gene') |&gt; \n  ggplot(aes(x=gene,y=cpm,color=TIG))+\n  facet_wrap(~gene+FDR_x+p, scales = \"free\", ncol = 3)+\n  geom_boxplot()+\n  geom_point(position = position_jitterdodge(jitter.width = 0, jitter.height = 0, dodge.width = 0.75))+\n  expand_limits(x=0,y=0)+\n  theme_bw()+\n  theme(axis.line.x = element_line(colour = \"black\", size = 0.25),\n        axis.line.y = element_line(colour = \"black\", size = 0.25),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.border = element_rect(colour = \"black\", fill=\"NA\"),\n        panel.background = element_blank(),\n        axis.title.x=element_blank(),\n        axis.text.x=element_blank(),\n        #strip.background = element_blank(),\n        axis.ticks.x=element_blank())"
  },
  {
    "objectID": "blog/2024/04/03/index.html#sessioninfo",
    "href": "blog/2024/04/03/index.html#sessioninfo",
    "title": "A comprehensive single-cell map of T cell exhaustion-associated immune environments in human breast cancer",
    "section": "SessionInfo",
    "text": "SessionInfo\n\nsessionInfo()"
  },
  {
    "objectID": "blog/2024/05/08/index.html",
    "href": "blog/2024/05/08/index.html",
    "title": "Normalization example for SomaLogic proteomic data",
    "section": "",
    "text": "library(here)\n## here() starts at /Users/zhonggr/Library/CloudStorage/OneDrive-Personal/quarto\nlibrary(fs)\nlibrary(tidyverse)\n## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n## ✔ dplyr     1.1.4     ✔ readr     2.1.5\n## ✔ forcats   1.0.0     ✔ stringr   1.5.1\n## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n## ✔ purrr     1.0.2\n## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n## ✖ dplyr::filter() masks stats::filter()\n## ✖ dplyr::lag()    masks stats::lag()\n## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n### Project dir\ndir  &lt;-  \"projects/2024_Plasma7k_SomaScan\""
  },
  {
    "objectID": "blog/2024/05/08/index.html#intial-setup",
    "href": "blog/2024/05/08/index.html#intial-setup",
    "title": "Normalization example for SomaLogic proteomic data",
    "section": "",
    "text": "library(here)\n## here() starts at /Users/zhonggr/Library/CloudStorage/OneDrive-Personal/quarto\nlibrary(fs)\nlibrary(tidyverse)\n## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n## ✔ dplyr     1.1.4     ✔ readr     2.1.5\n## ✔ forcats   1.0.0     ✔ stringr   1.5.1\n## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n## ✔ purrr     1.0.2\n## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n## ✖ dplyr::filter() masks stats::filter()\n## ✖ dplyr::lag()    masks stats::lag()\n## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n### Project dir\ndir  &lt;-  \"projects/2024_Plasma7k_SomaScan\""
  },
  {
    "objectID": "blog/2024/05/08/index.html#step0-load-data",
    "href": "blog/2024/05/08/index.html#step0-load-data",
    "title": "Normalization example for SomaLogic proteomic data",
    "section": "Step0: Load data",
    "text": "Step0: Load data\n\n### Normalization methods\nnorm &lt;- c(\n    \"raw\", \"hyb\", \"hyb.msnCal\", \"hyb.msnCal.ps\", \"hyb.msnCal.ps.cal\", \n    \"hyb.msnCal.ps.cal.msnAll\"\n    )\nn_norm &lt;- length(norm)\n\n### Container to save normalized data\nRFU &lt;- vector(\"list\", n_norm)\n\n### Load sample meta as matrix\nsamples &lt;- read.table(\n    here(dir, \"data/sample.txt\"), header = T, quote = \"\", \n    comment.char = \"\", sep = \"\\t\"\n) |&gt;\n    as.matrix()\n\n### 1806 human plasma samples,  2050 sample and controls across 22 plates\ndim(samples)\n## [1] 2050   32\nsamples[1:5, 1:5]\n##      PlateId    PlateRunDate ScannerID    PlatePosition SlideId       \n## [1,] \"P0031168\" \"2021-12-03\" \"SG12344217\" \"A1\"          \"258633829464\"\n## [2,] \"P0031168\" \"2021-12-03\" \"SG12344217\" \"A10\"         \"258633829473\"\n## [3,] \"P0031168\" \"2021-12-03\" \"SG12344217\" \"A11\"         \"258633829518\"\n## [4,] \"P0031168\" \"2021-12-03\" \"SG12344217\" \"A12\"         \"258633829519\"\n## [5,] \"P0031168\" \"2021-12-03\" \"SG12344217\" \"A2\"          \"258633829465\"\nn_sample &lt;- nrow(samples)\nplates &lt;- unique(samples[, \"PlateId\"])\nn_plate &lt;- length(plates)\n\n### Load feature meta\nsomamers &lt;- read.table(\n    here(dir, \"data/somamer.txt\"), header = T, quote = \"\", \n    comment.char = \"\", sep = \"\\t\"\n) |&gt;\n    as.matrix()\n\n### Total 7596 SOMAmers (feature); 7288 human protein, others are control\ndim(somamers)\n## [1] 7596   13\nsomamers[1:5, 1:13]\n##      SeqId      SeqIdVersion SomaId     Target  UniProt  EntrezGeneID\n## [1,] \"10000-28\" \" 3\"         \"SL019233\" \"CRBB2\" \"P43320\" \"1415\"      \n## [2,] \"10001-7\"  \" 3\"         \"SL002564\" \"c-Raf\" \"P04049\" \"5894\"      \n## [3,] \"10003-15\" \" 3\"         \"SL019245\" \"ZNF41\" \"P51814\" \"7592\"      \n## [4,] \"10006-25\" \" 3\"         \"SL019228\" \"ELK1\"  \"P19419\" \"2002\"      \n## [5,] \"10008-43\" \" 3\"         \"SL019234\" \"GUC1A\" \"P43080\" \"2978\"      \n##      EntrezGeneSymbol Organism Units Type      Dilution\n## [1,] \"CRYBB2\"         \"Human\"  \"RFU\" \"Protein\" \"2e+01\" \n## [2,] \"RAF1\"           \"Human\"  \"RFU\" \"Protein\" \"2e+01\" \n## [3,] \"ZNF41\"          \"Human\"  \"RFU\" \"Protein\" \"5e-01\" \n## [4,] \"ELK1\"           \"Human\"  \"RFU\" \"Protein\" \"2e+01\" \n## [5,] \"GUCA1A\"         \"Human\"  \"RFU\" \"Protein\" \"2e+01\" \n##      Cal_Interplate_Ref_Pass1 Cal_Interplate_Ref_Pass2\n## [1,] \"8.879371e+02\"           \"8.942875e+02\"          \n## [2,] \"3.963486e+02\"           \"3.980628e+02\"          \n## [3,] \"2.260907e+02\"           \"2.241294e+02\"          \n## [4,] \"8.352066e+02\"           \"8.344351e+02\"          \n## [5,] \"7.299779e+02\"           \"7.297289e+02\"\nn_somamer &lt;- nrow(somamers)\n\n### Load SomaScan raw assay data matrix (2050 x 7596)\nRFU[[1]] &lt;- read.table(here(dir, \"data/RFU_raw.txt\"), header = F, sep = \"\\t\") |&gt; \n    as.matrix()\n\n### 2050x7596\ndim(RFU[[1]])\n## [1] 2050 7596\nRFU[[1]][1:5, 1:5]\n##         V1    V2    V3    V4     V5\n## [1,] 748.8 325.4 217.1 572.0  720.7\n## [2,] 577.5 385.4 325.7 634.8  731.0\n## [3,] 526.8 318.6 203.0 581.3  618.0\n## [4,] 508.4 422.7 213.1 641.2  688.2\n## [5,] 450.5 290.5 202.2 580.2 2294.6\n\n### Dilution groups\ndilution &lt;- c(0.005, 0.5, 20)\ndilution_lab &lt;- c(\"0_005\", \"0_5\", \"20\")\nn_dilution &lt;- length(dilution)"
  },
  {
    "objectID": "blog/2024/05/08/index.html#step1-hybridization-control-normalization",
    "href": "blog/2024/05/08/index.html#step1-hybridization-control-normalization",
    "title": "Normalization example for SomaLogic proteomic data",
    "section": "Step1: Hybridization control normalization",
    "text": "Step1: Hybridization control normalization\nHybridization control normalization is designed to adjust for nui- sance variance on the basis of individual wells. Each well contains nHCE = 12 HCE (Hybridization Control Elu‑ tion) SOMAmers at different concentrations spanning more than 3 orders of magnitude. By comparing each observed HCE probe to its corresponding reference value, and then calculating the median over all HCE probes, we obtain the scale factor for the i-th well, i.e.\nNotice that this normalization step is performed independently for each well; once the scale factor is determined, all SOMAmer RFUs in the well are multiplied by the same scale factor.\n\n### well = sample\n### Get idx for Hybridization feature \nsomamer_HCE &lt;- somamers[, \"Type\"] == \"Hybridization Control Elution\"\ntable(somamer_HCE)\n## somamer_HCE\n## FALSE  TRUE \n##  7584    12\n\n### 12 control SOMAmer reagents addded to the eluate just prior to readout\nn_HCE &lt;- sum(somamer_HCE)\n\n### Get hybridization control data: 1) Subset only the HYBs for all samples\nRFU_HCE &lt;- RFU[[1]][, somamer_HCE]\n\n### Use another container to save hybridization normalized data\nRFU[[2]] &lt;- RFU[[1]]\n\n### Empty container to save scale factor for hyb \nhyb_scale_factor &lt;- rep(NA, n_sample)\n\n### Empty container to save ratio\nHCE_ratio &lt;- matrix(rep(NA, n_sample * n_HCE), ncol = n_HCE)\n\n### Loop through plates\nfor (i_plate in 1:n_plate) {\n\n    ### Get current sample index from current plate\n    sample_idx &lt;- samples[, \"PlateId\"] == plates[i_plate]\n\n    ### Get current sample data from current plate\n    RFU_plate &lt;- RFU[[2]][sample_idx, ]\n\n    ### Current plate ratio\n    HCE_ratio_plate &lt;- HCE_ratio[sample_idx, ]\n\n    ### Current plate hyb scale factor\n    hyb_scale_factor_plate &lt;- hyb_scale_factor[sample_idx]\n\n    ### Calculate the median of each HYB for calibrators\n    hyb_intra_ref &lt;- apply(RFU_HCE[sample_idx, ], 2, median)\n    \n    ### Loop through sample within the plate for HCE\n    for (i_sample in 1:sum(sample_idx)) {\n        \n        ### Calculate the ratio\n        HCE_ratio_plate[i_sample, ] &lt;- hyb_intra_ref / RFU_plate[i_sample, somamer_HCE]\n        \n        ### Use the median of HCE somamers as scale factor for each sample\n        hyb_scale_factor_plate[i_sample] &lt;- median(HCE_ratio_plate[i_sample, ])\n       \n        ### Apply the same scale factor for all features by each sample\n        RFU_plate[i_sample, ] &lt;- hyb_scale_factor_plate[i_sample] * RFU_plate[i_sample, ]\n    }\n\n    HCE_ratio[sample_idx, ] &lt;- HCE_ratio_plate\n    hyb_scale_factor[sample_idx] &lt;- hyb_scale_factor_plate\n    RFU[[2]][sample_idx, ] &lt;- RFU_plate\n}\n\nHCE_ratio[1:5, 1:12]\n##           [,1]      [,2]      [,3]     [,4]      [,5]      [,6]      [,7]\n## [1,] 0.9028951 0.8465086 0.8636644 0.840359 0.8238109 0.8347273 0.8409453\n## [2,] 1.0688565 1.0757213 1.0718344 1.074034 1.0761508 1.0865276 1.0898142\n## [3,] 1.1755157 1.0443237 1.0618485 1.027817 1.0278632 1.0458846 1.0242561\n## [4,] 1.2409731 1.0985134 1.1283522 1.093489 1.0620677 1.0887500 1.0404074\n## [5,] 0.9606874 0.8826018 0.8870467 0.870571 0.8706513 0.8889404 0.8772853\n##           [,8]      [,9]     [,10]     [,11]     [,12]\n## [1,] 0.8245079 0.8392952 0.8265836 0.8554753 0.8322683\n## [2,] 1.0839455 1.1161029 1.0670241 1.0616821 1.1057077\n## [3,] 1.0360929 1.0523256 1.0140127 1.0951655 1.0508598\n## [4,] 1.0976469 1.0806892 1.0949106 1.1302752 1.1075787\n## [5,] 0.8698039 0.8517074 0.8504274 0.9175154 0.8744776"
  },
  {
    "objectID": "blog/2024/05/08/index.html#step2-median-signal-normalization-on-calibrators",
    "href": "blog/2024/05/08/index.html#step2-median-signal-normalization-on-calibrators",
    "title": "Normalization example for SomaLogic proteomic data",
    "section": "Step2: Median signal normalization on calibrators",
    "text": "Step2: Median signal normalization on calibrators\nMedian signal normalization is an intra-plate normalization procedure performed within wells of the same sample class (i.e. separately for buffer, QC, calibrator, and experimental samples) and within SOMAmers of the same dilution grouping (i.e. 20%, 0.5%, and 0.005%).\nIt is intended to remove sample-to-sample differences in total RFU brightness that may be due to differences in overall protein concentration, pipetting variation, variation in reagent concentrations, assay timing, and other sources of variability within a group of otherwise comparable samples. Since RFU brightness differs significantly across SOMAmers, median signal normalization proceeds in two steps.\n\nFirst, the median RFU of each SOMAmer is determined (across all samples of the same sample type) and sample RFUs are divided by it. The ratio corresponding to the i-th sample and α-th SOMAmer is thus given by Performing median signal normalization on experimental samples before inter-plate calibration presents the risk of enhancing plate-to-plate differences. Thus, in this step, we restrict median signal normalization to calibrators only.\n\n\nRFU[[3]] = RFU[[2]]\nSF_medNormInt &lt;- matrix(rep(1, n_sample * n_dilution), ncol = n_dilution)\n\n### Only do the normalization on calibrator samples\nsample_type  &lt;- c(\"Calibrator\")\n\n### Loop throuh plate\nfor (i_plate in 1:length(plates)) {\n    \n    sel1  &lt;-  samples[, \"PlateId\"] == plates[i_plate]\n    \n    ### Loop through sample type\n    for (i_sample_type in 1:length(sample_type)) {\n        \n        ### Get the Calibrator sample idx\n        sel2  &lt;-  samples[, \"SampleType\"] == sample_type[i_sample_type]\n        \n        sample_idx  &lt;-  which(sel1 & sel2)\n        \n        ### Loop through dilution\n        for (i_dilution in 1:n_dilution) {\n            \n            sel_somamer &lt;- as.numeric(somamers[, \"Dilution\"]) == dilution[i_dilution]\n            \n            dat  &lt;-  RFU[[3]][sample_idx, sel_somamer, drop = F]\n            \n            dat2 &lt;- dat\n            \n            ### Loop throuhg dilution somamers\n            for (i in 1:ncol(dat2)) {\n\n                ### Get the median of dilution somamer  \n                dat2[, i]  &lt;-  dat2[, i] / median(dat2[, i])\n            }\n\n            for (i in 1:nrow(dat)) {\n                \n                SF_medNormInt[sample_idx[i], i_dilution] = 1 / median(dat2[i, ])\n                \n                dat[i, ] = dat[i, ] * SF_medNormInt[sample_idx[i], i_dilution]\n            }\n\n            RFU[[3]][sample_idx, sel_somamer]  &lt;-  dat\n        }\n    }\n}\n\nRFU[[3]][1:5, 1:10]\n##            V1       V2       V3       V4        V5       V6       V7       V8\n## [1,] 628.8625 273.2797 182.3265 480.3811  605.2634 300.3222 1951.674 1160.725\n## [2,] 621.3531 414.6658 350.4324 683.0042  786.5093 445.3299 3063.620 2156.176\n## [3,] 550.5609 332.9702 212.1561 607.5190  645.8744 331.9251 2623.734 1432.524\n## [4,] 557.3481 463.3970 233.6170 702.9339  754.4590 373.1733 2593.796 1444.457\n## [5,] 394.5846 254.4436 177.1032 508.1864 2009.7976 243.4075 1846.358 1060.342\n##            V9       V10\n## [1,] 354.1551  721.9994\n## [2,] 521.5062 1008.0445\n## [3,] 431.5235  832.8435\n## [4,] 431.6050  932.3851\n## [5,] 312.3393  608.3873"
  },
  {
    "objectID": "blog/2024/05/08/index.html#step3-plate-scale-normalization",
    "href": "blog/2024/05/08/index.html#step3-plate-scale-normalization",
    "title": "Normalization example for SomaLogic proteomic data",
    "section": "Step3: Plate-scale normalization",
    "text": "Step3: Plate-scale normalization\nPlate-scale normalization aims to control for variance in total signal intensity from plate to plate. No protein spikes are added to the calibrator; the procedure solely relies on the endogenous levels of each protein within the set of calibrator replicates\nWe utilize an internal reference determined by the median across all calibrators on all plates, i.e.\n\\[\n\\begin{aligned} RFU_{\\alpha }^{Cal,ref}\\equiv \\text {median}\\left\\{ RFU_{i\\alpha }^{Cal,obs} \\right\\} _{i=1,\\ldots ,n_{Cal}}^{p=1,\\ldots ,n_p}\\ . \\end{aligned}\n\\]\nFor the - SOMAmer on the p- plate, \\[\n\\begin{aligned} SF_\\alpha ^p = RFU_\\alpha ^{Cal,ref}/\\text {median}\\left\\{ RFU_{i\\alpha }^{Cal,obs} \\right\\} _{i=1,\\ldots ,n_{Cal}}^p\\ . \\end{aligned}\n\\]\n\nRFU[[4]] = RFU[[3]]\n\nSF &lt;- matrix(rep(NA, n_plate * n_somamer), ncol = n_somamer)\n\n### Get calibrator sample idx\nsel_cal &lt;- samples[, \"SampleType\"] == \"Calibrator\"\n\ncal_interplate_ref &lt;- rep(NA, n_somamer)\n\n### Loop through features\nfor (i_somamer in 1:n_somamer) {\n    ### Get the median of control\n    cal_interplate_ref[i_somamer]  &lt;-  median(RFU[[4]][sel_cal, i_somamer])\n\n    for (i_plate in 1:n_plate) {\n\n        sel_plate = samples[, \"PlateId\"] == plates[i_plate]\n        \n        cal_intraplate_ref = median(RFU[[4]][sel_cal & sel_plate, i_somamer])\n\n        SF[i_plate, i_somamer] = cal_interplate_ref[i_somamer] / cal_intraplate_ref\n    }\n}\n\nSF_plateScale  &lt;-  apply(SF, 1, median)\n\nfor (i_plate in 1:n_plate) {\n\n    sel_plate = samples[, \"PlateId\"] == plates[i_plate]\n\n    RFU[[4]][sel_plate, ] = RFU[[4]][sel_plate, ] * SF_plateScale[i_plate]\n}\n\nn order to correct the overall brightness level of the p- plate, we calculate the plate-scale scale factor as the median of across all SOMAmers, i.e."
  },
  {
    "objectID": "blog/2024/05/08/index.html#step4-inter-plate-calibration",
    "href": "blog/2024/05/08/index.html#step4-inter-plate-calibration",
    "title": "Normalization example for SomaLogic proteomic data",
    "section": "Step4: Inter-plate calibration",
    "text": "Step4: Inter-plate calibration\n\nRFU[[5]] &lt;- RFU[[4]]\n\nSF_cal &lt;- matrix(rep(NA, n_plate * n_somamer), ncol = n_somamer)\nsel_cal &lt;- samples[, \"SampleType\"] == \"Calibrator\"\n\n### New interplate reference\ncal_interplate_ref_N = rep(NA, n_somamer)\n\nfor (i_somamer in 1:n_somamer) {\n    \n    cal_interplate_ref_N[i_somamer] &lt;- median(RFU[[5]][sel_cal, i_somamer])\n    \n    for (i_plate in 1:n_plate) {\n    \n        sel_plate &lt;- samples[, \"PlateId\"] == plates[i_plate]\n    \n        cal_intraplate_ref &lt;- median(RFU[[5]][sel_cal & sel_plate, i_somamer])\n\n        SF_cal[i_plate, i_somamer] &lt;- cal_interplate_ref_N[i_somamer] / cal_intraplate_ref\n        \n        RFU[[5]][sel_plate, i_somamer] &lt;- RFU[[5]][sel_plate, i_somamer] * SF_cal[i_plate, i_somamer]\n    }\n}"
  },
  {
    "objectID": "blog/2024/05/08/index.html#step6-median-signal-normalization-on-all-sample-types",
    "href": "blog/2024/05/08/index.html#step6-median-signal-normalization-on-all-sample-types",
    "title": "Normalization example for SomaLogic proteomic data",
    "section": "Step6: Median signal normalization on all sample types",
    "text": "Step6: Median signal normalization on all sample types\n\nRFU[[6]] &lt;- RFU[[5]]\n\nSF_medNormFull  &lt;- matrix(rep(1, n_sample * n_dilution), ncol = n_dilution)\n\nsample_type &lt;- c(\"QC\", \"Sample\", \"Buffer\", \"Calibrator\")\nn_sampl_type = length(sample_type)\n\nfor (i_sample_type in 1:length(sample_type)) {\n    \n    sample_idx &lt;- which(samples[, \"SampleType\"] == sample_type[i_sample_type])\n    \n    for (i_dilution in 1:n_dilution) {\n\n        sel_somamer &lt;- as.numeric(somamers[, \"Dilution\"]) == dilution[i_dilution]\n        \n        dat &lt;- RFU[[6]][sample_idx, sel_somamer, drop = F]\n        \n        dat2 &lt;- dat\n        \n        for (i in 1:ncol(dat2)) {\n            \n            dat2[, i] &lt;- dat2[, i] / median(dat2[, i])\n        }\n\n        for (i in 1:nrow(dat)) {\n        \n            SF_medNormFull[sample_idx[i], i_dilution] &lt;- 1 / median(dat2[i, ])\n        \n            dat[i, ] = dat[i, ] * SF_medNormFull[sample_idx[i], i_dilution]\n        }\n\n        RFU[[6]][sample_idx, sel_somamer]  &lt;-  dat\n    }\n}"
  },
  {
    "objectID": "blog/2024/05/08/index.html#save-results",
    "href": "blog/2024/05/08/index.html#save-results",
    "title": "Normalization example for SomaLogic proteomic data",
    "section": "Save results",
    "text": "Save results\n\n### Save normalized results\ndir_create(here(dir, \"results\"))\nfor (i_norm in 2:n_norm) {\n    outfile &lt;- path(here(dir, \"results\", paste0(\"RFU_\", norm[i_norm], \".txt\")))\n    write(t(RFU[[i_norm]]), ncol = n_somamer, file = outfile, sep = \"\\t\")\n}\n\n### Save sample scale factors\noutfile &lt;- path(here(dir, \"results\", \"samples_SF.txt\"))\nheader &lt;- c(\n    colnames(samples), \"hyb_scale_factor\", paste0(\"SF_msnCal_d\", dilution_lab), \n    paste0(\"SF_msnAll_d\", dilution_lab)\n)\noutput &lt;- rbind(header, cbind(samples, hyb_scale_factor, SF_medNormInt, SF_medNormFull))\nwrite(t(output), ncol = ncol(output), file = outfile, sep = \"\\t\")\n\n### Save feature scale factor\noutfile &lt;- path(here(dir, \"results\", \"somamers_SF.txt\"))\nheader &lt;- c(\n    colnames(somamers), \"Cal_Interplate_Ref_Pass1\", \"Cal_Interplate_Ref_Pass2\"\n)\noutput &lt;- rbind(\n    header, \n    cbind(somamers, cal_interplate_ref, cal_interplate_ref_N)\n)\nwrite(t(output), ncol = ncol(output), file = outfile, sep = \"\\t\")\n\n### Save plate scale factor\noutfile &lt;- path(here(dir, \"results\", \"plates_SF.txt\"))\nheader &lt;- c(\"Plate\", \"SF_plateScale\", paste0(\"SF_cal_\", somamers[, \"SeqId\"]))\noutput &lt;- rbind(header, cbind(plate, SF_plateScale, SF_cal))\nwrite(t(output), ncol = ncol(output), file = outfile, sep = \"\\t\")"
  },
  {
    "objectID": "blog/2024/05/08/index.html#reference",
    "href": "blog/2024/05/08/index.html#reference",
    "title": "Normalization example for SomaLogic proteomic data",
    "section": "Reference",
    "text": "Reference\n\nAssessment of Variability in the Plasma 7k SomaScan Proteomics Assay"
  },
  {
    "objectID": "blog/2024/06/05/index.html",
    "href": "blog/2024/06/05/index.html",
    "title": "Parallel Processing in R",
    "section": "",
    "text": "library(parallel)\nlibrary(lme4)\n\nLoading required package: Matrix\n### Check the number of cores\ndetectCores()\n\n[1] 8"
  },
  {
    "objectID": "blog/2024/06/05/index.html#reference",
    "href": "blog/2024/06/05/index.html#reference",
    "title": "Parallel Processing in R",
    "section": "Reference",
    "text": "Reference"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Guorui Zhong",
    "section": "",
    "text": "July 1, 2024\n        \n        \n            Simple SVM classification example in R\n\n            \n            \n                \n                \n                    svm\n                \n                \n            \n            \n\n            \n        \n        \n    \n    \n    \n                  \n            June 5, 2024\n        \n        \n            Parallel Processing in R\n\n            \n            \n                \n                \n                    parallel\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            May 11, 2024\n        \n        \n            Plot scatter plot with 2D density\n\n            \n            \n                \n                \n                    density\n                \n                \n            \n            \n\n            2d density plot is helpful for examining the connection between 2 numerical variables. It divides the plot area into several little fragments to prevent overlapping (as in the scatterplot next to it) and shows the number of points in each fragment.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            May 8, 2024\n        \n        \n            Normalization example for SomaLogic proteomic data\n\n            \n            \n                \n                \n                    proteomic\n                \n                \n                \n                    normalization\n                \n                \n            \n            \n\n            Raw SomaScan Assay data may contain systematic biases from many sources, such as variation introduced by the readout, pipetting errors, inherent sample variation, or consumable reagent changes. Standardization is an important  tool for removing nuisance variance\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            April 18, 2024\n        \n        \n            Multiplex image-based phenotypic data analysis\n\n            \n            \n                \n                \n                    mIF\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            April 3, 2024\n        \n        \n            A comprehensive single-cell map of T cell exhaustion-associated immune environments in human breast cancer\n\n            \n            \n                \n                \n                    scrna\n                \n                \n                \n                    paper\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            March 18, 2024\n        \n        \n            Seurat V5 | 10X course example\n\n            \n            \n                \n                \n                    seurat\n                \n                \n                \n                    scrna\n                \n                \n            \n            \n\n            \n        \n        \n    \n    \n    \n                  \n            March 15, 2024\n        \n        \n            Analysis of single cell RNA-seq data with {SingleCellExperiment}\n\n            \n            \n                \n                \n                    scrna\n                \n                \n            \n            \n\n            Using SingleCellExperiment object to analysis single cell data\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            March 13, 2024\n        \n        \n            SingleCellExperiment | Practise Single-cell RNA-seq data analysis\n\n            \n            \n                \n                \n                    scrna\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html#section",
    "href": "blog/index.html#section",
    "title": "Guorui Zhong",
    "section": "",
    "text": "July 1, 2024\n        \n        \n            Simple SVM classification example in R\n\n            \n            \n                \n                \n                    svm\n                \n                \n            \n            \n\n            \n        \n        \n    \n    \n    \n                  \n            June 5, 2024\n        \n        \n            Parallel Processing in R\n\n            \n            \n                \n                \n                    parallel\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            May 11, 2024\n        \n        \n            Plot scatter plot with 2D density\n\n            \n            \n                \n                \n                    density\n                \n                \n            \n            \n\n            2d density plot is helpful for examining the connection between 2 numerical variables. It divides the plot area into several little fragments to prevent overlapping (as in the scatterplot next to it) and shows the number of points in each fragment.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            May 8, 2024\n        \n        \n            Normalization example for SomaLogic proteomic data\n\n            \n            \n                \n                \n                    proteomic\n                \n                \n                \n                    normalization\n                \n                \n            \n            \n\n            Raw SomaScan Assay data may contain systematic biases from many sources, such as variation introduced by the readout, pipetting errors, inherent sample variation, or consumable reagent changes. Standardization is an important  tool for removing nuisance variance\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            April 18, 2024\n        \n        \n            Multiplex image-based phenotypic data analysis\n\n            \n            \n                \n                \n                    mIF\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            April 3, 2024\n        \n        \n            A comprehensive single-cell map of T cell exhaustion-associated immune environments in human breast cancer\n\n            \n            \n                \n                \n                    scrna\n                \n                \n                \n                    paper\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            March 18, 2024\n        \n        \n            Seurat V5 | 10X course example\n\n            \n            \n                \n                \n                    seurat\n                \n                \n                \n                    scrna\n                \n                \n            \n            \n\n            \n        \n        \n    \n    \n    \n                  \n            March 15, 2024\n        \n        \n            Analysis of single cell RNA-seq data with {SingleCellExperiment}\n\n            \n            \n                \n                \n                    scrna\n                \n                \n            \n            \n\n            Using SingleCellExperiment object to analysis single cell data\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            March 13, 2024\n        \n        \n            SingleCellExperiment | Practise Single-cell RNA-seq data analysis\n\n            \n            \n                \n                \n                    scrna\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html#section-1",
    "href": "blog/index.html#section-1",
    "title": "Guorui Zhong",
    "section": "2023",
    "text": "2023\n\n\n    \n    \n                  \n            December 8, 2023\n        \n        \n            Pseudobulk differential expression analysis\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    scrna\n                \n                \n                \n                    pseudobulk\n                \n                \n            \n            \n\n            \n        \n        \n    \n    \n    \n                  \n            December 3, 2023\n        \n        \n            Save ggplot2 plots with custom fonts using Cairo graphics across OS\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    ggplot2\n                \n                \n                \n                    cairo\n                \n                \n            \n            \n\n            The Cairo graphics library makes it easy to embed custom fonts in PDFs and create high resolution PNGs (with either AGG or Cairo).\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            December 2, 2023\n        \n        \n            Customization of Seurat plots using ggplot2\n\n            \n            \n                \n                \n                    seurat\n                \n                \n                \n                    ggplot2\n                \n                \n            \n            \n\n            The DimPlot, FeaturePlot, Dotplot, VlnPlot, and DoHeatmap from Seurat can be further customized with ggplot2.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            December 1, 2023\n        \n        \n            Use colorblind-friendly palette for visualization\n\n            \n            \n                \n                \n                    colors\n                \n                \n                \n                    ggplot2\n                \n                \n            \n            \n\n            Use ggplot2 to make nice coordinate, colors, and size with friendly colors.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            November 29, 2023\n        \n        \n            Visual the usage of CPU and memory with htop\n\n            \n            \n                \n                \n                    linux\n                \n                \n            \n            \n\n            htop is an interactive process viewer and system monitor.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            November 27, 2023\n        \n        \n            Practise Seurat for single cell data analysis\n\n            \n            \n                \n                \n                    seurat\n                \n                \n            \n            \n\n            Practise scRNA data analysis with Genome Medicine using Seurat package.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            November 26, 2023\n        \n        \n            Learning Harmony to integrate single cell RNA-seq data for batch borrection and meta analysis\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    scRNA-seq\n                \n                \n            \n            \n\n            Harmony allow integrating data across several variables (for example, by experimental batch and by condition),  and significant gain in speed and lower memory requirements for integration of large datasets.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            November 25, 2023\n        \n        \n            Learning Seruat for scRNA-seq data analysis\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    seurat\n                \n                \n                \n                    scRNA-seq\n                \n                \n            \n            \n\n            The package that must to learn for scRNA-seq data analysis.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            November 13, 2023\n        \n        \n            Using ggbeeswarm plot to represent categorical data\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    ggbeeswarm\n                \n                \n            \n            \n\n            The plot shows all data points with a color-code for each replicate, as well as the averages of each replicate, the total average and the SEM.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            November 3, 2023\n        \n        \n            Best Practise for R programming\n\n            \n            \n                \n                \n                    r\n                \n                \n            \n            \n\n            \n        \n        \n    \n    \n    \n                  \n            October 1, 2023\n        \n        \n            General understanding of scRNA-seq data analysis\n\n            \n            \n                \n                \n                    scRNA-seq\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            August 11, 2023\n        \n        \n            Commonly used Vim commands\n\n            \n            \n                \n                \n                    vim\n                \n                \n                \n                    linux\n                \n                \n            \n            \n\n            a list of essential Vim commands that could be used every day\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            August 9, 2023\n        \n        \n            Combat to remove batch effects in high-throughput experiments\n\n            \n            \n                \n                \n                    batch effect\n                \n                \n            \n            \n\n            Comat models batch effects as multiplicative and additive noise to the biological signal and uses a Bayesian framework to fit linear models that factor such noise out of the readouts.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            August 8, 2023\n        \n        \n            Using renv to manage R environment for reproducible coding\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    renv\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            August 7, 2023\n        \n        \n            Install Conda to manage R/Python environments and packages\n\n            \n            \n                \n                \n                    linux\n                \n                \n                \n                    conda\n                \n                \n            \n            \n\n            Sometimes, We need to install R in the Linux server, but we don't the root permission\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            July 5, 2023\n        \n        \n            Learning [ropls] for multivariate analysis and feature selection of omics data\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    pca\n                \n                \n                \n                    plsda\n                \n                \n                \n                    supervised\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            July 4, 2023\n        \n        \n            Analyze Omics data using [structToolbox]\n\n            \n            \n                \n                \n                    r\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            June 8, 2023\n        \n        \n            Regular expression with R\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    regex\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            May 28, 2023\n        \n        \n            Tips for using shapes for ggplot2\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    ggplot2\n                \n                \n                \n                    shapes\n                \n                \n            \n            \n\n            Change ggplot point shape values. Use special point shapes, including pch 21 and pch 24. The interesting feature of these point symbols is that you can change their background fill color and, their border line type and color\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            May 28, 2023\n        \n        \n            PCA, PLS-DA and OPLS-DA analysis using [ropls]\n\n            \n            \n                \n                \n                    plsda\n                \n                \n                \n                    supervised\n                \n                \n            \n            \n\n            \n        \n        \n    \n    \n    \n                  \n            May 18, 2023\n        \n        \n            PCA Graph Customization\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    pca\n                \n                \n                \n                    unsupervised\n                \n                \n                \n                    dimensional reduction\n                \n                \n            \n            \n\n            Arguments to customize the PCA graph of variables and individuals.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            May 17, 2023\n        \n        \n            Perform Principal Component Analysis\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    pca\n                \n                \n                \n                    unsupervised\n                \n                \n                \n                    dimensional reduction\n                \n                \n            \n            \n\n            Principle component methods are used to summarize and viusalize the information contained in a large multivariate datasets.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            May 3, 2023\n        \n        \n            Make heatmap using ComplexHeatmap\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    complexheatmap\n                \n                \n                \n                    unsupervised\n                \n                \n            \n            \n\n            Heatmap (or heat map) is way to visualize hierarchical clustering. It’s also called a false colored image, where data values are transformed to color scale.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            April 10, 2023\n        \n        \n            Using Tmux and Screen for Persistent Terminal in VSCode Remote Session\n\n            \n            \n                \n                \n                    linux\n                \n                \n                \n                    tmux\n                \n                \n                \n                    screen\n                \n                \n            \n            \n\n            The solution is to set the default terminal provider on the remote settings to be tmux, and have it attach to either an existing session named main, or create a new one if it doesn't exist.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            April 5, 2023\n        \n        \n            The best way to perform feature scaling using R\n\n            \n            \n                \n                \n                    r\n                \n                \n            \n            \n\n            Data normalization methods are used to make variables, measured in different scales, have comparable values. This preprocessing steps is important for clustering and heatmap visualization, principal component analysis and other machine learning algorithms based on distance measures.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            March 31, 2023\n        \n        \n            Add p-value and significant level at facet boxplot\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    p-value\n                \n                \n                \n                    ggplot2\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            March 30, 2023\n        \n        \n            Add p-values onto basic barplot or boxplot\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    ggplot2\n                \n                \n                \n                    p-value\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            March 11, 2023\n        \n        \n            Barplot with negative and positive value\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    barplot\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            March 8, 2023\n        \n        \n            Ridgeline plots in ggplot2\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    ggplot2\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            March 6, 2023\n        \n        \n            Equalizing Bar Widths\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    ggplot2\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            March 6, 2023\n        \n        \n            ggplot2 with p-value and significant level\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    p-value\n                \n                \n                \n                    ggplot2\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            March 5, 2023\n        \n        \n            Scatter plot with ggplot2\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    ggplot2\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html#section-2",
    "href": "blog/index.html#section-2",
    "title": "Guorui Zhong",
    "section": "2022",
    "text": "2022\n\n\n    \n    \n                  \n            December 24, 2022\n        \n        \n            Setup SSH to work in remote server\n\n            \n            \n                \n                \n                    linux\n                \n                \n                \n                    ssh\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            December 23, 2022\n        \n        \n            VSCode Keyboard Shortcut Cheat Sheet\n\n            \n            \n                \n                \n                    vscode\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            December 20, 2022\n        \n        \n            Using R in VSCode\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    vscode\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            December 19, 2022\n        \n        \n            Learn Linux basic for computing\n\n            \n            \n                \n                \n                    linux\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            December 18, 2022\n        \n        \n            ggplot2 Theme Elements\n\n            \n            \n                \n                \n                    ggplot2\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            October 1, 2022\n        \n        \n            Nomenclature for the description of mutations and variations\n\n            \n            \n                \n                \n                    mutation\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            August 1, 2022\n        \n        \n            View data from 96/384 multi-well plates\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    plate\n                \n                \n            \n            \n\n            plater makes it easy to work with data from experiments performed in plates.\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            May 2, 2022\n        \n        \n            Make scatter plot with truncated axis\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    ggplot2\n                \n                \n            \n            \n\n            Make scatter plot more beautiful with truncated axis\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            February 1, 2022\n        \n        \n            Add errorbar and p-value on barplot with ggsignif\n\n            \n            \n                \n                \n                    barplot\n                \n                \n                \n                    p-value\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            January 22, 2022\n        \n        \n            Use colorblind-friendly palette for visualization\n\n            \n            \n                \n                \n                    colors\n                \n                \n            \n            \n\n            Use friendly colors in a graph with ggplot2\n        \n        \n        \n            \n        \n        \n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html#section-3",
    "href": "blog/index.html#section-3",
    "title": "Guorui Zhong",
    "section": "2021",
    "text": "2021\n\n\n    \n    \n                  \n            June 1, 2021\n        \n        \n            Using greek unicode in Inkscape\n\n            \n            \n                \n                \n                    inkscape\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            March 16, 2021\n        \n        \n            Crop image and add scale bar with ImageJ/Fiji\n\n            \n            \n                \n                \n                    imagej\n                \n                \n            \n            \n\n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            February 1, 2021\n        \n        \n            Punctuation marks words\n\n            \n            \n                \n                \n                    punctuation\n                \n                \n            \n            \n\n            I don't know why i can not remember this English punctuation marks\n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            January 2, 2021\n        \n        \n            Markdown input greek letters\n\n            \n            \n                \n                \n                    markdown\n                \n                \n            \n            \n\n            Commonly used greek letters when using markdown\n        \n        \n        \n            \n        \n        \n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "imaging/index.html",
    "href": "imaging/index.html",
    "title": "Spatial",
    "section": "",
    "text": "Enabling technologies from : Seferbekova, Zaira, Artem Lomakin, Lucy R. Yates, and Moritz Gerstung. “Spatial Biology of Cancer Evolution.” Nature Reviews Genetics 24, no. 5 (May 2023): 295–313. https://doi.org/10.1038/s41576-022-00553-x.\n\n\n\nBaSISS, base-specific ISS;\nCODEX, co-detection by indexing;\ncorrFISH, correlation FISH;\nDBiT-seq, deterministic barcoding in tissue for spatial omics sequencing;\nepiMERFISH, epigenetic MERFISH; FISSEQ, fluorescent ISS; HDST, high-definition spatial transcriptomics;\nhybISS, hybridization-based ISS;\nImmunoSABER, immunostaining with signal amplification by exchange reaction;\nMIBI-TOF, MIBI by time of flight;\nosmFISH, ouroboros smFISH, pciSeq, probabilistic cell typing by ISS;\nsmFISH, single-molecule FISH; ST, spatial transcriptomics;\nSTARmap, spatially resolved transcript amplicon readout mapping;\nStereo-seq, spatial enhanced resolution omics sequencing;\nTSCS, topographic single-cell sequencing; Visium HD, Visium high definition.\n\n\n\n\nSpatial omic analysis from : Seferbekova, Zaira, Artem Lomakin, Lucy R. Yates, and Moritz Gerstung. “Spatial Biology of Cancer Evolution.” Nature Reviews Genetics 24, no. 5 (May 2023): 295–313. https://doi.org/10.1038/s41576-022-00553-x."
  },
  {
    "objectID": "imaging/index.html#latest-review",
    "href": "imaging/index.html#latest-review",
    "title": "Spatial",
    "section": "",
    "text": "Enabling technologies from : Seferbekova, Zaira, Artem Lomakin, Lucy R. Yates, and Moritz Gerstung. “Spatial Biology of Cancer Evolution.” Nature Reviews Genetics 24, no. 5 (May 2023): 295–313. https://doi.org/10.1038/s41576-022-00553-x.\n\n\n\nBaSISS, base-specific ISS;\nCODEX, co-detection by indexing;\ncorrFISH, correlation FISH;\nDBiT-seq, deterministic barcoding in tissue for spatial omics sequencing;\nepiMERFISH, epigenetic MERFISH; FISSEQ, fluorescent ISS; HDST, high-definition spatial transcriptomics;\nhybISS, hybridization-based ISS;\nImmunoSABER, immunostaining with signal amplification by exchange reaction;\nMIBI-TOF, MIBI by time of flight;\nosmFISH, ouroboros smFISH, pciSeq, probabilistic cell typing by ISS;\nsmFISH, single-molecule FISH; ST, spatial transcriptomics;\nSTARmap, spatially resolved transcript amplicon readout mapping;\nStereo-seq, spatial enhanced resolution omics sequencing;\nTSCS, topographic single-cell sequencing; Visium HD, Visium high definition.\n\n\n\n\nSpatial omic analysis from : Seferbekova, Zaira, Artem Lomakin, Lucy R. Yates, and Moritz Gerstung. “Spatial Biology of Cancer Evolution.” Nature Reviews Genetics 24, no. 5 (May 2023): 295–313. https://doi.org/10.1038/s41576-022-00553-x."
  },
  {
    "objectID": "imaging/index.html#motivation",
    "href": "imaging/index.html#motivation",
    "title": "Spatial",
    "section": "Motivation",
    "text": "Motivation\n\nImaging-based phenotypic profiling enables systematic quantification of complex cellular phenotypes and tissue organizations under different treatment and disease conditions.\nCompare the morphology of cells from patients with and without disease, if we can find a difference in their profiles, this can serve as a diagnostic tool.\nEven better, we can test thousands of drugs to find any that are able to reverse the disease profile and make cells looks healthy again."
  },
  {
    "objectID": "imaging/index.html#typical-analysis-workflow",
    "href": "imaging/index.html#typical-analysis-workflow",
    "title": "Spatial",
    "section": "Typical Analysis workflow",
    "text": "Typical Analysis workflow\n\nStep1: Image analysis\nStep2: Image quality control\nStep3: Preprocessing extracted features\nStep4: Dimensionality reduction\nStep5: Single-cell data aggregation\nStep6: Measuring profile similarity\nStep7: Assay quality assessment\nStep8: Downstream analysis"
  },
  {
    "objectID": "imaging/index.html#reference",
    "href": "imaging/index.html#reference",
    "title": "Spatial",
    "section": "Reference",
    "text": "Reference\n\nAnne Carpenter - CellProfiler software- Image-Based Cell Profiling\nImage-Based Cell Profiling and Data Analysis\nAnalysis workflow for IMC data"
  },
  {
    "objectID": "now/index.html",
    "href": "now/index.html",
    "title": "Now",
    "section": "",
    "text": "Living in Singapore and working as an research fellow in the Complex Phenotype Analysis Group at the Bioinformatics institute (BII), A*STAR.\n\nEarning money to marry Miss Zhou Haiyan (She is doing her Ph.D in University of Hong Kong).\nLearning High-throughput phenotypic profiling from mentor Dr. Loo Lit-Hsin.\nLearning to write papers, grants and apply grant for independent research.\nImproving R coding skills."
  },
  {
    "objectID": "now/index.html#section",
    "href": "now/index.html#section",
    "title": "Now",
    "section": "",
    "text": "Living in Singapore and working as an research fellow in the Complex Phenotype Analysis Group at the Bioinformatics institute (BII), A*STAR.\n\nEarning money to marry Miss Zhou Haiyan (She is doing her Ph.D in University of Hong Kong).\nLearning High-throughput phenotypic profiling from mentor Dr. Loo Lit-Hsin.\nLearning to write papers, grants and apply grant for independent research.\nImproving R coding skills."
  },
  {
    "objectID": "r/index.html",
    "href": "r/index.html",
    "title": "R Programming",
    "section": "",
    "text": "dir()                            # Show the directory\ngetwd()                          # Check working directory\nsetwd()                          # Change working directory\ndata()                           # Load built-in dataset\nview()                           # View the entire dataset\ntail()                           # Just show the last 6 rows\nclass()                          # Check the class of an R object\nstr()                            # Display internal structure of an R object\nlength()                         # Give length of a vector\ndim()                            # View the number of rows and columns of a matrix or a data frame\nnames()                          # List names of variables in a data frame\nset.seed()                       # Generate random number seed to make sure the results do not change.\nls()                             # list the variables in the workspace\nrm()                             # remove the variable from workspace\nrm(list = ls())                  # remove all the variables from the workspace\nlist.files()                     # List the filename under specific directory\n.libPaths()                      # R installation site\nhelp(package=\"\")                 # Check the functions of R library\nsystem.file(package=“dagdata”)   # Extract the location of package\ncolnames(installed.packages())   # list the installed packages"
  },
  {
    "objectID": "r/index.html#basic-concepts",
    "href": "r/index.html#basic-concepts",
    "title": "R Programming",
    "section": "",
    "text": "dir()                            # Show the directory\ngetwd()                          # Check working directory\nsetwd()                          # Change working directory\ndata()                           # Load built-in dataset\nview()                           # View the entire dataset\ntail()                           # Just show the last 6 rows\nclass()                          # Check the class of an R object\nstr()                            # Display internal structure of an R object\nlength()                         # Give length of a vector\ndim()                            # View the number of rows and columns of a matrix or a data frame\nnames()                          # List names of variables in a data frame\nset.seed()                       # Generate random number seed to make sure the results do not change.\nls()                             # list the variables in the workspace\nrm()                             # remove the variable from workspace\nrm(list = ls())                  # remove all the variables from the workspace\nlist.files()                     # List the filename under specific directory\n.libPaths()                      # R installation site\nhelp(package=\"\")                 # Check the functions of R library\nsystem.file(package=“dagdata”)   # Extract the location of package\ncolnames(installed.packages())   # list the installed packages"
  },
  {
    "objectID": "r/index.html#best-practise-for-r-coding",
    "href": "r/index.html#best-practise-for-r-coding",
    "title": "R Programming",
    "section": "Best practise for R coding",
    "text": "Best practise for R coding\n\nVariables = my_variable\nFunctions = RunThisStuffs()\nConstants = CONSTANTS\nUse 4 spaces (and not tab) for indentations\nAlways writing documentation above function definition\nA function should not be longer than one screen\nAvoid using for loop, learn lapply and vector operations\nNever ever use hard-coded variables in functions\n\n### ====== to divide function blocks\n\n### ------ to divide parts in a function\nName and style code consistently\n\nrm(list =ls()) and gc() to tidy up its memory\nDon’t save a session history\nKeep track of sessionInfo() in project folder\nUse version control"
  },
  {
    "objectID": "r/index.html#ggplot2-variable-repacement",
    "href": "r/index.html#ggplot2-variable-repacement",
    "title": "R Programming",
    "section": "ggplot2 Variable repacement",
    "text": "ggplot2 Variable repacement\n!!as.name(), get(), !!sym(), .data[[]]\n\nlibrary(ggplot2)\ndata &lt;- data.frame(\n  x = c(1, 2, 3, 4),\n  y = c(10, 20, 30, 40),\n  group = c(\"A\", \"A\", \"B\", \"B\")\n)\n\ncolor_var &lt;- \"group\"\nggplot(data, aes(x = x, y = y, color = !!as.name(color_var))) +\n  geom_point()\n  \nggplot(data, aes(x = x, y = y, color = get(color_var))) +\n  geom_point()\n\n\nggplot(data, aes(x = x, y = y, color = !!sym(color_var))) +\n  geom_point()\n\nggplot(data, aes(x = x, y = y, color = .data[[color_var]])) +\n  geom_point()"
  },
  {
    "objectID": "r/index.html#reference",
    "href": "r/index.html#reference",
    "title": "R Programming",
    "section": "Reference",
    "text": "Reference\n\nAn Introduction to Statistical Learning\nR for Data Science (2e)\nR Graphics Cookbook, 2nd edition\nAdvanced R\nggplot2: Elegant Graphics for Data Analysis\nFunctional Programming\nThe Epidemiologist R Handbook\nModern Statistics for Modern Biology\nData Analysis and Prediction Algorithms with R\nBioinformatics Training & Education Program\nSaving R Graphics across OSs\nTutorial on Advanced Stats and Machine Learning with R\nPublication ready plots using ggpubr\ndatanovia\nData Analysis in Genome Biology\nData Viz with Python and R\nPH525x series - Biomedical Data Science"
  },
  {
    "objectID": "terms/index.html",
    "href": "terms/index.html",
    "title": "Terms",
    "section": "",
    "text": "Likely pathogenic/benign\n“likely pathogenic” and “likely benign” be used to mean greater than 90% certainty of a variant either being disease- causing or benign\nIt should also be noted that at present most variants do not have data to support a quan- titative assignment of variant certainty to any of the five cat- egories given the heterogeneous nature of most diseases.\n\n\nMutation\nMutation is defined as a permanent change in the nucleotide sequence.\n\n\nPolymorphism\nPolymorphism is defined as a vari- ant with a frequency above 1%."
  },
  {
    "objectID": "wiki/index.html",
    "href": "wiki/index.html",
    "title": "Wiki",
    "section": "",
    "text": "These are the collections of things that I beleived useful in my daily researh work."
  },
  {
    "objectID": "wiki/index.html#to-be-a-biologist",
    "href": "wiki/index.html#to-be-a-biologist",
    "title": "Wiki",
    "section": "To be a biologist",
    "text": "To be a biologist\n\nBioturing\niBiology - Bringing the world’s best biology to you, for free!\nSequence Variant Nomenclature\nEncyclopedia Britannica\nLabpedia.net\nThe bumbling chemist\nToxTutor"
  },
  {
    "objectID": "wiki/index.html#researh-labs",
    "href": "wiki/index.html#researh-labs",
    "title": "Wiki",
    "section": "Researh Labs",
    "text": "Researh Labs\n\nhttps://www.jax.org - Leading the research for tomorrow’s cures\nhttps://www.snijderlab.org/ - Use systems biology to discover things about cells.\nhttps://zlab.bio/ - Zhang Feng Biological Discovery & Engineering\nhttps://www.ciccialab.com/ - Genome Integrity and Genome Editing\nhttps://sizunjianglab.com - Investigate host-disease interaction\nhttp://rafalab.dfci.harvard.edu/ - Development of statistical tools\nhttps://hostmicrobe.org/ - Study the biological basis of diseases caused by microbes\nhttps://cheesemanlab.wi.mit.edu/ - World of cell division\nhttps://blainey.mit.edu/ - Pooled optical genetic screening in human cells\nhttps://marsonlab.org/ - Decoding and rewriting human immune cells with CRISPR\nhttps://liulab-dfci.github.io/ - Computational methods for the design (SSC), analysis (MAGeCK), hit prioritization (NEST), and visualization (VISPR) of genome-wide CRISPR screens\nStatistical Bioinformatics Lab"
  },
  {
    "objectID": "wiki/index.html#research-proposal",
    "href": "wiki/index.html#research-proposal",
    "title": "Wiki",
    "section": "Research Proposal",
    "text": "Research Proposal\n\nNMRC | Open Fund - Young Individual Research Grant\nFunding Opportunities - Abramson Cancer Center | Penn Medicine\nWrite Your Research Plan"
  },
  {
    "objectID": "wiki/index.html#paper-writting",
    "href": "wiki/index.html#paper-writting",
    "title": "Wiki",
    "section": "Paper writting",
    "text": "Paper writting\n\nThe underappreciated art of creating publication-quality figures"
  },
  {
    "objectID": "wiki/index.html#useful-tools",
    "href": "wiki/index.html#useful-tools",
    "title": "Wiki",
    "section": "Useful Tools",
    "text": "Useful Tools\n\nDIY.transcriptomics\nProteinPaint\nHiplot\nFree Icons and Stickers\nBootstrap Icons\nBlood PBMCs\ndistill"
  },
  {
    "objectID": "wiki/index.html#learning-r",
    "href": "wiki/index.html#learning-r",
    "title": "Wiki",
    "section": "Learning R",
    "text": "Learning R\n\nAn Introduction to Statistical Learning\nR for Data Science (2e)\nR Graphics Cookbook, 2nd edition\nAdvanced R\nggplot2: Elegant Graphics for Data Analysis\nThe Epidemiologist R Handbook\nModern Statistics for Modern Biology\nData Analysis and Prediction Algorithms with R\nBioinformatics Training & Education Program\nSaving R Graphics across OSs\nTutorial on Advanced Stats and Machine Learning with R\nPublication ready plots using ggpubr\ndatanovia\nData Analysis in Genome Biology\nData Viz with Python and R"
  },
  {
    "objectID": "wiki/index.html#bioinformatics-training",
    "href": "wiki/index.html#bioinformatics-training",
    "title": "Wiki",
    "section": "Bioinformatics Training",
    "text": "Bioinformatics Training\n\nBioinformatics for Biologists\nNational Cancer Institute: Bioinformatics Training & Education Program\nHigh dimensional statistics with R Introduction to high-dimensional data\nBioinformatics Training at the Harvard Chan Bioinformatics Core"
  },
  {
    "objectID": "wiki/index.html#nice-blogs",
    "href": "wiki/index.html#nice-blogs",
    "title": "Wiki",
    "section": "Nice Blogs",
    "text": "Nice Blogs\n\nhttps://www.andrewheiss.com/blog/\nhttps://www.andreashandel.com/\nhttps://renkun.me/\nhttps://morphoscape.wordpress.com/category/tech/\nhttps://albert-rapp.de/\nhttps://jokergoo.github.io/\n&lt;&gt;"
  },
  {
    "objectID": "wiki/index.html#books",
    "href": "wiki/index.html#books",
    "title": "Wiki",
    "section": "Books",
    "text": "Books\n\nR for Data science\nR Graphics Cookbook, 2nd edition\nggplot2: Elegant Graphics for Data Analysis\nModern Statistics for Modern Biology\nAn Introduction to Statistical Learning\nFunctional Programming\nThe Epidemiologist R Handbook\nData Analysis and Prediction Algorithms with R\nData Analysis in Genome Biology\nPH525x series - Biomedical Data Science"
  },
  {
    "objectID": "blog/2021/02/01/index.html",
    "href": "blog/2021/02/01/index.html",
    "title": "Punctuation marks words",
    "section": "",
    "text": "Full Stop / Period (.)\nComma (,)\nQuestion Mark (?)\nExclamation Mark (!)\nQuotation Marks / Speech Marks (” “)\nApostrophe (’)\nHyphen (-)\nDash (– or —)\nColon (:)\nSemicolon (;)\nParentheses ()\nBrackets []\nEllipsis (…)\nSlash (/)"
  },
  {
    "objectID": "blog/2021/06/01/index.html",
    "href": "blog/2021/06/01/index.html",
    "title": "Using greek unicode in Inkscape",
    "section": "",
    "text": "To get Greek letters in Inkscape, go into text mode and type Ctrl+U and the 4-digit unicode for the desired Greek letter.\n\n\n\ngreekscape"
  },
  {
    "objectID": "blog/2022/12/18/index.html",
    "href": "blog/2022/12/18/index.html",
    "title": "ggplot2 Theme Elements",
    "section": "",
    "text": "Modify components of a theme: https://ggplot2.tidyverse.org/reference/theme"
  },
  {
    "objectID": "blog/2022/12/18/index.html#design-concept-of-ggplot2",
    "href": "blog/2022/12/18/index.html#design-concept-of-ggplot2",
    "title": "ggplot2 Theme Elements",
    "section": "Design Concept of ggplot2",
    "text": "Design Concept of ggplot2\n\nTheme: styles to be used, such as fonts, backgrounds, etc.\nCoordinates: the plotting space\nStatistics: data models and summaries\nFacets: row and column layout of sub-plots\nGeometries: shapes used to represent data (e.g. bar or scatter plot)\nAesthetics: the scales onto which the data will be mapped\nData: the actual data to be plotted"
  },
  {
    "objectID": "blog/2022/12/18/index.html#reference-sheet",
    "href": "blog/2022/12/18/index.html#reference-sheet",
    "title": "ggplot2 Theme Elements",
    "section": "Reference sheet",
    "text": "Reference sheet\n \n\nGraphics and Data Visualization in R\nggplot2 Theme Elements Reference Sheet\nggplot2 Theme Elements Demonstration"
  },
  {
    "objectID": "blog/2022/12/20/index.html",
    "href": "blog/2022/12/20/index.html",
    "title": "Using R in VSCode",
    "section": "",
    "text": "The details refer to: https://github.com/REditorSupport/vscode-R\n\n\nInstall r packages\npacman::p_load(\n    jsonlite,\n    rlang,\n    languageserver, \n    httpgd,\n    IRkernel,\n    rmarkdown\n)\n### A modern R console from python\npip install -U radian\n\n\nIntall VSCode extensions\n\nvscode-R\nR Debugger\nError lens\nLive Preview\nvscode-pdf\nvscode-icons\nRemote Development\nLiveShare\nExcel Viewer\nProject Manager\nQuarto\nPath Intellisense\nCodesnap\n\nGit Graph\n\n\n\nSSH using Keys\nopen Users/zhonggr/.ssh/config, add the following\nHost nucleus\n    HostName 172.20.***.** ## host ip address\n    User zhonggr\n\n\nUser Settings\n\nUser settings.json:\n\n{ \"files.associations\": {\n        \"*.Rmd\": \"rmd\",\n        \"*.R\": \"r\"\n    },\n    \"security.workspace.trust.untrustedFiles\": \"open\",\n    \"editor.fontSize\": 14,\n    \"editor.rulers\": [80],\n    \"explorer.confirmDelete\": false,\n    \"r.rterm.mac\": \"/opt/homebrew/bin/radian\",\n    // \"r.rterm.mac\": \"/opt/homebrew/Caskroom/miniforge/base/bin/radian\",\n    \"r.rpath.mac\": \"/usr/local/bin/R\",\n    // \"r.rpath.mac\": \"/opt/homebrew/Caskroom/miniforge/base/bin/R\",\n    // \"r.rterm.windows\": \"C:\\\\Program Files\\\\R\\\\R-4.2.1\\\\bin\\\\R.exe\",\n    \"r.rterm.windows\": \"C:\\\\Users\\\\zhonggr\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Scripts\\\\radian.exe\",\n    \"r.rpath.windows\": \"C:\\\\Program Files\\\\R\\\\R-4.2.1\\\\bin\\\\R.exe\",\n    \"r.plot.useHttpgd\": true,\n    \"r.rterm.option\": [],\n    \"r.bracketedPaste\": true,\n    \"r.sessionWatcher\": true,\n    \"r.alwaysUseActiveTerminal\": true,\n    \"quarto.render.previewType\": \"external\",\n    // \"terminal.integrated.fontSize\": 15,\n    // \"terminal.integrated.defaultProfile.windows\": \"Git Bash\",\n    \"terminal.integrated.defaultProfile.windows\": \"R Terminal\",\n    // \"terminal.integrated.defaultProfile.osx\": \"R Terminal\",\n    \"terminal.integrated.defaultProfile.osx\": \"zsh\",\n    \"workbench.iconTheme\": \"vscode-icons\",\n    \"r.helpPanel.cacheIndexFiles\": \"Global\",\n    \"workbench.preferredDarkColorTheme\": \"Monokai\",\n    \"workbench.preferredHighContrastColorTheme\": \"GitHub Dark Default\",\n    \"r.rmarkdown.chunkBackgroundColor\": \"\",\n    \"workbench.colorTheme\": \"GitHub Dark\",\n    \"liveServer.settings.donotShowInfoMsg\": true,\n    \"workbench.tree.indent\": 25,\n    \"python.analysis.completeFunctionParens\": true,\n    \"editor.minimap.enabled\": false,\n    \"explorer.confirmDragAndDrop\": false,\n    \"window.restoreWindows\": \"none\",\n    \"remote.SSH.remotePlatform\": {\n        \"nucleus\": \"linux\"\n    },\n    \"editor.guides.bracketPairs\": true,\n    \"workbench.colorCustomizations\": {\n        \"editorBracketHighlight.foreground1\": \"#5bb3b3\",\n        \"editorBracketHighlight.foreground2\": \"#fac863\",\n        \"editorBracketHighlight.foreground3\": \"#f99157\",\n        \"editorBracketHighlight.foreground4\": \"#ec5f67\",\n        \"editorBracketHighlight.foreground5\": \"#bb80b3\",\n        \"editorBracketHighlight.foreground6\": \"#98C379\",\n    },\n    \"editor.parameterHints.enabled\": false,\n    \"task.quickOpen.history\": 3,\n    \"terminal.integrated.tabs.enableAnimation\": false,\n    \"terminal.integrated.tabs.enabled\": false,\n    \"terminal.integrated.fontSize\": 13,\n    \"editor.acceptSuggestionOnEnter\": \"off\",\n    \"editor.tabCompletion\": \"on\",\n    \"editor.guides.indentation\": false,\n    \"vsicons.dontShowNewVersionMessage\": true,\n    \"files.exclude\": {\n        \"**/.git\": true,\n        \"**/.svn\": true,\n        \"**/.hg\": true,\n        \"**/CVS\": true,\n        \"**/.DS_Store\": true,\n        \"**/Thumbs.db\": true\n\n    }\n}\n\n\nRemote Server Settings\n[SSH:nucleus] settings.json\n{\n    \"r.rterm.linux\": \"/home/zhonggr/.local/bin/radian\",\n    // \"r.rterm.linux\": \"/bin/R\",\n    \"r.rpath.linux\": \"/bin/R\",\n    \"r.alwaysUseActiveTerminal\": true,\n    \"r.bracketedPaste\": true,\n    \"r.sessionWatcher\": true,\n    // \"terminal.integrated.defaultProfile.linux\": \"R Terminal\",\n    // \"terminal.integrated.defaultProfile.linux\": \"tmux\",\n    \"terminal.integrated.defaultProfile.linux\": \"bash\",\n    \"r.plot.useHttpgd\": true\n}\n\n\nKeyboard Shortcuts\n// April 09, 2023 updated\n[\n    {\n        \"key\": \"alt+-\",\n        \"command\": \"type\",\n        // \"when\": \"editorLangId == r && editorTextFocus || editorLangId == rmd && editorTextFocus\",\n        // if you want using quarto, try this\n        \"when\": \"editorLangId =~ /r|rmd|qmd/ && editorTextFocus\",\n        \"args\": {\n            \"text\": \" &lt;- \"\n        }\n    },\n    {\n        \"key\": \"ctrl+shift+m\",\n        \"command\": \"type\",\n        // \"when\": \"editorLangId == r && editorTextFocus || editorLangId == rmd && editorTextFocus\",\n        \"when\": \"editorLangId =~ /r|rmd|qmd/ && editorTextFocus\",\n        \"args\": {\n            \"text\": \" |&gt; \"\n        }\n    },\n    {\n        \"key\": \"ctrl+shift+m\",\n        \"command\": \"-workbench.actions.view.problems\"\n    },\n    // input indicative of r markdown code chunk\n    {\n        \"key\": \"ctrl+shift+i\",\n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus && editorLangId == 'rmd'\",\n        \"args\": {\n            \"snippet\": \"```{r}\\n${TM_SELECTED_TEXT}$0\\n```\"\n        },\n        \"label\": \"input indicative of r markdown code chunk\"\n    },\n    // you can also input indicative of code chunk in `r` file by inserting \"# %% \":\n    // specifics in `https://github.com/REditorSupport/vscode-R/pull/662`\n    {\n        \"key\": \"ctrl+shift+i\",\n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus && editorLangId == 'r'\",\n        \"args\": {\n            \"snippet\": \"$LINE_COMMENT %% \"\n        },\n        \"label\": \"input indicative of code chunk\"\n    },\n    // open help panel for selection\n    {\n        \"key\": \"f1\",\n        \"command\": \"r.helpPanel.openForSelection\",\n        \"when\": \"editorTextFocus && editorLangId == 'r' || editorTextFocus && editorLangId == 'rmd'\"\n    },\n    // RStudio keybinding for R Package development\n    // {\n    //     \"key\": \"ctrl+shift+b\",\n    //     \"command\": \"r.install\",\n    //     \"when\": \"resourceLangId == 'r'\"\n    // },\n    // {\n    //     \"key\": \"ctrl+shift+e\",\n    //     \"command\": \"r.check\",\n    //     \"when\": \"resourceLangId == 'r'\"\n    // },\n    // {\n    //     \"key\": \"ctrl+shift+t\",\n    //     \"command\": \"r.test\",\n    //     \"when\": \"resourceLangId == 'r'\"\n    // },\n    // {\n    //     \"key\": \"ctrl+shift+d\",\n    //     \"command\": \"r.document\",\n    //     \"when\": \"resourceLangId == 'r'\"\n    // },\n    // {\n    //     \"key\": \"ctrl+shift+l\",\n    //     \"command\": \"r.loadAll\",\n    //     \"when\": \"resourceLangId == 'r'\"\n    // },\n    {\n        \"key\": \"ctrl+alt+p\",\n        \"command\": \"r.runCommand\",\n        \"when\": \"editorTextFocus && editorLangId == 'r'\",\n        \"args\": \".vsc.browser(httpgd::hgd_url(), viewer = \\\"Beside\\\")\"\n    },\n    // terminal settings\n    {\n        \"key\": \"alt+-\", // or whatever keybinding you want\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": {\n            \"text\": \" &lt;- \"\n        },\n        \"when\": \"terminalFocus && !terminalTextSelected\"\n    },\n    {\n        \"key\": \"ctrl+shift+m\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"when\": \"terminalFocus && !terminalTextSelected\",\n        \"args\": {\n            \"text\": \" |&gt; \"\n        }\n    }\n]\n\n\nToning down code linting\ncreating a ~/.lintr file in the project folder\nlinters: with_defaults(\n  line_length_linter = NULL,\n  open_curly_linter = NULL, \n  object_usage_linter = NULL,\n  commented_code_linter = NULL,\n  object_name_linter = NULL,\n  object_length_lnter = NULL,\n  infix_spaces_linter = NULL,\n  commas_linter = NULL,\n  function_left_parentheses_linter = NULL,\n  trailing_whitespace_linter = NULL)\n\n\nReference\n\nQuick list of useful R packages\nManaging R with .Rprofile, .Renviron, Rprofile.site, Renviron.site, rsession.conf, and repos.conf\nMy Fully Remote Research Workflow in VS Code"
  },
  {
    "objectID": "blog/2022/12/24/index.html",
    "href": "blog/2022/12/24/index.html",
    "title": "Setup SSH to work in remote server",
    "section": "",
    "text": "The following setup will help to ogin to server without using password and IP address with SSH remote key\n\nAdd remote server host into lost hosts files\n\n\nMac: code /etc/hosts\nWindows: C:\\Windows\\System32\\drivers\\etc\\hosts\n\n### On the local machine: \n172.20.***.** nucleus.ccpa nucleus\n172.20.***.** lipid-droplets.ccpa lipid-droplets\n\nGenerate public key\n\n### \nlocal&gt; cd ~/.ssh\nlocal&gt; ssh-keygen -t ed25519\nlocal&gt; ls\nlocal&gt; cat id_ed25519.pub \n\nAdd the public key to remote server\n\n###  On the remote server\nremote&gt; cd ~/.ssh\nremote&gt; chown -R chase:users .ssh\nremote&gt; chmod 700 .ssh\nremote&gt; scp username@local://home/user/.ssh/id_ed25519.pub .ssh/authorized_keys\nremote&gt; chmod 644 .ssh/authorized_keys\n### For multiple machines, add the publick key to the authorized_keys in a new line\nlocal&gt; cat id_ed25519.pub"
  },
  {
    "objectID": "blog/2022/12/24/index.html#setup-ssh-remote-keys",
    "href": "blog/2022/12/24/index.html#setup-ssh-remote-keys",
    "title": "Setup SSH to work in remote server",
    "section": "",
    "text": "The following setup will help to ogin to server without using password and IP address with SSH remote key\n\nAdd remote server host into lost hosts files\n\n\nMac: code /etc/hosts\nWindows: C:\\Windows\\System32\\drivers\\etc\\hosts\n\n### On the local machine: \n172.20.***.** nucleus.ccpa nucleus\n172.20.***.** lipid-droplets.ccpa lipid-droplets\n\nGenerate public key\n\n### \nlocal&gt; cd ~/.ssh\nlocal&gt; ssh-keygen -t ed25519\nlocal&gt; ls\nlocal&gt; cat id_ed25519.pub \n\nAdd the public key to remote server\n\n###  On the remote server\nremote&gt; cd ~/.ssh\nremote&gt; chown -R chase:users .ssh\nremote&gt; chmod 700 .ssh\nremote&gt; scp username@local://home/user/.ssh/id_ed25519.pub .ssh/authorized_keys\nremote&gt; chmod 644 .ssh/authorized_keys\n### For multiple machines, add the publick key to the authorized_keys in a new line\nlocal&gt; cat id_ed25519.pub"
  },
  {
    "objectID": "blog/2022/12/24/index.html#make-bash-with-colors",
    "href": "blog/2022/12/24/index.html#make-bash-with-colors",
    "title": "Setup SSH to work in remote server",
    "section": "Make Bash with colors",
    "text": "Make Bash with colors\nIn the remote server, add the following script to the ~/.bashrc\nPS1='\\[\\033[1;36m\\]\\u\\[\\033[1;37m\\] @\\[\\033[1;32m\\] \\h:\\[\\033[1;33m\\] \\w\\[\\033[0;97m [\\t]\\[\\033[0;97m \\n\\[\\033[1;35m\\]\\$\\[\\033[0m\\] '"
  },
  {
    "objectID": "blog/2022/12/24/index.html#powerful-terminal",
    "href": "blog/2022/12/24/index.html#powerful-terminal",
    "title": "Setup SSH to work in remote server",
    "section": "Powerful Terminal",
    "text": "Powerful Terminal\n### Install [Home-brew](https://brew.sh/)\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n### Change default shell from bash to zsh\nchsh -s $(which zsh)\n\n### Install oh-my-zsh in the terminal\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n\n###  change default theme to ys\nopen ~/.zshrc\n\nZSH_THEME=\"ys\"\n\n### install oh-my-zsh plugins\ngit clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n\ngit clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\n\n### make oh-my-zsh plugins working\nvim ~/.zshrc\n### then add following \nplugins=(\n  git\n  zsh-autosuggestions\n  zsh-syntax-highlighting\n  colored-man-pages\n  colorize\n)\n### Make it working\nsource ~/.zshrc"
  },
  {
    "objectID": "blog/2022/12/24/index.html#mount-remote-files-on-mac",
    "href": "blog/2022/12/24/index.html#mount-remote-files-on-mac",
    "title": "Setup SSH to work in remote server",
    "section": "Mount remote files on mac",
    "text": "Mount remote files on mac\n\n\nInstall macFUSE and SSHFS: https://osxfuse.github.io/\nCreate mount directory in local\n\n$ mkdir ~/mount/mountpoint\n\nMount directory\n\nsshfs «user»@«host»: «mountpoint»\n\nUn-mounting the remote volume\n\n$ umount ~/mount/mountpoint"
  }
]